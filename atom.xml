<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Richard Xin&#39;s Blog</title>
  
  <subtitle>Quick notes</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.lichao.xin/"/>
  <updated>2021-06-14T01:33:22.391Z</updated>
  <id>https://blog.lichao.xin/</id>
  
  <author>
    <name>Richard</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>重学 K8s 之 Kubernetes 集群搭建与实践</title>
    <link href="https://blog.lichao.xin/back-end/k8s/k8s-02/"/>
    <id>https://blog.lichao.xin/back-end/k8s/k8s-02/</id>
    <published>2021-05-05T15:10:00.000Z</published>
    <updated>2021-06-14T01:33:22.391Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes 集群搭建与实践、深入解析Pod对象。</p><a id="more"></a><h2 id="Kubernetes一键部署利器：kubeadm"><a href="#Kubernetes一键部署利器：kubeadm" class="headerlink" title="Kubernetes一键部署利器：kubeadm"></a>Kubernetes一键部署利器：kubeadm</h2><p>通过前面的内容，我其实阐述了这样一个思想：<strong>要真正发挥容器技术的实力，你就不能仅仅局限于对 Linux 容器本身的钻研和使用。</strong></p><p>这些知识更适合作为你的技术储备，以便在需要的时候可以帮你更快的定位问题，并解决问题。</p><p>而更深入的学习容器技术的关键在于，<strong>如何使用这些技术来“容器化”你的应用。</strong></p><p>比如，我们的应用既可能是 Java Web 和 MySQL 这样的组合，也可能是 Cassandra 这样的分布式系统。而要使用容器把后者运行起来，你单单通过 Docker 把一个 Cassandra 镜像跑起来是没用的。</p><p>要把 Cassandra 应用容器化的关键，在于如何处理好这些 Cassandra 容器之间的编排关系。比如，哪些 Cassandra 容器是主，哪些是从？主从容器如何区分？它们之间又如何进行自动发现和通信？Cassandra 容器的持久化数据又如何保持，等等。</p><p>这也是为什么我们要反复强调 Kubernetes 项目的主要原因：这个项目体现出来的容器化“表达能力”，具有独有的先进性和完备性。这就使得它不仅能运行 Java Web 与 MySQL 这样的常规组合，还能够处理 Cassandra 容器集群等复杂编排问题。所以，对这种编排能力的剖析、解读和最佳实践，将是本专栏最重要的一部分内容。</p><p>不过，万事开头难。</p><p>作为一个典型的分布式项目，Kubernetes 的部署一直以来都是挡在初学者前面的一只“拦路虎”。尤其是在 Kubernetes 项目发布初期，它的部署完全要依靠一堆由社区维护的脚本。</p><p>其实，Kubernetes 作为一个 Golang 项目，已经免去了很多类似于 Python 项目要安装语言级别依赖的麻烦。但是，除了将各个组件编译成二进制文件外，用户还要负责为这些二进制文件编写对应的配置文件、配置自启动脚本，以及为 kube-apiserver 配置授权文件等等诸多运维工作。</p><p>目前，各大云厂商最常用的部署的方法，是使用 SaltStack、Ansible 等运维工具自动化地执行这些步骤。</p><p>但即使这样，这个部署过程依然非常繁琐。因为，SaltStack 这类专业运维工具本身的学习成本，就可能比 Kubernetes 项目还要高。</p><p><strong>难道 Kubernetes 项目就没有简单的部署方法了吗？</strong></p><p>这个问题，在 Kubernetes 社区里一直没有得到足够重视。直到 2017 年，在志愿者的推动下，社区才终于发起了一个独立的部署工具，名叫：<a href="https://github.com/kubernetes/kubeadm" target="_blank" rel="noopener">kubeadm</a>。</p><blockquote><p><a href="/back-end/k8s/k8s-installation-kubeadm">Kubeadm 部署 Kubernetes</a></p></blockquote><p>这个项目的目的，就是要让用户能够通过这样两条指令完成一个 Kubernetes 集群的部署：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个 Master 节点</span></span><br><span class="line">$ kubeadm init</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将一个 Node 节点加入到当前集群中</span></span><br><span class="line">$ kubeadm join &lt;Master 节点的 IP 和端口 &gt;</span><br></pre></td></tr></table></figure><p>是不是非常方便呢？</p><p>不过，你可能也会有所顾虑：<strong>Kubernetes 的功能那么多，这样一键部署出来的集群，能用于生产环境吗？</strong></p><p>为了回答这个问题，在今天这篇文章，我就先和你介绍一下 kubeadm 的工作原理吧。</p><h3 id="kubeadm-的工作原理"><a href="#kubeadm-的工作原理" class="headerlink" title="kubeadm 的工作原理"></a>kubeadm 的工作原理</h3><p>在上一篇文章《从容器到容器云：谈谈 Kubernetes 的本质》中，我已经详细介绍了 Kubernetes 的架构和它的组件。在部署时，它的每一个组件都是一个需要被执行的、单独的二进制文件。所以不难想象，SaltStack 这样的运维工具或者由社区维护的脚本的功能，就是要把这些二进制文件传输到指定的机器当中，然后编写控制脚本来启停这些组件。</p><p>不过，在理解了容器技术之后，你可能已经萌生出了这样一个想法，<strong>为什么不用容器部署 Kubernetes 呢？</strong></p><p>这样，我只要给每个 Kubernetes 组件做一个容器镜像，然后在每台宿主机上用 docker run 指令启动这些组件容器，部署不就完成了吗？</p><p>事实上，在 Kubernetes 早期的部署脚本里，确实有一个脚本就是用 Docker 部署 Kubernetes 项目的，这个脚本相比于 SaltStack 等的部署方式，也的确简单了不少。</p><p>但是，<strong>这样做会带来一个很麻烦的问题，即：如何容器化 kubelet。</strong></p><p>我在上一篇文章中，已经提到 kubelet 是 Kubernetes 项目用来操作 Docker 等容器运行时的核心组件。可是，除了跟容器运行时打交道外，kubelet 在配置容器网络、管理容器数据卷时，都需要直接操作宿主机。</p><p>而如果现在 kubelet 本身就运行在一个容器里，那么直接操作宿主机就会变得很麻烦。对于网络配置来说还好，kubelet 容器可以通过不开启 Network Namespace（即 Docker 的 host network 模式）的方式，直接共享宿主机的网络栈。可是，要让 kubelet 隔着容器的 Mount Namespace 和文件系统，操作宿主机的文件系统，就有点儿困难了。</p><p>比如，如果用户想要使用 NFS 做容器的持久化数据卷，那么 kubelet 就需要在容器进行绑定挂载前，在宿主机的指定目录上，先挂载 NFS 的远程目录。</p><p>可是，这时候问题来了。由于现在 kubelet 是运行在容器里的，这就意味着它要做的这个“mount -F nfs”命令，被隔离在了一个单独的 Mount Namespace 中。即，kubelet 做的挂载操作，不能被“传播”到宿主机上。</p><p>对于这个问题，有人说，可以使用 setns() 系统调用，在宿主机的 Mount Namespace 中执行这些挂载操作；也有人说，应该让 Docker 支持一个–mnt=host 的参数。</p><p>但是，到目前为止，在容器里运行 kubelet，依然没有很好的解决办法，我也不推荐你用容器去部署 Kubernetes 项目。</p><p>正因为如此，kubeadm 选择了一种妥协方案：</p><blockquote><p>把 kubelet 直接运行在宿主机上，然后使用容器部署其他的 Kubernetes 组件。</p></blockquote><p>所以，你使用 kubeadm 的第一步，是在机器上手动安装 kubeadm、kubelet 和 kubectl 这三个二进制文件。当然，kubeadm 的作者已经为各个发行版的 Linux 准备好了安装包，所以你只需要执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ apt-get install kubeadm</span><br></pre></td></tr></table></figure><p>就可以了。</p><p>接下来，你就可以使用“kubeadm init”部署 Master 节点了。</p><h3 id="kubeadm-init-的工作流程"><a href="#kubeadm-init-的工作流程" class="headerlink" title="kubeadm init 的工作流程"></a>kubeadm init 的工作流程</h3><p>当你执行 kubeadm init 指令后，<strong>kubeadm 首先要做的，是一系列的检查工作，以确定这台机器可以用来部署 Kubernetes</strong>。这一步检查，我们称为“Preflight Checks”，它可以为你省掉很多后续的麻烦。</p><p>其实，Preflight Checks 包括了很多方面，比如：</p><ul><li>Linux 内核的版本必须是否是 3.10 以上？</li><li>Linux Cgroups 模块是否可用？</li><li>机器的 hostname 是否标准？在 Kubernetes 项目里，机器的名字以及一切存储在 Etcd 中的 API 对象，都必须使用标准的 DNS 命名（RFC 1123）。</li><li>用户安装的 kubeadm 和 kubelet 的版本是否匹配？</li><li>机器上是不是已经安装了 Kubernetes 的二进制文件？</li><li>Kubernetes 的工作端口 10250/10251/10252 端口是不是已经被占用？</li><li>ip、mount 等 Linux 指令是否存在？</li><li>Docker 是否已经安装？</li><li>……</li></ul><p><strong>在通过了 Preflight Checks 之后，kubeadm 要为你做的，是生成 Kubernetes 对外提供服务所需的各种证书和对应的目录。</strong></p><p>Kubernetes 对外提供服务时，除非专门开启“不安全模式”，否则都要通过 HTTPS 才能访问 kube-apiserver。这就需要为 Kubernetes 集群配置好证书文件。</p><p>kubeadm 为 Kubernetes 项目生成的证书文件都放在 Master 节点的 /etc/kubernetes/pki 目录下。在这个目录下，最主要的证书文件是 ca.crt 和对应的私钥 ca.key。</p><p>此外，用户使用 kubectl 获取容器日志等 streaming 操作时，需要通过 kube-apiserver 向 kubelet 发起请求，这个连接也必须是安全的。kubeadm 为这一步生成的是 apiserver-kubelet-client.crt 文件，对应的私钥是 apiserver-kubelet-client.key。</p><p>除此之外，Kubernetes 集群中还有 Aggregate APIServer 等特性，也需要用到专门的证书，这里我就不再一一列举了。需要指出的是，你可以选择不让 kubeadm 为你生成这些证书，而是拷贝现有的证书到如下证书的目录里：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/kubernetes/pki/ca.&#123;crt,key&#125;</span><br></pre></td></tr></table></figure><p>这时，kubeadm 就会跳过证书生成的步骤，把它完全交给用户处理。</p><p><strong>证书生成后，kubeadm 接下来会为其他组件生成访问 kube-apiserver 所需的配置文件</strong>。这些文件的路径是：/etc/kubernetes/xxx.conf：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls /etc/kubernetes/</span><br><span class="line">admin.conf  controller-manager.conf  kubelet.conf  scheduler.conf</span><br></pre></td></tr></table></figure><p>这些文件里面记录的是，当前这个 Master 节点的服务器地址、监听端口、证书目录等信息。这样，对应的客户端（比如 scheduler，kubelet 等），可以直接加载相应的文件，使用里面的信息与 kube-apiserver 建立安全连接。</p><p><strong>接下来，kubeadm 会为 Master 组件生成 Pod 配置文件</strong>。我已经在上一篇文章中和你介绍过 Kubernetes 有三个 Master 组件 kube-apiserver、kube-controller-manager、kube-scheduler，而它们都会被使用 Pod 的方式部署起来。</p><p>你可能会有些疑问：这时，Kubernetes 集群尚不存在，难道 kubeadm 会直接执行 docker run 来启动这些容器吗？</p><p>当然不是。</p><p>在 Kubernetes 中，有一种特殊的容器启动方法叫做“Static Pod”。它允许你把要部署的 Pod 的 YAML 文件放在一个指定的目录里。这样，当这台机器上的 kubelet 启动时，它会自动检查这个目录，加载所有的 Pod YAML 文件，然后在这台机器上启动它们。</p><p>从这一点也可以看出，kubelet 在 Kubernetes 项目中的地位非常高，在设计上它就是一个完全独立的组件，而其他 Master 组件，则更像是辅助性的系统容器。</p><p>在 kubeadm 中，Master 组件的 YAML 文件会被生成在 /etc/kubernetes/manifests 路径下。比如，kube-apiserver.yaml：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">scheduler.alpha.kubernetes.io/critical-pod:</span> <span class="string">""</span></span><br><span class="line">  <span class="attr">creationTimestamp:</span> <span class="literal">null</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">component:</span> <span class="string">kube-apiserver</span></span><br><span class="line">    <span class="attr">tier:</span> <span class="string">control-plane</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kube-apiserver</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">command:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">kube-apiserver</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">--authorization-mode=Node,RBAC</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">--runtime-config=api/all=true</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">--advertise-address=10.168.0.2</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">--tls-cert-file=/etc/kubernetes/pki/apiserver.crt</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">--tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">k8s.gcr.io/kube-apiserver-amd64:v1.11.1</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="string">...</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">kube-apiserver</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">250m</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/usr/share/ca-certificates</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">usr-share-ca-certificates</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">priorityClassName:</span> <span class="string">system-cluster-critical</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/etc/ca-certificates</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">DirectoryOrCreate</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">etc-ca-certificates</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure><p>关于一个 Pod 的 YAML 文件怎么写、里面的字段如何解读，我会在后续专门的文章中为你详细分析。在这里，你只需要关注这样几个信息：</p><ol><li>这个 Pod 里只定义了一个容器，它使用的镜像是：<code>k8s.gcr.io/kube-apiserver-amd64:v1.11.1</code> 。这个镜像是 Kubernetes 官方维护的一个组件镜像。</li><li>这个容器的启动命令（commands）是 kube-apiserver –authorization-mode=Node,RBAC …，这样一句非常长的命令。其实，它就是容器里 kube-apiserver 这个二进制文件再加上指定的配置参数而已。</li><li>如果你要修改一个已有集群的 kube-apiserver 的配置，需要修改这个 YAML 文件。</li><li>这些组件的参数也可以在部署时指定，我很快就会讲解到。</li></ol><p>在这一步完成后，kubeadm 还会再生成一个 Etcd 的 Pod YAML 文件，用来通过同样的 Static Pod 的方式启动 Etcd。所以，最后 Master 组件的 Pod YAML 文件如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /etc/kubernetes/manifests/</span><br><span class="line">etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml</span><br></pre></td></tr></table></figure><p>而一旦这些 YAML 文件出现在被 kubelet 监视的 /etc/kubernetes/manifests 目录下，kubelet 就会自动创建这些 YAML 文件中定义的 Pod，即 Master 组件的容器。</p><p>Master 容器启动后，kubeadm 会通过检查 localhost:6443/healthz 这个 Master 组件的健康检查 URL，等待 Master 组件完全运行起来。</p><p><strong>然后，kubeadm 就会为集群生成一个 bootstrap token</strong>。在后面，只要持有这个 token，任何一个安装了 kubelet 和 kubadm 的节点，都可以通过 kubeadm join 加入到这个集群当中。</p><p>这个 token 的值和使用方法会，会在 kubeadm init 结束后被打印出来。</p><p><strong>在 token 生成之后，kubeadm 会将 ca.crt 等 Master 节点的重要信息，通过 ConfigMap 的方式保存在 Etcd 当中，供后续部署 Node 节点使用</strong>。这个 ConfigMap 的名字是 cluster-info。</p><p><strong>kubeadm init 的最后一步，就是安装默认插件</strong>。Kubernetes 默认 kube-proxy 和 DNS 这两个插件是必须安装的。它们分别用来提供整个集群的服务发现和 DNS 功能。其实，这两个插件也只是两个容器镜像而已，所以 kubeadm 只要用 Kubernetes 客户端创建两个 Pod 就可以了。</p><h3 id="kubeadm-join-的工作流程"><a href="#kubeadm-join-的工作流程" class="headerlink" title="kubeadm join 的工作流程"></a>kubeadm join 的工作流程</h3><p>这个流程其实非常简单，kubeadm init 生成 bootstrap token 之后，你就可以在任意一台安装了 kubelet 和 kubeadm 的机器上执行 kubeadm join 了。</p><p>可是，为什么执行 kubeadm join 需要这样一个 token 呢？</p><p>因为，任何一台机器想要成为 Kubernetes 集群中的一个节点，就必须在集群的 kube-apiserver 上注册。可是，要想跟 apiserver 打交道，这台机器就必须要获取到相应的证书文件（CA 文件）。可是，为了能够一键安装，我们就不能让用户去 Master 节点上手动拷贝这些文件。</p><p>所以，kubeadm 至少需要发起一次“不安全模式”的访问到 kube-apiserver，从而拿到保存在 ConfigMap 中的 cluster-info（它保存了 APIServer 的授权信息）。而 bootstrap token，扮演的就是这个过程中的安全验证的角色。</p><p>只要有了 cluster-info 里的 kube-apiserver 的地址、端口、证书，kubelet 就可以以“安全模式”连接到 apiserver 上，这样一个新的节点就部署完成了。</p><p>接下来，你只要在其他节点上重复这个指令就可以了。</p><h3 id="配置-kubeadm-的部署参数"><a href="#配置-kubeadm-的部署参数" class="headerlink" title="配置 kubeadm 的部署参数"></a>配置 kubeadm 的部署参数</h3><p>我在前面讲解了 kubeadm 部署 Kubernetes 集群最关键的两个步骤，kubeadm init 和 kubeadm join。相信你一定会有这样的疑问：kubeadm 确实简单易用，可是我又该如何定制我的集群组件参数呢？</p><p>比如，我要指定 kube-apiserver 的启动参数，该怎么办？</p><p>在这里，我强烈推荐你在使用 kubeadm init 部署 Master 节点时，使用下面这条指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm init --config kubeadm.yaml</span><br></pre></td></tr></table></figure><p>这时，你就可以给 kubeadm 提供一个 YAML 文件（比如，kubeadm.yaml），它的内容如下所示（我仅列举了主要部分）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1alpha2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">MasterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">v1.11.0</span></span><br><span class="line"><span class="attr">api:</span></span><br><span class="line">  <span class="attr">advertiseAddress:</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.102</span></span><br><span class="line">  <span class="attr">bindPort:</span> <span class="number">6443</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">etcd:</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">dataDir:</span> <span class="string">/var/lib/etcd</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">k8s.gcr.io</span></span><br><span class="line"><span class="attr">kubeProxy:</span></span><br><span class="line">  <span class="attr">config:</span></span><br><span class="line">    <span class="attr">bindAddress:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line"><span class="attr">kubeletConfiguration:</span></span><br><span class="line">  <span class="attr">baseConfig:</span></span><br><span class="line">    <span class="attr">address:</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">    <span class="string">...</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line">  <span class="attr">dnsDomain:</span> <span class="string">cluster.local</span></span><br><span class="line">  <span class="attr">podSubnet:</span> <span class="string">""</span></span><br><span class="line">  <span class="attr">serviceSubnet:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span></span><br><span class="line"><span class="attr">nodeRegistration:</span></span><br><span class="line">  <span class="attr">criSocket:</span> <span class="string">/var/run/dockershim.sock</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure><p>通过制定这样一个部署参数配置文件，你就可以很方便地在这个文件里填写各种自定义的部署参数了。比如，我现在要指定 kube-apiserver 的参数，那么我只要在这个文件里加上这样一段信息：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">apiServerExtraArgs:</span></span><br><span class="line">  <span class="attr">advertise-address:</span> <span class="number">192.168</span><span class="number">.0</span><span class="number">.103</span></span><br><span class="line">  <span class="attr">anonymous-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">enable-admission-plugins:</span> <span class="string">AlwaysPullImages,DefaultStorageClass</span></span><br><span class="line">  <span class="attr">audit-log-path:</span> <span class="string">/home/johndoe/audit.log</span></span><br></pre></td></tr></table></figure><p>然后，kubeadm 就会使用上面这些信息替换 /etc/kubernetes/manifests/kube-apiserver.yaml 里的 command 字段里的参数了。</p><p>而这个 YAML 文件提供的可配置项远不止这些。比如，你还可以修改 kubelet 和 kube-proxy 的配置，修改 Kubernetes 使用的基础镜像的 URL（默认的k8s.gcr.io/xxx镜像 URL 在国内访问是有困难的），指定自己的证书文件，指定特殊的容器运行时等等。这些配置项，就留给你在后续实践中探索了。</p><p><strong>小结</strong></p><p>在今天的这次分享中，我重点介绍了 kubeadm 这个部署工具的工作原理和使用方法。紧接着，我会在后面，使用它一步步地部署一个完整的 Kubernetes 集群。</p><p>从今天的分享中，你可以看到，kubeadm 的设计非常简洁。并且，它在实现每一步部署功能时，都在最大程度地重用 Kubernetes 已有的功能，这也就使得我们在使用 kubeadm 部署 Kubernetes 项目时，非常有“原生”的感觉，一点都不会感到突兀。</p><p>而 kubeadm 的源代码，直接就在 kubernetes/cmd/kubeadm 目录下，是 Kubernetes 项目的一部分。其中，app/phases 文件夹下的代码，对应的就是我在这篇文章中详细介绍的每一个具体步骤。</p><p>看到这里，你可能会猜想，kubeadm 的作者一定是 Google 公司的某个“大神”吧。</p><p>实际上，kubeadm 几乎完全是一位高中生的作品。他叫 Lucas Käldström，芬兰人，今年只有 18 岁。kubeadm，是他 17 岁时用业余时间完成的一个社区项目。</p><p>所以说，开源社区的魅力也在于此：一个成功的开源项目，总能够吸引到全世界最厉害的贡献者参与其中。尽管参与者的总体水平参差不齐，而且频繁的开源活动又显得杂乱无章难以管控，但一个有足够热度的社区最终的收敛方向，却一定是代码越来越完善、Bug 越来越少、功能越来越强大。</p><!-- 最后，我再来回答一下我在今天这次分享开始提到的问题：kubeadm 能够用于生产环境吗？到目前为止（2018 年 9 月），这个问题的答案是：不能。·因为 kubeadm 目前最欠缺的是，一键部署一个高可用的 Kubernetes 集群，即：Etcd、Master 组件都应该是多节点集群，而不是现在这样的单点。这，当然也正是 kubeadm 接下来发展的主要方向。另一方面，Lucas 也正在积极地把 kubeadm phases 开放给用户，即：用户可以更加自由地定制 kubeadm 的每一个部署步骤。这些举措，都可以让这个项目更加完善，我对它的发展走向也充满了信心。当然，如果你有部署规模化生产环境的需求，我推荐使用[kops](https://github.com/kubernetes/kops)或者 SaltStack 这样更复杂的部署工具。但，在本专栏接下来的讲解中，我都会以 kubeadm 为依据进行讲述。 --><ul><li>一方面，作为 Kubernetes 项目的原生部署工具，kubeadm 对 Kubernetes 项目特性的使用和集成，确实要比其他项目“技高一筹”，非常值得我们学习和借鉴；</li><li>另一方面，kubeadm 的部署方法，不会涉及到太多的运维工作，也不需要我们额外学习复杂的部署工具。而它部署的 Kubernetes 集群，跟一个完全使用二进制文件搭建起来的集群几乎没有任何区别。</li></ul><p>因此，使用 kubeadm 去部署一个 Kubernetes 集群，对于你理解 Kubernetes 组件的工作方式和架构，最好不过了。</p><h2 id="从0到1：搭建一个完整的Kubernetes集群"><a href="#从0到1：搭建一个完整的Kubernetes集群" class="headerlink" title="从0到1：搭建一个完整的Kubernetes集群"></a>从0到1：搭建一个完整的Kubernetes集群</h2><p>在前面，我介绍了 kubeadm 这个 Kubernetes 半官方管理工具的工作原理。既然 kubeadm 的初衷是让 Kubernetes 集群的部署不再让人头疼，那么这篇文章，我们就来使用它部署一个完整的 Kubernetes 集群吧。</p><blockquote><p>备注：这里所说的“完整”，指的是这个集群具备 Kubernetes 项目在 GitHub 上已经发布的所有功能，并能够模拟生产环境的所有使用需求。但并不代表这个集群是生产级别可用的：类似于高可用、授权、多租户、灾难备份等生产级别集群的功能暂时不在本篇文章的讨论范围。<br>目前，kubeadm 的高可用部署<a href="https://kubernetes.io/docs/setup/independent/high-availability/" target="_blank" rel="noopener">已经有了第一个发布</a>。</p></blockquote><p>这次部署，我不会依赖于任何公有云或私有云的能力，而是完全在 Bare-metal 环境中完成。这样的部署经验会更有普适性。而在后续的讲解中，如非特殊强调，我也都会以本次搭建的这个集群为基础。</p><blockquote><p>该专栏版搭建的版本较老(我这里只想跟着张磊大神的步骤完全走下来），建议参考我之前的文章 <a href="/back-end/k8s/k8s-installation-kubeadm">Kubeadm 部署 Kubernetes</a></p></blockquote><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><p>首先，准备机器。最直接的办法，自然是到公有云上申请几个虚拟机。当然，如果条件允许的话，拿几台本地的物理服务器来组集群是最好不过了。这些机器只要满足如下几个条件即可：</p><ol><li>满足安装 Docker 项目所需的要求，比如 64 位的 Linux 操作系统、3.10 及以上的内核版本；</li><li>x86 或者 ARM 架构均可；</li><li>机器之间网络互通，这是将来容器之间网络互通的前提；</li><li>有外网访问权限，因为需要拉取镜像；</li><li>能够访问到<code>gcr.io、quay.io</code>这两个 docker registry，因为有小部分镜像需要在这里拉取；</li><li>单机可用资源建议 2 核 CPU、8 GB 内存或以上，再小的话问题也不大，但是能调度的 Pod 数量就比较有限了；</li><li>30 GB 或以上的可用磁盘空间，这主要是留给 Docker 镜像和日志文件用的。</li></ol><p>在本次部署中，我准备的机器配置如下：</p><ol><li>2 核 CPU、 7.5 GB 内存；</li><li>30 GB 磁盘；</li><li>Ubuntu 16.04；</li><li>内网互通；</li><li>外网访问权限不受限制。</li></ol><blockquote><p>备注：在开始部署前，我推荐你先花几分钟时间，回忆一下 Kubernetes 的架构。</p></blockquote><p>然后，我再和你介绍一下今天实践的目标：</p><ol><li>在所有节点上安装 Docker 和 kubeadm；</li><li>部署 Kubernetes Master；</li><li>部署容器网络插件；</li><li>部署 Kubernetes Worker；</li><li>部署 Dashboard 可视化插件；</li><li>部署容器存储插件。</li></ol><p>好了，现在，就来开始这次集群部署之旅吧！</p><h3 id="安装-kubeadm-和-Docker"><a href="#安装-kubeadm-和-Docker" class="headerlink" title="安装 kubeadm 和 Docker"></a>安装 kubeadm 和 Docker</h3><p>我在前面《 Kubernetes 一键部署利器：kubeadm》中，已经介绍过 kubeadm 的基础用法，它的一键安装非常方便，我们只需要添加 kubeadm 的源，然后直接使用 apt-get 安装即可，具体流程如下所示：</p><blockquote><p>备注：为了方便讲解，我后续都直接会在 root 用户下进行操作</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line">$ cat &lt;&lt;EOF &gt; /etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb http://apt.kubernetes.io/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">$ apt-get update</span><br><span class="line">$ apt-get install -y docker.io kubeadm</span><br></pre></td></tr></table></figure><p>在上述安装 kubeadm 的过程中，kubeadm 和 kubelet、kubectl、kubernetes-cni 这几个二进制文件都会被自动安装好。</p><p>另外，这里我直接使用 Ubuntu 的 docker.io 的安装源，原因是 Docker 公司每次发布的最新的 Docker CE（社区版）产品往往还没有经过 Kubernetes 项目的验证，可能会有兼容性方面的问题。</p><h3 id="部署-Kubernetes-的-Master-节点"><a href="#部署-Kubernetes-的-Master-节点" class="headerlink" title="部署 Kubernetes 的 Master 节点"></a>部署 Kubernetes 的 Master 节点</h3><p>在前面，我已经介绍过 kubeadm 可以一键部署 Master 节点。不过，在本篇文章中既然要部署一个“完整”的 Kubernetes 集群，那我们不妨稍微提高一下难度：通过配置文件来开启一些实验性功能。</p><p>所以，这里我编写了一个给 kubeadm 用的 YAML 文件（名叫：kubeadm.yaml）：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">MasterConfiguration</span></span><br><span class="line"><span class="attr">controllerManagerExtraArgs:</span></span><br><span class="line">  <span class="attr">horizontal-pod-autoscaler-use-rest-clients:</span> <span class="string">"true"</span></span><br><span class="line">  <span class="attr">horizontal-pod-autoscaler-sync-period:</span> <span class="string">"10s"</span></span><br><span class="line">  <span class="attr">node-monitor-grace-period:</span> <span class="string">"10s"</span></span><br><span class="line"><span class="attr">apiServerExtraArgs:</span></span><br><span class="line">  <span class="attr">runtime-config:</span> <span class="string">"api/all=true"</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="string">"stable-1.11"</span></span><br></pre></td></tr></table></figure><p>这个配置中，我给 kube-controller-manager 设置了：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">horizontal-pod-autoscaler-use-rest-clients:</span> <span class="string">"true"</span></span><br></pre></td></tr></table></figure><p>这意味着，将来部署的 kube-controller-manager 能够使用自定义资源（Custom Metrics）进行自动水平扩展。这是我后面文章中会重点介绍的一个内容。</p><p>其中，“stable-1.11”就是 kubeadm 帮我们部署的 Kubernetes 版本号，即：Kubernetes release 1.11 最新的稳定版，在我的环境下，它是 v1.11.1。你也可以直接指定这个版本，比如：kubernetesVersion: “v1.11.1”。</p><p>然后，我们只需要执行一句指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm init --config kubeadm.yaml</span><br></pre></td></tr></table></figure><p>就可以完成 Kubernetes Master 的部署了，这个过程只需要几分钟。部署完成后，kubeadm 会生成一行指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 10.168.0.2:6443 --token 00bwbx.uvnaa2ewjflwu1ry --discovery-token-ca-cert-hash sha256:00eb62a2a6020f94132e3fe1ab721349bbcd3e9b94da9654cfe15f2985ebd711</span><br></pre></td></tr></table></figure><p>这个 kubeadm join 命令，就是用来给这个 Master 节点添加更多工作节点（Worker）的命令。我们在后面部署 Worker 节点的时候马上会用到它，所以找一个地方把这条命令记录下来。</p><p>此外，kubeadm 还会提示我们第一次使用 Kubernetes 集群所需要的配置命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>而需要这些配置命令的原因是：Kubernetes 集群默认需要加密方式访问。所以，这几条命令，就是将刚刚部署生成的 Kubernetes 集群的安全配置文件，保存到当前用户的.kube 目录下，kubectl 默认会使用这个目录下的授权信息访问 Kubernetes 集群。</p><p>如果不这么做的话，我们每次都需要通过 export KUBECONFIG 环境变量告诉 kubectl 这个安全配置文件的位置。</p><p>现在，我们就可以使用 kubectl get 命令来查看当前唯一一个节点的状态了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get nodes</span><br><span class="line"> </span><br><span class="line">NAME      STATUS     ROLES     AGE       VERSION</span><br><span class="line">master    NotReady   master    1d        v1.11.1</span><br></pre></td></tr></table></figure><p>可以看到，这个 get 指令输出的结果里，Master 节点的状态是 NotReady，这是为什么呢？</p><p>在调试 Kubernetes 集群时，最重要的手段就是用 kubectl describe 来查看这个节点（Node）对象的详细信息、状态和事件（Event），我们来试一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe node master</span><br><span class="line"> </span><br><span class="line">...</span><br><span class="line">Conditions:</span><br><span class="line">...</span><br><span class="line"> </span><br><span class="line">Ready   False ... KubeletNotReady  runtime network not ready: NetworkReady=<span class="literal">false</span> reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br></pre></td></tr></table></figure><p>通过 kubectl describe 指令的输出，我们可以看到 NodeNotReady 的原因在于，我们尚未部署任何网络插件。</p><p>另外，我们还可以通过 kubectl 检查这个节点上各个系统 Pod 的状态，其中，kube-system 是 Kubernetes 项目预留的系统 Pod 的工作空间（Namepsace，注意它并不是 Linux Namespace，它只是 Kubernetes 划分不同工作空间的单位）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-system</span><br><span class="line"> </span><br><span class="line">NAME               READY   STATUS   RESTARTS  AGE</span><br><span class="line">coredns-78fcdf6894-j9s52     0/1    Pending  0     1h</span><br><span class="line">coredns-78fcdf6894-jm4wf     0/1    Pending  0     1h</span><br><span class="line">etcd-master           1/1    Running  0     2s</span><br><span class="line">kube-apiserver-master      1/1    Running  0     1s</span><br><span class="line">kube-controller-manager-master  0/1    Pending  0     1s</span><br><span class="line">kube-proxy-xbd47         1/1    NodeLost  0     1h</span><br><span class="line">kube-scheduler-master      1/1    Running  0     1s</span><br></pre></td></tr></table></figure><p>可以看到，CoreDNS、kube-controller-manager 等依赖于网络的 Pod 都处于 Pending 状态，即调度失败。这当然是符合预期的：因为这个 Master 节点的网络尚未就绪。</p><h3 id="部署网络插件"><a href="#部署网络插件" class="headerlink" title="部署网络插件"></a>部署网络插件</h3><p>在 Kubernetes 项目“一切皆容器”的设计理念指导下，部署网络插件非常简单，只需要执行一句 kubectl apply 指令，以 Weave 为例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f https://git.io/weave-kube-1.6</span><br></pre></td></tr></table></figure><p>部署完成后，我们可以通过 kubectl get 重新检查 Pod 的状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-system</span><br><span class="line"> </span><br><span class="line">NAME                             READY     STATUS    RESTARTS   AGE</span><br><span class="line">coredns-78fcdf6894-j9s52         1/1       Running   0          1d</span><br><span class="line">coredns-78fcdf6894-jm4wf         1/1       Running   0          1d</span><br><span class="line">etcd-master                      1/1       Running   0          9s</span><br><span class="line">kube-apiserver-master            1/1       Running   0          9s</span><br><span class="line">kube-controller-manager-master   1/1       Running   0          9s</span><br><span class="line">kube-proxy-xbd47                 1/1       Running   0          1d</span><br><span class="line">kube-scheduler-master            1/1       Running   0          9s</span><br><span class="line">weave-net-cmk27                  2/2       Running   0          19s</span><br></pre></td></tr></table></figure><p>可以看到，所有的系统 Pod 都成功启动了，而刚刚部署的 Weave 网络插件则在 kube-system 下面新建了一个名叫 weave-net-cmk27 的 Pod，一般来说，这些 Pod 就是容器网络插件在每个节点上的控制组件。</p><p>Kubernetes 支持容器网络插件，使用的是一个名叫 CNI 的通用接口，它也是当前容器网络的事实标准，市面上的所有容器网络开源项目都可以通过 CNI 接入 Kubernetes，比如 Flannel、Calico、Canal、Romana 等等，它们的部署方式也都是类似的“一键部署”。关于这些开源项目的实现细节和差异，我会在后续的网络部分详细介绍。</p><p>至此，Kubernetes 的 Master 节点就部署完成了。如果你只需要一个单节点的 Kubernetes，现在你就可以使用了。不过，在默认情况下，Kubernetes 的 Master 节点是不能运行用户 Pod 的，所以还需要额外做一个小操作。在本篇的最后部分，我会介绍到它。</p><h3 id="部署-Kubernetes-的-Worker-节点"><a href="#部署-Kubernetes-的-Worker-节点" class="headerlink" title="部署 Kubernetes 的 Worker 节点"></a>部署 Kubernetes 的 Worker 节点</h3><p>Kubernetes 的 Worker 节点跟 Master 节点几乎是相同的，它们运行着的都是一个 kubelet 组件。唯一的区别在于，在 kubeadm init 的过程中，kubelet 启动后，Master 节点上还会自动运行 kube-apiserver、kube-scheduler、kube-controller-manger 这三个系统 Pod。</p><p>所以，相比之下，部署 Worker 节点反而是最简单的，只需要两步即可完成。</p><p>第一步，在所有 Worker 节点上执行“安装 kubeadm 和 Docker”一节的所有步骤。</p><p>第二步，执行部署 Master 节点时生成的 kubeadm join 指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm join 10.168.0.2:6443 --token 00bwbx.uvnaa2ewjflwu1ry --discovery-token-ca-cert-hash sha256:00eb62a2a6020f94132e3fe1ab721349bbcd3e9b94da9654cfe15f2985ebd711</span><br></pre></td></tr></table></figure><h3 id="通过-Taint-Toleration-调整-Master-执行-Pod-的策略"><a href="#通过-Taint-Toleration-调整-Master-执行-Pod-的策略" class="headerlink" title="通过 Taint/Toleration 调整 Master 执行 Pod 的策略"></a>通过 Taint/Toleration 调整 Master 执行 Pod 的策略</h3><p>我在前面提到过，默认情况下 Master 节点是不允许运行用户 Pod 的。而 Kubernetes 做到这一点，依靠的是 Kubernetes 的 Taint/Toleration 机制。</p><p>它的原理非常简单：一旦某个节点被加上了一个 Taint，即被“打上了污点”，那么所有 Pod 就都不能在这个节点上运行，因为 Kubernetes 的 Pod 都有“洁癖”。</p><p>除非，有个别的 Pod 声明自己能“容忍”这个“污点”，即声明了 Toleration，它才可以在这个节点上运行。</p><p>其中，为节点打上“污点”（Taint）的命令是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl taint nodes node1 foo=bar:NoSchedule</span><br></pre></td></tr></table></figure><p>这时，该 node1 节点上就会增加一个键值对格式的 Taint，即：foo=bar:NoSchedule。其中值里面的 NoSchedule，意味着这个 Taint 只会在调度新 Pod 时产生作用，而不会影响已经在 node1 上运行的 Pod，哪怕它们没有 Toleration。</p><p>那么 Pod 又如何声明 Toleration 呢？</p><p>我们只要在 Pod 的.yaml 文件中的 spec 部分，加入 tolerations 字段即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">...</span><br><span class="line">spec:</span><br><span class="line">  tolerations:</span><br><span class="line">  - key: <span class="string">"foo"</span></span><br><span class="line">    operator: <span class="string">"Equal"</span></span><br><span class="line">    value: <span class="string">"bar"</span></span><br><span class="line">    effect: <span class="string">"NoSchedule"</span></span><br></pre></td></tr></table></figure><p>这个 Toleration 的含义是，这个 Pod 能“容忍”所有键值对为 foo=bar 的 Taint（ operator: “Equal”，“等于”操作）。</p><p>现在回到我们已经搭建的集群上来。这时，如果你通过 kubectl describe 检查一下 Master 节点的 Taint 字段，就会有所发现了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe node master</span><br><span class="line"> </span><br><span class="line">Name:               master</span><br><span class="line">Roles:              master</span><br><span class="line">Taints:             node-role.kubernetes.io/master:NoSchedule</span><br></pre></td></tr></table></figure><p>可以看到，Master 节点默认被加上了node-role.kubernetes.io/master:NoSchedule这样一个“污点”，其中“键”是node-role.kubernetes.io/master，而没有提供“值”。</p><p>此时，你就需要像下面这样用“Exists”操作符（operator: “Exists”，“存在”即可）来说明，该 Pod 能够容忍所有以 foo 为键的 Taint，才能让这个 Pod 运行在该 Master 节点上：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tolerations:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">"foo"</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">"Exists"</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">"NoSchedule"</span></span><br></pre></td></tr></table></figure><p>当然，如果你就是想要一个单节点的 Kubernetes，删除这个 Taint 才是正确的选择：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl taint nodes --all node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure><p>如上所示，我们在“node-role.kubernetes.io/master”这个键后面加上了一个短横线“-”，这个格式就意味着移除所有以“node-role.kubernetes.io/master”为键的 Taint。</p><p>到了这一步，一个基本完整的 Kubernetes 集群就部署完毕了。是不是很简单呢？</p><p>有了 kubeadm 这样的原生管理工具，Kubernetes 的部署已经被大大简化。更重要的是，像证书、授权、各个组件的配置等部署中最麻烦的操作，kubeadm 都已经帮你完成了。</p><p>接下来，我们再在这个 Kubernetes 集群上安装一些其他的辅助插件，比如 Dashboard 和存储插件。</p><h3 id="部署-Dashboard-可视化插件"><a href="#部署-Dashboard-可视化插件" class="headerlink" title="部署 Dashboard 可视化插件"></a>部署 Dashboard 可视化插件</h3><p>在 Kubernetes 社区中，有一个很受欢迎的 Dashboard 项目，它可以给用户提供一个可视化的 Web 界面来查看当前集群的各种信息。毫不意外，它的部署也相当简单：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><p>部署完成之后，我们就可以查看 Dashboard 对应的 Pod 的状态了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-system</span><br><span class="line"> </span><br><span class="line">kubernetes-dashboard-6948bdb78-f67xk   1/1       Running   0          1m</span><br></pre></td></tr></table></figure><p>需要注意的是，由于 Dashboard 是一个 Web Server，很多人经常会在自己的公有云上无意地暴露 Dashboard 的端口，从而造成安全隐患。所以，1.7 版本之后的 Dashboard 项目部署完成后，默认只能通过 Proxy 的方式在本地访问。具体的操作，你可以查看 Dashboard 项目的<a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener">官方文档</a>。</p><p>而如果你想从集群外访问这个 Dashboard 的话，就需要用到 Ingress，我会在后面的文章中专门介绍这部分内容。</p><h3 id="部署容器存储插件"><a href="#部署容器存储插件" class="headerlink" title="部署容器存储插件"></a>部署容器存储插件</h3><p>接下来，让我们完成这个 Kubernetes 集群的最后一块拼图：容器持久化存储。</p><p>我在前面介绍容器原理时已经提到过，很多时候我们需要用数据卷（Volume）把外面宿主机上的目录或者文件挂载进容器的 Mount Namespace 中，从而达到容器和宿主机共享这些目录或者文件的目的。容器里的应用，也就可以在这些数据卷中新建和写入文件。</p><p>可是，如果你在某一台机器上启动的一个容器，显然无法看到其他机器上的容器在它们的数据卷里写入的文件。<strong>这是容器最典型的特征之一：无状态。</strong></p><p>而容器的持久化存储，就是用来保存容器存储状态的重要手段：存储插件会在容器里挂载一个基于网络或者其他机制的远程数据卷，使得在容器里创建的文件，实际上是保存在远程存储服务器上，或者以分布式的方式保存在多个节点上，而与当前宿主机没有任何绑定关系。这样，无论你在其他哪个宿主机上启动新的容器，都可以请求挂载指定的持久化存储卷，从而访问到数据卷里保存的内容。<strong>这就是“持久化”的含义。</strong></p><p>由于 Kubernetes 本身的松耦合设计，绝大多数存储项目，比如 Ceph、GlusterFS、NFS 等，都可以为 Kubernetes 提供持久化存储能力。在这次的部署实战中，我会选择部署一个很重要的 Kubernetes 存储插件项目：Rook。</p><p>Rook 项目是一个基于 Ceph 的 Kubernetes 存储插件（它后期也在加入对更多存储实现的支持）。不过，不同于对 Ceph 的简单封装，Rook 在自己的实现中加入了水平扩展、迁移、灾难备份、监控等大量的企业级功能，使得这个项目变成了一个完整的、生产级别可用的容器存储插件。</p><p>得益于容器化技术，用两条指令，Rook 就可以把复杂的 Ceph 存储后端部署起来：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/operator.yaml</span><br><span class="line"> </span><br><span class="line">$ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/cluster.yaml</span><br></pre></td></tr></table></figure><p>在部署完成后，你就可以看到 Rook 项目会将自己的 Pod 放置在由它自己管理的两个 Namespace 当中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n rook-ceph-system</span><br><span class="line">NAME                                  READY     STATUS    RESTARTS   AGE</span><br><span class="line">rook-ceph-agent-7cv62                 1/1       Running   0          15s</span><br><span class="line">rook-ceph-operator-78d498c68c-7fj72   1/1       Running   0          44s</span><br><span class="line">rook-discover-2ctcv                   1/1       Running   0          15s</span><br><span class="line"> </span><br><span class="line">$ kubectl get pods -n rook-ceph</span><br><span class="line">NAME                   READY     STATUS    RESTARTS   AGE</span><br><span class="line">rook-ceph-mon0-kxnzh   1/1       Running   0          13s</span><br><span class="line">rook-ceph-mon1-7dn2t   1/1       Running   0          2s</span><br></pre></td></tr></table></figure><p>这样，一个基于 Rook 持久化存储集群就以容器的方式运行起来了，而接下来在 Kubernetes 项目上创建的所有 Pod 就能够通过 Persistent Volume（PV）和 Persistent Volume Claim（PVC）的方式，在容器里挂载由 Ceph 提供的数据卷了。</p><p>而 Rook 项目，则会负责这些数据卷的生命周期管理、灾难备份等运维工作。关于这些容器持久化存储的知识，我会在后续章节中专门讲解。</p><p>这时候，你可能会有个疑问：为什么我要选择 Rook 项目呢？</p><p>其实，是因为这个项目很有前途。</p><p>如果你去研究一下 Rook 项目的实现，就会发现它巧妙地依赖了 Kubernetes 提供的编排能力，合理的使用了很多诸如 Operator、CRD 等重要的扩展特性（这些特性我都会在后面的文章中逐一讲解到）。这使得 Rook 项目，成为了目前社区中基于 Kubernetes API 构建的最完善也最成熟的容器存储插件。我相信，这样的发展路线，很快就会得到整个社区的推崇。</p><blockquote><p>备注：其实，在很多时候，大家说的所谓“云原生”，就是“Kubernetes 原生”的意思。而像 Rook、Istio 这样的项目，正是贯彻这个思路的典范。在我们后面讲解了声明式 API 之后，相信你对这些项目的设计思想会有更深刻的体会。</p></blockquote><p><strong>小结</strong></p><p>在本小结中，我们完全从 0 开始，在 Bare-metal 环境下使用 kubeadm 工具部署了一个完整的 Kubernetes 集群：这个集群有一个 Master 节点和多个 Worker 节点；使用 Weave 作为容器网络插件；使用 Rook 作为容器持久化存储插件；使用 Dashboard 插件提供了可视化的 Web 界面。</p><p>这个集群，也将会是我进行后续讲解所依赖的集群环境，并且在后面的讲解中，我还会给它安装更多的插件，添加更多的新能力。</p><p>另外，这个集群的部署过程并不像传说中那么繁琐，这主要得益于：</p><ol><li>kubeadm 项目大大简化了部署 Kubernetes 的准备工作，尤其是配置文件、证书、二进制文件的准备和制作，以及集群版本管理等操作，都被 kubeadm 接管了。</li><li>Kubernetes 本身“一切皆容器”的设计思想，加上良好的可扩展机制，使得插件的部署非常简便。</li></ol><p>上述思想，也是开发和使用 Kubernetes 的重要指导思想，即：基于 Kubernetes 开展工作时，你一定要优先考虑这两个问题：</p><ol><li>我的工作是不是可以容器化？</li><li>我的工作是不是可以借助 Kubernetes API 和可扩展机制来完成？</li></ol><p>而一旦这项工作能够基于 Kubernetes 实现容器化，就很有可能像上面的部署过程一样，大幅简化原本复杂的运维工作。对于时间宝贵的技术人员来说，这个变化的重要性是不言而喻的。</p><!-- kubeadm最新版本已经为1.12，看到上面很多人遇到提示版本不对，重新安装低版本就好了apt remove kubelet kubectl kubeadmapt install kubelet=1.11.3-00apt install kubectl=1.11.3-00apt install kubeadm=1.11.3-00--><h2 id="牛刀小试：我的第一个容器化应用"><a href="#牛刀小试：我的第一个容器化应用" class="headerlink" title="牛刀小试：我的第一个容器化应用"></a>牛刀小试：我的第一个容器化应用</h2><p>我们就来扮演一个应用开发者的角色，使用这个 Kubernetes 集群发布第一个容器化应用。</p><p>在开始实践之前，我先给你讲解一下 Kubernetes 里面与开发者关系最密切的几个概念。</p><p>作为一个应用开发者，你首先要做的，是制作容器的镜像。这一部分内容，我已经在容器基础部分《白话容器基础（三）：深入理解容器镜像》重点讲解过了。</p><p>而有了容器镜像之后，你需要按照 Kubernetes 项目的规范和要求，将你的镜像组织为它能够“认识”的方式，然后提交上去。</p><p>那么，<strong>什么才是 Kubernetes 项目能“认识”的方式呢？</strong></p><p>这就是使用 Kubernetes 的必备技能：编写配置文件。</p><blockquote><p>备注：这些配置文件可以是 YAML 或者 JSON 格式的。为方便阅读与理解，在后面的讲解中，我会统一使用 YAML 文件来指代它们。</p></blockquote><p>Kubernetes 跟 Docker 等很多项目最大的不同，就在于它不推荐你使用命令行的方式直接运行容器（虽然 Kubernetes 项目也支持这种方式，比如：kubectl run），而是希望你用 YAML 文件的方式，即：把容器的定义、参数、配置，统统记录在一个 YAML 文件中，然后用这样一句指令把它运行起来：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f 我的配置文件</span><br></pre></td></tr></table></figure><p>这么做最直接的好处是，你会有一个文件能记录下 Kubernetes 到底“run”了什么。比如下面这个例子：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>像这样的一个 YAML 文件，对应到 Kubernetes 中，就是一个 API Object（API 对象）。当你为这个对象的各个字段填好值并提交给 Kubernetes 之后，Kubernetes 就会负责创建出这些对象所定义的容器或者其他类型的 API 资源。</p><p>可以看到，这个 YAML 文件中的 Kind 字段，指定了这个 API 对象的类型（Type），是一个 Deployment。</p><p>所谓 Deployment，是一个定义多副本应用（即多个副本 Pod）的对象，我在前面的文章中（也是第 9 篇文章《从容器到容器云：谈谈 Kubernetes 的本质》）曾经简单提到过它的用法。此外，Deployment 还负责在 Pod 定义发生变化时，对每个副本进行滚动更新（Rolling Update）。</p><p>在上面这个 YAML 文件中，我给它定义的 Pod 副本个数 (spec.replicas) 是：2。</p><p>而这些 Pod 具体的又长什么样子呢？</p><p>为此，我定义了一个 Pod 模版（spec.template），这个模版描述了我想要创建的 Pod 的细节。在上面的例子里，这个 Pod 里只有一个容器，这个容器的镜像（spec.containers.image）是 nginx:1.7.9，这个容器监听端口（containerPort）是 80。</p><p>关于 Pod 的设计和用法我已经在《从容器到容器云：谈谈 Kubernetes 的本质》中简单的介绍过。而在这里，你需要记住这样一句话：</p><blockquote><p>Pod 就是 Kubernetes 世界里的“应用”；而一个应用，可以由多个容器组成。</p></blockquote><p>需要注意的是，像这样使用一种 API 对象（Deployment）管理另一种 API 对象（Pod）的方法，在 Kubernetes 中，叫作“控制器”模式（controller pattern）。在我们的例子中，Deployment 扮演的正是 Pod 的控制器的角色。关于 Pod 和控制器模式的更多细节，我会在后续编排部分做进一步讲解。</p><p>你可能还注意到，这样的每一个 API 对象都有一个叫作 Metadata 的字段，这个字段就是 API 对象的“标识”，即元数据，它也是我们从 Kubernetes 里找到这个对象的主要依据。这其中最主要使用到的字段是 Labels。</p><p>顾名思义，Labels 就是一组 key-value 格式的标签。而像 Deployment 这样的控制器对象，就可以通过这个 Labels 字段从 Kubernetes 中过滤出它所关心的被控制对象。</p><p>比如，在上面这个 YAML 文件中，Deployment 会把所有正在运行的、携带“app: nginx”标签的 Pod 识别为被管理的对象，并确保这些 Pod 的总数严格等于两个。</p><p>而这个过滤规则的定义，是在 Deployment 的“spec.selector.matchLabels”字段。我们一般称之为：Label Selector。</p><p>另外，在 Metadata 中，还有一个与 Labels 格式、层级完全相同的字段叫 Annotations，它专门用来携带 key-value 格式的内部信息。所谓内部信息，指的是对这些信息感兴趣的，是 Kubernetes 组件本身，而不是用户。所以大多数 Annotations，都是在 Kubernetes 运行过程中，被自动加在这个 API 对象上。</p><p>一个 Kubernetes 的 API 对象的定义，大多可以分为 Metadata 和 Spec 两个部分。前者存放的是这个对象的元数据，对所有 API 对象来说，这一部分的字段和格式基本上是一样的；而后者存放的，则是属于这个对象独有的定义，用来描述它所要表达的功能。</p><p><strong>在了解了上述 Kubernetes 配置文件的基本知识之后，我们现在就可以把这个 YAML 文件“运行”起来。</strong>正如前所述，你可以使用 kubectl create 指令完成这个操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f nginx-deployment.yaml</span><br></pre></td></tr></table></figure><p>然后，通过 kubectl get 命令检查这个 YAML 运行起来的状态是不是与我们预期的一致：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -l app=nginx</span><br><span class="line">NAME                                READY     STATUS    RESTARTS   AGE</span><br><span class="line">nginx-deployment-67594d6bf6-9gdvr   1/1       Running   0          10m</span><br><span class="line">nginx-deployment-67594d6bf6-v6j7w   1/1       Running   0          10m</span><br></pre></td></tr></table></figure><p>kubectl get 指令的作用，就是从 Kubernetes 里面获取（GET）指定的 API 对象。可以看到，在这里我还加上了一个 -l 参数，即获取所有匹配 app: nginx 标签的 Pod。需要注意的是，<strong>在命令行中，所有 key-value 格式的参数，都使用“=”而非“:”表示。</strong></p><p>从这条指令返回的结果中，我们可以看到现在有两个 Pod 处于 Running 状态，也就意味着我们这个 Deployment 所管理的 Pod 都处于预期的状态。</p><p>此外， 你还可以使用 kubectl describe 命令，查看一个 API 对象的细节，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod nginx-deployment-67594d6bf6-9gdvr</span><br><span class="line">Name:               nginx-deployment-67594d6bf6-9gdvr</span><br><span class="line">Namespace:          default</span><br><span class="line">Priority:           0</span><br><span class="line">PriorityClassName:  &lt;none&gt;</span><br><span class="line">Node:               node-1/10.168.0.3</span><br><span class="line">Start Time:         Thu, 16 Aug 2018 08:48:42 +0000</span><br><span class="line">Labels:             app=nginx</span><br><span class="line">                    pod-template-hash=2315082692</span><br><span class="line">Annotations:        &lt;none&gt;</span><br><span class="line">Status:             Running</span><br><span class="line">IP:                 10.32.0.23</span><br><span class="line">Controlled By:      ReplicaSet/nginx-deployment-67594d6bf6</span><br><span class="line">...</span><br><span class="line">Events:</span><br><span class="line"> </span><br><span class="line">  Type     Reason                  Age                From               Message</span><br><span class="line"> </span><br><span class="line">  ----     ------                  ----               ----               -------</span><br><span class="line">  </span><br><span class="line">  Normal   Scheduled               1m                 default-scheduler  Successfully assigned default/nginx-deployment-67594d6bf6-9gdvr to node-1</span><br><span class="line">  Normal   Pulling                 25s                kubelet, node-1    pulling image <span class="string">"nginx:1.7.9"</span></span><br><span class="line">  Normal   Pulled                  17s                kubelet, node-1    Successfully pulled image <span class="string">"nginx:1.7.9"</span></span><br><span class="line">  Normal   Created                 17s                kubelet, node-1    Created container</span><br><span class="line">  Normal   Started                 17s                kubelet, node-1    Started container</span><br></pre></td></tr></table></figure><p>在 kubectl describe 命令返回的结果中，你可以清楚地看到这个 Pod 的详细信息，比如它的 IP 地址等等。其中，有一个部分值得你特别关注，它就是<strong>Events（事件）。</strong></p><p>在 Kubernetes 执行的过程中，对 API 对象的所有重要操作，都会被记录在这个对象的 Events 里，并且显示在 kubectl describe 指令返回的结果中。</p><p>比如，对于这个 Pod，我们可以看到它被创建之后，被调度器调度（Successfully assigned）到了 node-1，拉取了指定的镜像（pulling image），然后启动了 Pod 里定义的容器（Started container）。</p><p>所以，这个部分正是我们将来进行 Debug 的重要依据。<strong>如果有异常发生，你一定要第一时间查看这些 Events</strong>，往往可以看到非常详细的错误信息。</p><p><strong>接下来，如果我们要对这个 Nginx 服务进行升级，把它的镜像版本从 1.7.9 升级为 1.8，要怎么做呢？</strong></p><p>很简单，我们只要修改这个 YAML 文件即可。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span>    </span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.8</span> <span class="comment"># 这里被从 1.7.9 修改为 1.8</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>可是，这个修改目前只发生在本地，如何让这个更新在 Kubernetes 里也生效呢？</p><p>我们可以使用 kubectl replace 指令来完成这个更新：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl replace -f nginx-deployment.yaml</span><br></pre></td></tr></table></figure><p>不过，我推荐你使用 kubectl apply 命令，来统一进行 Kubernetes 对象的创建和更新操作，具体做法如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f nginx-deployment.yaml</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 修改 nginx-deployment.yaml 的内容</span></span><br><span class="line"> </span><br><span class="line">$ kubectl apply -f nginx-deployment.yaml</span><br></pre></td></tr></table></figure><p>这样的操作方法，是 Kubernetes“声明式 API”所推荐的使用方法。也就是说，作为用户，你不必关心当前的操作是创建，还是更新，你执行的命令始终是 kubectl apply，而 Kubernetes 则会根据 YAML 文件的内容变化，自动进行具体的处理。</p><p>而这个流程的好处是，它有助于帮助开发和运维人员，围绕着可以版本化管理的 YAML 文件，而不是“行踪不定”的命令行进行协作，从而大大降低开发人员和运维人员之间的沟通成本。</p><p>举个例子，一位开发人员开发好一个应用，制作好了容器镜像。那么他就可以在应用的发布目录里附带上一个 Deployment 的 YAML 文件。</p><p>而运维人员，拿到这个应用的发布目录后，就可以直接用这个 YAML 文件执行 kubectl apply 操作把它运行起来。</p><p>这时候，如果开发人员修改了应用，生成了新的发布内容，那么这个 YAML 文件，也就需要被修改，并且成为这次变更的一部分。</p><p>而接下来，运维人员可以使用 git diff 命令查看到这个 YAML 文件本身的变化，然后继续用 kubectl apply 命令更新这个应用。</p><p>所以说，如果通过容器镜像，我们能够保证应用本身在开发与部署环境里的一致性的话，那么现在，Kubernetes 项目通过这些 YAML 文件，就保证了应用的“部署参数”在开发与部署环境中的一致性。</p><p><strong>而当应用本身发生变化时，开发人员和运维人员可以依靠容器镜像来进行同步；当应用部署参数发生变化时，这些 YAML 文件就是他们相互沟通和信任的媒介。</strong></p><p>以上，就是 Kubernetes 发布应用的最基本操作了。</p><p>接下来，我们再在这个 Deployment 中尝试声明一个 Volume。</p><p>在 Kubernetes 中，Volume 是属于 Pod 对象的一部分。所以，我们就需要修改这个 YAML 文件里的 template.spec 字段，如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.8</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">"/usr/share/nginx/html"</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">nginx-vol</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-vol</span></span><br><span class="line">        <span class="attr">emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><p>可以看到，我们在 Deployment 的 Pod 模板部分添加了一个 volumes 字段，定义了这个 Pod 声明的所有 Volume。它的名字叫作 nginx-vol，类型是 emptyDir。</p><p>那什么是 emptyDir 类型呢？</p><p>它其实就等同于我们之前讲过的 Docker 的隐式 Volume 参数，即：不显式声明宿主机目录的 Volume。所以，Kubernetes 也会在宿主机上创建一个临时目录，这个目录将来就会被绑定挂载到容器所声明的 Volume 目录上。</p><blockquote><p>备注：不难看到，Kubernetes 的 emptyDir 类型，只是把 Kubernetes 创建的临时目录作为 Volume 的宿主机目录，交给了 Docker。这么做的原因，是 Kubernetes 不想依赖 Docker 自己创建的那个 _data 目录。</p></blockquote><p>而 Pod 中的容器，使用的是 volumeMounts 字段来声明自己要挂载哪个 Volume，并通过 mountPath 字段来定义容器内的 Volume 目录，比如：/usr/share/nginx/html。</p><p>当然，Kubernetes 也提供了显式的 Volume 定义，它叫做 hostPath。比如下面的这个 YAML 文件：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span>   </span><br><span class="line">   <span class="attr">volumes:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-vol</span></span><br><span class="line">       <span class="attr">hostPath:</span> </span><br><span class="line">         <span class="attr">path:</span> <span class="string">/var/data</span></span><br></pre></td></tr></table></figure><p>这样，容器 Volume 挂载的宿主机目录，就变成了 /var/data。</p><p>在上述修改完成后，我们还是使用 kubectl apply 指令，更新这个 Deployment:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl apply -f nginx-deployment.yaml</span><br></pre></td></tr></table></figure><p>接下来，你可以通过 kubectl get 指令，查看两个 Pod 被逐一更新的过程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods</span><br><span class="line">NAME                                READY     STATUS              RESTARTS   AGE</span><br><span class="line">nginx-deployment-5c678cfb6d-v5dlh   0/1       ContainerCreating   0          4s</span><br><span class="line">nginx-deployment-67594d6bf6-9gdvr   1/1       Running             0          10m</span><br><span class="line">nginx-deployment-67594d6bf6-v6j7w   1/1       Running             0          10m</span><br><span class="line">$ kubectl get pods</span><br><span class="line">NAME                                READY     STATUS    RESTARTS   AGE</span><br><span class="line">nginx-deployment-5c678cfb6d-lg9lw   1/1       Running   0          8s</span><br><span class="line">nginx-deployment-5c678cfb6d-v5dlh   1/1       Running   0          19s</span><br></pre></td></tr></table></figure><p>从返回结果中，我们可以看到，新旧两个 Pod，被交替创建、删除，最后剩下的就是新版本的 Pod。这个滚动更新的过程，我也会在后续进行详细的讲解。</p><p>然后，你可以使用 kubectl describe 查看一下最新的 Pod，就会发现 Volume 的信息已经出现在了 Container 描述部分：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">Containers:</span><br><span class="line">  nginx:</span><br><span class="line">    Container ID:   docker://07b4f89248791c2aa47787e3da3cc94b48576cd173018356a6ec8db2b6041343</span><br><span class="line">    Image:          nginx:1.8</span><br><span class="line">    ...</span><br><span class="line">    Environment:    &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /usr/share/nginx/html from nginx-vol (rw)</span><br><span class="line">...</span><br><span class="line">Volumes:</span><br><span class="line">  nginx-vol:</span><br><span class="line">    Type:    EmptyDir (a temporary directory that shares a pod<span class="string">'s lifetime)</span></span><br></pre></td></tr></table></figure><blockquote><p>备注：作为一个完整的容器化平台项目，Kubernetes 为我们提供的 Volume 类型远远不止这些，在容器存储章节里，我将会为你详细介绍这部分内容。</p></blockquote><p>最后，你还可以使用 kubectl exec 指令，进入到这个 Pod 当中（即容器的 Namespace 中）查看这个 Volume 目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">exec</span> -it nginx-deployment-5c678cfb6d-lg9lw -- /bin/bash</span><br><span class="line"><span class="comment"># ls /usr/share/nginx/html</span></span><br></pre></td></tr></table></figure><p>此外，你想要从 Kubernetes 集群中删除这个 Nginx Deployment 的话，直接执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete -f nginx-deployment.yaml</span><br></pre></td></tr></table></figure><p>就可以了。</p><p><strong>小结</strong></p><p>在今天的分享中，我通过一个小案例，和你近距离体验了 Kubernetes 的使用方法。</p><p>可以看到，Kubernetes 推荐的使用方式，是用一个 YAML 文件来描述你所要部署的 API 对象。然后，统一使用 kubectl apply 命令完成对这个对象的创建和更新操作。</p><p>而 Kubernetes 里“最小”的 API 对象是 Pod。Pod 可以等价为一个应用，所以，Pod 可以由多个紧密协作的容器组成。</p><p>在 Kubernetes 中，我们经常会看到它通过一种 API 对象来管理另一种 API 对象，比如 Deployment 和 Pod 之间的关系；而由于 Pod 是“最小”的对象，所以它往往都是被其他对象控制的。这种组合方式，正是 Kubernetes 进行容器编排的重要模式。</p><p>而像这样的 Kubernetes API 对象，往往由 Metadata 和 Spec 两部分组成，其中 Metadata 里的 Labels 字段是 Kubernetes 过滤对象的主要手段。</p><p>在这些字段里面，容器想要使用的数据卷，也就是 Volume，正是 Pod 的 Spec 字段的一部分。而 Pod 里的每个容器，则需要显式的声明自己要挂载哪个 Volume。</p><p>上面这些基于 YAML 文件的容器管理方式，跟 Docker、Mesos 的使用习惯都是不一样的，而从 docker run 这样的命令行操作，向 kubectl apply YAML 文件这样的声明式 API 的转变，是每一个容器技术学习者，必须要跨过的第一道门槛。</p><p>所以，如果你想要快速熟悉 Kubernetes，请按照下面的流程进行练习：</p><ul><li>首先，在本地通过 Docker 测试代码，制作镜像；</li><li>然后，选择合适的 Kubernetes API 对象，编写对应 YAML 文件（比如，Pod，Deployment）；</li><li>最后，在 Kubernetes 上部署这个 YAML 文件。</li></ul><p>更重要的是，在部署到 Kubernetes 之后，接下来的所有操作，要么通过 kubectl 来执行，要么通过修改 YAML 文件来实现，<strong>就尽量不要再碰 Docker 的命令行了</strong>。</p><h2 id="为什么我们需要Pod？"><a href="#为什么我们需要Pod？" class="headerlink" title="为什么我们需要Pod？"></a>为什么我们需要Pod？</h2><p>在前面，我详细介绍了在 Kubernetes 里部署一个应用的过程。在这些讲解中，我提到了这样一个知识点：Pod，是 Kubernetes 项目中最小的 API 对象。如果换一个更专业的说法，我们可以这样描述：Pod，是 Kubernetes 项目的原子调度单位。</p><p>不过，我相信你在学习和使用 Kubernetes 项目的过程中，已经不止一次地想要问这样一个问题：为什么我们会需要 Pod？</p><p>是啊，我们在前面已经花了很多精力去解读 Linux 容器的原理、分析了 Docker 容器的本质，终于，“Namespace 做隔离，Cgroups 做限制，rootfs 做文件系统”这样的“三句箴言”可以朗朗上口了，<strong>为什么 Kubernetes 项目又突然搞出一个 Pod 来呢？</strong></p><p>要回答这个问题，我们还是要一起回忆一下我曾经反复强调的一个问题：容器的本质到底是什么？</p><p>你现在应该可以不假思索地回答出来：容器的本质是进程。</p><p>没错。容器，就是未来云计算系统中的进程；容器镜像就是这个系统里的“.exe”安装包。那么 Kubernetes 呢？</p><p>你应该也能立刻回答上来：Kubernetes 就是操作系统！</p><p>非常正确。</p><p>现在，就让我们登录到一台 Linux 机器里，执行一条如下所示的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ pstree -g</span><br></pre></td></tr></table></figure><p>这条命令的作用，是展示当前系统中正在运行的进程的树状结构。它的返回结果如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">systemd(1)-+-accounts-daemon(1984)-+-&#123;gdbus&#125;(1984)</span><br><span class="line">           | `-&#123;gmain&#125;(1984)</span><br><span class="line">           |-acpid(2044)</span><br><span class="line">          ...      </span><br><span class="line">           |-lxcfs(1936)-+-&#123;lxcfs&#125;(1936)</span><br><span class="line">           | `-&#123;lxcfs&#125;(1936)</span><br><span class="line">           |-mdadm(2135)</span><br><span class="line">           |-ntpd(2358)</span><br><span class="line">           |-polkitd(2128)-+-&#123;gdbus&#125;(2128)</span><br><span class="line">           | `-&#123;gmain&#125;(2128)</span><br><span class="line">           |-rsyslogd(1632)-+-&#123;<span class="keyword">in</span>:imklog&#125;(1632)</span><br><span class="line">           |  |-&#123;<span class="keyword">in</span>:imuxsock) S 1(1632)</span><br><span class="line">           | `-&#123;rs:main Q:Reg&#125;(1632)</span><br><span class="line">           |-snapd(1942)-+-&#123;snapd&#125;(1942)</span><br><span class="line">           |  |-&#123;snapd&#125;(1942)</span><br><span class="line">           |  |-&#123;snapd&#125;(1942)</span><br><span class="line">           |  |-&#123;snapd&#125;(1942)</span><br><span class="line">           |  |-&#123;snapd&#125;(1942)</span><br></pre></td></tr></table></figure><p>不难发现，在一个真正的操作系统里，进程并不是“孤苦伶仃”地独自运行的，而是以进程组的方式，“有原则地”组织在一起。比如，这里有一个叫作 rsyslogd 的程序，它负责的是 Linux 操作系统里的日志处理。可以看到，rsyslogd 的主程序 main，和它要用到的内核日志模块 imklog 等，同属于 1632 进程组。这些进程相互协作，共同完成 rsyslogd 程序的职责。</p><blockquote><p>注意：我在本篇中提到的“进程”，比如，rsyslogd 对应的 imklog，imuxsock 和 main，严格意义上来说，其实是 Linux 操作系统语境下的“线程”。这些线程，或者说，轻量级进程之间，可以共享文件、信号、数据内存、甚至部分代码，从而紧密协作共同完成一个程序的职责。所以同理，我提到的“进程组”，对应的也是 Linux 操作系统语境下的“线程组”。这种命名关系与实际情况的不一致，是 Linux 发展历史中的一个遗留问题。对这个话题感兴趣的同学，可以阅读<a href="https://www.ibm.com/developerworks/cn/linux/kernel/l-thread/index.html" target="_blank" rel="noopener">这篇技术文章</a>来了解一下。</p></blockquote><p>而 Kubernetes 项目所做的，其实就是将“进程组”的概念映射到了容器技术中，并使其成为了这个云计算“操作系统”里的“一等公民”。</p><p>Kubernetes 项目之所以要这么做的原因，我在前面介绍 Kubernetes 和 Borg 的关系时曾经提到过：在 Borg 项目的开发和实践过程中，Google 公司的工程师们发现，他们部署的应用，往往都存在着类似于“进程和进程组”的关系。更具体地说，就是这些应用之间有着密切的协作关系，使得它们必须部署在同一台机器上。</p><p>而如果事先没有“组”的概念，像这样的运维关系就会非常难以处理。</p><p>我还是以前面的 rsyslogd 为例子。已知 rsyslogd 由三个进程组成：一个 imklog 模块，一个 imuxsock 模块，一个 rsyslogd 自己的 main 函数主进程。这三个进程一定要运行在同一台机器上，否则，它们之间基于 Socket 的通信和文件交换，都会出现问题。</p><p>现在，我要把 rsyslogd 这个应用给容器化，由于受限于容器的“单进程模型”，这三个模块必须被分别制作成三个不同的容器。而在这三个容器运行的时候，它们设置的内存配额都是 1 GB。</p><blockquote><p>再次强调一下：容器的“单进程模型”，并不是指容器里只能运行“一个”进程，而是指容器没有管理多个进程的能力。这是因为容器里 PID=1 的进程就是应用本身，其他的进程都是这个 PID=1 进程的子进程。可是，用户编写的应用，并不能够像正常操作系统里的 init 进程或者 systemd 那样拥有进程管理的功能。比如，你的应用是一个 Java Web 程序（PID=1），然后你执行 docker exec 在后台启动了一个 Nginx 进程（PID=3）。可是，当这个 Nginx 进程异常退出的时候，你该怎么知道呢？这个进程退出后的垃圾收集工作，又应该由谁去做呢？</p></blockquote><p>假设我们的 Kubernetes 集群上有两个节点：node-1 上有 3 GB 可用内存，node-2 有 2.5 GB 可用内存。</p><p>这时，假设我要用 Docker Swarm 来运行这个 rsyslogd 程序。为了能够让这三个容器都运行在同一台机器上，我就必须在另外两个容器上设置一个 affinity=main（与 main 容器有亲密性）的约束，即：它们俩必须和 main 容器运行在同一台机器上。</p><p>然后，我顺序执行：“docker run main”“docker run imklog”和“docker run imuxsock”，创建这三个容器。</p><p>这样，这三个容器都会进入 Swarm 的待调度队列。然后，main 容器和 imklog 容器都先后出队并被调度到了 node-2 上（这个情况是完全有可能的）。</p><p>可是，当 imuxsock 容器出队开始被调度时，Swarm 就有点懵了：node-2 上的可用资源只有 0.5 GB 了，并不足以运行 imuxsock 容器；可是，根据 affinity=main 的约束，imuxsock 容器又只能运行在 node-2 上。</p><p>这就是一个典型的成组调度（gang scheduling）没有被妥善处理的例子。</p><p>在工业界和学术界，关于这个问题的讨论可谓旷日持久，也产生了很多可供选择的解决方案。</p><p>比如，Mesos 中就有一个资源囤积（resource hoarding）的机制，会在所有设置了 Affinity 约束的任务都达到时，才开始对它们统一进行调度。而在 Google Omega 论文中，则提出了使用乐观调度处理冲突的方法，即：先不管这些冲突，而是通过精心设计的回滚机制在出现了冲突之后解决问题。</p><p>可是这些方法都谈不上完美。资源囤积带来了不可避免的调度效率损失和死锁的可能性；而乐观调度的复杂程度，则不是常规技术团队所能驾驭的。</p><p>但是，到了 Kubernetes 项目里，这样的问题就迎刃而解了：Pod 是 Kubernetes 里的原子调度单位。这就意味着，Kubernetes 项目的调度器，是统一按照 Pod 而非容器的资源需求进行计算的。</p><p>所以，像 imklog、imuxsock 和 main 函数主进程这样的三个容器，正是一个典型的由三个容器组成的 Pod。Kubernetes 项目在调度时，自然就会去选择可用内存等于 3 GB 的 node-1 节点进行绑定，而根本不会考虑 node-2。</p><p>像这样容器间的紧密协作，我们可以称为“超亲密关系”。这些具有“超亲密关系”容器的典型特征包括但不限于：互相之间会发生直接的文件交换、使用 localhost 或者 Socket 文件进行本地通信、会发生非常频繁的远程调用、需要共享某些 Linux Namespace（比如，一个容器要加入另一个容器的 Network Namespace）等等。</p><p>这也就意味着，并不是所有有“关系”的容器都属于同一个 Pod。比如，PHP 应用容器和 MySQL 虽然会发生访问关系，但并没有必要、也不应该部署在同一台机器上，它们更适合做成两个 Pod。</p><p>不过，相信此时你可能会有第二个疑问：</p><p>对于初学者来说，一般都是先学会了用 Docker 这种单容器的工具，才会开始接触 Pod。</p><p>而如果 Pod 的设计只是出于调度上的考虑，那么 Kubernetes 项目似乎完全没有必要非得把 Pod 作为“一等公民”吧？这不是故意增加用户的学习门槛吗？</p><p>没错，如果只是处理“超亲密关系”这样的调度问题，有 Borg 和 Omega 论文珠玉在前，Kubernetes 项目肯定可以在调度器层面给它解决掉。</p><p>不过，Pod 在 Kubernetes 项目里还有更重要的意义，那就是：<strong>容器设计模式。</strong></p><p>为了理解这一层含义，我就必须先给你介绍一下<strong>Pod 的实现原理。</strong></p><p><strong>首先，关于 Pod 最重要的一个事实是：它只是一个逻辑概念。</strong></p><p>也就是说，Kubernetes 真正处理的，还是宿主机操作系统上 Linux 容器的 Namespace 和 Cgroups，而并不存在一个所谓的 Pod 的边界或者隔离环境。</p><p>那么，Pod 又是怎么被“创建”出来的呢？</p><p>也就是说，Kubernetes 真正处理的，还是宿主机操作系统上 Linux 容器的 Namespace 和 Cgroups，而并不存在一个所谓的 Pod 的边界或者隔离环境。</p><p>那么，Pod 又是怎么被“创建”出来的呢？</p><p>答案是：Pod，其实是一组共享了某些资源的容器。</p><p>具体的说：<strong>Pod 里的所有容器，共享的是同一个 Network Namespace，并且可以声明共享同一个 Volume。</strong></p><p>那这么来看的话，一个有 A、B 两个容器的 Pod，不就是等同于一个容器（容器 A）共享另外一个容器（容器 B）的网络和 Volume 的玩儿法么？</p><p>这好像通过 docker run –net –volumes-from 这样的命令就能实现嘛，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --net=B --volumes-from=B --name=A image-A ...</span><br></pre></td></tr></table></figure><p>但是，你有没有考虑过，如果真这样做的话，容器 B 就必须比容器 A 先启动，这样一个 Pod 里的多个容器就不是对等关系，而是拓扑关系了。</p><p>所以，在 Kubernetes 项目里，Pod 的实现需要使用一个中间容器，这个容器叫作 Infra 容器。在这个 Pod 中，Infra 容器永远都是第一个被创建的容器，而其他用户定义的容器，则通过 Join Network Namespace 的方式，与 Infra 容器关联在一起。这样的组织关系，可以用下面这样一个示意图来表达：</p><p><img src="/images/k8s/k8s-02/1.jpg" alt="1"></p><p>如上图所示，这个 Pod 里有两个用户容器 A 和 B，还有一个 Infra 容器。很容易理解，在 Kubernetes 项目里，Infra 容器一定要占用极少的资源，所以它使用的是一个非常特殊的镜像，叫作：k8s.gcr.io/pause。这个镜像是一个用汇编语言编写的、永远处于“暂停”状态的容器，解压后的大小也只有 100~200 KB 左右。</p><p>而在 Infra 容器“Hold 住”Network Namespace 后，用户容器就可以加入到 Infra 容器的 Network Namespace 当中了。所以，如果你查看这些容器在宿主机上的 Namespace 文件（这个 Namespace 文件的路径，我已经在前面的内容中介绍过），它们指向的值一定是完全一样的。</p><p>这也就意味着，对于 Pod 里的容器 A 和容器 B 来说：</p><ul><li>它们可以直接使用 localhost 进行通信；</li><li>它们看到的网络设备跟 Infra 容器看到的完全一样；</li><li>一个 Pod 只有一个 IP 地址，也就是这个 Pod 的 Network Namespace 对应的 IP 地址；</li><li>当然，其他的所有网络资源，都是一个 Pod 一份，并且被该 Pod 中的所有容器共享；</li><li>Pod 的生命周期只跟 Infra 容器一致，而与容器 A 和 B 无关。</li></ul><p>而对于同一个 Pod 里面的所有用户容器来说，它们的进出流量，也可以认为都是通过 Infra 容器完成的。这一点很重要，因为<strong>将来如果你要为 Kubernetes 开发一个网络插件时，应该重点考虑的是如何配置这个 Pod 的 Network Namespace，而不是每一个用户容器如何使用你的网络配置，这是没有意义的。</strong></p><p>这就意味着，如果你的网络插件需要在容器里安装某些包或者配置才能完成的话，是不可取的：Infra 容器镜像的 rootfs 里几乎什么都没有，没有你随意发挥的空间。当然，这同时也意味着你的网络插件完全不必关心用户容器的启动与否，而只需要关注如何配置 Pod，也就是 Infra 容器的 Network Namespace 即可。</p><p>有了这个设计之后，共享 Volume 就简单多了：Kubernetes 项目只要把所有 Volume 的定义都设计在 Pod 层级即可。</p><p>这样，一个 Volume 对应的宿主机目录对于 Pod 来说就只有一个，Pod 里的容器只要声明挂载这个 Volume，就一定可以共享这个 Volume 对应的宿主机目录。比如下面这个例子：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">two-containers</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shared-data</span></span><br><span class="line">    <span class="attr">hostPath:</span>      </span><br><span class="line">      <span class="attr">path:</span> <span class="string">/data</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shared-data</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">debian-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">debian</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shared-data</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/pod-data</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">["/bin/sh"]</span></span><br><span class="line">    <span class="attr">args:</span> <span class="string">["-c",</span> <span class="string">"echo Hello from the debian container &gt; /pod-data/index.html"</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>在这个例子中，debian-container 和 nginx-container 都声明挂载了 shared-data 这个 Volume。而 shared-data 是 hostPath 类型。所以，它对应在宿主机上的目录就是：/data。而这个目录，其实就被同时绑定挂载进了上述两个容器当中。</p><p>这就是为什么，nginx-container 可以从它的 /usr/share/nginx/html 目录中，读取到 debian-container 生成的 index.html 文件的原因。</p><p><strong>明白了 Pod 的实现原理后，我们再来讨论“容器设计模式”，就容易多了。</strong></p><p>Pod 这种“超亲密关系”容器的设计思想，实际上就是希望，当用户想在一个容器里跑多个功能并不相关的应用时，应该优先考虑它们是不是更应该被描述成一个 Pod 里的多个容器。</p><p>为了能够掌握这种思考方式，你就应该尽量尝试使用它来描述一些用单个容器难以解决的问题。</p><p><strong>第一个最典型的例子是：WAR 包与 Web 服务器。</strong></p><p>我们现在有一个 Java Web 应用的 WAR 包，它需要被放在 Tomcat 的 webapps 目录下运行起来。</p><p>假如，你现在只能用 Docker 来做这件事情，那该如何处理这个组合关系呢？</p><ul><li>一种方法是，把 WAR 包直接放在 Tomcat 镜像的 webapps 目录下，做成一个新的镜像运行起来。可是，这时候，如果你要更新 WAR 包的内容，或者要升级 Tomcat 镜像，就要重新制作一个新的发布镜像，非常麻烦。</li><li>另一种方法是，你压根儿不管 WAR 包，永远只发布一个 Tomcat 容器。不过，这个容器的 webapps 目录，就必须声明一个 hostPath 类型的 Volume，从而把宿主机上的 WAR 包挂载进 Tomcat 容器当中运行起来。不过，这样你就必须要解决一个问题，即：如何让每一台宿主机，都预先准备好这个存储有 WAR 包的目录呢？这样来看，你只能独立维护一套分布式存储系统了。</li></ul><p>实际上，有了 Pod 之后，这样的问题就很容易解决了。我们可以把 WAR 包和 Tomcat 分别做成镜像，然后把它们作为一个 Pod 里的两个容器“组合”在一起。这个 Pod 的配置文件如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">javaweb-2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">geektime/sample:v2</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">war</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">["cp",</span> <span class="string">"/sample.war"</span><span class="string">,</span> <span class="string">"/app"</span><span class="string">]</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/app</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">app-volume</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">geektime/tomcat:7.0</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tomcat</span></span><br><span class="line">    <span class="attr">command:</span> <span class="string">["sh","-c","/root/apache-tomcat-7.0.42-v2/bin/start.sh"]</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/root/apache-tomcat-7.0.42-v2/webapps</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">app-volume</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">      <span class="attr">hostPort:</span> <span class="number">8001</span> </span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app-volume</span></span><br><span class="line">    <span class="attr">emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><p>在这个 Pod 中，我们定义了两个容器，第一个容器使用的镜像是 geektime/sample:v2，这个镜像里只有一个 WAR 包（sample.war）放在根目录下。而第二个容器则使用的是一个标准的 Tomcat 镜像。</p><p>不过，你可能已经注意到，WAR 包容器的类型不再是一个普通容器，而是一个 Init Container 类型的容器。</p><p>在 Pod 中，所有 Init Container 定义的容器，都会比 spec.containers 定义的用户容器先启动。并且，Init Container 容器会按顺序逐一启动，而直到它们都启动并且退出了，用户容器才会启动。</p><p>所以，这个 Init Container 类型的 WAR 包容器启动后，我执行了一句”cp /sample.war /app”，把应用的 WAR 包拷贝到 /app 目录下，然后退出。</p><p>而后这个 /app 目录，就挂载了一个名叫 app-volume 的 Volume。</p><p>接下来就很关键了。Tomcat 容器，同样声明了挂载 app-volume 到自己的 webapps 目录下。</p><p>所以，等 Tomcat 容器启动时，它的 webapps 目录下就一定会存在 sample.war 文件：这个文件正是 WAR 包容器启动时拷贝到这个 Volume 里面的，而这个 Volume 是被这两个容器共享的。</p><p>像这样，我们就用一种“组合”方式，解决了 WAR 包与 Tomcat 容器之间耦合关系的问题。</p><p>实际上，这个所谓的“组合”操作，正是容器设计模式里最常用的一种模式，它的名字叫：sidecar。</p><p>顾名思义，sidecar 指的就是我们可以在一个 Pod 中，启动一个辅助容器，来完成一些独立于主进程（主容器）之外的工作。</p><p>比如，在我们的这个应用 Pod 中，Tomcat 容器是我们要使用的主容器，而 WAR 包容器的存在，只是为了给它提供一个 WAR 包而已。所以，我们用 Init Container 的方式优先运行 WAR 包容器，扮演了一个 sidecar 的角色。</p><p><strong>第二个例子，则是容器的日志收集。</strong></p><p>比如，我现在有一个应用，需要不断地把日志文件输出到容器的 /var/log 目录中。</p><p>这时，我就可以把一个 Pod 里的 Volume 挂载到应用容器的 /var/log 目录上。</p><p>然后，我在这个 Pod 里同时运行一个 sidecar 容器，它也声明挂载同一个 Volume 到自己的 /var/log 目录上。</p><p>这样，接下来 sidecar 容器就只需要做一件事儿，那就是不断地从自己的 /var/log 目录里读取日志文件，转发到 MongoDB 或者 Elasticsearch 中存储起来。这样，一个最基本的日志收集工作就完成了。</p><p>跟第一个例子一样，这个例子中的 sidecar 的主要工作也是使用共享的 Volume 来完成对文件的操作。</p><p>但不要忘记，Pod 的另一个重要特性是，它的所有容器都共享同一个 Network Namespace。这就使得很多与 Pod 网络相关的配置和管理，也都可以交给 sidecar 完成，而完全无须干涉用户容器。这里最典型的例子莫过于 Istio 这个微服务治理项目了。</p><p>Istio 项目使用 sidecar 容器完成微服务治理的原理，我在后面很快会讲解到。</p><blockquote><p>备注：Kubernetes 社区曾经把“容器设计模式”这个理论，整理成了<a href="https://www.usenix.org/conference/hotcloud16/workshop-program/presentation/burns" target="_blank" rel="noopener">一篇小论文</a>，你可以点击链接浏览。</p></blockquote><p><strong>小结</strong></p><p>在本篇文章中我重点分享了 Kubernetes 项目中 Pod 的实现原理。</p><p>Pod 是 Kubernetes 项目与其他单容器项目相比最大的不同，也是一位容器技术初学者需要面对的第一个与常规认知不一致的知识点。</p><p>事实上，直到现在，仍有很多人把容器跟虚拟机相提并论，他们把容器当做性能更好的虚拟机，喜欢讨论如何把应用从虚拟机无缝地迁移到容器中。</p><p>但实际上，无论是从具体的实现原理，还是从使用方法、特性、功能等方面，容器与虚拟机几乎没有任何相似的地方；也不存在一种普遍的方法，能够把虚拟机里的应用无缝迁移到容器中。因为，容器的性能优势，必然伴随着相应缺陷，即：它不能像虚拟机那样，完全模拟本地物理机环境中的部署方法。</p><p>所以，这个“上云”工作的完成，最终还是要靠深入理解容器的本质，即：进程。</p><p>实际上，一个运行在虚拟机里的应用，哪怕再简单，也是被管理在 systemd 或者 supervisord 之下的<strong>一组进程，而不是一个进程</strong>。这跟本地物理机上应用的运行方式其实是一样的。这也是为什么，从物理机到虚拟机之间的应用迁移，往往并不困难。</p><p>可是对于容器来说，一个容器永远只能管理一个进程。更确切地说，一个容器，就是一个进程。这是容器技术的“天性”，不可能被修改。所以，将一个原本运行在虚拟机里的应用，“无缝迁移”到容器中的想法，实际上跟容器的本质是相悖的。</p><p>这也是当初 Swarm 项目无法成长起来的重要原因之一：一旦到了真正的生产环境上，Swarm 这种单容器的工作方式，就难以描述真实世界里复杂的应用架构了。</p><p>所以，你现在可以这么理解 Pod 的本质：</p><blockquote><p>Pod，实际上是在扮演传统基础设施里“虚拟机”的角色；而容器，则是这个虚拟机里运行的用户程序。</p></blockquote><p>所以下一次，当你需要把一个运行在虚拟机里的应用迁移到 Docker 容器中时，一定要仔细分析到底有哪些进程（组件）运行在这个虚拟机里。</p><p>然后，你就可以把整个虚拟机想象成为一个 Pod，把这些进程分别做成容器镜像，把有顺序关系的容器，定义为 Init Container。这才是更加合理的、松耦合的容器编排诀窍，也是从传统应用架构，到“微服务架构”最自然的过渡方式。</p><blockquote><p>注意：Pod 这个概念，提供的是一种编排思想，而不是具体的技术方案。所以，如果愿意的话，你完全可以使用虚拟机来作为 Pod 的实现，然后把用户容器都运行在这个虚拟机里。比如，Mirantis 公司的<a href="https://github.com/Mirantis/virtlet" target="_blank" rel="noopener">virtlet 项目</a>就在干这个事情。甚至，你可以去实现一个带有 Init 进程的容器项目，来模拟传统应用的运行方式。这些工作，在 Kubernetes 中都是非常轻松的，也是我们后面讲解 CRI 时会提到的内容。</p></blockquote><p>相反的，如果强行把整个应用塞到一个容器里，甚至不惜使用 Docker In Docker 这种在生产环境中后患无穷的解决方案，恐怕最后往往会得不偿失。</p><h2 id="深入解析Pod对象（一）：基本概念"><a href="#深入解析Pod对象（一）：基本概念" class="headerlink" title="深入解析Pod对象（一）：基本概念"></a>深入解析Pod对象（一）：基本概念</h2><p>现在，你已经非常清楚：Pod，而不是容器，才是 Kubernetes 项目中的最小编排单位。将这个设计落实到 API 对象上，容器（Container）就成了 Pod 属性里的一个普通的字段。那么，一个很自然的问题就是：到底哪些属性属于 Pod 对象，而又有哪些属性属于 Container 呢？</p><p>要彻底理解这个问题，你就一定要牢记我在上一篇文章中提到的一个结论：Pod 扮演的是传统部署环境里“虚拟机”的角色。这样的设计，是为了使用户从传统环境（虚拟机环境）向 Kubernetes（容器环境）的迁移，更加平滑。</p><p>而如果你能把 Pod 看成传统环境里的“机器”、把容器看作是运行在这个“机器”里的“用户程序”，那么很多关于 Pod 对象的设计就非常容易理解了。</p><p>比如，<strong>凡是调度、网络、存储，以及安全相关的属性，基本上是 Pod 级别的。</strong></p><p>这些属性的共同特征是，它们描述的是“机器”这个整体，而不是里面运行的“程序”。比如，配置这个“机器”的网卡（即：Pod 的网络定义），配置这个“机器”的磁盘（即：Pod 的存储定义），配置这个“机器”的防火墙（即：Pod 的安全定义）。更不用说，这台“机器”运行在哪个服务器之上（即：Pod 的调度）。</p><p>接下来，我就先为你介绍 Pod 中几个重要字段的含义和用法。</p><p><strong>NodeSelector：是一个供用户将 Pod 与 Node 进行绑定的字段</strong>，用法如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"> <span class="attr">nodeSelector:</span></span><br><span class="line">   <span class="attr">disktype:</span> <span class="string">ssd</span></span><br></pre></td></tr></table></figure><p>这样的一个配置，意味着这个 Pod 永远只能运行在携带了“disktype: ssd”标签（Label）的节点上；否则，它将调度失败。</p><p>NodeName：一旦 Pod 的这个字段被赋值，Kubernetes 项目就会被认为这个 Pod 已经经过了调度，调度的结果就是赋值的节点名字。所以，这个字段一般由调度器负责设置，但用户也可以设置它来“骗过”调度器，当然这个做法一般是在测试或者调试的时候才会用到。</p><p><strong>HostAliases：定义了 Pod 的 hosts 文件（比如 /etc/hosts）里的内容，用法如下：</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hostAliases:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">ip:</span> <span class="string">"10.1.2.3"</span></span><br><span class="line">    <span class="attr">hostnames:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"foo.remote"</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"bar.remote"</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure><p>在这个 Pod 的 YAML 文件中，我设置了一组 IP 和 hostname 的数据。这样，这个 Pod 启动后，/etc/hosts 文件的内容将如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/hosts</span><br><span class="line"><span class="comment"># Kubernetes-managed hosts file.</span></span><br><span class="line">127.0.0.1 localhost</span><br><span class="line">...</span><br><span class="line">10.244.135.10 hostaliases-pod</span><br><span class="line">10.1.2.3 foo.remote</span><br><span class="line">10.1.2.3 bar.remote</span><br></pre></td></tr></table></figure><p>其中，最下面两行记录，就是我通过 HostAliases 字段为 Pod 设置的。需要指出的是，在 Kubernetes 项目中，如果要设置 hosts 文件里的内容，一定要通过这种方法。否则，如果直接修改了 hosts 文件的话，在 Pod 被删除重建之后，kubelet 会自动覆盖掉被修改的内容。</p><p>除了上述跟“机器”相关的配置外，你可能也会发现，<strong>凡是跟容器的 Linux Namespace 相关的属性，也一定是 Pod 级别的。</strong>这个原因也很容易理解：Pod 的设计，就是要让它里面的容器尽可能多地共享 Linux Namespace，仅保留必要的隔离和限制能力。这样，Pod 模拟出的效果，就跟虚拟机里程序间的关系非常类似了。</p><p>举个例子，在下面这个 Pod 的 YAML 文件中，我定义了 shareProcessNamespace=true：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">shareProcessNamespace:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shell</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">stdin:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">tty:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>这就意味着这个 Pod 里的容器要共享 PID Namespace。</p><p>而在这个 YAML 文件中，我还定义了两个容器：一个是 nginx 容器，一个是开启了 tty 和 stdin 的 shell 容器。</p><p>我在前面介绍容器基础时，曾经讲解过什么是 tty 和 stdin。而在 Pod 的 YAML 文件里声明开启它们俩，其实等同于设置了 docker run 里的 -it（-i 即 stdin，-t 即 tty）参数。</p><p>如果你还是不太理解它们俩的作用的话，可以直接认为 tty 就是 Linux 给用户提供的一个常驻小程序，用于接收用户的标准输入，返回操作系统的标准输出。当然，为了能够在 tty 中输入信息，你还需要同时开启 stdin（标准输入流）。</p><p>于是，这个 Pod 被创建后，你就可以使用 shell 容器的 tty 跟这个容器进行交互了。我们一起实践一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f nginx.yaml</span><br></pre></td></tr></table></figure><p>接下来，我们使用 kubectl attach 命令，连接到 shell 容器的 tty 上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl attach -it nginx -c shell</span><br></pre></td></tr></table></figure><p>这样，我们就可以在 shell 容器里执行 ps 指令，查看所有正在运行的进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl attach -it nginx -c shell</span><br><span class="line">/ <span class="comment"># ps ax</span></span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 /pause</span><br><span class="line">    8 root      0:00 nginx: master process nginx -g daemon off;</span><br><span class="line">   14 101       0:00 nginx: worker process</span><br><span class="line">   15 root      0:00 sh</span><br><span class="line">   21 root      0:00 ps ax</span><br></pre></td></tr></table></figure><p>可以看到，在这个容器里，我们不仅可以看到它本身的 ps ax 指令，还可以看到 nginx 容器的进程，以及 Infra 容器的 /pause 进程。这就意味着，整个 Pod 里的每个容器的进程，对于所有容器来说都是可见的：它们共享了同一个 PID Namespace。</p><p><strong>类似地，凡是 Pod 中的容器要共享宿主机的 Namespace，也一定是 Pod 级别的定义，比如：</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hostNetwork:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostIPC:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hostPID:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">shell</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">stdin:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">tty:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>在这个 Pod 中，我定义了共享宿主机的 Network、IPC 和 PID Namespace。这就意味着，这个 Pod 里的所有容器，会直接使用宿主机的网络、直接与宿主机进行 IPC 通信、看到宿主机里正在运行的所有进程。</p><p>当然，除了这些属性，Pod 里最重要的字段当属“Containers”了。而在上一篇文章中，我还介绍过“Init Containers”。其实，这两个字段都属于 Pod 对容器的定义，内容也完全相同，只是 Init Containers 的生命周期，会先于所有的 Containers，并且严格按照定义的顺序执行。</p><p>Kubernetes 项目中对 Container 的定义，和 Docker 相比并没有什么太大区别。我在前面的容器技术概念入门系列文章中，和你分享的 Image（镜像）、Command（启动命令）、workingDir（容器的工作目录）、Ports（容器要开发的端口），以及 volumeMounts（容器要挂载的 Volume）都是构成 Kubernetes 项目中 Container 的主要字段。不过在这里，还有这么几个属性值得你额外关注。</p><p><strong>首先，是 ImagePullPolicy 字段</strong>。它定义了镜像拉取的策略。而它之所以是一个 Container 级别的属性，是因为容器镜像本来就是 Container 定义中的一部分。</p><p>ImagePullPolicy 的值默认是 Always，即每次创建 Pod 都重新拉取一次镜像。另外，当容器的镜像是类似于 nginx 或者 nginx:latest 这样的名字时，ImagePullPolicy 也会被认为 Always。</p><p>而如果它的值被定义为 Never 或者 IfNotPresent，则意味着 Pod 永远不会主动拉取这个镜像，或者只在宿主机上不存在这个镜像时才拉取。</p><p><strong>其次，是 Lifecycle 字段</strong>。它定义的是 Container Lifecycle Hooks。顾名思义，Container Lifecycle Hooks 的作用，是在容器状态发生变化时触发一系列“钩子”。我们来看这样一个例子：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">lifecycle-demo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-demo-container</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">lifecycle:</span></span><br><span class="line">      <span class="attr">postStart:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">          <span class="attr">command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"echo Hello from the postStart handler &gt; /usr/share/message"</span><span class="string">]</span></span><br><span class="line">      <span class="attr">preStop:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">          <span class="attr">command:</span> <span class="string">["/usr/sbin/nginx","-s","quit"]</span></span><br></pre></td></tr></table></figure><p>这是一个来自 Kubernetes 官方文档的 Pod 的 YAML 文件。它其实非常简单，只是定义了一个 nginx 镜像的容器。不过，在这个 YAML 文件的容器（Containers）部分，你会看到这个容器分别设置了一个 postStart 和 preStop 参数。这是什么意思呢？</p><p>先说 postStart 吧。它指的是，在容器启动后，立刻执行一个指定的操作。需要明确的是，postStart 定义的操作，虽然是在 Docker 容器 ENTRYPOINT 执行之后，但它并不严格保证顺序。也就是说，在 postStart 启动时，ENTRYPOINT 有可能还没有结束。</p><p>当然，如果 postStart 执行超时或者错误，Kubernetes 会在该 Pod 的 Events 中报出该容器启动失败的错误信息，导致 Pod 也处于失败的状态。</p><p>而类似地，preStop 发生的时机，则是容器被杀死之前（比如，收到了 SIGKILL 信号）。而需要明确的是，preStop 操作的执行，是同步的。所以，它会阻塞当前的容器杀死流程，直到这个 Hook 定义操作完成之后，才允许容器被杀死，这跟 postStart 不一样。</p><p>所以，在这个例子中，我们在容器成功启动之后，在 /usr/share/message 里写入了一句“欢迎信息”（即 postStart 定义的操作）。而在这个容器被删除之前，我们则先调用了 nginx 的退出指令（即 preStop 定义的操作），从而实现了容器的“优雅退出”。</p><p>在熟悉了 Pod 以及它的 Container 部分的主要字段之后，我再和你分享一下<strong>这样一个的 Pod 对象在 Kubernetes 中的生命周期</strong>。</p><p>Pod 生命周期的变化，主要体现在 Pod API 对象的<strong>Status 部分</strong>，这是它除了 Metadata 和 Spec 之外的第三个重要字段。其中，pod.status.phase，就是 Pod 的当前状态，它有如下几种可能的情况：</p><ol><li>Pending。这个状态意味着，Pod 的 YAML 文件已经提交给了 Kubernetes，API 对象已经被创建并保存在 Etcd 当中。但是，这个 Pod 里有些容器因为某种原因而不能被顺利创建。比如，调度不成功。</li><li>Running。这个状态下，Pod 已经调度成功，跟一个具体的节点绑定。它包含的容器都已经创建成功，并且至少有一个正在运行中。</li><li>Succeeded。这个状态意味着，Pod 里的所有容器都正常运行完毕，并且已经退出了。这种情况在运行一次性任务时最为常见。</li><li>Failed。这个状态下，Pod 里至少有一个容器以不正常的状态（非 0 的返回码）退出。这个状态的出现，意味着你得想办法 Debug 这个容器的应用，比如查看 Pod 的 Events 和日志。</li><li>Unknown。这是一个异常状态，意味着 Pod 的状态不能持续地被 kubelet 汇报给 kube-apiserver，这很有可能是主从节点（Master 和 Kubelet）间的通信出现了问题。</li></ol><p>更进一步地，Pod 对象的 Status 字段，还可以再细分出一组 Conditions。这些细分状态的值包括：PodScheduled、Ready、Initialized，以及 Unschedulable。它们主要用于描述造成当前 Status 的具体原因是什么。</p><p>比如，Pod 当前的 Status 是 Pending，对应的 Condition 是 Unschedulable，这就意味着它的调度出现了问题。</p><p>而其中，Ready 这个细分状态非常值得我们关注：它意味着 Pod 不仅已经正常启动（Running 状态），而且已经可以对外提供服务了。这两者之间（Running 和 Ready）是有区别的，你不妨仔细思考一下。</p><p>Pod 的这些状态信息，是我们判断应用运行情况的重要标准，尤其是 Pod 进入了非“Running”状态后，你一定要能迅速做出反应，根据它所代表的异常情况开始跟踪和定位，而不是去手忙脚乱地查阅文档。</p><p><strong>小结</strong></p><p>在今天这篇文章中，我详细讲解了 Pod API 对象，介绍了 Pod 的核心使用方法，并分析了 Pod 和 Container 在字段上的异同。希望这些讲解能够帮你更好地理解和记忆 Pod YAML 中的核心字段，以及这些字段的准确含义。</p><p>实际上，Pod API 对象是整个 Kubernetes 体系中最核心的一个概念，也是后面我讲解各种控制器时都要用到的。</p><p>在学习完这篇文章后，我希望你能仔细阅读 $GOPATH/src/k8s.io/kubernetes/vendor/k8s.io/api/core/v1/types.go 里，type Pod struct ，尤其是 PodSpec 部分的内容。争取做到下次看到一个 Pod 的 YAML 文件时，不再需要查阅文档，就能做到把常用字段及其作用信手拈来。</p><!-- 对于 Pod 状态是 Ready，实际上不能提供服务的情况能想到几个例子：1. 程序本身有 bug，本来应该返回 200，但因为代码问题，返回的是500；2. 程序因为内存问题，已经僵死，但进程还在，但无响应；3. Dockerfile 写的不规范，应用程序不是主进程，那么主进程出了什么问题都无法发现；4. 程序出现死循环。--><h2 id="深入解析Pod对象（二）：使用进阶"><a href="#深入解析Pod对象（二）：使用进阶" class="headerlink" title="深入解析Pod对象（二）：使用进阶"></a>深入解析Pod对象（二）：使用进阶</h2><p>作为 Kubernetes 项目里最核心的编排对象，Pod 携带的信息非常丰富。其中，资源定义（比如 CPU、内存等），以及调度相关的字段，我会在后面专门讲解调度器时再进行深入的分析。在本篇，我们就先从一种特殊的 Volume 开始，来帮助你更加深入地理解 Pod 对象各个重要字段的含义。</p><p>这种特殊的 Volume，叫作 Projected Volume，你可以把它翻译为“投射数据卷”。</p><blockquote><p>备注：Projected Volume 是 Kubernetes v1.11 之后的新特性</p></blockquote><p>这是什么意思呢？</p><p>在 Kubernetes 中，有几种特殊的 Volume，它们存在的意义不是为了存放容器里的数据，也不是用来进行容器和宿主机之间的数据交换。这些特殊 Volume 的作用，是为容器提供预先定义好的数据。所以，从容器的角度来看，这些 Volume 里的信息就是仿佛是<strong>被 Kubernetes“投射”（Project）进入容器当中的</strong>。这正是 Projected Volume 的含义。</p><p>到目前为止，Kubernetes 支持的 Projected Volume 一共有四种：</p><ol><li>Secret；</li><li>ConfigMap；</li><li>Downward API；</li><li>ServiceAccountToken。</li></ol><p>在今天这篇文章中，<strong>我首先和你分享的是 Secret。</strong>它的作用，是帮你把 Pod 想要访问的加密数据，存放到 Etcd 中。然后，你就可以通过在 Pod 的容器里挂载 Volume 的方式，访问到这些 Secret 里保存的信息了。</p><p>Secret 最典型的使用场景，莫过于存放数据库的 Credential 信息，比如下面这个例子：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-projected-volume</span> </span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-secret-volume</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">args:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">sleep</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">"86400"</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql-cred</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">"/projected-volume"</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mysql-cred</span></span><br><span class="line">    <span class="attr">projected:</span></span><br><span class="line">      <span class="attr">sources:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">secret:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">user</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">secret:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">pass</span></span><br></pre></td></tr></table></figure><p>在这个 Pod 中，我定义了一个简单的容器。它声明挂载的 Volume，并不是常见的 emptyDir 或者 hostPath 类型，而是 projected 类型。而这个 Volume 的数据来源（sources），则是名为 user 和 pass 的 Secret 对象，分别对应的是数据库的用户名和密码。</p><p>这里用到的数据库的用户名、密码，正是以 Secret 对象的方式交给 Kubernetes 保存的。完成这个操作的指令，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ cat ./username.txt</span><br><span class="line">admin</span><br><span class="line">$ cat ./password.txt</span><br><span class="line">c1oudc0w!</span><br><span class="line"> </span><br><span class="line">$ kubectl create secret generic user --from-file=./username.txt</span><br><span class="line">$ kubectl create secret generic pass --from-file=./password.txt</span><br></pre></td></tr></table></figure><p>其中，username.txt 和 password.txt 文件里，存放的就是用户名和密码；而 user 和 pass，则是我为 Secret 对象指定的名字。而我想要查看这些 Secret 对象的话，只要执行一条 kubectl get 命令就可以了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get secrets</span><br><span class="line">NAME           TYPE                                DATA      AGE</span><br><span class="line">user          Opaque                                1         51s</span><br><span class="line">pass          Opaque                                1         51s</span><br></pre></td></tr></table></figure><p>当然，除了使用 kubectl create secret 指令外，我也可以直接通过编写 YAML 文件的方式来创建这个 Secret 对象，比如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">user:</span> <span class="string">YWRtaW4=</span></span><br><span class="line">  <span class="attr">pass:</span> <span class="string">MWYyZDFlMmU2N2Rm</span></span><br></pre></td></tr></table></figure><p>可以看到，通过编写 YAML 文件创建出来的 Secret 对象只有一个。但它的 data 字段，却以 Key-Value 的格式保存了两份 Secret 数据。其中，“user”就是第一份数据的 Key，“pass”是第二份数据的 Key。</p><p>需要注意的是，Secret 对象要求这些数据必须是经过 Base64 转码的，以免出现明文密码的安全隐患。这个转码操作也很简单，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> -n <span class="string">'admin'</span> | base64</span><br><span class="line">YWRtaW4=</span><br><span class="line">$ <span class="built_in">echo</span> -n <span class="string">'1f2d1e2e67df'</span> | base64</span><br><span class="line">MWYyZDFlMmU2N2Rm</span><br></pre></td></tr></table></figure><p>这里需要注意的是，像这样创建的 Secret 对象，它里面的内容仅仅是经过了转码，而并没有被加密。在真正的生产环境中，你需要在 Kubernetes 中开启 Secret 的加密插件，增强数据的安全性。关于开启 Secret 加密插件的内容，我会在后续专门讲解 Secret 的时候，再做进一步说明。</p><p>接下来，我们尝试一下创建这个 Pod：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f <span class="built_in">test</span>-projected-volume.yaml</span><br></pre></td></tr></table></figure><p>当 Pod 变成 Running 状态之后，我们再验证一下这些 Secret 对象是不是已经在容器里了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">exec</span> -it <span class="built_in">test</span>-projected-volume -- /bin/sh</span><br><span class="line">$ ls /projected-volume/</span><br><span class="line">user</span><br><span class="line">pass</span><br><span class="line">$ cat /projected-volume/user</span><br><span class="line">root</span><br><span class="line">$ cat /projected-volume/pass</span><br><span class="line">1f2d1e2e67df</span><br></pre></td></tr></table></figure><p>从返回结果中，我们可以看到，保存在 Etcd 里的用户名和密码信息，已经以文件的形式出现在了容器的 Volume 目录里。而这个文件的名字，就是 kubectl create secret 指定的 Key，或者说是 Secret 对象的 data 字段指定的 Key。</p><p>更重要的是，像这样通过挂载方式进入到容器里的 Secret，一旦其对应的 Etcd 里的数据被更新，这些 Volume 里的文件内容，同样也会被更新。其实，<strong>这是 kubelet 组件在定时维护这些 Volume。</strong></p><p>需要注意的是，这个更新可能会有一定的延时。所以<strong>在编写应用程序时，在发起数据库连接的代码处写好重试和超时的逻辑，绝对是个好习惯。</strong></p><p><strong>与 Secret 类似的是 ConfigMap</strong>，它与 Secret 的区别在于，ConfigMap 保存的是不需要加密的、应用所需的配置信息。而 ConfigMap 的用法几乎与 Secret 完全相同：你可以使用 kubectl create configmap 从文件或者目录创建 ConfigMap，也可以直接编写 ConfigMap 对象的 YAML 文件。</p><p>比如，一个 Java 应用所需的配置文件（.properties 文件），就可以通过下面这样的方式保存在 ConfigMap 里：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># .properties 文件的内容</span></span><br><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">example/ui.properties</span></span><br><span class="line"><span class="string">color.good=purple</span></span><br><span class="line"><span class="string">color.bad=yellow</span></span><br><span class="line"><span class="string">allow.textmode=true</span></span><br><span class="line"><span class="string">how.nice.to.look=fairlyNice</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 从.properties 文件创建 ConfigMap</span></span><br><span class="line"><span class="string">$</span> <span class="string">kubectl</span> <span class="string">create</span> <span class="string">configmap</span> <span class="string">ui-config</span> <span class="string">--from-file=example/ui.properties</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 查看这个 ConfigMap 里保存的信息 (data)</span></span><br><span class="line"><span class="string">$</span> <span class="string">kubectl</span> <span class="string">get</span> <span class="string">configmaps</span> <span class="string">ui-config</span> <span class="string">-o</span> <span class="string">yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">ui.properties:</span> <span class="string">|</span></span><br><span class="line">    <span class="string">color.good=purple</span></span><br><span class="line">    <span class="string">color.bad=yellow</span></span><br><span class="line">    <span class="string">allow.textmode=true</span></span><br><span class="line">    <span class="string">how.nice.to.look=fairlyNice</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ui-config</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure><blockquote><p>备注：kubectl get -o yaml 这样的参数，会将指定的 Pod API 对象以 YAML 的方式展示出来。</p></blockquote><p>接下来是 Downward API，它的作用是：让 Pod 里的容器能够直接获取到这个 Pod API 对象本身的信息。</p><p>举个例子：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-downwardapi-volume</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">zone:</span> <span class="string">us-est-coast</span></span><br><span class="line">    <span class="attr">cluster:</span> <span class="string">test-cluster1</span></span><br><span class="line">    <span class="attr">rack:</span> <span class="string">rack-22</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">client-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">k8s.gcr.io/busybox</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">["sh",</span> <span class="string">"-c"</span><span class="string">]</span></span><br><span class="line">      <span class="attr">args:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">while</span> <span class="literal">true</span><span class="string">;</span> <span class="string">do</span></span><br><span class="line">          <span class="string">if</span> <span class="string">[[</span> <span class="string">-e</span> <span class="string">/etc/podinfo/labels</span> <span class="string">]];</span> <span class="string">then</span></span><br><span class="line">            <span class="string">echo</span> <span class="string">-en</span> <span class="string">'\n\n'</span><span class="string">;</span> <span class="string">cat</span> <span class="string">/etc/podinfo/labels;</span> <span class="string">fi;</span></span><br><span class="line">          <span class="string">sleep</span> <span class="number">5</span><span class="string">;</span></span><br><span class="line">        <span class="string">done;</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">podinfo</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/podinfo</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">podinfo</span></span><br><span class="line">      <span class="attr">projected:</span></span><br><span class="line">        <span class="attr">sources:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">downwardAPI:</span></span><br><span class="line">            <span class="attr">items:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">"labels"</span></span><br><span class="line">                <span class="attr">fieldRef:</span></span><br><span class="line">                  <span class="attr">fieldPath:</span> <span class="string">metadata.labels</span></span><br></pre></td></tr></table></figure><p>在这个 Pod 的 YAML 文件中，我定义了一个简单的容器，声明了一个 projected 类型的 Volume。只不过这次 Volume 的数据来源，变成了 Downward API。而这个 Downward API Volume，则声明了要暴露 Pod 的 metadata.labels 信息给容器。</p><p>通过这样的声明方式，当前 Pod 的 Labels 字段的值，就会被 Kubernetes 自动挂载成为容器里的 /etc/podinfo/labels 文件。</p><p>而这个容器的启动命令，则是不断打印出 /etc/podinfo/labels 里的内容。所以，当我创建了这个 Pod 之后，就可以通过 kubectl logs 指令，查看到这些 Labels 字段被打印出来，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f dapi-volume.yaml</span><br><span class="line">$ kubectl logs <span class="built_in">test</span>-downwardapi-volume</span><br><span class="line">cluster=<span class="string">"test-cluster1"</span></span><br><span class="line">rack=<span class="string">"rack-22"</span></span><br><span class="line">zone=<span class="string">"us-est-coast"</span></span><br></pre></td></tr></table></figure><p>目前，Downward API 支持的字段已经非常丰富了，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">1. 使用 fieldRef 可以声明使用:</span><br><span class="line">spec.nodeName - 宿主机名字</span><br><span class="line">status.hostIP - 宿主机 IP</span><br><span class="line">metadata.name - Pod 的名字</span><br><span class="line">metadata.namespace - Pod 的 Namespace</span><br><span class="line">status.podIP - Pod 的 IP</span><br><span class="line">spec.serviceAccountName - Pod 的 Service Account 的名字</span><br><span class="line">metadata.uid - Pod 的 UID</span><br><span class="line">metadata.labels[<span class="string">'&lt;KEY&gt;'</span>] - 指定 &lt;KEY&gt; 的 Label 值</span><br><span class="line">metadata.annotations[<span class="string">'&lt;KEY&gt;'</span>] - 指定 &lt;KEY&gt; 的 Annotation 值</span><br><span class="line">metadata.labels - Pod 的所有 Label</span><br><span class="line">metadata.annotations - Pod 的所有 Annotation</span><br><span class="line"> </span><br><span class="line">2. 使用 resourceFieldRef 可以声明使用:</span><br><span class="line">容器的 CPU <span class="built_in">limit</span></span><br><span class="line">容器的 CPU request</span><br><span class="line">容器的 memory <span class="built_in">limit</span></span><br><span class="line">容器的 memory request</span><br></pre></td></tr></table></figure><p>上面这个列表的内容，随着 Kubernetes 项目的发展肯定还会不断增加。所以这里列出来的信息仅供参考，你在使用 Downward API 时，还是要记得去查阅一下官方文档。</p><p>不过，需要注意的是，Downward API 能够获取到的信息，<strong>一定是 Pod 里的容器进程启动之前就能够确定下来的信息</strong>。而如果你想要获取 Pod 容器运行后才会出现的信息，比如，容器进程的 PID，那就肯定不能使用 Downward API 了，而应该考虑在 Pod 里定义一个 sidecar 容器。</p><p>其实，Secret、ConfigMap，以及 Downward API 这三种 Projected Volume 定义的信息，大多还可以通过环境变量的方式出现在容器里。但是，通过环境变量获取这些信息的方式，不具备自动更新的能力。所以，一般情况下，我都建议你使用 Volume 文件的方式获取这些信息。</p><p>在明白了 Secret 之后，我再为你讲解 Pod 中一个与它密切相关的概念：Service Account。</p><p>相信你一定有过这样的想法：我现在有了一个 Pod，我能不能在这个 Pod 里安装一个 Kubernetes 的 Client，这样就可以从容器里直接访问并且操作这个 Kubernetes 的 API 了呢？</p><p>这当然是可以的。</p><p>不过，你首先要解决 API Server 的授权问题。</p><p>Service Account 对象的作用，就是 Kubernetes 系统内置的一种“服务账户”，它是 Kubernetes 进行权限分配的对象。比如，Service Account A，可以只被允许对 Kubernetes API 进行 GET 操作，而 Service Account B，则可以有 Kubernetes API 的所有操作的权限。</p><p>像这样的 Service Account 的授权信息和文件，实际上保存在它所绑定的一个特殊的 Secret 对象里的。这个特殊的 Secret 对象，就叫作<strong>ServiceAccountToken</strong>。任何运行在 Kubernetes 集群上的应用，都必须使用这个 ServiceAccountToken 里保存的授权信息，也就是 Token，才可以合法地访问 API Server。</p><p>所以说，Kubernetes 项目的 Projected Volume 其实只有三种，因为第四种 ServiceAccountToken，只是一种特殊的 Secret 而已。</p><p>另外，为了方便使用，Kubernetes 已经为你提供了一个的默认“服务账户”（default Service Account）。并且，任何一个运行在 Kubernetes 里的 Pod，都可以直接使用这个默认的 Service Account，而无需显示地声明挂载它。</p><p><strong>这是如何做到的呢？</strong></p><p>当然还是靠 Projected Volume 机制。</p><p>如果你查看一下任意一个运行在 Kubernetes 集群里的 Pod，就会发现，每一个 Pod，都已经自动声明一个类型是 Secret、名为 default-token-xxxx 的 Volume，然后 自动挂载在每个容器的一个固定目录上。比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod nginx-deployment-5c678cfb6d-lg9lw</span><br><span class="line">Containers:</span><br><span class="line">...</span><br><span class="line">  Mounts:</span><br><span class="line">    /var/run/secrets/kubernetes.io/serviceaccount from default-token-s8rbq (ro)</span><br><span class="line">Volumes:</span><br><span class="line">  default-token-s8rbq:</span><br><span class="line">  Type:       Secret (a volume populated by a Secret)</span><br><span class="line">  SecretName:  default-token-s8rbq</span><br><span class="line">  Optional:    <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>这个 Secret 类型的 Volume，正是默认 Service Account 对应的 ServiceAccountToken。所以说，Kubernetes 其实在每个 Pod 创建的时候，自动在它的 spec.volumes 部分添加上了默认 ServiceAccountToken 的定义，然后自动给每个容器加上了对应的 volumeMounts 字段。这个过程对于用户来说是完全透明的。</p><p>这样，一旦 Pod 创建完成，容器里的应用就可以直接从这个默认 ServiceAccountToken 的挂载目录里访问到授权信息和文件。这个容器内的路径在 Kubernetes 里是固定的，即：/var/run/secrets/kubernetes.io/serviceaccount ，而这个 Secret 类型的 Volume 里面的内容如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /var/run/secrets/kubernetes.io/serviceaccount </span><br><span class="line">ca.crt namespace  token</span><br></pre></td></tr></table></figure><p>所以，你的应用程序只要直接加载这些授权文件，就可以访问并操作 Kubernetes API 了。而且，如果你使用的是 Kubernetes 官方的 Client 包（k8s.io/client-go）的话，它还可以自动加载这个目录下的文件，你不需要做任何配置或者编码操作。</p><p><strong>这种把 Kubernetes 客户端以容器的方式运行在集群里，然后使用 default Service Account 自动授权的方式，被称作“InClusterConfig”，也是我最推荐的进行 Kubernetes API 编程的授权方式。</strong></p><p>当然，考虑到自动挂载默认 ServiceAccountToken 的潜在风险，Kubernetes 允许你设置默认不为 Pod 里的容器自动挂载这个 Volume。</p><p>除了这个默认的 Service Account 外，我们很多时候还需要创建一些我们自己定义的 Service Account，来对应不同的权限设置。这样，我们的 Pod 里的容器就可以通过挂载这些 Service Account 对应的 ServiceAccountToken，来使用这些自定义的授权信息。在后面讲解为 Kubernetes 开发插件的时候，我们将会实践到这个操作。</p><p><strong>接下来，我们再来看 Pod 的另一个重要的配置：容器健康检查和恢复机制。</strong> </p><p>在 Kubernetes 中，你可以为 Pod 里的容器定义一个健康检查“探针”（Probe）。这样，kubelet 就会根据这个 Probe 的返回值决定这个容器的状态，而不是直接以容器进行是否运行（来自 Docker 返回的信息）作为依据。这种机制，是生产环境中保证应用健康存活的重要手段。</p><p>我们一起来看一个 Kubernetes 文档中的例子。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">test:</span> <span class="string">liveness</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-liveness-exec</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">    <span class="attr">args:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">touch</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">30</span><span class="string">;</span> <span class="string">rm</span> <span class="string">-rf</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">600</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">      <span class="attr">exec:</span></span><br><span class="line">        <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">cat</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">/tmp/healthy</span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">5</span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">5</span></span><br></pre></td></tr></table></figure><p>在这个 Pod 中，我们定义了一个有趣的容器。它在启动之后做的第一件事，就是在 /tmp 目录下创建了一个 healthy 文件，以此作为自己已经正常运行的标志。而 30 s 过后，它会把这个文件删除掉。</p><p>与此同时，我们定义了一个这样的 livenessProbe（健康检查）。它的类型是 exec，这意味着，它会在容器启动后，在容器里面执行一句我们指定的命令，比如：“cat /tmp/healthy”。这时，如果这个文件存在，这条命令的返回值就是 0，Pod 就会认为这个容器不仅已经启动，而且是健康的。这个健康检查，在容器启动 5 s 后开始执行（initialDelaySeconds: 5），每 5 s 执行一次（periodSeconds: 5）。</p><p>现在，让我们来具体实践一下这个过程。</p><p>首先，创建这个 Pod：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f <span class="built_in">test</span>-liveness-exec.yaml</span><br></pre></td></tr></table></figure><p>然后，查看这个 Pod 的状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod</span><br><span class="line">NAME                READY     STATUS    RESTARTS   AGE</span><br><span class="line"><span class="built_in">test</span>-liveness-exec   1/1       Running   0          10s</span><br></pre></td></tr></table></figure><p>可以看到，由于已经通过了健康检查，这个 Pod 就进入了 Running 状态。</p><p>而 30 s 之后，我们再查看一下 Pod 的 Events：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod <span class="built_in">test</span>-liveness-exec</span><br></pre></td></tr></table></figure><p>你会发现，这个 Pod 在 Events 报告了一个异常：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FirstSeen LastSeen    Count   From            SubobjectPath           Type        Reason      Message</span><br><span class="line">--------- --------    -----   ----            -------------           --------    ------      -------</span><br><span class="line">2s        2s      1   &#123;kubelet worker0&#125;   spec.containers&#123;liveness&#125;   Warning     Unhealthy   Liveness probe failed: cat: can<span class="string">'t open '</span>/tmp/healthy<span class="string">': No such file or directory</span></span><br></pre></td></tr></table></figure><p>显然，这个健康检查探查到 /tmp/healthy 已经不存在了，所以它报告容器是不健康的。那么接下来会发生什么呢？</p><p>我们不妨再次查看一下这个 Pod 的状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod <span class="built_in">test</span>-liveness-exec</span><br><span class="line">NAME           READY     STATUS    RESTARTS   AGE</span><br><span class="line">liveness-exec   1/1       Running   1          1m</span><br></pre></td></tr></table></figure><p>这时我们发现，Pod 并没有进入 Failed 状态，而是保持了 Running 状态。这是为什么呢？</p><p>其实，如果你注意到 RESTARTS 字段从 0 到 1 的变化，就明白原因了：这个异常的容器已经被 Kubernetes 重启了。在这个过程中，Pod 保持 Running 状态不变。</p><p>需要注意的是：Kubernetes 中并没有 Docker 的 Stop 语义。所以虽然是 Restart（重启），但实际却是重新创建了容器。</p><p>这个功能就是 Kubernetes 里的<strong>Pod 恢复机制</strong>，也叫 restartPolicy。它是 Pod 的 Spec 部分的一个标准字段（pod.spec.restartPolicy），默认值是 Always，即：任何时候这个容器发生了异常，它一定会被重新创建。</p><p>但一定要强调的是，Pod 的恢复过程，永远都是发生在当前节点上，而不会跑到别的节点上去。事实上，一旦一个 Pod 与一个节点（Node）绑定，除非这个绑定发生了变化（pod.spec.node 字段被修改），否则它永远都不会离开这个节点。这也就意味着，如果这个宿主机宕机了，这个 Pod 也不会主动迁移到其他节点上去。</p><p>而如果你想让 Pod 出现在其他的可用节点上，就必须使用 Deployment 这样的“控制器”来管理 Pod，哪怕你只需要一个 Pod 副本。这就是我《牛刀小试：我的第一个容器化应用》最后给你留的思考题的答案，即一个单 Pod 的 Deployment 与一个 Pod 最主要的区别。</p><p>而作为用户，你还可以通过设置 restartPolicy，改变 Pod 的恢复策略。除了 Always，它还有 OnFailure 和 Never 两种情况：</p><ul><li>Always：在任何情况下，只要容器不在运行状态，就自动重启容器；</li><li>OnFailure: 只在容器 异常时才自动重启容器；</li><li>Never: 从来不重启容器。</li></ul><p>在实际使用时，我们需要根据应用运行的特性，合理设置这三种恢复策略。</p><p>比如，一个 Pod，它只计算 1+1=2，计算完成输出结果后退出，变成 Succeeded 状态。这时，你如果再用 restartPolicy=Always 强制重启这个 Pod 的容器，就没有任何意义了。</p><p>而如果你要关心这个容器退出后的上下文环境，比如容器退出后的日志、文件和目录，就需要将 restartPolicy 设置为 Never。因为一旦容器被自动重新创建，这些内容就有可能丢失掉了（被垃圾回收了）。</p><p>值得一提的是，Kubernetes 的官方文档，把 restartPolicy 和 Pod 里容器的状态，以及 Pod 状态的对应关系，<a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#example-states" target="_blank" rel="noopener">总结了非常复杂的一大堆情况</a>。实际上，你根本不需要死记硬背这些对应关系，只要记住如下两个基本的设计原理即可：</p><ol><li><strong>只要 Pod 的 restartPolicy 指定的策略允许重启异常的容器（比如：Always），那么这个 Pod 就会保持 Running 状态，并进行容器重启</strong>。否则，Pod 就会进入 Failed 状态 。</li><li><strong>对于包含多个容器的 Pod，只有它里面所有的容器都进入异常状态后，Pod 才会进入 Failed 状态</strong>。在此之前，Pod 都是 Running 状态。此时，Pod 的 READY 字段会显示正常容器的个数，比如：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod <span class="built_in">test</span>-liveness-exec</span><br><span class="line">NAME           READY     STATUS    RESTARTS   AGE</span><br><span class="line">liveness-exec   0/1       Running   1          1m</span><br></pre></td></tr></table></figure><p>所以，假如一个 Pod 里只有一个容器，然后这个容器异常退出了。那么，只有当 restartPolicy=Never 时，这个 Pod 才会进入 Failed 状态。而其他情况下，由于 Kubernetes 都可以重启这个容器，所以 Pod 的状态保持 Running 不变。</p><p>而如果这个 Pod 有多个容器，仅有一个容器异常退出，它就始终保持 Running 状态，哪怕即使 restartPolicy=Never。只有当所有容器也异常退出之后，这个 Pod 才会进入 Failed 状态。</p><p>其他情况，都可以以此类推出来。</p><p>现在，我们一起回到前面提到的 livenessProbe 上来。</p><p>除了在容器中执行命令外，livenessProbe 也可以定义为发起 HTTP 或者 TCP 请求的方式，定义格式如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">livenessProbe:</span></span><br><span class="line">     <span class="attr">httpGet:</span></span><br><span class="line">       <span class="attr">path:</span> <span class="string">/healthz</span></span><br><span class="line">       <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">       <span class="attr">httpHeaders:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">X-Custom-Header</span></span><br><span class="line">         <span class="attr">value:</span> <span class="string">Awesome</span></span><br><span class="line">       <span class="attr">initialDelaySeconds:</span> <span class="number">3</span></span><br><span class="line">       <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">livenessProbe:</span></span><br><span class="line">  <span class="attr">tcpSocket:</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">8080</span></span><br><span class="line">  <span class="attr">initialDelaySeconds:</span> <span class="number">15</span></span><br><span class="line">  <span class="attr">periodSeconds:</span> <span class="number">20</span></span><br></pre></td></tr></table></figure><p>所以，你的 Pod 其实可以暴露一个健康检查 URL（比如 /healthz），或者直接让健康检查去检测应用的监听端口。这两种配置方法，在 Web 服务类的应用中非常常用。</p><p>在 Kubernetes 的 Pod 中，还有一个叫 readinessProbe 的字段。虽然它的用法与 livenessProbe 类似，但作用却大不一样。readinessProbe 检查结果的成功与否，决定的这个 Pod 是不是能被通过 Service 的方式访问到，而并不影响 Pod 的生命周期。这部分内容，我会留在讲解 Service 时再重点介绍。</p><p>在讲解了这么多字段之后，想必你对 Pod 对象的语义和描述能力，已经有了一个初步的感觉。</p><p>这时，你有没有产生这样一个想法：Pod 的字段这么多，我又不可能全记住，<strong>Kubernetes 能不能自动给 Pod 填充某些字段呢？</strong></p><p>这个需求实际上非常实用。比如，开发人员只需要提交一个基本的、非常简单的 Pod YAML，Kubernetes 就可以自动给对应的 Pod 对象加上其他必要的信息，比如 labels，annotations，volumes 等等。而这些信息，可以是运维人员事先定义好的。</p><p>这么一来，开发人员编写 Pod YAML 的门槛，就被大大降低了。</p><p>所以，这个叫作 PodPreset（Pod 预设置）的功能 已经出现在了 v1.11 版本的 Kubernetes 中。</p><p>举个例子，现在开发人员编写了如下一个 pod.yaml 文件：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">website</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">website</span></span><br><span class="line">    <span class="attr">role:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">website</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>作为 Kubernetes 的初学者，你肯定眼前一亮：这不就是我最擅长编写的、最简单的 Pod 嘛。没错，这个 YAML 文件里的字段，想必你现在闭着眼睛也能写出来。</p><p>可是，如果运维人员看到了这个 Pod，他一定会连连摇头：这种 Pod 在生产环境里根本不能用啊！</p><p>所以，这个时候，运维人员就可以定义一个 PodPreset 对象。在这个对象中，凡是他想在开发人员编写的 Pod 里追加的字段，都可以预先定义好。比如这个 preset.yaml：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">settings.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PodPreset</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">allow-database</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">role:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">env:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">DB_PORT</span></span><br><span class="line">      <span class="attr">value:</span> <span class="string">"6379"</span></span><br><span class="line">  <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/cache</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">cache-volume</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cache-volume</span></span><br><span class="line">      <span class="attr">emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><p>在这个 PodPreset 的定义中，首先是一个 selector。这就意味着后面这些追加的定义，只会作用于 selector 所定义的、带有“role: frontend”标签的 Pod 对象，这就可以防止“误伤”。</p><p>然后，我们定义了一组 Pod 的 Spec 里的标准字段，以及对应的值。比如，env 里定义了 DB_PORT 这个环境变量，volumeMounts 定义了容器 Volume 的挂载目录，volumes 定义了一个 emptyDir 的 Volume。</p><p>接下来，我们假定运维人员先创建了这个 PodPreset，然后开发人员才创建 Pod：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f preset.yaml</span><br><span class="line">$ kubectl create -f pod.yaml</span><br></pre></td></tr></table></figure><p>这时，Pod 运行起来之后，我们查看一下这个 Pod 的 API 对象：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod website -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: website</span><br><span class="line">  labels:</span><br><span class="line">    app: website</span><br><span class="line">    role: frontend</span><br><span class="line">  annotations:</span><br><span class="line">    podpreset.admission.kubernetes.io/podpreset-allow-database: <span class="string">"resource version"</span></span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">    - name: website</span><br><span class="line">      image: nginx</span><br><span class="line">      volumeMounts:</span><br><span class="line">        - mountPath: /cache</span><br><span class="line">          name: cache-volume</span><br><span class="line">      ports:</span><br><span class="line">        - containerPort: 80</span><br><span class="line">      env:</span><br><span class="line">        - name: DB_PORT</span><br><span class="line">          value: <span class="string">"6379"</span></span><br><span class="line">  volumes:</span><br><span class="line">    - name: cache-volume</span><br><span class="line">      emptyDir: &#123;&#125;</span><br></pre></td></tr></table></figure><p>这个时候，我们就可以清楚地看到，这个 Pod 里多了新添加的 labels、env、volumes 和 volumeMount 的定义，它们的配置跟 PodPreset 的内容一样。此外，这个 Pod 还被自动加上了一个 annotation 表示这个 Pod 对象被 PodPreset 改动过。</p><p><strong>需要说明的是，PodPreset 里定义的内容，只会在 Pod API 对象被创建之前追加在这个对象本身上，而不会影响任何 Pod 的控制器的定义。</strong></p><p>比如，我们现在提交的是一个 nginx-deployment，那么这个 Deployment 对象本身是永远不会被 PodPreset 改变的，被修改的只是这个 Deployment 创建出来的所有 Pod。这一点请务必区分清楚。</p><p>这里有一个问题：如果你定义了同时作用于一个 Pod 对象的多个 PodPreset，会发生什么呢？</p><p>实际上，Kubernetes 项目会帮你合并（Merge）这两个 PodPreset 要做的修改。而如果它们要做的修改有冲突的话，这些冲突字段就不会被修改。</p><p><strong>小结</strong></p><p>在今天这篇文章中，我和你详细介绍了 Pod 对象更高阶的使用方法，希望通过对这些实例的讲解，你可以更深入地理解 Pod API 对象的各个字段。</p><p>而在学习这些字段的同时，你还应该认真体会一下 Kubernetes“一切皆对象”的设计思想：比如应用是 Pod 对象，应用的配置是 ConfigMap 对象，应用要访问的密码则是 Secret 对象。</p><p>所以，也就自然而然地有了 PodPreset 这样专门用来对 Pod 进行批量化、自动化修改的工具对象。在后面的内容中，我会为你讲解更多的这种对象，还会和你介绍 Kubernetes 项目如何围绕着这些对象进行容器编排。</p><p>在本专栏中，Pod 对象相关的知识点非常重要，它是接下来 Kubernetes 能够描述和编排各种复杂应用的基石所在，希望你能够继续多实践、多体会。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《深入剖析 Kubernetes》</li><li>《Kubernetes 原理剖析与实战应用》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://kubernetes.io" target="_blank" rel="noopener">https://kubernetes.io</a></li><li><a href="/back-end/k8s/k8s-installation-kubeadm">Kubeadm 部署 Kubernetes</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes 集群搭建与实践、深入解析Pod对象。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://blog.lichao.xin/categories/Kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="https://blog.lichao.xin/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>重学 K8s 之 容器的前世今生</title>
    <link href="https://blog.lichao.xin/back-end/k8s/k8s-01/"/>
    <id>https://blog.lichao.xin/back-end/k8s/k8s-01/</id>
    <published>2021-05-02T10:20:00.000Z</published>
    <updated>2021-06-14T01:33:22.391Z</updated>
    
    <content type="html"><![CDATA[<p>预习容器的前世今生</p><a id="more"></a><h2 id="预习篇-小鲸鱼大事记（一）：初出茅庐"><a href="#预习篇-小鲸鱼大事记（一）：初出茅庐" class="headerlink" title="预习篇 - 小鲸鱼大事记（一）：初出茅庐"></a>预习篇 - 小鲸鱼大事记（一）：初出茅庐</h2><p>2013 年的后端技术领域，已经太久没有出现过令人兴奋的东西了。曾经被人们寄予厚望的云计算技术，也已经从当初虚无缥缈的概念蜕变成了实实在在的虚拟机和账单。而相比于的如日中天 AWS 和盛极一时的 OpenStack，以 Cloud Foundry 为代表的开源 PaaS 项目，却成为了当时云计算技术中的一股清流。</p><p>这时，Cloud Foundry 项目已经基本度过了最艰难的概念普及和用户教育阶段，吸引了包括百度、京东、华为、IBM 等一大批国内外技术厂商，开启了以开源 PaaS 为核心构建平台层服务能力的变革。如果你有机会问问当时的云计算从业者们，他们十有八九都会告诉你：PaaS 的时代就要来了！</p><p>这个说法其实一点儿没错，如果不是后来一个叫 Docker 的开源项目突然冒出来的话。</p><p>事实上，当时还名叫 dotCloud 的 Docker 公司，也是这股 PaaS 热潮中的一份子。只不过相比于 Heroku、Pivotal、Red Hat 等 PaaS 弄潮儿们，dotCloud 公司实在是太微不足道了，而它的主打产品由于跟主流的 Cloud Foundry 社区脱节，长期以来也无人问津。眼看就要被如火如荼的 PaaS 风潮抛弃，dotCloud 公司却做出了这样一个决定：开源自己的容器项目 Docker。</p><p>显然，这个决定在当时根本没人在乎。</p><p>“容器”这个概念从来就不是什么新鲜的东西，也不是 Docker 公司发明的。即使在当时最热门的 PaaS 项目 Cloud Foundry 中，容器也只是其最底层、最没人关注的那一部分。说到这里，我正好以当时的事实标准 Cloud Foundry 为例，来解说一下 PaaS 技术。</p><p><strong>PaaS 项目被大家接纳的一个主要原因，就是它提供了一种名叫“应用托管”的能力</strong>。 在当时，虚拟机和云计算已经是比较普遍的技术和服务了，那时主流用户的普遍用法，就是租一批 AWS 或者 OpenStack 的虚拟机，然后像以前管理物理服务器那样，用脚本或者手工的方式在这些机器上部署应用。</p><p>当然，这个部署过程难免会碰到云端虚拟机和本地环境不一致的问题，所以当时的云计算服务，比的就是谁能更好地模拟本地服务器环境，能带来更好的“上云”体验。而 PaaS 开源项目的出现，就是当时解决这个问题的一个最佳方案。</p><p>举个例子，虚拟机创建好之后，运维人员只需要在这些机器上部署一个 Cloud Foundry 项目，然后开发者只要执行一条命令就能把本地的应用部署到云上，这条命令就是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cf push <span class="string">" 我的应用 "</span></span><br></pre></td></tr></table></figure><p>是不是很神奇？</p><p>事实上，<strong>像 Cloud Foundry 这样的 PaaS 项目，最核心的组件就是一套应用的打包和分发机制。</strong> Cloud Foundry 为每种主流编程语言都定义了一种打包格式，而“cf push”的作用，基本上等同于用户把应用的可执行文件和启动脚本打进一个压缩包内，上传到云上 Cloud Foundry 的存储中。接着，Cloud Foundry 会通过调度器选择一个可以运行这个应用的虚拟机，然后通知这个机器上的 Agent 把应用压缩包下载下来启动。</p><p>这时候关键来了，由于需要在一个虚拟机上启动很多个来自不同用户的应用，Cloud Foundry 会调用操作系统的 Cgroups 和 Namespace 机制为每一个应用单独创建一个称作“沙盒”的隔离环境，然后在“沙盒”中启动这些应用进程。这样，就实现了把多个用户的应用互不干涉地在虚拟机里批量地、自动地运行起来的目的。</p><p><strong>这，正是 PaaS 项目最核心的能力。</strong> 而这些 Cloud Foundry 用来运行应用的隔离环境，或者说“沙盒”，就是所谓的“容器”。</p><p>而 Docker 项目，实际上跟 Cloud Foundry 的容器并没有太大不同，所以在它发布后不久，Cloud Foundry 的首席产品经理 James Bayer 就在社区里做了一次详细对比，告诉用户 Docker 实际上只是一个同样使用 Cgroups 和 Namespace 实现的“沙盒”而已，没有什么特别的黑科技，也不需要特别关注。</p><p>然而，短短几个月，Docker 项目就迅速崛起了。它的崛起速度如此之快，以至于 Cloud Foundry 以及所有的 PaaS 社区还没来得及成为它的竞争对手，就直接被宣告出局了。那时候，一位多年的 PaaS 从业者曾经如此感慨道：这简直就是一场“降维打击”啊。</p><p>难道这一次，连闯荡多年的“老江湖”James Bayer 也看走眼了么？</p><p>并没有。</p><p>事实上，Docker 项目确实与 Cloud Foundry 的容器在大部分功能和实现原理上都是一样的，可偏偏就是这剩下的一小部分不一样的功能，成了 Docker 项目接下来“呼风唤雨”的不二法宝。</p><p><strong>这个功能，就是 Docker 镜像。</strong></p><p>恐怕连 Docker 项目的作者 Solomon Hykes 自己当时都没想到，这个小小的创新，在短短几年内就如此迅速地改变了整个云计算领域的发展历程。</p><p>我前面已经介绍过，PaaS 之所以能够帮助用户大规模部署应用到集群里，是因为它提供了一套应用打包的功能。可偏偏就是这个打包功能，却成了 PaaS 日后不断遭到用户诟病的一个“软肋”。</p><p>出现这个问题的根本原因是，一旦用上了 PaaS，用户就必须为每种语言、每种框架，甚至每个版本的应用维护一个打好的包。这个打包过程，没有任何章法可循，更麻烦的是，明明在本地运行得好好的应用，却需要做很多修改和配置工作才能在 PaaS 里运行起来。而这些修改和配置，并没有什么经验可以借鉴，基本上得靠不断试错，直到你摸清楚了本地应用和远端 PaaS 匹配的“脾气”才能够搞定。</p><p>最后结局就是，“cf push”确实是能一键部署了，但是为了实现这个一键部署，用户为每个应用打包的工作可谓一波三折，费尽心机。</p><p>而<strong>Docker 镜像解决的，恰恰就是打包这个根本性的问题。</strong> 所谓 Docker 镜像，其实就是一个压缩包。但是这个压缩包里的内容，比 PaaS 的应用可执行文件 + 启停脚本的组合就要丰富多了。实际上，大多数 Docker 镜像是直接由一个完整操作系统的所有文件和目录构成的，所以这个压缩包里的内容跟你本地开发和测试环境用的操作系统是完全一样的。</p><p>这就有意思了：假设你的应用在本地运行时，能看见的环境是 CentOS 7.2 操作系统的所有文件和目录，那么只要用 CentOS 7.2 的 ISO 做一个压缩包，再把你的应用可执行文件也压缩进去，那么无论在哪里解压这个压缩包，都可以得到与你本地测试时一样的环境。当然，你的应用也在里面！</p><p>这就是 Docker 镜像最厉害的地方：只要有这个压缩包在手，你就可以使用某种技术创建一个“沙盒”，在“沙盒”中解压这个压缩包，然后就可以运行你的程序了。</p><p>更重要的是，这个压缩包包含了完整的操作系统文件和目录，也就是包含了这个应用运行所需要的所有依赖，所以你可以先用这个压缩包在本地进行开发和测试，完成之后，再把这个压缩包上传到云端运行。</p><p>在这个过程中，你完全不需要进行任何配置或者修改，因为这个压缩包赋予了你一种极其宝贵的能力：本地环境和云端环境的高度一致！</p><p>这，<strong>正是 Docker 镜像的精髓。</strong></p><p>那么，有了 Docker 镜像这个利器，PaaS 里最核心的打包系统一下子就没了用武之地，最让用户抓狂的打包过程也随之消失了。相比之下，在当今的互联网里，Docker 镜像需要的操作系统文件和目录，可谓唾手可得。</p><p>所以，你只需要提供一个下载好的操作系统文件与目录，然后使用它制作一个压缩包即可，这个命令就是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build <span class="string">" 我的镜像 "</span></span><br></pre></td></tr></table></figure><p>一旦镜像制作完成，用户就可以让 Docker 创建一个“沙盒”来解压这个镜像，然后在“沙盒”中运行自己的应用，这个命令就是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="string">" 我的镜像 "</span></span><br></pre></td></tr></table></figure><p>当然，docker run 创建的“沙盒”，也是使用 Cgroups 和 Namespace 机制创建出来的隔离环境。我会在后面，详细介绍这个机制的实现原理。</p><p>所以，<strong>Docker 项目给 PaaS 世界带来的“降维打击”，其实是提供了一种非常便利的打包机制。这种机制直接打包了应用运行所需要的整个操作系统，从而保证了本地环境和云端环境的高度一致，避免了用户通过“试错”来匹配两种不同运行环境之间差异的痛苦过程。</strong></p><p>而对于开发者们来说，在终于体验到了生产力解放所带来的痛快之后，他们自然选择了用脚投票，直接宣告了 PaaS 时代的结束。</p><p>不过，Docker 项目固然解决了应用打包的难题，但正如前面所介绍的那样，它并不能代替 PaaS 完成大规模部署应用的职责。</p><p>遗憾的是，考虑到 Docker 公司是一个与自己有潜在竞争关系的商业实体，再加上对 Docker 项目普及程度的错误判断，Cloud Foundry 项目并没有第一时间使用 Docker 作为自己的核心依赖，去替换自己那套饱受诟病的打包流程。</p><p>反倒是一些机敏的创业公司，纷纷在第一时间推出了 Docker 容器集群管理的开源项目（比如 Deis 和 Flynn），它们一般称自己为 CaaS，即 Container-as-a-Service，用来跟“过时”的 PaaS 们划清界限。</p><p>而在 2014 年底的 DockerCon 上，Docker 公司雄心勃勃地对外发布了自家研发的“Docker 原生”容器集群管理项目 Swarm，不仅将这波“CaaS”热推向了一个前所未有的高潮，更是寄托了整个 Docker 公司重新定义 PaaS 的宏伟愿望。</p><p>在 2014 年的这段巅峰岁月里，Docker 公司离自己的理想真的只有一步之遥。</p><p><strong>小结</strong></p><p>2013~2014 年，以 Cloud Foundry 为代表的 PaaS 项目，逐渐完成了教育用户和开拓市场的艰巨任务，也正是在这个将概念逐渐落地的过程中，应用“打包”困难这个问题，成了整个后端技术圈子的一块心病。</p><p>Docker 项目的出现，则为这个根本性的问题提供了一个近乎完美的解决方案。这正是 Docker 项目刚刚开源不久，就能够带领一家原本默默无闻的 PaaS 创业公司脱颖而出，然后迅速占领了所有云计算领域头条的技术原因。</p><p>而在成为了基础设施领域近十年难得一见的技术明星之后，dotCloud 公司则在 2013 年底大胆改名为 Docker 公司。不过，这个在当时就颇具争议的改名举动，也成为了日后容器技术圈风云变幻的一个关键伏笔。</p><h2 id="预习篇-小鲸鱼大事记（二）：崭露头角"><a href="#预习篇-小鲸鱼大事记（二）：崭露头角" class="headerlink" title="预习篇 - 小鲸鱼大事记（二）：崭露头角"></a>预习篇 - 小鲸鱼大事记（二）：崭露头角</h2><p>在前面，我说到，伴随着 PaaS 概念的逐步普及，以 Cloud Foundry 为代表的经典 PaaS 项目，开始进入基础设施领域的视野，平台化和 PaaS 化成了这个生态中的一个最为重要的进化趋势。</p><p>就在对开源 PaaS 项目落地的不断尝试中，这个领域的从业者们发现了 PaaS 中最为棘手也最亟待解决的一个问题：究竟如何给应用打包？</p><p>遗憾的是，无论是 Cloud Foundry、OpenShift，还是 Clodify，面对这个问题都没能给出一个完美的答案，反而在竞争中走向了碎片化的歧途。</p><p>而就在这时，一个并不引人瞩目的 PaaS 创业公司 dotCloud，却选择了开源自家的一个容器项目 Docker。更出人意料的是，<strong>就是这样一个普通到不能再普通的技术，却开启了一个名为“Docker”的全新时代。</strong></p><p>你可能会有疑问，Docker 项目的崛起，是不是偶然呢？</p><p>事实上，<strong>这个以“鲸鱼”为注册商标的技术创业公司，最重要的战略之一就是：坚持把“开发者”群体放在至高无上的位置。</strong></p><p>相比于其他正在企业级市场里厮杀得头破血流的经典 PaaS 项目们，Docker 项目的推广策略从一开始就呈现出一副“憨态可掬”的亲人姿态，把每一位后端技术人员（而不是他们的老板）作为主要的传播对象。</p><p>简洁的 UI，有趣的 demo，“1 分钟部署一个 WordPress 网站”“3 分钟部署一个 Nginx 集群”，这种同开发者之间与生俱来的亲近关系，使 Docker 项目迅速成为了全世界 Meetup 上最受欢迎的一颗新星。</p><p>在过去的很长一段时间里，相较于前端和互联网技术社区，服务器端技术社区一直是一个相对沉闷而小众的圈子。在这里，从事 Linux 内核开发的极客们自带“不合群”的“光环”，后端开发者们啃着多年不变的 TCP/IP 发着牢骚，运维更是天生注定的幕后英雄。</p><p>而 Docker 项目，却给后端开发者提供了走向聚光灯的机会。就比如 Cgroups 和 Namespace 这种已经存在多年却很少被人们关心的特性，在 2014 年和 2015 年竟然频繁入选各大技术会议的分享议题，就因为听众们想要知道 Docker 这个东西到底是怎么一回事儿。</p><p><strong>而 Docker 项目之所以能取得如此高的关注，一方面正如前面我所说的那样，它解决了应用打包和发布这一困扰运维人员多年的技术难题；而另一方面，就是因为它第一次把一个纯后端的技术概念，通过非常友好的设计和封装，交到了最广大的开发者群体手里。</strong></p><p>在这种独特的氛围烘托下，你不需要精通 TCP/IP，也无需深谙 Linux 内核原理，哪怕只是一个前端或者网站的 PHP 工程师，都会对如何把自己的代码打包成一个随处可以运行的 Docker 镜像充满好奇和兴趣。</p><p>这种受众群体的变革，正是 Docker 这样一个后端开源项目取得巨大成功的关键。这也是经典 PaaS 项目想做却没有做好的一件事情：PaaS 的最终用户和受益者，一定是为这个 PaaS 编写应用的开发者们，而在 Docker 项目开源之前，PaaS 与开发者之间的关系却从未如此紧密过。</p><p><strong>解决了应用打包这个根本性的问题，同开发者与生俱来的的亲密关系，再加上 PaaS 概念已经深入人心的完美契机，成为 Docker 这个技术上看似平淡无奇的项目一举走红的重要原因。</strong></p><p>一时之间，“容器化”取代“PaaS 化”成为了基础设施领域最炙手可热的关键词，一个以“容器”为中心的、全新的云计算市场，正呼之欲出。而作为这个生态的一手缔造者，此时的 dotCloud 公司突然宣布将公司名称改为“Docker”。</p><p>这个举动，在当时颇受质疑。在大家印象中，Docker 只是一个开源项目的名字。可是现在，这个单词却成了 Docker 公司的注册商标，任何人在商业活动中使用这个单词，以及鲸鱼的 Logo，都会立刻受到法律警告。</p><p>那么，Docker 公司这个举动到底卖的什么药？这个问题，我不妨后面再做解读，因为相较于这件“小事儿”，Docker 公司在 2014 年发布 Swarm 项目才是真正的“大事儿”。</p><p>那么，Docker 公司为什么一定要发布 Swarm 项目呢？</p><p>通过我对 Docker 项目崛起背后原因的分析，你应该能发现这样一个有意思的事实：虽然通过“容器”这个概念完成了对经典 PaaS 项目的“降维打击”，但是 Docker 项目和 Docker 公司，兜兜转转了一年多，却还是回到了 PaaS 项目原本深耕了多年的那个战场：<strong>如何让开发者把应用部署在我的项目上。</strong></p><p>没错，Docker 项目从发布之初就全面发力，从技术、社区、商业、市场全方位争取到的开发者群体，实际上是为此后吸引整个生态到自家“PaaS”上的一个铺垫。<strong>只不过这时，“PaaS”的定义已经全然不是 Cloud Foundry 描述的那个样子，而是变成了一套以 Docker 容器为技术核心，以 Docker 镜像为打包标准的、全新的“容器化”思路。</strong></p><p>这，正是 Docker 项目从一开始悉心运作“容器化”理念和经营整个 Docker 生态的主要目的。</p><p>而 Swarm 项目，正是接下来承接 Docker 公司所有这些努力的关键所在。</p><p><strong>小结</strong></p><p>今天，我着重介绍了 Docker 项目在短时间内迅速崛起的三个重要原因：</p><ol><li>Docker 镜像通过技术手段解决了 PaaS 的根本性问题；</li><li>Docker 容器同开发者之间有着与生俱来的密切关系；</li><li>PaaS 概念已经深入人心的完美契机。</li></ol><p>崭露头角的 Docker 公司，也终于能够以一个更加强硬的姿态来面对这个曾经无比强势，但现在却完全不知所措的云计算市场。而 2014 年底的 DockerCon 欧洲峰会，则正式拉开了 Docker 公司扩张的序幕。</p><blockquote><p>无开源不生态，无生态不商业。</p></blockquote><h2 id="预习篇-小鲸鱼大事记（三）：群雄并起"><a href="#预习篇-小鲸鱼大事记（三）：群雄并起" class="headerlink" title="预习篇 - 小鲸鱼大事记（三）：群雄并起"></a>预习篇 - 小鲸鱼大事记（三）：群雄并起</h2><p>在前面，我剖析了 Docker 项目迅速走红背后的技术与非技术原因，也介绍了 Docker 公司开启平台化战略的野心。可是，Docker 公司为什么在 Docker 项目已经取得巨大成功之后，却执意要重新走回那条已经让无数先驱们尘沙折戟的 PaaS 之路呢？</p><p>实际上，Docker 项目一日千里的发展势头，一直伴随着公司管理层和股东们的阵阵担忧。他们心里明白，虽然 Docker 项目备受追捧，但用户们最终要部署的，还是他们的网站、服务、数据库，甚至是云计算业务。</p><p>这就意味着，只有那些能够为用户提供平台层能力的工具，才会真正成为开发者们关心和愿意付费的产品。而 Docker 项目这样一个只能用来创建和启停容器的小工具，最终只能充当这些平台项目的“幕后英雄”。</p><p>而谈到 Docker 项目的定位问题，就不得不说说 Docker 公司的老朋友和老对手 CoreOS 了。</p><p>CoreOS 是一个基础设施领域创业公司。 它的核心产品是一个定制化的操作系统，用户可以按照分布式集群的方式，管理所有安装了这个操作系统的节点。从而，用户在集群里部署和管理应用就像使用单机一样方便了。</p><p>Docker 项目发布后，CoreOS 公司很快就认识到可以把“容器”的概念无缝集成到自己的这套方案中，从而为用户提供更高层次的 PaaS 能力。所以，CoreOS 很早就成了 Docker 项目的贡献者，并在短时间内成为了 Docker 项目中第二重要的力量。</p><p>然而，这段短暂的蜜月期到 2014 年底就草草结束了。CoreOS 公司以强烈的措辞宣布与 Docker 公司停止合作，并直接推出了自己研制的 Rocket（后来叫 rkt）容器。</p><p>这次决裂的根本原因，正是源于 Docker 公司对 Docker 项目定位的不满足。Docker 公司解决这种不满足的方法就是，让 Docker 项目提供更多的平台层能力，即向 PaaS 项目进化。而这，显然与 CoreOS 公司的核心产品和战略发生了严重冲突。</p><p>也就是说，Docker 公司在 2014 年就已经定好了平台化的发展方向，并且绝对不会跟 CoreOS 在平台层面开展任何合作。这样看来，Docker 公司在 2014 年 12 月的 DockerCon 上发布 Swarm 的举动，也就一点都不突然了。</p><p>相较于 CoreOS 是依托于一系列开源项目（比如 Container Linux 操作系统、Fleet 作业调度工具、systemd 进程管理和 rkt 容器），一层层搭建起来的平台产品，Swarm 项目则是以一个完整的整体来对外提供集群管理功能。而 Swarm 的最大亮点，则是它完全使用 Docker 项目原本的容器管理 API 来完成集群管理，比如：</p><ul><li>单机 Docker 项目：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run <span class="string">" 我的容器</span></span><br></pre></td></tr></table></figure><ul><li>多机 Docker 项目：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -H <span class="string">" 我的 Swarm 集群 API 地址 "</span> <span class="string">" 我的容器 "</span></span><br></pre></td></tr></table></figure><p>所以在部署了 Swarm 的多机环境下，用户只需要使用原先的 Docker 指令创建一个容器，这个请求就会被 Swarm 拦截下来处理，然后通过具体的调度算法找到一个合适的 Docker Daemon 运行起来。</p><p>这个操作方式简洁明了，对于已经了解过 Docker 命令行的开发者们也很容易掌握。所以，这样一个“原生”的 Docker 容器集群管理项目一经发布，就受到了已有 Docker 用户群的热捧。而相比之下，CoreOS 的解决方案就显得非常另类，更不用说用户还要去接受完全让人摸不着头脑、新造的容器项目 rkt 了。</p><p>当然，Swarm 项目只是 Docker 公司重新定义“PaaS”的关键一环而已。在 2014 年到 2015 年这段时间里，Docker 项目的迅速走红催生出了一个非常繁荣的“Docker 生态”。在这个生态里，围绕着 Docker 在各个层次进行集成和创新的项目层出不穷。</p><p>而此时已经大红大紫到“不差钱”的<strong>Docker 公司，开始及时地借助这波浪潮通过并购来完善自己的平台层能力。</strong>其中一个最成功的案例，莫过于对 Fig 项目的收购。</p><p>要知道，Fig 项目基本上只是靠两个人全职开发和维护的，可它却是当时 GitHub 上热度堪比 Docker 项目的明星。</p><p><strong>Fig 项目之所以受欢迎，在于它在开发者面前第一次提出了“容器编排”（Container Orchestration）的概念。</strong></p><p>其实，“编排”（Orchestration）在云计算行业里不算是新词汇，它主要是指用户如何通过某些工具或者配置来完成一组虚拟机以及关联资源的定义、配置、创建、删除等工作，然后由云计算平台按照这些指定的逻辑来完成的过程。</p><p>而容器时代，“编排”显然就是对 Docker 容器的一系列定义、配置和创建动作的管理。而 Fig 的工作实际上非常简单：假如现在用户需要部署的是应用容器 A、数据库容器 B、负载均衡容器 C，那么 Fig 就允许用户把 A、B、C 三个容器定义在一个配置文件中，并且可以指定它们之间的关联关系，比如容器 A 需要访问数据库容器 B。</p><p>接下来，你只需要执行一条非常简单的指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ fig up</span><br></pre></td></tr></table></figure><p>Fig 就会把这些容器的定义和配置交给 Docker API 按照访问逻辑依次创建，你的一系列容器就都启动了；而容器 A 与 B 之间的关联关系，也会交给 Docker 的 Link 功能通过写入 hosts 文件的方式进行配置。更重要的是，你还可以在 Fig 的配置文件里定义各种容器的副本个数等编排参数，再加上 Swarm 的集群管理能力，一个活脱脱的 PaaS 呼之欲出。</p><p>Fig 项目被收购后改名为 Compose，它成了 Docker 公司到目前为止第二大受欢迎的项目，一直到今天也依然被很多人使用。</p><p>当时的这个容器生态里，还有很多令人眼前一亮的开源项目或公司。比如，专门负责处理容器网络的 SocketPlane 项目（后来被 Docker 公司收购），专门负责处理容器存储的 Flocker 项目（后来被 EMC 公司收购），专门给 Docker 集群做图形化管理界面和对外提供云服务的 Tutum 项目（后来被 Docker 公司收购）等等。</p><p>一时之间，整个后端和云计算领域的聪明才俊都汇集在了这个“小鲸鱼”的周围，为 Docker 生态的蓬勃发展献上了自己的智慧。</p><p>而除了这个异常繁荣的、围绕着 Docker 项目和公司的生态之外，还有一个势力在当时也是风头无两，这就是老牌集群管理项目 Mesos 和它背后的创业公司 Mesosphere。</p><p>Mesos 作为 Berkeley 主导的大数据套件之一，是大数据火热时最受欢迎的资源管理项目，也是跟 Yarn 项目杀得难舍难分的实力派选手。</p><p>不过，大数据所关注的计算密集型离线业务，其实并不像常规的 Web 服务那样适合用容器进行托管和扩容，也没有对应用打包的强烈需求，所以 Hadoop、Spark 等项目到现在也没在容器技术上投下更大的赌注；但是对于 Mesos 来说，天生的两层调度机制让它非常容易从大数据领域抽身，转而去支持受众更加广泛的 PaaS 业务。</p><p>在这种思路的指导下，Mesosphere 公司发布了一个名为 Marathon 的项目，而这个项目很快就成为了 Docker Swarm 的一个有力竞争对手。</p><p><strong>虽然不能提供像 Swarm 那样的原生 Docker API，Mesos 社区却拥有一个独特的竞争力：超大规模集群的管理经验。</strong></p><p>早在几年前，Mesos 就已经通过了万台节点的验证，2014 年之后又被广泛使用在 eBay 等大型互联网公司的生产环境中。而这次通过 Marathon 实现了诸如应用托管和负载均衡的 PaaS 功能之后，Mesos+Marathon 的组合实际上进化成了一个高度成熟的 PaaS 项目，同时还能很好地支持大数据业务。</p><p>所以，在这波容器化浪潮中，Mesosphere 公司不失时机地提出了一个名叫“DC/OS”（数据中心操作系统）的口号和产品，旨在使用户能够像管理一台机器那样管理一个万级别的物理机集群，并且使用 Docker 容器在这个集群里自由地部署应用。而这，对很多大型企业来说具有着非同寻常的吸引力。</p><p>这时，如果你再去审视当时的容器技术生态，就不难发现 CoreOS 公司竟然显得有些尴尬了。它的 rkt 容器完全打不开局面，Fleet 集群管理项目更是少有人问津，CoreOS 完全被 Docker 公司压制了。</p><p>而处境同样不容乐观的似乎还有 RedHat，作为 Docker 项目早期的重要贡献者，RedHat 也是因为对 Docker 公司平台化战略不满而愤愤退出。但此时，它竟只剩下 OpenShift 这个跟 Cloud Foundry 同时代的经典 PaaS 一张牌可以打，跟 Docker Swarm 和转型后的 Mesos 完全不在同一个“竞技水平”之上。</p><p>那么，事实果真如此吗？</p><p>2014 年注定是一个神奇的年份。就在这一年的 6 月，基础设施领域的翘楚 Google 公司突然发力，正式宣告了一个名叫 Kubernetes 项目的诞生。而这个项目，不仅挽救了当时的 CoreOS 和 RedHat，还如同当年 Docker 项目的横空出世一样，再一次改变了整个容器市场的格局。</p><p><strong>小结</strong></p><p>我分享了 Docker 公司平台化战略的来龙去脉，阐述了 Docker Swarm 项目发布的意义和它背后的设计思想，介绍了 Fig（后来的 Compose）项目如何成为了继 Docker 之后最受瞩目的新星。</p><p>同时，我也和你一起回顾了 2014~2015 年间如火如荼的容器化浪潮里群雄并起的繁荣姿态。在这次生态大爆发中，Docker 公司和 Mesosphere 公司，依托自身优势率先占据了有利位置。</p><p>但是，更强大的挑战者们，即将在不久后纷至沓来。</p><h2 id="预习篇-小鲸鱼大事记（四）：尘埃落定"><a href="#预习篇-小鲸鱼大事记（四）：尘埃落定" class="headerlink" title="预习篇 - 小鲸鱼大事记（四）：尘埃落定"></a>预习篇 - 小鲸鱼大事记（四）：尘埃落定</h2><p>在前面的分享中我提到，伴随着 Docker 公司一手打造出来的容器技术生态在云计算市场中站稳了脚跟，围绕着 Docker 项目进行的各个层次的集成与创新产品，也如雨后春笋般出现在这个新兴市场当中。而 Docker 公司，不失时机地发布了 Docker Compose、Swarm 和 Machine“三件套”，在重新定义 PaaS 的方向上走出了最关键的一步。</p><p>这段时间，也正是 Docker 生态创业公司们的春天，大量围绕着 Docker 项目的网络、存储、监控、CI/CD，甚至 UI 项目纷纷出台，也涌现出了很多 Rancher、Tutum 这样在开源与商业上均取得了巨大成功的创业公司。</p><p>在 2014~2015 年间，整个容器社区可谓热闹非凡。</p><p>这令人兴奋的繁荣背后，却浮现出了更多的担忧。这其中最主要的负面情绪，是对 Docker 公司商业化战略的种种顾虑。</p><p>事实上，很多从业者也都看得明白，Docker 项目此时已经成为 Docker 公司一个商业产品。而开源，只是 Docker 公司吸引开发者群体的一个重要手段。不过这么多年来，开源社区的商业化其实都是类似的思路，无非是高不高调、心不心急的问题罢了。</p><p>而真正令大多数人不满意的是，Docker 公司在 Docker 开源项目的发展上，始终保持着绝对的权威和发言权，并在多个场合用实际行动挑战到了其他玩家（比如，CoreOS、RedHat，甚至谷歌和微软）的切身利益。</p><p>那么，这个时候，大家的不满也就不再是在 GitHub 上发发牢骚这么简单了。</p><p>相信很多容器领域的老玩家们都听说过，Docker 项目刚刚兴起时，Google 也开源了一个在内部使用多年、经历过生产环境验证的 Linux 容器：lmctfy（Let Me Container That For You）。</p><p>然而，面对 Docker 项目的强势崛起，这个对用户没那么友好的 Google 容器项目根本没有招架之力。所以，知难而退的 Google 公司，向 Docker 公司表示了合作的愿望：关停这个项目，和 Docker 公司共同推进一个中立的容器运行时（container runtime）库作为 Docker 项目的核心依赖。</p><p>不过，Docker 公司并没有认同这个明显会削弱自己地位的提议，还在不久后，自己发布了一个容器运行时库 Libcontainer。这次匆忙的、由一家主导的、并带有战略性考量的重构，成了 Libcontainer 被社区长期诟病代码可读性差、可维护性不强的一个重要原因。</p><p>至此，Docker 公司在容器运行时层面上的强硬态度，以及 Docker 项目在高速迭代中表现出来的不稳定和频繁变更的问题，开始让社区叫苦不迭。</p><p>这种情绪在 2015 年达到了一个小高潮，容器领域的其他几位玩家开始商议“切割”Docker 项目的话语权。而“切割”的手段也非常经典，那就是成立一个中立的基金会。</p><p>于是，2015 年 6 月 22 日，由 Docker 公司牵头，CoreOS、Google、RedHat 等公司共同宣布，Docker 公司将 Libcontainer 捐出，并改名为 RunC 项目，交由一个完全中立的基金会管理，然后以 RunC 为依据，大家共同制定一套容器和镜像的标准和规范。</p><p>这套标准和规范，就是 OCI（ Open Container Initiative ）。<strong>OCI 的提出，意在将容器运行时和镜像的实现从 Docker 项目中完全剥离出来。</strong>这样做，一方面可以改善 Docker 公司在容器技术上一家独大的现状，另一方面也为其他玩家不依赖于 Docker 项目构建各自的平台层能力提供了可能。</p><p>不过，不难看出，OCI 的成立更多的是这些容器玩家出于自身利益进行干涉的一个妥协结果。所以，尽管 Docker 是 OCI 的发起者和创始成员，它却很少在 OCI 的技术推进和标准制定等事务上扮演关键角色，也没有动力去积极地推进这些所谓的标准。</p><p>这，也正是迄今为止 OCI 组织效率持续低下的根本原因。</p><p>眼看着 OCI 并没能改变 Docker 公司在容器领域一家独大的现状，Google 和 RedHat 等公司于是把与第二把武器摆上了台面。</p><p>Docker 之所以不担心 OCI 的威胁，原因就在于它的 Docker 项目是容器生态的事实标准，而它所维护的 Docker 社区也足够庞大。可是，一旦这场斗争被转移到容器之上的平台层，或者说 PaaS 层，Docker 公司的竞争优势便立刻捉襟见肘了。</p><p>在这个领域里，像 Google 和 RedHat 这样的成熟公司，都拥有着深厚的技术积累；而像 CoreOS 这样的创业公司，也拥有像 Etcd 这样被广泛使用的开源基础设施项目。</p><p>可是 Docker 公司呢？它却只有一个 Swarm。</p><p>所以这次，Google、RedHat 等开源基础设施领域玩家们，共同牵头发起了一个名为 CNCF（Cloud Native Computing Foundation）的基金会。这个基金会的目的其实很容易理解：它希望，以 Kubernetes 项目为基础，建立一个由开源基础设施领域厂商主导的、按照独立基金会方式运营的平台级社区，来对抗以 Docker 公司为核心的容器商业生态。</p><p>而为了打造出这样一个围绕 Kubernetes 项目的“护城河”，CNCF 社区就需要至少确保两件事情：</p><ol><li>Kubernetes 项目必须能够在容器编排领域取得足够大的竞争优势；</li><li>CNCF 社区必须以 Kubernetes 项目为核心，覆盖足够多的场景。</li></ol><p><strong>我们先来看看 CNCF 社区如何解决 Kubernetes 项目在编排领域的竞争力的问题。</strong></p><p>在容器编排领域，Kubernetes 项目需要面对来自 Docker 公司和 Mesos 社区两个方向的压力。不难看出，Swarm 和 Mesos 实际上分别从两个不同的方向讲出了自己最擅长的故事：Swarm 擅长的是跟 Docker 生态的无缝集成，而 Mesos 擅长的则是大规模集群的调度与管理。</p><p>这两个方向，也是大多数人做容器集群管理项目时最容易想到的两个出发点。也正因为如此，Kubernetes 项目如果继续在这两个方向上做文章恐怕就不太明智了。</p><p>所以这一次，Kubernetes 选择的应对方式是：<strong>Borg。</strong></p><p>如果你看过 Kubernetes 项目早期的 GitHub Issue 和 Feature 的话，就会发现它们大多来自于 <strong>Borg 和 Omega</strong> 系统的内部特性，这些特性落到 Kubernetes 项目上，就是 <strong>Pod、Sidecar</strong> 等功能和设计模式。</p><p>这就解释了，为什么 Kubernetes 发布后，很多人“抱怨”其设计思想过于“超前”的原因：Kubernetes 项目的基础特性，并不是几个工程师突然“拍脑袋”想出来的东西，而是 Google 公司在容器化基础设施领域多年来实践经验的沉淀与升华。这，正是 Kubernetes 项目能够从一开始就避免同 Swarm 和 Mesos 社区同质化的重要手段。</p><p>于是，CNCF 接下来的任务就是，如何把这些先进的思想通过技术手段在开源社区落地，并培育出一个认同这些理念的生态？这时，RedHat 就发挥了重要作用。</p><p>当时，Kubernetes 团队规模很小，能够投入的工程能力也十分紧张，而这恰恰是 RedHat 的长处。更难得的是，RedHat 是世界上为数不多的、能真正理解开源社区运作和项目研发真谛的合作伙伴。</p><p>所以，RedHat 与 Google 联盟的成立，不仅保证了 RedHat 在 Kubernetes 项目上的影响力，也正式开启了容器编排领域“三国鼎立”的局面。</p><p>这时，我们再重新审视容器生态的格局，就不难发现 Kubernetes 项目、Docker 公司和 Mesos 社区这三大玩家的关系已经发生了微妙的变化。</p><p>其中，Mesos 社区与容器技术的关系，更像是“借势”，而不是这个领域真正的参与者和领导者。这个事实，加上它所属的 Apache 社区固有的封闭性，导致了 Mesos 社区虽然技术最为成熟，却在容器编排领域鲜有创新。</p><p>这也是为何，Google 公司很快就把注意力转向了动作更加激进的 Docker 公司。</p><p>有意思的是，Docker 公司对 Mesos 社区也是类似的看法。所以从一开始，Docker 公司就把应对 Kubernetes 项目的竞争摆在了首要位置：一方面，不断强调“Docker Native”的“重要性”，另一方面，与 Kubernetes 项目在多个场合进行了直接的碰撞。</p><p>不过，这次竞争的发展态势，很快就超过了 Docker 公司的预期。</p><p>Kubernetes 项目并没有跟 Swarm 项目展开同质化的竞争，所以“Docker Native”的说辞并没有太大的杀伤力。相反地，Kubernetes 项目让人耳目一新的设计理念和号召力，很快就构建出了一个与众不同的容器编排与管理的生态。</p><p>就这样，Kubernetes 项目在 GitHub 上的各项指标开始一骑绝尘，将 Swarm 项目远远地甩在了身后。</p><p><strong>有了这个基础，CNCF 社区就可以放心地解决第二个问题了。</strong></p><p>在已经囊括了容器监控事实标准的 Prometheus 项目之后，CNCF 社区迅速在成员项目中添加了 Fluentd、OpenTracing、CNI 等一系列容器生态的知名工具和项目。</p><p>而在看到了 CNCF 社区对用户表现出来的巨大吸引力之后，大量的公司和创业团队也开始专门针对 CNCF 社区而非 Docker 公司制定推广策略。</p><p>面对这样的竞争态势，Docker 公司决定更进一步。在 2016 年，Docker 公司宣布了一个震惊所有人的计划：放弃现有的 Swarm 项目，将容器编排和集群管理功能全部内置到 Docker 项目当中。</p><p>显然，Docker 公司意识到了 Swarm 项目目前唯一的竞争优势，就是跟 Docker 项目的无缝集成。那么，如何让这种优势最大化呢？那就是把 Swarm 内置到 Docker 项目当中。</p><p>实际上，从工程角度来看，这种做法的风险很大。内置容器编排、集群管理和负载均衡能力，固然可以使得 Docker 项目的边界直接扩大到一个完整的 PaaS 项目的范畴，但这种变更带来的技术复杂度和维护难度，长远来看对 Docker 项目是不利的。</p><p>不过，在当时的大环境下，Docker 公司的选择恐怕也带有一丝孤注一掷的意味。</p><p>而<strong>Kubernetes 的应对策略则是反其道而行之，开始在整个社区推进“民主化”架构，</strong>即：从 API 到容器运行时的每一层，Kubernetes 项目都为开发者暴露出了可以扩展的插件机制，鼓励用户通过代码的方式介入到 Kubernetes 项目的每一个阶段。</p><p>Kubernetes 项目的这个变革的效果立竿见影，很快在整个容器社区中催生出了大量的、基于 Kubernetes API 和扩展接口的二次创新工作，比如：</p><ul><li>目前热度极高的微服务治理项目 Istio；</li><li>被广泛采用的有状态应用部署框架 Operator；</li><li>还有像 Rook 这样的开源创业项目，它通过 Kubernetes 的可扩展接口，把 Ceph 这样的重量级产品封装成了简单易用的容器存储插件。</li></ul><p>就这样，在这种鼓励二次创新的整体氛围当中，Kubernetes 社区在 2016 年之后得到了空前的发展。更重要的是，不同于之前局限于“打包、发布”这样的 PaaS 化路线，<strong>这一次容器社区的繁荣，是一次完全以 Kubernetes 项目为核心的“百家争鸣”。</strong></p><p>面对 Kubernetes 社区的崛起和壮大，Docker 公司也不得不面对自己豪赌失败的现实。但在早前拒绝了微软的天价收购之后，Docker 公司实际上已经没有什么回旋余地，只能选择逐步放弃开源社区而专注于自己的商业化转型。</p><p>所以，从 2017 年开始，Docker 公司先是将 Docker 项目的容器运行时部分 Containerd 捐赠给 CNCF 社区，标志着 Docker 项目已经全面升级成为一个 PaaS 平台；紧接着，Docker 公司宣布将 Docker 项目改名为 Moby，然后交给社区自行维护，而 Docker 公司的商业产品将占有 Docker 这个注册商标。</p><p>Docker 公司这些举措背后的含义非常明确：它将全面放弃在开源社区同 Kubernetes 生态的竞争，转而专注于自己的商业业务，并且通过将 Docker 项目改名为 Moby 的举动，将原本属于 Docker 社区的用户转化成了自己的客户。</p><p>2017 年 10 月，Docker 公司出人意料地宣布，将在自己的主打产品 Docker 企业版中内置 Kubernetes 项目，这标志着持续了近两年之久的“编排之争”至此落下帷幕。</p><p>2018 年 1 月 30 日，RedHat 宣布斥资 2.5 亿美元收购 CoreOS。</p><p>2018 年 3 月 28 日，这一切纷争的始作俑者，Docker 公司的 CTO Solomon Hykes 宣布辞职，曾经纷纷扰扰的容器技术圈子，到此尘埃落定。</p><p><strong>小结</strong></p><p>容器技术圈子在短短几年里发生了很多变数，但很多事情其实也都在情理之中。就像 Docker 这样一家创业公司，在通过开源社区的运作取得了巨大的成功之后，就不得不面对来自整个云计算产业的竞争和围剿。而这个产业的垄断特性，对于 Docker 这样的技术型创业公司其实天生就不友好。</p><p>在这种局势下，接受微软的天价收购，在大多数人看来都是一个非常明智和实际的选择。可是 Solomon Hykes 却多少带有一些理想主义的影子，既然不甘于“寄人篱下”，那他就必须带领 Docker 公司去对抗来自整个云计算产业的压力。</p><p>只不过，Docker 公司最后选择的对抗方式，是将开源项目与商业产品紧密绑定，打造了一个极端封闭的技术生态。而这，其实违背了 Docker 项目与开发者保持亲密关系的初衷。相比之下，Kubernetes 社区，正是以一种更加温和的方式，承接了 Docker 项目的未尽事业，即：以开发者为核心，构建一个相对民主和开放的容器生态。</p><p>这也是为何，Kubernetes 项目的成功其实是必然的。</p><p>现在，我们很难想象如果 Docker 公司最初选择了跟 Kubernetes 社区合作，如今的容器生态又将会是怎样的一番景象。不过我们可以肯定的是，Docker 公司在过去五年里的风云变幻，以及 Solomon Hykes 本人的传奇经历，都已经在云计算的长河中留下了浓墨重彩的一笔。</p><!-- 了解了背景和发展，对后面理解 为什么这么设计 其实帮助很大。开源项目千万不可拿过来蒙头读源码，这没有任何意义 --><h2 id="白话容器基础（一）：从进程说开去"><a href="#白话容器基础（一）：从进程说开去" class="headerlink" title="白话容器基础（一）：从进程说开去"></a>白话容器基础（一）：从进程说开去</h2><p>在前面的篇预习文章中，我梳理了“容器”这项技术的来龙去脉，通过这些内容，我希望你能理解如下几个事实：</p><ul><li>容器技术的兴起源于 PaaS 技术的普及；</li><li>Docker 公司发布的 Docker 项目具有里程碑式的意义；</li><li>Docker 项目通过“容器镜像”，解决了应用打包这个根本性难题。</li></ul><p>紧接着，我详细介绍了容器技术圈在过去五年里的“风云变幻”，而通过这部分内容，我希望你能理解这样一个道理：</p><blockquote><p>容器本身没有价值，有价值的是“容器编排”。</p></blockquote><p>也正因为如此，容器技术生态才爆发了一场关于“容器编排”的“战争”。而这次战争，最终以 Kubernetes 项目和 CNCF 社区的胜利而告终。所以，后面的内容，我会以 Docker 和 Kubernetes 项目为核心，为你详细介绍容器技术的各项实践与其中的原理。</p><p>不过在此之前，你还需要搞清楚一个更为基础的问题：</p><blockquote><p>容器，到底是怎么一回事儿？</p></blockquote><p>容器其实是一种沙盒技术。顾名思义，沙盒就是能够像一个集装箱一样，把你的应用“装”起来的技术。这样，应用与应用之间，就因为有了边界而不至于相互干扰；而被装进集装箱的应用，也可以被方便地搬来搬去，这不就是 PaaS 最理想的状态嘛。</p><p>不过，这两个能力说起来简单，但要用技术手段去实现它们，可能大多数人就无从下手了。</p><p><strong>所以，我就先来跟你说说这个“边界”的实现手段。</strong></p><p>假如，现在你要写一个计算加法的小程序，这个程序需要的输入来自于一个文件，计算完成后的结果则输出到另一个文件中。</p><p>由于计算机只认识 0 和 1，所以无论用哪种语言编写这段代码，最后都需要通过某种方式翻译成二进制文件，才能在计算机操作系统中运行起来。</p><p>而为了能够让这些代码正常运行，我们往往还要给它提供数据，比如我们这个加法程序所需要的输入文件。这些数据加上代码本身的二进制文件，放在磁盘上，就是我们平常所说的一个“程序”，也叫代码的可执行镜像（executable image）。</p><p>然后，我们就可以在计算机上运行这个“程序”了。</p><p>首先，操作系统从“程序”中发现输入数据保存在一个文件中，所以这些数据就被会加载到内存中待命。同时，操作系统又读取到了计算加法的指令，这时，它就需要指示 CPU 完成加法操作。而 CPU 与内存协作进行加法计算，又会使用寄存器存放数值、内存堆栈保存执行的命令和变量。同时，计算机里还有被打开的文件，以及各种各样的 I/O 设备在不断地调用中修改自己的状态。</p><p>就这样，一旦“程序”被执行起来，它就从磁盘上的二进制文件，变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。<strong>像这样一个程序运起来后的计算机执行环境的总和，就是我们今天的主角：进程。</strong></p><p>所以，对于进程来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。</p><p><strong>而容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。</strong></p><p>对于 Docker 等大多数 Linux 容器来说，<strong>Cgroups 技术</strong>是用来制造约束的主要手段，而<strong>Namespace 技术</strong>则是用来修改进程视图的主要方法。</p><p>你可能会觉得 Cgroups 和 Namespace 这两个概念很抽象，别担心，接下来我们一起动手实践一下，你就很容易理解这两项技术了。</p><p>假设你已经有了一个 Linux 操作系统上的 Docker 项目在运行，比如我的环境是 Ubuntu 16.04 和 Docker CE 18.05。</p><p>接下来，让我们首先创建一个容器来试试。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it busybox /bin/sh</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>这个命令是 Docker 项目最重要的一个操作，即大名鼎鼎的 docker run。</p><p>而 -it 参数告诉了 Docker 项目在启动容器后，需要给我们分配一个文本输入 / 输出环境，也就是 TTY，跟容器的标准输入相关联，这样我们就可以和这个 Docker 容器进行交互了。而 /bin/sh 就是我们要在 Docker 容器里运行的程序。</p><p>所以，上面这条指令翻译成人类的语言就是：请帮我启动一个容器，在容器里执行 /bin/sh，并且给我分配一个命令行终端跟这个容器交互。</p><p>这样，我的 Ubuntu 16.04 机器就变成了一个宿主机，而一个运行着 /bin/sh 的容器，就跑在了这个宿主机里面。</p><p>上面的例子和原理，如果你已经玩过 Docker，一定不会感到陌生。此时，如果我们在容器里执行一下 ps 指令，就会发现一些更有趣的事情：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># ps</span></span><br><span class="line">PID  USER   TIME COMMAND</span><br><span class="line">  1 root   0:00 /bin/sh</span><br><span class="line">  10 root   0:00 ps</span><br></pre></td></tr></table></figure><p>可以看到，我们在 Docker 里最开始执行的 /bin/sh，就是这个容器内部的第 1 号进程（PID=1），而这个容器里一共只有两个进程在运行。这就意味着，前面执行的 /bin/sh，以及我们刚刚执行的 ps，已经被 Docker 隔离在了一个跟宿主机完全不同的世界当中。</p><p>这究竟是怎么做到呢？</p><p>本来，每当我们在宿主机上运行了一个 /bin/sh 程序，操作系统都会给它分配一个进程编号，比如 PID=100。这个编号是进程的唯一标识，就像员工的工牌一样。所以 PID=100，可以粗略地理解为这个 /bin/sh 是我们公司里的第 100 号员工，而第 1 号员工就自然是比尔 · 盖茨这样统领全局的人物。</p><p>而现在，我们要通过 Docker 把这个 /bin/sh 程序运行在一个容器当中。这时候，Docker 就会在这个第 100 号员工入职时给他施一个“障眼法”，让他永远看不到前面的其他 99 个员工，更看不到比尔 · 盖茨。这样，他就会错误地以为自己就是公司里的第 1 号员工。</p><p>这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如 PID=1。可实际上，他们在宿主机的操作系统里，还是原来的第 100 号进程。</p><p><strong>这种技术，就是 Linux 里面的 Namespace 机制。</strong>而 Namespace 的使用方式也非常有意思：它其实只是 Linux 创建新进程的一个可选参数。我们知道，在 Linux 系统中创建线程的系统调用是 clone()，比如：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> pid = clone(main_function, stack_size, SIGCHLD, <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure><p>这个系统调用就会为我们创建一个新的进程，并且返回它的进程号 pid。</p><p>而当我们用 clone() 系统调用创建一个新进程时，就可以在参数中指定 CLONE_NEWPID 参数，比如：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, <span class="literal">NULL</span>);</span><br></pre></td></tr></table></figure><p>这时，新创建的这个进程将会“看到”一个全新的进程空间，在这个进程空间里，它的 PID 是 1。之所以说“看到”，是因为这只是一个“障眼法”，在宿主机真实的进程空间里，这个进程的 PID 还是真实的数值，比如 100。</p><p>当然，我们还可以多次执行上面的 clone() 调用，这样就会创建多个 PID Namespace，而每个 Namespace 里的应用进程，都会认为自己是当前容器里的第 1 号进程，它们既看不到宿主机里真正的进程空间，也看不到其他 PID Namespace 里的具体情况。</p><p><strong>而除了我们刚刚用到的 PID Namespace，Linux 操作系统还提供了 Mount、UTS、IPC、Network 和 User 这些 Namespace，用来对各种不同的进程上下文进行“障眼法”操作。</strong></p><p>比如，Mount Namespace，用于让被隔离进程只看到当前 Namespace 里的挂载点信息；Network Namespace，用于让被隔离进程看到当前 Namespace 里的网络设备和配置。</p><p><strong>这，就是 Linux 容器最基本的实现原理了。</strong></p><p>所以，Docker 容器这个听起来玄而又玄的概念，实际上是在创建容器进程时，指定了这个进程所需要启用的一组 Namespace 参数。这样，容器就只能“看”到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。</p><p><strong>所以说，容器，其实是一种特殊的进程而已。</strong></p><p><strong>小结</strong></p><p>谈到为“进程划分一个独立空间”的思想，相信你一定会联想到虚拟机。而且，你应该还看过一张虚拟机和容器的对比图。</p><p><img src="/images/k8s/k8s-01/1.jpg" alt="1"></p><p>这幅图的左边，画出了虚拟机的工作原理。其中，名为 Hypervisor 的软件是虚拟机最主要的部分。它通过硬件虚拟化功能，模拟出了运行一个操作系统需要的各种硬件，比如 CPU、内存、I/O 设备等等。然后，它在这些虚拟的硬件上安装了一个新的操作系统，即 Guest OS。</p><p>这样，用户的应用进程就可以运行在这个虚拟的机器中，它能看到的自然也只有 Guest OS 的文件和目录，以及这个机器里的虚拟设备。这就是为什么虚拟机也能起到将不同的应用进程相互隔离的作用。</p><p>而这幅图的右边，则用一个名为 Docker Engine 的软件替换了 Hypervisor。这也是为什么，很多人会把 Docker 项目称为“轻量级”虚拟化技术的原因，实际上就是把虚拟机的概念套在了容器上。</p><p><strong>可是这样的说法，却并不严谨。</strong></p><p>在理解了 Namespace 的工作方式之后，你就会明白，跟真实存在的虚拟机不同，在使用 Docker 的时候，并没有一个真正的“Docker 容器”运行在宿主机里面。Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker 为它们加上了各种各样的 Namespace 参数。</p><p>这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自 Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，就仿佛运行在一个个“容器”里面，与世隔绝。</p><p>不过，相信你此刻已经会心一笑：这些不过都是“障眼法”罢了。</p><h2 id="白话容器基础（二）：隔离与限制"><a href="#白话容器基础（二）：隔离与限制" class="headerlink" title="白话容器基础（二）：隔离与限制"></a>白话容器基础（二）：隔离与限制</h2><p>在前面，我详细介绍了 Linux 容器中用来实现“隔离”的技术手段：Namespace。而通过这些讲解，你应该能够明白，<strong>Namespace 技术实际上修改了应用进程看待整个计算机“视图”，即它的“视线”被操作系统做了限制，只能“看到”某些指定的内容。</strong>但对于宿主机来说，这些被“隔离”了的进程跟其他进程并没有太大区别。</p><p>说到这一点，相信你也能够知道我在上一篇文章最后给你留下的第一个思考题的答案了：在之前虚拟机与容器技术的对比图里，不应该把 Docker Engine 或者任何容器管理工具放在跟 Hypervisor 相同的位置，因为它们并不像 Hypervisor 那样对应用进程的隔离环境负责，也不会创建任何实体的“容器”，真正对隔离环境负责的是宿主机操作系统本身：</p><p><img src="/images/k8s/k8s-01/2.jpg" alt="2"></p><p>所以，在这个对比图里，我们应该把 Docker 画在跟应用同级别并且靠边的位置。这意味着，用户运行在容器里的应用进程，跟宿主机上的其他进程一样，都由宿主机操作系统统一管理，只不过这些被隔离的进程拥有额外设置过的 Namespace 参数。而 Docker 项目在这里扮演的角色，更多的是旁路式的辅助和管理工作。</p><p>我在后续分享 CRI 和容器运行时的时候还会专门介绍到，其实像 Docker 这样的角色甚至可以去掉。</p><p>这样的架构也解释了为什么 Docker 项目比虚拟机更受欢迎的原因。</p><p>这是因为，使用虚拟化技术作为应用沙盒，就必须要由 Hypervisor 来负责创建虚拟机，这个虚拟机是真实存在的，并且它里面必须运行一个完整的 Guest OS 才能执行用户的应用进程。这就不可避免地带来了额外的资源消耗和占用。</p><p>根据实验，一个运行着 CentOS 的 KVM 虚拟机启动后，在不做优化的情况下，虚拟机自己就需要占用 100~200 MB 内存。此外，用户应用运行在虚拟机里面，它对宿主机操作系统的调用就不可避免地要经过虚拟化软件的拦截和处理，这本身又是一层性能损耗，尤其对计算资源、网络和磁盘 I/O 的损耗非常大。</p><p>而相比之下，容器化后的用户应用，却依然还是一个宿主机上的普通进程，这就意味着这些因为虚拟化而带来的性能损耗都是不存在的；而另一方面，使用 Namespace 作为隔离手段的容器并不需要单独的 Guest OS，这就使得容器额外的资源占用几乎可以忽略不计。</p><p>所以说，<strong>“敏捷”和“高性能”是容器相较于虚拟机最大的优势，也是它能够在 PaaS 这种更细粒度的资源管理平台上大行其道的重要原因。</strong></p><p>不过，有利就有弊，基于 Linux Namespace 的隔离机制相比于虚拟化技术也有很多不足之处，其中最主要的问题就是：<strong>隔离得不彻底。</strong></p><p><strong>首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。</strong></p><p>尽管你可以在容器里通过 Mount Namespace 单独挂载其他不同版本的操作系统文件，比如 CentOS 或者 Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。</p><p>而相比之下，拥有硬件虚拟化技术和独立 Guest OS 的虚拟机就要方便得多了。最极端的例子是，Microsoft 的云计算平台 Azure，实际上就是运行在 Windows 服务器集群上的，但这并不妨碍你在它上面创建各种 Linux 虚拟机出来。</p><p><strong>其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。</strong></p><p>这就意味着，如果你的容器中的程序使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题。</p><p>此外，由于上述问题，尤其是共享宿主机内核的事实，容器给应用暴露出来的攻击面是相当大的，应用“越狱”的难度自然也比虚拟机低得多。</p><p>更为棘手的是，尽管在实践中我们确实可以使用 Seccomp 等技术，对容器内部发起的所有系统调用进行过滤和甄别来进行安全加固，但这种方法因为多了一层对系统调用的过滤，一定会拖累容器的性能。何况，默认情况下，谁也不知道到底该开启哪些系统调用，禁止哪些系统调用。</p><p>所以，在生产环境中，没有人敢把运行在物理机上的 Linux 容器直接暴露到公网上。当然，我后续会讲到的基于虚拟化或者独立内核技术的容器实现，则可以比较好地在隔离与性能之间做出平衡。</p><p><strong>在介绍完容器的“隔离”技术之后，我们再来研究一下容器的“限制”问题。</strong></p><p>也许你会好奇，我们不是已经通过 Linux Namespace 创建了一个“容器”吗，为什么还需要对容器做“限制”呢？</p><p>我还是以 PID Namespace 为例，来给你解释这个问题。</p><p>虽然容器内的第 1 号进程在“障眼法”的干扰下只能看到容器里的情况，但是宿主机上，它作为第 100 号进程与其他所有进程之间依然是平等的竞争关系。这就意味着，虽然第 100 号进程表面上被隔离了起来，但是它所能够使用到的资源（比如 CPU、内存），却是可以随时被宿主机上的其他进程（或者其他容器）占用的。当然，这个 100 号进程自己也可能把所有资源吃光。这些情况，显然都不是一个“沙盒”应该表现出来的合理行为。</p><p><strong>而Linux Cgroups 就是 Linux 内核中用来为进程设置资源限制的一个重要功能。</strong></p><p>有意思的是，Google 的工程师在 2006 年发起这项特性的时候，曾将它命名为“进程容器”（process container）。实际上，在 Google 内部，“容器”这个术语长期以来都被用于形容被 Cgroups 限制过的进程组。后来 Google 的工程师们说，他们的 KVM 虚拟机也运行在 Borg 所管理的“容器”里，其实也是运行在 Cgroups“容器”当中。这和我们今天说的 Docker 容器差别很大。</p><p><strong>Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。</strong></p><p>此外，Cgroups 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。在今天的分享中，我只和你重点探讨它与容器关系最紧密的“限制”能力，并通过一组实践来带你认识一下 Cgroups。</p><p>在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。在 Ubuntu 16.04 机器里，我可以用 mount 指令把它们展示出来，这条命令是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ mount -t cgroup </span><br><span class="line">cpuset on /sys/fs/cgroup/cpuset <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</span><br><span class="line">cpu on /sys/fs/cgroup/cpu <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpu)</span><br><span class="line">cpuacct on /sys/fs/cgroup/cpuacct <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)</span><br><span class="line">blkio on /sys/fs/cgroup/blkio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,blkio)</span><br><span class="line">memory on /sys/fs/cgroup/memory <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,memory)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>它的输出结果，是一系列文件系统目录。如果你在自己的机器上没有看到这些目录，那你就需要自己去挂载 Cgroups，具体做法可以自行 Google。</p><p>可以看到，在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件，这个指令是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ ls /sys/fs/cgroup/cpu</span><br><span class="line">cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release</span><br><span class="line">cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks</span><br></pre></td></tr></table></figure><p>如果熟悉 Linux CPU 管理的话，你就会在它的输出里注意到 cfs_period 和 cfs_quota 这样的关键词。这两个参数需要组合使用，可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间。</p><p>而这样的配置文件又如何使用呢？</p><p>你需要在对应的子系统下面创建一个目录，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu:/sys/fs/cgroup/cpu$ mkdir container</span><br><span class="line">root@ubuntu:/sys/fs/cgroup/cpu$ ls container/</span><br><span class="line">cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release</span><br><span class="line">cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks</span><br></pre></td></tr></table></figure><p>这个目录就称为一个“控制组”。你会发现，操作系统会在你新创建的 container 目录下，自动生成该子系统对应的资源限制文件。</p><p>现在，我们在后台执行这样一条脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="keyword">while</span> : ; <span class="keyword">do</span> : ; <span class="keyword">done</span> &amp;</span><br><span class="line">[1] 226</span><br></pre></td></tr></table></figure><p>显然，它执行了一个死循环，可以把计算机的 CPU 吃到 100%，根据它的输出，我们可以看到这个脚本在后台运行的进程号（PID）是 226。</p><p>这样，我们可以用 top 指令来确认一下 CPU 有没有被打满：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ top</span><br><span class="line">%Cpu0 :100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st</span><br></pre></td></tr></table></figure><p>在输出里可以看到，CPU 的使用率已经 100% 了（%Cpu0 :100.0 us）。</p><p>而此时，我们可以通过查看 container 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us </span><br><span class="line">-1</span><br><span class="line">$ cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us </span><br><span class="line">100000</span><br></pre></td></tr></table></figure><p>接下来，我们可以通过修改这些文件的内容来设置限制。</p><p>比如，向 container 组里的 cfs_quota 文件写入 20 ms（20000 us）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> 20000 &gt; /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us</span><br></pre></td></tr></table></figure><p>结合前面的介绍，你应该能明白这个操作的含义，它意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。</p><p>接下来，我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> 226 &gt; /sys/fs/cgroup/cpu/container/tasks</span><br></pre></td></tr></table></figure><p>我们可以用 top 指令查看一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ top</span><br><span class="line">%Cpu0 : 20.3 us, 0.0 sy, 0.0 ni, 79.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st</span><br></pre></td></tr></table></figure><p>可以看到，计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.3 us）。</p><p>除 CPU 子系统外，Cgroups 的每一项子系统都有其独有的资源限制能力，比如：</p><ul><li>blkio，为​​​块​​​设​​​备​​​设​​​定​​​I/O 限​​​制，一般用于磁盘等设备；</li><li>cpuset，为进程分配单独的 CPU 核和对应的内存节点；</li><li>memory，为进程设定内存使用的限制。</li></ul><p><strong>Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。</strong>而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。</p><p>而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash</span><br></pre></td></tr></table></figure><p>在启动这个容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，“docker”这个控制组里的资源限制文件的内容来确认：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us </span><br><span class="line">100000</span><br><span class="line">$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us </span><br><span class="line">20000</span><br></pre></td></tr></table></figure><p>这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。</p><p><strong>小结</strong></p><p>在里，我首先介绍了容器使用 Linux Namespace 作为隔离手段的优势和劣势，对比了 Linux 容器跟虚拟机技术的不同，进一步明确了“容器只是一种特殊的进程”这个结论。</p><p>除了创建 Namespace 之外，在后续关于容器网络的分享中，我还会介绍一些其他 Namespace 的操作，比如看不见摸不着的 Linux Namespace 在计算机中到底如何表示、一个进程如何“加入”到其他进程的 Namespace 当中，等等。</p><p>紧接着，我详细介绍了容器在做好了隔离工作之后，又如何通过 Linux Cgroups 实现资源的限制，并通过一系列简单的实验，模拟了 Docker 项目创建容器限制的过程。</p><p>通过以上讲述，你现在应该能够理解，一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程，而这个进程能够使用的资源量，则受 Cgroups 配置的限制。</p><p>这也是容器技术中一个非常重要的概念，即：<strong>容器是一个“单进程”模型。</strong></p><p>由于一个容器的本质就是一个进程，用户的应用进程实际上就是容器里 PID=1 的进程，也是其他后续创建的所有进程的父进程。这就意味着，在一个容器中，你没办法同时运行两个不同的应用，除非你能事先找到一个公共的 PID=1 的程序来充当两个不同应用的父进程，这也是为什么很多人都会用 systemd 或者 supervisord 这样的软件来代替应用本身作为容器的启动进程。</p><p>但是，在后面分享容器设计模式时，我还会推荐其他更好的解决办法。这是因为容器本身的设计，就是希望容器和应用能够<strong>同生命周期，</strong>这个概念对后续的容器编排非常重要。否则，一旦出现类似于“容器是正常运行的，但是里面的应用早已经挂了”的情况，编排系统处理起来就非常麻烦了。</p><p>另外，跟 Namespace 的情况类似，Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题。</p><p>众所周知，Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如 CPU 使用情况、内存占用率等，这些文件也是 top 指令查看系统信息的主要数据来源。</p><p>但是，你如果在容器里执行 top 指令，就会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据。</p><p>造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。</p><p>在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的 CPU 核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。这也是在企业中，容器化应用碰到的一个常见问题，也是容器相较于虚拟机另一个不尽如人意的地方。</p><h2 id="白话容器基础（三）：深入理解容器镜像"><a href="#白话容器基础（三）：深入理解容器镜像" class="headerlink" title="白话容器基础（三）：深入理解容器镜像"></a>白话容器基础（三）：深入理解容器镜像</h2><p>在前面，我讲解了 Linux 容器最基础的两种技术：Namespace 和 Cgroups。希望此时，你已经彻底理解了“容器的本质是一种特殊的进程”这个最重要的概念。</p><p>而正如我前面所说的，Namespace 的作用是“隔离”，它让应用进程只能看到该 Namespace 内的“世界”；而 Cgroups 的作用是“限制”，它给这个“世界”围上了一圈看不见的墙。这么一折腾，进程就真的被“装”在了一个与世隔绝的房间里，而这些房间就是 PaaS 项目赖以生存的应用“沙盒”。</p><p>可是，还有一个问题不知道你有没有仔细思考过：这个房间四周虽然有了墙，但是如果容器进程低头一看地面，又是怎样一副景象呢？</p><p>换句话说，<strong>容器里的进程看到的文件系统又是什么样子的呢？</strong></p><p>可能你立刻就能想到，这一定是一个关于 Mount Namespace 的问题：容器里的应用进程，理应看到一份完全独立的文件系统。这样，它就可以在自己的容器目录（比如 /tmp）下进行操作，而完全不会受宿主机以及其他容器的影响。</p><p>那么，真实情况是这样吗？</p><p>“左耳朵耗子”叔在多年前写的一篇<a href="https://coolshell.cn/articles/17010.html" target="_blank" rel="noopener">关于 Docker 基础知识的博客</a>里，曾经介绍过一段小程序。这段小程序的作用是，在创建子进程时开启指定的 Namespace。</p><p>下面，我们不妨使用它来验证一下刚刚提到的问题。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/mount.h&gt; </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> STACK_SIZE (1024 * 1024)</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> container_stack[STACK_SIZE];</span><br><span class="line"><span class="keyword">char</span>* <span class="keyword">const</span> container_args[] = &#123;</span><br><span class="line">  <span class="string">"/bin/bash"</span>,</span><br><span class="line">  <span class="literal">NULL</span></span><br><span class="line">&#125;;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">container_main</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Container - inside the container!\n"</span>);</span><br><span class="line">  execv(container_args[<span class="number">0</span>], container_args);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Something's wrong!\n"</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Parent - start a container!\n"</span>);</span><br><span class="line">  <span class="keyword">int</span> container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWNS | SIGCHLD , <span class="literal">NULL</span>);</span><br><span class="line">  waitpid(container_pid, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Parent - container stopped!\n"</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码的功能非常简单：在 main 函数里，我们通过 clone() 系统调用创建了一个新的子进程 container_main，并且声明要为它启用 Mount Namespace（即：CLONE_NEWNS 标志）。</p><p>而这个子进程执行的，是一个“/bin/bash”程序，也就是一个 shell。所以这个 shell 就运行在了 Mount Namespace 的隔离环境中。</p><p>我们来一起编译一下这个程序：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -o ns ns.c</span><br><span class="line">$ ./ns</span><br><span class="line">Parent - start a container!</span><br><span class="line">Container - inside the container!</span><br></pre></td></tr></table></figure><p>这样，我们就进入了这个“容器”当中。可是，如果在“容器”里执行一下 ls 指令的话，我们就会发现一个有趣的现象： /tmp 目录下的内容跟宿主机的内容是一样的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /tmp</span><br><span class="line"><span class="comment"># 你会看到好多宿主机的文件</span></span><br></pre></td></tr></table></figure><p>也就是说：</p><blockquote><p>即使开启了 Mount Namespace，容器进程看到的文件系统也跟宿主机完全一样。</p></blockquote><p>这是怎么回事呢？</p><p>仔细思考一下，你会发现这其实并不难理解：<strong>Mount Namespace 修改的，是容器进程对文件系统“挂载点”的认知。</strong>但是，这也就意味着，只有在“挂载”这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器会直接继承宿主机的各个挂载点。</p><p>这时，你可能已经想到了一个解决办法：创建新进程时，除了声明要启用 Mount Namespace 之外，我们还可以告诉容器进程，有哪些目录需要重新挂载，就比如这个 /tmp 目录。于是，我们在容器进程执行前可以添加一步重新挂载 /tmp 目录的操作：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">container_main</span><span class="params">(<span class="keyword">void</span>* arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Container - inside the container!\n"</span>);</span><br><span class="line">  <span class="comment">// 如果你的机器的根目录的挂载类型是 shared，那必须先重新挂载根目录</span></span><br><span class="line">  <span class="comment">// mount("", "/", NULL, MS_PRIVATE, "");</span></span><br><span class="line">  mount(<span class="string">"none"</span>, <span class="string">"/tmp"</span>, <span class="string">"tmpfs"</span>, <span class="number">0</span>, <span class="string">""</span>);</span><br><span class="line">  execv(container_args[<span class="number">0</span>], container_args);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"Something's wrong!\n"</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，在修改后的代码里，我在容器进程启动之前，加上了一句 mount(“none”, “/tmp”, “tmpfs”, 0, “”) 语句。就这样，我告诉了容器以 tmpfs（内存盘）格式，重新挂载了 /tmp 目录。</p><p>这段修改后的代码，编译执行后的结果又如何呢？我们可以试验一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -o ns ns.c</span><br><span class="line">$ ./ns</span><br><span class="line">Parent - start a container!</span><br><span class="line">Container - inside the container!</span><br><span class="line">$ ls /tmp</span><br></pre></td></tr></table></figure><p>可以看到，这次 /tmp 变成了一个空目录，这意味着重新挂载生效了。我们可以用 mount -l 检查一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mount -l | grep tmpfs</span><br><span class="line">none on /tmp <span class="built_in">type</span> tmpfs (rw,relatime)</span><br></pre></td></tr></table></figure><p>可以看到，容器里的 /tmp 目录是以 tmpfs 方式单独挂载的。</p><p>更重要的是，因为我们创建的新进程启用了 Mount Namespace，所以这次重新挂载的操作，只在容器进程的 Mount Namespace 中有效。如果在宿主机上用 mount -l 来检查一下这个挂载，你会发现它是不存在的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在宿主机上</span></span><br><span class="line">$ mount -l | grep tmpfs</span><br></pre></td></tr></table></figure><p><strong>这就是 Mount Namespace 跟其他 Namespace 的使用略有不同的地方：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。</strong></p><p>可是，作为一个普通用户，我们希望的是一个更友好的情况：每当创建一个新容器时，我希望容器进程看到的文件系统就是一个独立的隔离环境，而不是继承自宿主机的文件系统。怎么才能做到这一点呢？</p><p>不难想到，我们可以在容器进程启动之前重新挂载它的整个根目录“/”。而由于 Mount Namespace 的存在，这个挂载对宿主机不可见，所以容器进程就可以在里面随便折腾了。</p><p>在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。它的用法也非常简单。</p><p>假设，我们现在有一个 $HOME/test 目录，想要把它作为一个 /bin/bash 进程的根目录。</p><p>首先，创建一个 test 目录和几个 lib 文件夹：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir -p <span class="variable">$HOME</span>/<span class="built_in">test</span></span><br><span class="line">$ mkdir -p <span class="variable">$HOME</span>/<span class="built_in">test</span>/&#123;bin,lib64,lib&#125;</span><br><span class="line">$ <span class="built_in">cd</span> <span class="variable">$T</span></span><br></pre></td></tr></table></figure><p>然后，把 bash 命令拷贝到 test 目录对应的 bin 路径下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp -v /bin/&#123;bash,ls&#125; <span class="variable">$HOME</span>/<span class="built_in">test</span>/bin</span><br></pre></td></tr></table></figure><p>接下来，把 bash 命令需要的所有 so 文件，也拷贝到 test 目录对应的 lib 路径下。找到 so 文件可以用 ldd 命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ T=<span class="variable">$HOME</span>/<span class="built_in">test</span></span><br><span class="line">$ list=<span class="string">"<span class="variable">$(ldd /bin/ls | egrep -o '/lib.*\.[0-9]')</span>"</span></span><br><span class="line">$ <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$list</span>; <span class="keyword">do</span> cp -v <span class="string">"<span class="variable">$i</span>"</span> <span class="string">"<span class="variable">$&#123;T&#125;</span><span class="variable">$&#123;i&#125;</span>"</span>; <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>最后，执行 chroot 命令，告诉操作系统，我们将使用 $HOME/test 目录作为 /bin/bash 进程的根目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ chroot <span class="variable">$HOME</span>/<span class="built_in">test</span> /bin/bash</span><br></pre></td></tr></table></figure><p>这时，你如果执行 “ls /“，就会看到，它返回的都是 $HOME/test 目录下面的内容，而不是宿主机的内容。</p><p>更重要的是，对于被 chroot 的进程来说，它并不会感受到自己的根目录已经被“修改”成 $HOME/test 了。</p><p>这种视图被修改的原理，是不是跟我之前介绍的 Linux Namespace 很类似呢？</p><p>没错！</p><p><strong>实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。</strong></p><p>当然，为了能够让容器的这个根目录看起来更“真实”，我们一般会在这个容器的根目录下挂载一个完整操作系统的文件系统，比如 Ubuntu16.04 的 ISO。这样，在容器启动之后，我们在容器里通过执行 “ls /“ 查看根目录下的内容，就是 Ubuntu 16.04 的所有目录和文件。</p><p><strong>而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。</strong></p><p>所以，一个最常见的 rootfs，或者说容器镜像，会包括如下所示的一些目录和文件，比如 /bin，/etc，/proc 等等：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /</span><br><span class="line">bin dev etc home lib lib64 mnt opt proc root run sbin sys tmp usr var</span><br></pre></td></tr></table></figure><p>而你进入容器之后执行的 /bin/bash，就是 /bin 目录下的可执行文件，与宿主机的 /bin/bash 完全不同。</p><p>现在，你应该可以理解，对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程：</p><ol><li>启用 Linux Namespace 配置；</li><li>设置指定的 Cgroups 参数；</li><li>切换进程的根目录（Change Root）。</li></ol><p>这样，一个完整的容器就诞生了。不过，Docker 项目在最后一步的切换上会优先使用 pivot_root 系统调用，如果系统不支持，才会使用 chroot。这两个系统调用虽然功能类似，但是也有细微的区别，这一部分小知识就交给你课后去探索了。</p><p><strong>另外，需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。</strong></p><p>所以说，rootfs 只包括了操作系统的“躯壳”，并没有包括操作系统的“灵魂”。</p><p>那么，对于容器来说，这个操作系统的“灵魂”又在哪里呢？</p><p>实际上，同一台机器上的所有容器，都共享宿主机操作系统的内核。</p><p>这就意味着，如果你的应用程序需要配置内核参数、加载额外的内核模块，以及跟内核进行直接的交互，你就需要注意了：这些操作和依赖的对象，都是宿主机操作系统的内核，它对于该机器上的所有容器来说是一个“全局变量”，牵一发而动全身。</p><p>这也是容器相比于虚拟机的主要缺陷之一：毕竟后者不仅有模拟出来的硬件机器充当沙盒，而且每个沙盒里还运行着一个完整的 Guest OS 给应用随便折腾。</p><p><strong>不过，正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：一致性。</strong></p><p>什么是容器的“一致性”呢？</p><p>在前面中曾经提到过：由于云端与本地服务器环境不同，应用的打包过程，一直是使用 PaaS 时最“痛苦”的一个步骤。</p><p>但有了容器之后，更准确地说，有了容器镜像（即 rootfs）之后，这个问题被非常优雅地解决了。</p><p><strong>由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。</strong></p><p>事实上，对于大多数开发者而言，他们对应用依赖的理解，一直局限在编程语言层面。比如 Golang 的 Godeps.json。但实际上，一个一直以来很容易被忽视的事实是，<strong>对一个应用来说，操作系统本身才是它运行所需要的最完整的“依赖库”。</strong></p><p>有了容器镜像“打包操作系统”的能力，这个最基础的依赖环境也终于变成了应用沙盒的一部分。这就赋予了容器所谓的一致性：无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出来了。</p><p><strong>这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟。</strong></p><p>不过，这时你可能已经发现了另一个非常棘手的问题：难道我每开发一个应用，或者升级一下现有的应用，都要重复制作一次 rootfs 吗？</p><p>比如，我现在用 Ubuntu 操作系统的 ISO 做了一个 rootfs，然后又在里面安装了 Java 环境，用来部署我的 Java 应用。那么，我的另一个同事在发布他的 Java 应用时，显然希望能够直接使用我安装过 Java 环境的 rootfs，而不是重复这个流程。</p><p>一种比较直观的解决办法是，我在制作 rootfs 的时候，每做一步“有意义”的操作，就保存一个 rootfs 出来，这样其他同事就可以按需求去用他需要的 rootfs 了。</p><p>但是，这个解决办法并不具备推广性。原因在于，一旦你的同事们修改了这个 rootfs，新旧两个 rootfs 之间就没有任何关系了。这样做的结果就是极度的碎片化。</p><p>那么，既然这些修改都基于一个旧的 rootfs，我们能不能以增量的方式去做这些修改呢？这样做的好处是，所有人都只需要维护相对于 base rootfs 修改的增量内容，而不是每次修改都制造一个“fork”。</p><p>答案当然是肯定的。</p><p>这也正是为何，Docker 公司在实现 Docker 镜像时并没有沿用以前制作 rootfs 的标准流程，而是做了一个小小的创新：</p><blockquote><p>Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。</p></blockquote><p>当然，这个想法不是凭空臆造出来的，而是用到了一种叫作联合文件系统（Union File System）的能力。</p><p>Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ tree</span><br><span class="line">.</span><br><span class="line">├── A</span><br><span class="line">│  ├── a</span><br><span class="line">│  └── x</span><br><span class="line">└── B</span><br><span class="line">  ├── b</span><br><span class="line">  └── x</span><br></pre></td></tr></table></figure><p>然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir C</span><br><span class="line">$ mount -t aufs -o <span class="built_in">dirs</span>=./A:./B none ./C</span><br></pre></td></tr></table></figure><p>这时，我再查看目录 C 的内容，就能看到目录 A 和 B 下的文件被合并到了一起：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ tree ./C</span><br><span class="line">./C</span><br><span class="line">├── a</span><br><span class="line">├── b</span><br><span class="line">└── x</span><br></pre></td></tr></table></figure><p>可以看到，在这个合并后的目录 C 里，有 a、b、x 三个文件，并且 x 文件只有一份。这，就是“合并”的含义。此外，如果你在目录 C 里对 a、b、x 文件做修改，这些修改也会在对应的目录 A、B 中生效。</p><p>那么，在 Docker 项目中，又是如何使用这种 Union File System 的呢？</p><p>我的环境是 Ubuntu 16.04 和 Docker CE 18.05，这对组合默认使用的是 AuFS 这个联合文件系统的实现。你可以通过 docker info 命令，查看到这个信息。</p><p>AuFS 的全称是 Another UnionFS，后改名为 Alternative UnionFS，再后来干脆改名叫作 Advance UnionFS，从这些名字中你应该能看出这样两个事实：</p><ol><li>它是对 Linux 原生 UnionFS 的重写和改进；</li><li>它的作者怨气好像很大。我猜是 Linus Torvalds（Linux 之父）一直不让 AuFS 进入 Linux 内核主干的缘故，所以我们只能在 Ubuntu 和 Debian 这些发行版上使用它。</li></ol><p>对于 AuFS 来说，它最关键的目录结构在 /var/lib/docker 路径下的 diff 目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/lib/docker/aufs/diff/&lt;layer_id&gt;</span><br></pre></td></tr></table></figure><p><strong>而这个目录的作用，我们不妨通过一个具体例子来看一下。</strong></p><p>现在，我们启动一个容器，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d ubuntu:latest sleep 3600</span><br></pre></td></tr></table></figure><p>这时候，Docker 就会从 Docker Hub 上拉取一个 Ubuntu 镜像到本地。</p><p>这个所谓的“镜像”，实际上就是一个 Ubuntu 操作系统的 rootfs，它的内容是 Ubuntu 操作系统的所有文件和目录。不过，与之前我们讲述的 rootfs 稍微不同的是，Docker 镜像使用的 rootfs，往往由多个“层”组成：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ docker image inspect ubuntu:latest</span><br><span class="line">...</span><br><span class="line">     <span class="string">"RootFS"</span>: &#123;</span><br><span class="line">      <span class="string">"Type"</span>: <span class="string">"layers"</span>,</span><br><span class="line">      <span class="string">"Layers"</span>: [</span><br><span class="line">        <span class="string">"sha256:f49017d4d5ce9c0f544c..."</span>,</span><br><span class="line">        <span class="string">"sha256:8f2b771487e9d6354080..."</span>,</span><br><span class="line">        <span class="string">"sha256:ccd4d61916aaa2159429..."</span>,</span><br><span class="line">        <span class="string">"sha256:c01d74f99de40e097c73..."</span>,</span><br><span class="line">        <span class="string">"sha256:268a067217b5fe78e000..."</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>可以看到，这个 Ubuntu 镜像，实际上由五个层组成。这五个层就是五个增量 rootfs，每一层都是 Ubuntu 操作系统文件与目录的一部分；而在使用镜像时，Docker 会把这些增量联合挂载在一个统一的挂载点上（等价于前面例子里的“/C”目录）。</p><p>这个挂载点就是 /var/lib/docker/aufs/mnt/，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3e</span><br></pre></td></tr></table></figure><p>不出意外的，这个目录里面正是一个完整的 Ubuntu 操作系统：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fcfa2a2f5c89dc21ee30e166be823ceaeba15dce645b3e</span><br><span class="line">bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var</span><br></pre></td></tr></table></figure><p>那么，前面提到的五个镜像层，又是如何被联合挂载成这样一个完整的 Ubuntu 文件系统的呢？</p><p>这个信息记录在 AuFS 的系统目录 /sys/fs/aufs 下面。</p><p>首先，通过查看 AuFS 的挂载信息，我们可以找到这个目录对应的 AuFS 的内部 ID（也叫：si）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/mounts| grep aufs</span><br><span class="line">none /var/lib/docker/aufs/mnt/6e3be5d2ecccae7cc0fc... aufs rw,relatime,si=972c6d361e6b32ba,dio,dirperm1 0 0</span><br></pre></td></tr></table></figure><p>即，si=972c6d361e6b32ba。</p><p>然后使用这个 ID，你就可以在 /sys/fs/aufs 下查看被联合挂载在一起的各个层的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/fs/aufs/si_972c6d361e6b32ba/br[0-9]*</span><br><span class="line">/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...=rw</span><br><span class="line">/var/lib/docker/aufs/diff/6e3be5d2ecccae7cc...-init=ro+wh</span><br><span class="line">/var/lib/docker/aufs/diff/32e8e20064858c0f2...=ro+wh</span><br><span class="line">/var/lib/docker/aufs/diff/2b8858809bce62e62...=ro+wh</span><br><span class="line">/var/lib/docker/aufs/diff/20707dce8efc0d267...=ro+wh</span><br><span class="line">/var/lib/docker/aufs/diff/72b0744e06247c7d0...=ro+wh</span><br><span class="line">/var/lib/docker/aufs/diff/a524a729adadedb90...=ro+wh</span><br></pre></td></tr></table></figure><p>从这些信息里，我们可以看到，镜像的层都放置在 /var/lib/docker/aufs/diff 目录下，然后被联合挂载在 /var/lib/docker/aufs/mnt 里面。</p><p>而且，从这个结构可以看出来，这个容器的 rootfs 由如下图所示的三部分组成：</p><p><img src="/images/k8s/k8s-01/3.jpg" alt="3"></p><p><strong>第一部分，只读层。</strong></p><p>它是这个容器的 rootfs 最下面的五层，对应的正是 ubuntu:latest 镜像的五层。可以看到，它们的挂载方式都是只读的（ro+wh，即 readonly+whiteout，至于什么是 whiteout，我下面马上会讲到）。</p><p>这时，我们可以分别查看一下这些层的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ls /var/lib/docker/aufs/diff/72b0744e06247c7d0...</span><br><span class="line">etc sbin usr var</span><br><span class="line">$ ls /var/lib/docker/aufs/diff/32e8e20064858c0f2...</span><br><span class="line">run</span><br><span class="line">$ ls /var/lib/docker/aufs/diff/a524a729adadedb900...</span><br><span class="line">bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var</span><br></pre></td></tr></table></figure><p>可以看到，这些层，都以增量的方式分别包含了 Ubuntu 操作系统的一部分。</p><p><strong>第二部分，可读写层。</strong></p><p>它是这个容器的 rootfs 最上面的一层（6e3be5d2ecccae7cc），它的挂载方式为：rw，即 read write。在没有写入文件之前，这个目录是空的。而一旦在容器里做了写操作，你修改产生的内容就会以增量的方式出现在这个层中。</p><p>可是，你有没有想到这样一个问题：如果我现在要做的，是删除只读层里的一个文件呢？</p><p>为了实现这样的删除操作，AuFS 会在可读写层创建一个 whiteout 文件，把只读层里的文件“遮挡”起来。</p><p>比如，你要删除只读层里一个名叫 foo 的文件，那么这个删除操作实际上是在可读写层创建了一个名叫.wh.foo 的文件。这样，当这两个层被联合挂载之后，foo 文件就会被.wh.foo 文件“遮挡”起来，“消失”了。这个功能，就是“ro+wh”的挂载方式，即只读 +whiteout 的含义。我喜欢把 whiteout 形象地翻译为：“白障”。</p><p>所以，最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。</p><p><strong>第三部分，Init 层。</strong></p><p>它是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。</p><p>需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。</p><p>可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。</p><p>所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行 docker commit 只会提交可读写层，所以是不包含这些内容的。</p><p>最终，这 7 个层都被联合挂载到 /var/lib/docker/aufs/mnt 目录下，表现为一个完整的 Ubuntu 操作系统供容器使用。</p><p><strong>小结</strong></p><p>在今天的分享中，我着重介绍了 Linux 容器文件系统的实现方式。而这种机制，正是我们经常提到的容器镜像，也叫作：rootfs。它只是一个操作系统的所有文件和目录，并不包含内核，最多也就几百兆。而相比之下，传统虚拟机的镜像大多是一个磁盘的“快照”，磁盘有多大，镜像就至少有多大。</p><p>通过结合使用 Mount Namespace 和 rootfs，容器就能够为进程构建出一个完善的文件系统隔离环境。当然，这个功能的实现还必须感谢 chroot 和 pivot_root 这两个系统调用切换进程根目录的能力。</p><p>而在 rootfs 的基础上，Docker 公司创新性地提出了使用多个增量 rootfs 联合挂载一个完整 rootfs 的方案，这就是容器镜像中“层”的概念。</p><p>通过“分层镜像”的设计，以 Docker 镜像为核心，来自不同公司、不同团队的技术人员被紧密地联系在了一起。而且，由于容器镜像的操作是增量式的，这样每次镜像拉取、推送的内容，比原本多个完整的操作系统的大小要小得多；而共享层的存在，可以使得所有这些容器镜像需要的总空间，也比每个镜像的总和要小。这样就使得基于容器镜像的团队协作，要比基于动则几个 GB 的虚拟机磁盘镜像的协作要敏捷得多。</p><p>更重要的是，一旦这个镜像被发布，那么你在全世界的任何一个地方下载这个镜像，得到的内容都完全一致，可以完全复现这个镜像制作者当初的完整环境。这，就是容器技术“强一致性”的重要体现。</p><p>而这种价值正是支撑 Docker 公司在 2014~2016 年间迅猛发展的核心动力。容器镜像的发明，不仅打通了“开发 - 测试 - 部署”流程的每一个环节，更重要的是：</p><blockquote><p>容器镜像将会成为未来软件的主流发布方式。</p></blockquote><h2 id="白话容器基础（四）：重新认识Docker容器"><a href="#白话容器基础（四）：重新认识Docker容器" class="headerlink" title="白话容器基础（四）：重新认识Docker容器"></a>白话容器基础（四）：重新认识Docker容器</h2><p>在前面的分享中，我分别从 Linux Namespace 的隔离能力、Linux Cgroups 的限制能力，以及基于 rootfs 的文件系统三个角度，为你剖析了一个 Linux 容器的核心实现原理。</p><blockquote><p>备注：之所以要强调 Linux 容器，是因为比如 Docker on Mac，以及 Windows Docker（Hyper-V 实现），实际上是基于虚拟化技术实现的，跟我们这个专栏着重介绍的 Linux 容器完全不同。</p></blockquote><p>而在今天的分享中，我会通过一个实际案例，对“白话容器基础”系列的所有内容做一次深入的总结和扩展。希望通过这次的讲解，能够让你更透彻地理解 Docker 容器的本质。</p><p>在开始实践之前，你需要准备一台 Linux 机器，并安装 Docker。这个流程我就不再赘述了。</p><p>这一次，我要用 Docker 部署一个用 Python 编写的 Web 应用。这个应用的代码部分（app.py）非常简单：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"> </span><br><span class="line">app = Flask(__name__)</span><br><span class="line"> </span><br><span class="line"><span class="meta">@app.route('/')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">()</span>:</span></span><br><span class="line">    html = <span class="string">"&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;"</span> \</span><br><span class="line">           <span class="string">"&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;"</span>           </span><br><span class="line">    <span class="keyword">return</span> html.format(name=os.getenv(<span class="string">"NAME"</span>, <span class="string">"world"</span>), hostname=socket.gethostname())</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    app.run(host=<span class="string">'0.0.0.0'</span>, port=<span class="number">80</span>)</span><br></pre></td></tr></table></figure><p>在这段代码中，我使用 Flask 框架启动了一个 Web 服务器，而它唯一的功能是：如果当前环境中有“NAME”这个环境变量，就把它打印在“Hello”后，否则就打印“Hello world”，最后再打印出当前环境的 hostname。</p><p>这个应用的依赖，则被定义在了同目录下的 requirements.txt 文件里，内容如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat requirements.txt</span><br><span class="line">Flask</span><br></pre></td></tr></table></figure><p><strong>而将这样一个应用容器化的第一步，是制作容器镜像。</strong></p><p>不过，相较于我之前介绍的制作 rootfs 的过程，Docker 为你提供了一种更便捷的方式，叫作 Dockerfile，如下所示。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用官方提供的 Python 开发镜像作为基础镜像</span></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">2.7</span>-slim</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将工作目录切换为 /app</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /app</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将当前目录下的所有内容复制到 /app 下</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> . /app</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用 pip 命令安装这个应用所需要的依赖</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pip install --trusted-host pypi.python.org -r requirements.txt</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 允许外界访问容器的 80 端口</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">80</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置环境变量</span></span><br><span class="line"><span class="keyword">ENV</span> NAME World</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置容器进程为：python app.py，即：这个 Python 应用的启动命令</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"python"</span>, <span class="string">"app.py"</span>]</span></span><br></pre></td></tr></table></figure><p>通过这个文件的内容，你可以看到<strong>Dockerfile 的设计思想，是使用一些标准的原语（即大写高亮的词语），描述我们所要构建的 Docker 镜像。并且这些原语，都是按顺序处理的。</strong></p><p>比如 FROM 原语，指定了“python:2.7-slim”这个官方维护的基础镜像，从而免去了安装 Python 等语言环境的操作。否则，这一段我们就得这么写了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu:latest</span><br><span class="line">RUN apt-get update -yRUN apt-get install -y python-pip python-dev build-essential</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>其中，RUN 原语就是在容器里执行 shell 命令的意思。</p><p>而 WORKDIR，意思是在这一句之后，Dockerfile 后面的操作都以这一句指定的 /app 目录作为当前目录。</p><p>所以，到了最后的 CMD，意思是 Dockerfile 指定 python app.py 为这个容器的进程。这里，app.py 的实际路径是 /app/app.py。所以，CMD [“python”, “app.py”] 等价于 “docker runpython app.py”。</p><p>另外，在使用 Dockerfile 时，你可能还会看到一个叫作 ENTRYPOINT 的原语。实际上，它和 CMD 都是 Docker 容器进程启动所必需的参数，完整执行格式是：“ENTRYPOINT CMD”。</p><p>但是，默认情况下，Docker 会为你提供一个隐含的 ENTRYPOINT，即：/bin/sh -c。所以，在不指定 ENTRYPOINT 时，比如在我们这个例子里，实际上运行在容器里的完整进程是：/bin/sh -c “python app.py”，即 CMD 的内容就是 ENTRYPOINT 的参数。</p><blockquote><p>备注：基于以上原因，我们后面会统一称 Docker 容器的启动进程为 ENTRYPOINT，而不是 CMD。</p></blockquote><p>需要注意的是，Dockerfile 里的原语并不都是指对容器内部的操作。就比如 ADD，它指的是把当前目录（即 Dockerfile 所在的目录）里的文件，复制到指定容器内的目录当中。</p><p>读懂这个 Dockerfile 之后，我再把上述内容，保存到当前目录里一个名叫“Dockerfile”的文件中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls</span><br><span class="line">Dockerfile  app.py   requirements.txt</span><br></pre></td></tr></table></figure><p>接下来，我就可以让 Docker 制作这个镜像了，在当前目录执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t helloworld .</span><br></pre></td></tr></table></figure><p>其中，-t 的作用是给这个镜像加一个 Tag，即：起一个好听的名字。docker build 会自动加载当前目录下的 Dockerfile 文件，然后按照顺序，执行文件中的原语。而这个过程，实际上可以等同于 Docker 使用基础镜像启动了一个容器，然后在容器中依次执行 Dockerfile 中的原语。</p><p><strong>需要注意的是，Dockerfile 中的每个原语执行后，都会生成一个对应的镜像层。</strong>即使原语本身并没有明显地修改文件的操作（比如，ENV 原语），它对应的层也会存在。只不过在外界看来，这个层是空的。</p><p>docker build 操作完成后，我可以通过 docker images 命令查看结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker image ls</span><br><span class="line"> </span><br><span class="line">REPOSITORY            TAG                 IMAGE ID</span><br><span class="line">helloworld         latest              653287cdf998</span><br></pre></td></tr></table></figure><p>通过这个镜像 ID，你就可以使用在《白话容器基础（三）：深入理解容器镜像》中讲过的方法，查看这些新增的层在 AuFS 路径下对应的文件和目录了。</p><p>接下来，我使用这个镜像，通过 docker run 命令启动容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -p 4000:80 helloworld</span><br></pre></td></tr></table></figure><p>在这一句命令中，镜像名 helloworld 后面，我什么都不用写，因为在 Dockerfile 中已经指定了 CMD。否则，我就得把进程的启动命令加在后面：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -p 4000:80 helloworld python app.py</span><br></pre></td></tr></table></figure><p>容器启动之后，我可以使用 docker ps 命令看到：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED</span><br><span class="line">4ddf4638572d        helloworld       <span class="string">"python app.py"</span>     10 seconds ago</span><br></pre></td></tr></table></figure><p>同时，我已经通过 -p 4000:80 告诉了 Docker，请把容器内的 80 端口映射在宿主机的 4000 端口上。</p><p>这样做的目的是，只要访问宿主机的 4000 端口，我就可以看到容器里应用返回的结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://localhost:4000</span><br><span class="line">&lt;h3&gt;Hello World!&lt;/h3&gt;&lt;b&gt;Hostname:&lt;/b&gt; 4ddf4638572d&lt;br/&gt;</span><br></pre></td></tr></table></figure><p>否则，我就得先用 docker inspect 命令查看容器的 IP 地址，然后访问“http://&lt; 容器 IP 地址 &gt;:80”才可以看到容器内应用的返回。</p><p>至此，我已经使用容器完成了一个应用的开发与测试，如果现在想要把这个容器的镜像上传到 DockerHub 上分享给更多的人，我要怎么做呢？</p><p>为了能够上传镜像，<strong>我首先需要注册一个 Docker Hub 账号，然后使用 docker login 命令登录。</strong></p><p>接下来，我要<strong>用 docker tag 命令给容器镜像起一个完整的名字：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker tag helloworld geektime/helloworld:v1</span><br></pre></td></tr></table></figure><blockquote><p>注意：你自己做实验时，请将 “geektime” 替换成你自己的 Docker Hub 账户名称，比如 zhangsan/helloworld:v1</p></blockquote><p>其中，geektime 是我在 Docker Hub 上的用户名，它的“学名”叫镜像仓库（Repository）；“/”后面的 helloworld 是这个镜像的名字，而“v1”则是我给这个镜像分配的版本号。</p><p><strong>然后，我执行 docker push：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker push geektime/helloworld:v1</span><br></pre></td></tr></table></figure><p>这样，我就可以把这个镜像上传到 Docker Hub 上了。</p><p>此外，我还可以使用 docker commit 指令，把一个正在运行的容器，直接提交为一个镜像。一般来说，需要这么操作原因是：这个容器运行起来后，我又在里面做了一些操作，并且要把操作结果保存到镜像里，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it 4ddf4638572d /bin/sh</span><br><span class="line"><span class="comment"># 在容器内部新建了一个文件</span></span><br><span class="line">root@4ddf4638572d:/app<span class="comment"># touch test.txt</span></span><br><span class="line">root@4ddf4638572d:/app<span class="comment"># exit</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 将这个新建的文件提交到镜像中保存</span></span><br><span class="line">$ docker commit 4ddf4638572d geektime/helloworld:v2</span><br></pre></td></tr></table></figure><p>这里，我使用了 docker exec 命令进入到了容器当中。在了解了 Linux Namespace 的隔离机制后，你应该会很自然地想到一个问题：<strong>docker exec 是怎么做到进入容器里的呢？</strong></p><p>实际上，Linux Namespace 创建的隔离空间虽然看不见摸不着，但一个进程的 Namespace 信息在宿主机上是确确实实存在的，并且是以一个文件的方式存在。</p><p>比如，通过如下指令，你可以看到当前正在运行的 Docker 容器的进程号（PID）是 25686：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect --format <span class="string">'&#123;&#123; .State.Pid &#125;&#125;'</span>  4ddf4638572d</span><br><span class="line">25686</span><br></pre></td></tr></table></figure><p>这时，你可以通过查看宿主机的 proc 文件，看到这个 25686 进程的所有 Namespace 对应的文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ls -l  /proc/25686/ns</span><br><span class="line">total 0</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 cgroup -&gt; cgroup:[4026531835]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 ipc -&gt; ipc:[4026532278]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 mnt -&gt; mnt:[4026532276]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 net -&gt; net:[4026532281]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 pid -&gt; pid:[4026532279]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 pid_for_children -&gt; pid:[4026532279]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 user -&gt; user:[4026531837]</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 uts -&gt; uts:[4026532277]</span><br></pre></td></tr></table></figure><p>可以看到，一个进程的每种 Linux Namespace，都在它对应的 /proc/[进程号]/ns 下有一个对应的虚拟文件，并且链接到一个真实的 Namespace 文件上。</p><p>有了这样一个可以“hold 住”所有 Linux Namespace 的文件，我们就可以对 Namespace 做一些很有意义事情了，比如：加入到一个已经存在的 Namespace 当中。</p><p><strong>这也就意味着：一个进程，可以选择加入到某个进程已有的 Namespace 当中，从而达到“进入”这个进程所在容器的目的，这正是 docker exec 的实现原理。</strong></p><p>而这个操作所依赖的，乃是一个名叫 setns() 的 Linux 系统调用。它的调用方法，我可以用如下一段小程序为你说明：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> errExit(msg) do &#123; perror(msg); exit(EXIT_FAILURE);&#125; while (0)</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> fd;</span><br><span class="line">    </span><br><span class="line">    fd = <span class="built_in">open</span>(argv[<span class="number">1</span>], O_RDONLY);</span><br><span class="line">    <span class="keyword">if</span> (setns(fd, <span class="number">0</span>) == <span class="number">-1</span>) &#123;</span><br><span class="line">        errExit(<span class="string">"setns"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    execvp(argv[<span class="number">2</span>], &amp;argv[<span class="number">2</span>]); </span><br><span class="line">    errExit(<span class="string">"execvp"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码功能非常简单：它一共接收两个参数，第一个参数是 argv<a href="/images/k8s/k8s-01/1.jpg">1</a>，即当前进程要加入的 Namespace 文件的路径，比如 /proc/25686/ns/net；而第二个参数，则是你要在这个 Namespace 里运行的进程，比如 /bin/bash。</p><p>这段代码的的核心操作，则是通过 open() 系统调用打开了指定的 Namespace 文件，并把这个文件的描述符 fd 交给 setns() 使用。在 setns() 执行后，当前进程就加入了这个文件对应的 Linux Namespace 当中了。</p><p>现在，你可以编译执行一下这个程序，加入到容器进程（PID=25686）的 Network Namespace 中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ gcc -o set_ns set_ns.c </span><br><span class="line">$ ./set_ns /proc/25686/ns/net /bin/bash </span><br><span class="line">$ ifconfig</span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 02:42:ac:11:00:02  </span><br><span class="line">          inet addr:172.17.0.2  Bcast:0.0.0.0  Mask:255.255.0.0</span><br><span class="line">          inet6 addr: fe80::42:acff:fe11:2/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:12 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:10 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">   collisions:0 txqueuelen:0 </span><br><span class="line">          RX bytes:976 (976.0 B)  TX bytes:796 (796.0 B)</span><br><span class="line"> </span><br><span class="line">lo        Link encap:Local Loopback  </span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          inet6 addr: ::1/128 Scope:Host</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">  collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p>正如上所示，当我们执行 ifconfig 命令查看网络设备时，我会发现能看到的网卡“变少”了：只有两个。而我的宿主机则至少有四个网卡。这是怎么回事呢？</p><p>实际上，在 setns() 之后我看到的这两个网卡，正是我在前面启动的 Docker 容器里的网卡。也就是说，我新创建的这个 /bin/bash 进程，由于加入了该容器进程（PID=25686）的 Network Namepace，它看到的网络设备与这个容器里是一样的，即：/bin/bash 进程的网络设备视图，也被修改了。</p><p>而一旦一个进程加入到了另一个 Namespace 当中，在宿主机的 Namespace 文件上，也会有所体现。</p><p>在宿主机上，你可以用 ps 指令找到这个 set_ns 程序执行的 /bin/bash 进程，其真实的 PID 是 28499：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在宿主机上</span></span><br><span class="line">ps aux | grep /bin/bash</span><br><span class="line">root     28499  0.0  0.0 19944  3612 pts/0    S    14:15   0:00 /bin/bash</span><br></pre></td></tr></table></figure><p>这时，如果按照前面介绍过的方法，查看一下这个 PID=28499 的进程的 Namespace，你就会发现这样一个事实：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ls -l /proc/28499/ns/net</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:18 /proc/28499/ns/net -&gt; net:[4026532281]</span><br><span class="line"> </span><br><span class="line">$ ls -l  /proc/25686/ns/net</span><br><span class="line">lrwxrwxrwx 1 root root 0 Aug 13 14:05 /proc/25686/ns/net -&gt; net:[4026532281]</span><br></pre></td></tr></table></figure><p>在 /proc/[PID]/ns/net 目录下，这个 PID=28499 进程，与我们前面的 Docker 容器进程（PID=25686）指向的 Network Namespace 文件完全一样。这说明这两个进程，共享了这个名叫 net:[4026532281] 的 Network Namespace。</p><p>此外，Docker 还专门提供了一个参数，可以让你启动一个容器并“加入”到另一个容器的 Network Namespace 里，这个参数就是 -net，比如:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --net container:4ddf4638572d busybox ifconfig</span><br></pre></td></tr></table></figure><p>这样，我们新启动的这个容器，就会直接加入到 ID=4ddf4638572d 的容器，也就是我们前面的创建的 Python 应用容器（PID=25686）的 Network Namespace 中。所以，这里 ifconfig 返回的网卡信息，跟我前面那个小程序返回的结果一模一样，你也可以尝试一下。</p><p>而如果我指定–net=host，就意味着这个容器不会为进程启用 Network Namespace。这就意味着，这个容器拆除了 Network Namespace 的“隔离墙”，所以，它会和宿主机上的其他普通进程一样，直接共享宿主机的网络栈。这就为容器直接操作和使用宿主机网络提供了一个渠道。</p><p><strong>转了一个大圈子，我其实是为你详细解读了 docker exec 这个操作背后，Linux Namespace 更具体的工作原理。</strong></p><p><strong>这种通过操作系统进程相关的知识，逐步剖析 Docker 容器的方法，是理解容器的一个关键思路，希望你一定要掌握。</strong></p><p>现在，我们再一起回到前面提交镜像的操作 docker commit 上来吧。</p><p>docker commit，实际上就是在容器运行起来后，把最上层的“可读写层”，加上原先容器镜像的只读层，打包组成了一个新的镜像。当然，下面这些只读层在宿主机上是共享的，不会占用额外的空间。</p><p>而由于使用了联合文件系统，你在容器里对镜像 rootfs 所做的任何修改，都会被操作系统先复制到这个可读写层，然后再修改。这就是所谓的：Copy-on-Write。</p><p>而正如前所说，Init 层的存在，就是为了避免你执行 docker commit 时，把 Docker 自己对 /etc/hosts 等文件做的修改，也一起提交掉。</p><p>有了新的镜像，我们就可以把它推送到 Docker Hub 上了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker push geektime/helloworld:v2</span><br></pre></td></tr></table></figure><p>你可能还会有这样的问题：我在企业内部，能不能也搭建一个跟 Docker Hub 类似的镜像上传系统呢？</p><p>当然可以，这个统一存放镜像的系统，就叫作 Docker Registry。感兴趣的话，你可以查看<a href="https://docs.docker.com/registry/" target="_blank" rel="noopener">Docker 的官方文档</a>，以及<a href="https://github.com/goharbor/harbor" target="_blank" rel="noopener">VMware 的 Harbor</a> 项目。</p><p><strong>最后，我再来讲解一下 Docker 项目另一个重要的内容：Volume（数据卷）。</strong></p><p>前面我已经介绍过，容器技术使用了 rootfs 机制和 Mount Namespace，构建出了一个同宿主机完全隔离开的文件系统环境。这时候，我们就需要考虑这样两个问题：</p><ol><li>容器里进程新建的文件，怎么才能让宿主机获取到？</li><li>宿主机上的文件和目录，怎么才能让容器里的进程访问到？</li></ol><p>这正是 Docker Volume 要解决的问题：<strong>Volume 机制，允许你将宿主机上指定的目录或者文件，挂载到容器里面进行读取和修改操作。</strong></p><p>在 Docker 项目里，它支持两种 Volume 声明方式，可以把宿主机目录挂载进容器的 /test 目录当中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -v /<span class="built_in">test</span> ...</span><br><span class="line">$ docker run -v /home:/<span class="built_in">test</span> ...</span><br></pre></td></tr></table></figure><p>而这两种声明方式的本质，实际上是相同的：都是把一个宿主机的目录挂载进了容器的 /test 目录。</p><p>只不过，在第一种情况下，由于你并没有显示声明宿主机目录，那么 Docker 就会默认在宿主机上创建一个临时目录 /var/lib/docker/volumes/[VOLUME_ID]/_data，然后把它挂载到容器的 /test 目录上。而在第二种情况下，Docker 就直接把宿主机的 /home 目录挂载到容器的 /test 目录上。</p><p>那么，Docker 又是如何做到把一个宿主机上的目录或者文件，挂载到容器里面去呢？难道又是 Mount Namespace 的黑科技吗？</p><p>实际上，并不需要这么麻烦。</p><p>在《白话容器基础（三）：深入理解容器镜像》的分享中，我已经介绍过，当容器进程被创建之后，尽管开启了 Mount Namespace，但是在它执行 chroot（或者 pivot_root）之前，容器进程一直可以看到宿主机上的整个文件系统。</p><p>而宿主机上的文件系统，也自然包括了我们要使用的容器镜像。这个镜像的各个层，保存在 /var/lib/docker/aufs/diff 目录下，在容器进程启动后，它们会被联合挂载在 /var/lib/docker/aufs/mnt/ 目录中，这样容器所需的 rootfs 就准备好了。</p><p>所以，我们只需要在 rootfs 准备好之后，在执行 chroot 之前，把 Volume 指定的宿主机目录（比如 /home 目录），挂载到指定的容器目录（比如 /test 目录）在宿主机上对应的目录（即 /var/lib/docker/aufs/mnt/[可读写层 ID]/test）上，这个 Volume 的挂载工作就完成了。</p><p>更重要的是，由于执行这个挂载操作时，“容器进程”已经创建了，也就意味着此时 Mount Namespace 已经开启了。所以，这个挂载事件只在这个容器里可见。你在宿主机上，是看不见容器内部的这个挂载点的。这就<strong>保证了容器的隔离性不会被 Volume 打破。</strong></p><blockquote><p>注意：这里提到的 “ 容器进程 “，是 Docker 创建的一个容器初始化进程 (dockerinit)，而不是应用进程 (ENTRYPOINT + CMD)。dockerinit 会负责完成根目录的准备、挂载设备和目录、配置 hostname 等一系列需要在容器内进行的初始化操作。最后，它通过 execv() 系统调用，让应用进程取代自己，成为容器里的 PID=1 的进程。</p></blockquote><p>而这里要使用到的挂载技术，就是 Linux 的<strong>绑定挂载（bind mount）机制。</strong>它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。</p><p>其实，如果你了解 Linux 内核的话，就会明白，绑定挂载实际上是一个 inode 替换的过程。在 Linux 操作系统中，inode 可以理解为存放文件内容的“对象”，而 dentry，也叫目录项，就是访问这个 inode 所使用的“指针”。</p><p><img src="/images/k8s/k8s-01/4.jpg" alt="4"></p><p>正如上图所示，mount –bind /home /test，会将 /home 挂载到 /test 上。其实相当于将 /test 的 dentry，重定向到了 /home 的 inode。这样当我们修改 /test 目录时，实际修改的是 /home 目录的 inode。这也就是为何，一旦执行 umount 命令，/test 目录原先的内容就会恢复：因为修改真正发生在的，是 /home 目录里。</p><p><strong>所以，在一个正确的时机，进行一次绑定挂载，Docker 就可以成功地将一个宿主机上的目录或文件，不动声色地挂载到容器中。</strong></p><p>这样，进程在容器里对这个 /test 目录进行的所有操作，都实际发生在宿主机的对应目录（比如，/home，或者 /var/lib/docker/volumes/[VOLUME_ID]/_data）里，而不会影响容器镜像的内容。</p><p>那么，这个 /test 目录里的内容，既然挂载在容器 rootfs 的可读写层，它会不会被 docker commit 提交掉呢？</p><p>也不会。</p><p>这个原因其实我们前面已经提到过。容器的镜像操作，比如 docker commit，都是发生在宿主机空间的。而由于 Mount Namespace 的隔离作用，宿主机并不知道这个绑定挂载的存在。所以，在宿主机看来，容器中可读写层的 /test 目录（/var/lib/docker/aufs/mnt/[可读写层 ID]/test），<strong>始终是空的。</strong></p><p>不过，由于 Docker 一开始还是要创建 /test 这个目录作为挂载点，所以执行了 docker commit 之后，你会发现新产生的镜像里，会多出来一个空的 /test 目录。毕竟，新建目录操作，又不是挂载操作，Mount Namespace 对它可起不到“障眼法”的作用。</p><p>结合以上的讲解，我们现在来亲自验证一下：</p><p>首先，启动一个 helloworld 容器，给它声明一个 Volume，挂载在容器里的 /test 目录上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d -v /<span class="built_in">test</span> helloworld</span><br><span class="line">cf53b766fa6f</span><br></pre></td></tr></table></figure><p>容器启动之后，我们来查看一下这个 Volume 的 ID：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume ls</span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line"><span class="built_in">local</span>               cb1c2f7221fa9b0971cc35f68aa1034824755ac44a034c0c0a1dd318838d3a6d</span><br></pre></td></tr></table></figure><p>然后，使用这个 ID，可以找到它在 Docker 工作目录下的 volumes 路径：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls /var/lib/docker/volumes/cb1c2f7221fa/_data/</span><br></pre></td></tr></table></figure><p>这个 _data 文件夹，就是这个容器的 Volume 在宿主机上对应的临时目录了。</p><p>接下来，我们在容器的 Volume 里，添加一个文件 text.txt：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it cf53b766fa6f /bin/sh</span><br><span class="line"><span class="built_in">cd</span> <span class="built_in">test</span>/</span><br><span class="line">touch text.txt</span><br></pre></td></tr></table></figure><p>这时，我们再回到宿主机，就会发现 text.txt 已经出现在了宿主机上对应的临时目录里：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /var/lib/docker/volumes/cb1c2f7221fa/_data/</span><br><span class="line">text.txt</span><br></pre></td></tr></table></figure><p>可是，如果你在宿主机上查看该容器的可读写层，虽然可以看到这个 /test 目录，但其内容是空的（关于如何找到这个 AuFS 文件系统的路径，请参考我上一次分享的内容）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls /var/lib/docker/aufs/mnt/6780d0778b8a/<span class="built_in">test</span></span><br></pre></td></tr></table></figure><p>可以确认，容器 Volume 里的信息，并不会被 docker commit 提交掉；但这个挂载点目录 /test 本身，则会出现在新的镜像当中。</p><p>以上内容，就是 Docker Volume 的核心原理了。</p><p><strong>小结</strong></p><p>在今天的这次分享中，我用了一个非常经典的 Python 应用作为案例，讲解了 Docke 容器使用的主要场景。熟悉了这些操作，你也就基本上摸清了 Docker 容器的核心功能。</p><p>更重要的是，我着重介绍了如何使用 Linux Namespace、Cgroups，以及 rootfs 的知识，对容器进行了一次庖丁解牛似的解读。</p><p>借助这种思考问题的方法，最后的 Docker 容器，我们实际上就可以用下面这个“全景图”描述出来：</p><p><img src="/images/k8s/k8s-01/5.jpg" alt="5"></p><p>这个容器进程“python app.py”，运行在由 Linux Namespace 和 Cgroups 构成的隔离环境里；而它运行所需要的各种文件，比如 python，app.py，以及整个操作系统文件，则由多个联合挂载在一起的 rootfs 层提供。</p><p>这些 rootfs 层的最下层，是来自 Docker 镜像的只读层。</p><p>在只读层之上，是 Docker 自己添加的 Init 层，用来存放被临时修改过的 /etc/hosts 等文件。</p><p>而 rootfs 的最上层是一个可读写层，它以 Copy-on-Write 的方式存放任何对只读层的修改，容器声明的 Volume 的挂载点，也出现在这一层。</p><p>通过这样的剖析，对于曾经“神秘莫测”的容器技术，你是不是感觉清晰了很多呢？</p><h2 id="从容器到容器云：谈谈Kubernetes的本质"><a href="#从容器到容器云：谈谈Kubernetes的本质" class="headerlink" title="从容器到容器云：谈谈Kubernetes的本质"></a>从容器到容器云：谈谈Kubernetes的本质</h2><p>在前面，我以 Docker 项目为例，一步步剖析了 Linux 容器的具体实现方式。通过这些讲解你应该能够明白：一个“容器”，实际上是一个由 Linux Namespace、Linux Cgroups 和 rootfs 三种技术构建出来的进程的隔离环境。</p><p>从这个结构中我们不难看出，一个正在运行的 Linux 容器，其实可以被“一分为二”地看待：</p><ol><li>一组联合挂载在 /var/lib/docker/aufs/mnt 上的 rootfs，这一部分我们称为“容器镜像”（Container Image），是容器的静态视图；</li><li>一个由 Namespace+Cgroups 构成的隔离环境，这一部分我们称为“容器运行时”（Container Runtime），是容器的动态视图。</li></ol><p>更进一步地说，作为一名开发者，我并不关心容器运行时的差异。因为，在整个“开发 - 测试 - 发布”的流程中，真正承载着容器信息进行传递的，是容器镜像，而不是容器运行时。</p><p>这个重要假设，正是容器技术圈在 Docker 项目成功后不久，就迅速走向了“容器编排”这个“上层建筑”的主要原因：作为一家云服务商或者基础设施提供商，我只要能够将用户提交的 Docker 镜像以容器的方式运行起来，就能成为这个非常热闹的容器生态图上的一个承载点，从而将整个容器技术栈上的价值，沉淀在我的这个节点上。</p><p>更重要的是，只要从我这个承载点向 Docker 镜像制作者和使用者方向回溯，整条路径上的各个服务节点，比如 CI/CD、监控、安全、网络、存储等等，都有我可以发挥和盈利的余地。这个逻辑，正是所有云计算提供商如此热衷于容器技术的重要原因：通过容器镜像，它们可以和潜在用户（即，开发者）直接关联起来。</p><p>从一个开发者和单一的容器镜像，到无数开发者和庞大的容器集群，容器技术实现了从“容器”到“容器云”的飞跃，标志着它真正得到了市场和生态的认可。</p><p><strong>这样，容器就从一个开发者手里的小工具，一跃成为了云计算领域的绝对主角；而能够定义容器组织和管理规范的“容器编排”技术，则当仁不让地坐上了容器技术领域的“头把交椅”。</strong></p><p>这其中，最具代表性的容器编排工具，当属 Docker 公司的 Compose+Swarm 组合，以及 Google 与 RedHat 公司共同主导的 Kubernetes 项目。</p><p>跟很多基础设施领域先有工程实践、后有方法论的发展路线不同，Kubernetes 项目的理论基础则要比工程实践走得靠前得多，这当然要归功于 Google 公司在 2015 年 4 月发布的 Borg 论文了。</p><p>Borg 系统，一直以来都被誉为 Google 公司内部最强大的“秘密武器”。虽然略显夸张，但这个说法倒不算是吹牛。</p><p>因为，相比于 Spanner、BigTable 等相对上层的项目，Borg 要承担的责任，是承载 Google 公司整个基础设施的核心依赖。在 Google 公司已经公开发表的基础设施体系论文中，Borg 项目当仁不让地位居整个基础设施技术栈的最底层。</p><p><img src="/images/k8s/k8s-01/6.jpg" alt="6"></p><blockquote><p><a href="http://malteschwarzkopf.de/research/assets/google-stack.pdf" target="_blank" rel="noopener">http://malteschwarzkopf.de/research/assets/google-stack.pdf</a></p></blockquote><p>上面这幅图，来自于 Google Omega 论文的第一作者的博士毕业论文。它描绘了当时 Google 已经公开发表的整个基础设施栈。在这个图里，你既可以找到 MapReduce、BigTable 等知名项目，也能看到 Borg 和它的继任者 Omega 位于整个技术栈的最底层。</p><p>正是由于这样的定位，Borg 可以说是 Google 最不可能开源的一个项目。而幸运地是，得益于 Docker 项目和容器技术的风靡，它却终于得以以另一种方式与开源社区见面，这个方式就是 Kubernetes 项目。</p><p>所以，相比于“小打小闹”的 Docker 公司、“旧瓶装新酒”的 Mesos 社区，<strong>Kubernetes 项目从一开始就比较幸运地站上了一个他人难以企及的高度：</strong>在它的成长阶段，这个项目每一个核心特性的提出，几乎都脱胎于 Borg/Omega 系统的设计与经验。更重要的是，这些特性在开源社区落地的过程中，又在整个社区的合力之下得到了极大的改进，修复了很多当年遗留在 Borg 体系中的缺陷和问题。</p><p>所以，尽管在发布之初被批评是“曲高和寡”，但是在逐渐觉察到 Docker 技术栈的“稚嫩”和 Mesos 社区的“老迈”之后，这个社区很快就明白了：Kubernetes 项目在 Borg 体系的指导下，体现出了一种独有的“先进性”与“完备性”，而这些特质才是一个基础设施领域开源项目赖以生存的核心价值。</p><p>为了更好地理解这两种特质，我们不妨从 Kubernetes 的顶层设计说起。</p><p><strong>首先，Kubernetes 项目要解决的问题是什么？</strong></p><p>编排？调度？容器云？还是集群管理？</p><p>实际上，这个问题到目前为止都没有固定的答案。因为在不同的发展阶段，Kubernetes 需要着重解决的问题是不同的。</p><p>但是，对于大多数用户来说，他们希望 Kubernetes 项目带来的体验是确定的：现在我有了应用的容器镜像，请帮我在一个给定的集群上把这个应用运行起来。</p><p>更进一步地说，我还希望 Kubernetes 能给我提供路由网关、水平扩展、监控、备份、灾难恢复等一系列运维能力。</p><p>等一下，这些功能听起来好像有些耳熟？这不就是经典 PaaS（比如，Cloud Foundry）项目的能力吗？</p><p>而且，有了 Docker 之后，我根本不需要什么 Kubernetes、PaaS，只要使用 Docker 公司的 Compose+Swarm 项目，就完全可以很方便地 DIY 出这些功能了！</p><p>所以说，如果 Kubernetes 项目只是停留在拉取用户镜像、运行容器，以及提供常见的运维功能的话，那么别说跟“原生”的 Docker Swarm 项目竞争了，哪怕跟经典的 PaaS 项目相比也难有什么优势可言。</p><p>而实际上，在定义核心功能的过程中，Kubernetes 项目正是依托着 Borg 项目的理论优势，才在短短几个月内迅速站稳了脚跟，进而确定了一个如下图所示的全局架构：</p><p><img src="/images/k8s/k8s-01/7.jpg" alt="7"></p><p>我们可以看到，Kubernetes 项目的架构，跟它的原型项目 Borg 非常类似，都由 Master 和 Node 两种节点组成，而这两种角色分别对应着控制节点和计算节点。</p><p>其中，控制节点，即 Master 节点，由三个紧密协作的独立组件组合而成，它们分别是负责 API 服务的 kube-apiserver、负责调度的 kube-scheduler，以及负责容器编排的 kube-controller-manager。整个集群的持久化数据，则由 kube-apiserver 处理后保存在 Etcd 中。</p><p>而计算节点上最核心的部分，则是一个叫作 kubelet 的组件。</p><p><strong>在 Kubernetes 项目中，kubelet 主要负责同容器运行时（比如 Docker 项目）打交道。</strong>而这个交互所依赖的，是一个称作 CRI（Container Runtime Interface）的远程调用接口，这个接口定义了容器运行时的各项核心操作，比如：启动一个容器需要的所有参数。</p><p>这也是为何，Kubernetes 项目并不关心你部署的是什么容器运行时、使用的什么技术实现，只要你的这个容器运行时能够运行标准的容器镜像，它就可以通过实现 CRI 接入到 Kubernetes 项目当中。</p><p>而具体的容器运行时，比如 Docker 项目，则一般通过 OCI 这个容器运行时规范同底层的 Linux 操作系统进行交互，即：把 CRI 请求翻译成对 Linux 操作系统的调用（操作 Linux Namespace 和 Cgroups 等）。</p><p><strong>此外，kubelet 还通过 gRPC 协议同一个叫作 Device Plugin 的插件进行交互。</strong>这个插件，是 Kubernetes 项目用来管理 GPU 等宿主机物理设备的主要组件，也是基于 Kubernetes 项目进行机器学习训练、高性能作业支持等工作必须关注的功能。</p><p><strong>而kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。</strong>这两个插件与 kubelet 进行交互的接口，分别是 CNI（Container Networking Interface）和 CSI（Container Storage Interface）。</p><p>实际上，kubelet 这个奇怪的名字，来自于 Borg 项目里的同源组件 Borglet。不过，如果你浏览过 Borg 论文的话，就会发现，这个命名方式可能是 kubelet 组件与 Borglet 组件的唯一相似之处。因为 Borg 项目，并不支持我们这里所讲的容器技术，而只是简单地使用了 Linux Cgroups 对进程进行限制。</p><p>这就意味着，像 Docker 这样的“容器镜像”在 Borg 中是不存在的，Borglet 组件也自然不需要像 kubelet 这样考虑如何同 Docker 进行交互、如何对容器镜像进行管理的问题，也不需要支持 CRI、CNI、CSI 等诸多容器技术接口。</p><p>可以说，kubelet 完全就是为了实现 Kubernetes 项目对容器的管理能力而重新实现的一个组件，与 Borg 之间并没有直接的传承关系。</p><blockquote><p>备注：虽然不使用 Docker，但 Google 内部确实在使用一个包管理工具，名叫 Midas Package Manager (MPM)，其实它可以部分取代 Docker 镜像的角色。</p></blockquote><p><strong>那么，Borg 对于 Kubernetes 项目的指导作用又体现在哪里呢？</strong></p><p>答案是，Master 节点。</p><p>虽然在 Master 节点的实现细节上 Borg 项目与 Kubernetes 项目不尽相同，但它们的出发点却高度一致，即：如何编排、管理、调度用户提交的作业？</p><p>所以，Borg 项目完全可以把 Docker 镜像看做是一种新的应用打包方式。这样，Borg 团队过去在大规模作业管理与编排上的经验就可以直接“套”在 Kubernetes 项目上了。</p><p>这些经验最主要的表现就是，<strong>从一开始，Kubernetes 项目就没有像同时期的各种“容器云”项目那样，把 Docker 作为整个架构的核心，而仅仅把它作为最底层的一个容器运行时实现。</strong></p><p>而 Kubernetes 项目要着重解决的问题，则来自于 Borg 的研究人员在论文中提到的一个非常重要的观点：</p><blockquote><p>运行在大规模集群中的各种任务之间，实际上存在着各种各样的关系。这些关系的处理，才是作业编排和管理系统最困难的地方。</p></blockquote><p>事实也正是如此。</p><p>其实，这种任务与任务之间的关系，在我们平常的各种技术场景中随处可见。比如，一个 Web 应用与数据库之间的访问关系，一个负载均衡器和它的后端服务之间的代理关系，一个门户应用与授权组件之间的调用关系。</p><p>更进一步地说，同属于一个服务单位的不同功能之间，也完全可能存在这样的关系。比如，一个 Web 应用与日志搜集组件之间的文件交换关系。</p><p>而在容器技术普及之前，传统虚拟机环境对这种关系的处理方法都是比较“粗粒度”的。你会经常发现很多功能并不相关的应用被一股脑儿地部署在同一台虚拟机中，只是因为它们之间偶尔会互相发起几个 HTTP 请求。</p><p>更常见的情况则是，一个应用被部署在虚拟机里之后，你还得手动维护很多跟它协作的守护进程（Daemon），用来处理它的日志搜集、灾难恢复、数据备份等辅助工作。</p><p>但容器技术出现以后，你就不难发现，在“功能单位”的划分上，容器有着独一无二的“细粒度”优势：毕竟容器的本质，只是一个进程而已。</p><p>也就是说，只要你愿意，那些原先拥挤在同一个虚拟机里的各个应用、组件、守护进程，都可以被分别做成镜像，然后运行在一个个专属的容器中。它们之间互不干涉，拥有各自的资源配额，可以被调度在整个集群里的任何一台机器上。而这，正是一个 PaaS 系统最理想的工作状态，也是所谓“微服务”思想得以落地的先决条件。</p><p>当然，如果只做到“封装微服务、调度单容器”这一层次，Docker Swarm 项目就已经绰绰有余了。如果再加上 Compose 项目，你甚至还具备了处理一些简单依赖关系的能力，比如：一个“Web 容器”和它要访问的数据库“DB 容器”。</p><p>在 Compose 项目中，你可以为这样的两个容器定义一个“link”，而 Docker 项目则会负责维护这个“link”关系，其具体做法是：Docker 会在 Web 容器中，将 DB 容器的 IP 地址、端口等信息以环境变量的方式注入进去，供应用进程使用，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">DB_NAME=/web/db</span><br><span class="line">DB_PORT=tcp://172.17.0.5:5432</span><br><span class="line">DB_PORT_5432_TCP=tcp://172.17.0.5:5432</span><br><span class="line">DB_PORT_5432_TCP_PROTO=tcp</span><br><span class="line">DB_PORT_5432_TCP_PORT=5432</span><br><span class="line">DB_PORT_5432_TCP_ADDR=172.17.0.5</span><br></pre></td></tr></table></figure><p>而当 DB 容器发生变化时（比如，镜像更新，被迁移到其他宿主机上等等），这些环境变量的值会由 Docker 项目自动更新。<strong>这就是平台项目自动地处理容器间关系的典型例子。</strong></p><p>可是，如果我们现在的需求是，要求这个项目能够处理前面提到的所有类型的关系，甚至还要能够支持未来可能出现的更多种类的关系呢？</p><p>这时，“link”这种单独针对一种案例设计的解决方案就太过简单了。如果你做过架构方面的工作，就会深有感触：一旦要追求项目的普适性，那就一定要从顶层开始做好设计。</p><p><strong>所以，Kubernetes 项目最主要的设计思想是，从更宏观的角度，以统一的方式来定义任务之间的各种关系，并且为将来支持更多种类的关系留有余地。</strong></p><p>比如，Kubernetes 项目对容器间的“访问”进行了分类，首先总结出了一类非常常见的“紧密交互”的关系，即：这些应用之间需要非常频繁的交互和访问；又或者，它们会直接通过本地文件进行信息交换。</p><p>在常规环境下，这些应用往往会被直接部署在同一台机器上，通过 Localhost 通信，通过本地磁盘目录交换文件。而在 Kubernetes 项目中，这些容器则会被划分为一个“Pod”，Pod 里的容器共享同一个 Network Namespace、同一组数据卷，从而达到高效率交换信息的目的。</p><p>Pod 是 Kubernetes 项目中最基础的一个对象，源自于 Google Borg 论文中一个名叫 Alloc 的设计。在后续的章节中，我们会对 Pod 做更进一步地阐述。</p><p>而对于另外一种更为常见的需求，比如 Web 应用与数据库之间的访问关系，Kubernetes 项目则提供了一种叫作“Service”的服务。像这样的两个应用，往往故意不部署在同一台机器上，这样即使 Web 应用所在的机器宕机了，数据库也完全不受影响。可是，我们知道，对于一个容器来说，它的 IP 地址等信息不是固定的，那么 Web 应用又怎么找到数据库容器的 Pod 呢？</p><p>所以，Kubernetes 项目的做法是给 Pod 绑定一个 Service 服务，而 Service 服务声明的 IP 地址等信息是“终生不变”的。<strong>这个Service 服务的主要作用，就是作为 Pod 的代理入口（Portal），从而代替 Pod 对外暴露一个固定的网络地址。</strong></p><p>这样，对于 Web 应用的 Pod 来说，它需要关心的就是数据库 Pod 的 Service 信息。不难想象，Service 后端真正代理的 Pod 的 IP 地址、端口等信息的自动更新、维护，则是 Kubernetes 项目的职责。</p><p>像这样，围绕着容器和 Pod 不断向真实的技术场景扩展，我们就能够摸索出一幅如下所示的 Kubernetes 项目核心功能的“全景图”。</p><p><img src="/images/k8s/k8s-01/8.jpg" alt="8"></p><p>按照这幅图的线索，我们从容器这个最基础的概念出发，首先遇到了容器间“紧密协作”关系的难题，于是就扩展到了 Pod；有了 Pod 之后，我们希望能一次启动多个应用的实例，这样就需要 Deployment 这个 Pod 的多实例管理器；而有了这样一组相同的 Pod 后，我们又需要通过一个固定的 IP 地址和端口以负载均衡的方式访问它，于是就有了 Service。</p><p>可是，如果现在两个不同 Pod 之间不仅有“访问关系”，还要求在发起时加上授权信息。最典型的例子就是 Web 应用对数据库访问时需要 Credential（数据库的用户名和密码）信息。那么，在 Kubernetes 中这样的关系又如何处理呢？</p><p>Kubernetes 项目提供了一种叫作 Secret 的对象，它其实是一个保存在 Etcd 里的键值对数据。这样，你把 Credential 信息以 Secret 的方式存在 Etcd 里，Kubernetes 就会在你指定的 Pod（比如，Web 应用的 Pod）启动时，自动把 Secret 里的数据以 Volume 的方式挂载到容器里。这样，这个 Web 应用就可以访问数据库了。</p><p><strong>除了应用与应用之间的关系外，应用运行的形态是影响“如何容器化这个应用”的第二个重要因素。</strong></p><p>为此，Kubernetes 定义了新的、基于 Pod 改进后的对象。比如 Job，用来描述一次性运行的 Pod（比如，大数据任务）；再比如 DaemonSet，用来描述每个宿主机上必须且只能运行一个副本的守护进程服务；又比如 CronJob，则用于描述定时任务等等。</p><p>如此种种，正是 Kubernetes 项目定义容器间关系和形态的主要方法。</p><p>可以看到，Kubernetes 项目并没有像其他项目那样，为每一个管理功能创建一个指令，然后在项目中实现其中的逻辑。这种做法，的确可以解决当前的问题，但是在更多的问题来临之后，往往会力不从心。</p><p>相比之下，在 Kubernetes 项目中，我们所推崇的使用方法是：</p><ul><li>相比之下，在 Kubernetes 项目中，我们所推崇的使用方法是：</li><li>然后，再为它定义一些“服务对象”，比如 Service、Secret、Horizontal Pod Autoscaler（自动水平扩展器）等。这些对象，会负责具体的平台级功能。</li></ul><p><strong>这种使用方法，就是所谓的“声明式 API”。这种 API 对应的“编排对象”和“服务对象”，都是 Kubernetes 项目中的 API 对象（API Object）。</strong></p><p>这就是 Kubernetes 最核心的设计理念，也是接下来我会重点剖析的关键技术点。</p><p><strong>最后，我来回答一个更直接的问题：Kubernetes 项目如何启动一个容器化任务呢？</strong></p><p>比如，我现在已经制作好了一个 Nginx 容器镜像，希望让平台帮我启动这个镜像。并且，我要求平台帮我运行两个完全相同的 Nginx 副本，以负载均衡的方式共同对外提供服务。</p><ul><li>如果是自己 DIY 的话，可能需要启动两台虚拟机，分别安装两个 Nginx，然后使用 keepalived 为这两个虚拟机做一个虚拟 IP。</li><li>而如果使用 Kubernetes 项目呢？你需要做的则是编写如下这样一个 YAML 文件（比如名叫 nginx-deployment.yaml）：</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>在上面这个 YAML 文件中，我们定义了一个 Deployment 对象，它的主体部分（spec.template 部分）是一个使用 Nginx 镜像的 Pod，而这个 Pod 的副本数是 2（replicas=2）。</p><p>然后执行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f nginx-deployment.yaml</span><br></pre></td></tr></table></figure><p>这样，两个完全相同的 Nginx 容器副本就被启动了。</p><p>不过，这么看来，做同样一件事情，Kubernetes 用户要做的工作也不少嘛。</p><p>别急，在后续的讲解中，我会陆续介绍 Kubernetes 项目这种“声明式 API”的种种好处，以及基于它实现的强大的编排能力。</p><p>拭目以待吧。</p><p><strong>小结</strong></p><p>首先，我和你一起回顾了容器的核心知识，说明了容器其实可以分为两个部分：容器运行时和容器镜像。</p><p>然后，我重点介绍了 Kubernetes 项目的架构，详细讲解了它如何使用“声明式 API”来描述容器化业务和容器间关系的设计思想。</p><p>实际上，过去很多的集群管理项目（比如 Yarn、Mesos，以及 Swarm）所擅长的，都是把一个容器，按照某种规则，放置在某个最佳节点上运行起来。这种功能，我们称为“调度”。</p><p>而 Kubernetes 项目所擅长的，是按照用户的意愿和整个系统的规则，完全自动化地处理好容器之间的各种关系。<strong>这种功能，就是我们经常听到的一个概念：编排。</strong></p><p>所以说，Kubernetes 项目的本质，是为用户提供一个具有普遍意义的容器编排工具。</p><p>不过，更重要的是，Kubernetes 项目为用户提供的不仅限于一个工具。它真正的价值，乃在于提供了一套基于容器构建分布式系统的基础依赖。关于这一点，相信你会在今后的学习中，体会的越来越深。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《深入剖析 Kubernetes》</li><li>《Kubernetes 原理剖析与实战应用》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://kubernetes.io" target="_blank" rel="noopener">https://kubernetes.io</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;预习容器的前世今生&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kubernetes" scheme="https://blog.lichao.xin/categories/Kubernetes/"/>
    
    
      <category term="Kubernetes" scheme="https://blog.lichao.xin/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>重学 Docker 之 容器进阶（五）</title>
    <link href="https://blog.lichao.xin/back-end/docker/docker-08/"/>
    <id>https://blog.lichao.xin/back-end/docker/docker-08/</id>
    <published>2021-04-24T13:20:00.000Z</published>
    <updated>2021-06-14T01:33:22.383Z</updated>
    
    <content type="html"><![CDATA[<p>容器安全</p><a id="more"></a><h2 id="容器安全（1）：我的容器真的需要privileged权限吗"><a href="#容器安全（1）：我的容器真的需要privileged权限吗" class="headerlink" title="容器安全（1）：我的容器真的需要privileged权限吗?"></a>容器安全（1）：我的容器真的需要privileged权限吗?</h2><p>容器安全是一个很大的话题，容器的安全性很大程度是由容器的架构特性所决定的。比如容器与宿主机共享 Linux 内核，通过 Namespace 来做资源的隔离，通过 shim/runC 的方式来启动等等。</p><p>这些容器架构特性，在你选择使用容器之后，作为使用容器的用户，其实你已经没有多少能力去对架构这个层面做安全上的改动了。你可能会说用<a href="https://katacontainers.io/" target="_blank" rel="noopener">Kata Container</a>、<a href="https://gvisor.dev/" target="_blank" rel="noopener">gVisor</a> 就是安全“容器”了。不过，Kata 或者 gVisor 只是兼容了容器接口标准，而内部的实现完全是另外的技术了。</p><p>那么对于使用容器的用户，在运行容器的时候，在安全方面可以做些什么呢？我们主要可以从这两个方面来考虑：第一是赋予容器合理的 capabilities，第二是在容器中以非 root 用户来运行程序。</p><p>为什么是这两点呢？我通过两讲的内容和你讨论一下，这一讲我们先来看容器的 capabilities 的问题。</p><h3 id="问题再现"><a href="#问题再现" class="headerlink" title="问题再现"></a>问题再现</h3><p>刚刚使用容器的同学，往往会发现用缺省 docker run的方式启动容器后，在容器里很多操作都是不允许的，即使是以 root 用户来运行程序也不行。</p><p>我们用下面的例子来重现一下这个问题。我们先运行make image 做个容器镜像</p><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: image</span></span><br><span class="line"></span><br><span class="line"><span class="section">image:</span></span><br><span class="line">docker build -t registry/iptables:v1 .</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">docker rmi registry/iptables:v1</span><br></pre></td></tr></table></figure><p>Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y iptables</span></span><br></pre></td></tr></table></figure><p>drop_net_admin.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo /usr/sbin/capsh --keep=1 --user=root   --drop=cap_net_admin  --   -c <span class="string">'./iptables -L;sleep 100'</span></span><br></pre></td></tr></table></figure><p>start_container.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker stop iptables;docker rm iptables</span><br><span class="line">docker run --name iptables --<span class="built_in">cap</span>-add NET_ADMIN -it registry/iptables:v1 bash</span><br></pre></td></tr></table></figure><p>然后运行下面的脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run --name iptables -it registry/iptables:v1 bash</span></span><br><span class="line">[root@0b88d6486149 /]<span class="comment"># iptables -L</span></span><br><span class="line">iptables v1.8.4 (nf_tables): Could not fetch rule <span class="built_in">set</span> generation id: Permission denied (you must be root)</span><br><span class="line"> </span><br><span class="line">[root@0b88d6486149 /]<span class="comment"># id</span></span><br><span class="line">uid=0(root) gid=0(root) groups=0(root)</span><br></pre></td></tr></table></figure><p>在这里，我们想在容器中运行 iptables 这个命令，来查看一下防火墙的规则，但是执行命令之后，你会发现结果输出中给出了”Permission denied (you must be root)”的错误提示，这个提示要求我们用 root 用户来运行。</p><p>不过在容器中，我们现在已经是以 root 用户来运行了，么为什么还是不可以运行”iptables”这条命令呢？</p><p>你肯定会想到，是不是容器中又做了别的权限限制？如果你去查一下资料，就会看到启动容器有一个”privileged”的参数。我们可以试一下用上这个参数，没错，我们用了这个参数之后，iptables 这个命令就执行成功了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker stop iptables;docker rm iptables</span></span><br><span class="line">iptables</span><br><span class="line">iptables</span><br><span class="line"><span class="comment"># docker run --name iptables --privileged -it registry/iptables:v1 bash</span></span><br><span class="line">[root@44168f4b9b24 /]<span class="comment"># iptables -L</span></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"> </span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"> </span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br></pre></td></tr></table></figure><p>看上去，我们用了一个配置参数就已经解决了问题，似乎很容易。不过这里我们可以进一步想想，用”privileged”参数来解决问题，是不是一个合理的方法呢？用它会有什么问题吗？</p><p>要回答这些问题，我们先来了解一下”privileged”是什么意思。从 <a href="https://github.com/moby/moby/blob/17.03.x/daemon/exec_linux.go#L25" target="_blank" rel="noopener">Docker 的代码里</a>，我们可以看到，如果配置了 privileged 的参数的话，就会获取所有的 capabilities，那什么是 capabilities 呢？</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">if</span> ec.Privileged &#123;</span><br><span class="line">            p.Capabilities = caps.GetAllCapabilities()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><h3 id="Linux-capabilities"><a href="#Linux-capabilities" class="headerlink" title="Linux capabilities"></a>Linux capabilities</h3><p>要了解 Linux capabilities 的定义，我们可以先查看一下”Linux Programmer’s Manual”中关于<a href="https://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">Linux capabilities</a>的描述。</p><p>在 Linux capabilities 出现前，进程的权限可以简单分为两类，第一类是特权用户的进程（进程的有效用户 ID 是 0，简单来说，你可以认为它就是 root 用户的进程），第二类是非特权用户的进程（进程的有效用户 ID 是非 0，可以理解为非 root 用户进程）。</p><p>特权用户进程可以执行 Linux 系统上的所有操作，而非特权用户在执行某些操作的时候就会被内核限制执行。其实这个概念，也是我们通常对 Linux 中 root 用户与非 root 用户的理解。</p><p>从 kernel 2.2 开始，Linux 把特权用户所有的这些“特权”做了更详细的划分，这样被划分出来的每个单元就被称为 capability。</p><p>所有的 capabilities 都在<a href="https://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">Linux capabilities</a>的手册列出来了，你也可以在内核的文件<a href="https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/capability.h#L113" target="_blank" rel="noopener">capability.h</a>中看到所有 capabilities 的定义。</p><p>对于任意一个进程，在做任意一个特权操作的时候，都需要有这个特权操作对应的 capability。</p><p>比如说，运行 iptables 命令，对应的进程需要有 CAP_NET_ADMIN 这个 capability。如果要 mount 一个文件系统，那么对应的进程需要有 CAP_SYS_ADMIN 这个 capability。</p><p>我还要提醒你的是，CAP_SYS_ADMIN 这个 capability 里允许了大量的特权操作，包括文件系统，交换空间，还有对各种设备的操作，以及系统调试相关的调用等等。</p><p>在普通 Linux 节点上，非 root 用户启动的进程缺省没有任何 Linux capabilities，而 root 用户启动的进程缺省包含了所有的 Linux capabilities。</p><p>我们可以做个试验，对于 root 用户启动的进程，如果把 CAP_NET_ADMIN 这个 capability 移除，看看它是否还可以运行 iptables。</p><p>在这里我们要用到<a href="https://man7.org/linux/man-pages/man1/capsh.1.html" target="_blank" rel="noopener">capsh</a>这个工具，对这个工具不熟悉的同学可以查看超链接。接下来，我们就用 capsh 执行下面的这个命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sudo /usr/sbin/capsh --keep=1 --user=root   --drop=cap_net_admin  --   -c './iptables -L;sleep 100'</span></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"> </span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"> </span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">iptables: Permission denied (you must be root).</span><br></pre></td></tr></table></figure><p>这时候，我们可以看到即使是 root 用户，如果把”CAP_NET_ADMIN”给移除了，那么在执行 iptables 的时候就会看到”Permission denied (you must be root).”的提示信息。</p><p>同时，我们可以通过 /proc 文件系统找到对应进程的 status，这样就能确认进程中的 CAP_NET_ADMIN 是否已经被移除了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ps -ef | grep sleep</span></span><br><span class="line">root     22603 22275  0 19:44 pts/1    00:00:00 sudo /usr/sbin/capsh --keep=1 --user=root --drop=cap_net_admin -- -c ./iptables -L;sleep 100</span><br><span class="line">root     22604 22603  0 19:44 pts/1    00:00:00 /bin/bash -c ./iptables -L;sleep 100</span><br><span class="line"> </span><br><span class="line"><span class="comment"># cat /proc/22604/status | grep Cap</span></span><br><span class="line">CapInh:            0000000000000000</span><br><span class="line">CapPrm:          0000003fffffefff</span><br><span class="line">CapEff:             0000003fffffefff</span><br><span class="line">CapBnd:          0000003fffffefff</span><br><span class="line">CapAmb:         0000000000000000</span><br></pre></td></tr></table></figure><p>运行上面的命令查看 /proc//status 里 Linux capabilities 的相关参数之后，我们可以发现，输出结果中包含 5 个 Cap 参数。</p><p>这里我给你解释一下， 对于当前进程，直接影响某个特权操作是否可以被执行的参数，是”CapEff”，也就是”Effective capability sets”，这是一个 bitmap，每一个 bit 代表一项 capability 是否被打开。</p><p>在 Linux 内核<a href="https://github.com/torvalds/linux/blob/v5.4/include/uapi/linux/capability.h#L203" target="_blank" rel="noopener">capability.h</a>里把 CAP_NET_ADMIN 的值定义成 12，所以我们可以看到”CapEff”的值是”0000003fffffefff”，第 4 个数值是 16 进制的”e”，而不是 f。</p><p>这表示 CAP_NET_ADMIN 对应的第 12-bit 没有被置位了（0xefff = 0xffff &amp; (~(1 &lt;&lt; 12))），所以这个进程也就没有执行 iptables 命令的权限了。</p><p>对于进程 status 中其他几个 capabilities 相关的参数，它们还需要和应用程序文件属性中的 capabilities 协同工作，这样才能得到新启动的进程最终的 capabilities 参数的值。</p><p>我们看下面的图，结合这张图看后面的讲解：</p><p><img src="/images/docker/docker-08/1.jpg" alt="1"></p><p>如果我们要新启动一个程序，在 Linux 里的过程就是先通过 fork() 来创建出一个子进程，然后调用 execve() 系统调用读取文件系统里的程序文件，把程序文件加载到进程的代码段中开始运行。</p><p>就像图片所描绘的那样，这个新运行的进程里的相关 capabilities 参数的值，是由它的父进程以及程序文件中的 capabilities 参数值计算得来的。</p><p>具体的计算过程你可以看<a href="https://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">Linux capabilities</a>的手册中的描述，也可以读一下网上的这两篇文章：</p><ul><li><a href="https://blog.container-solutions.com/linux-capabilities-why-they-exist-and-how-they-work" target="_blank" rel="noopener">Capabilities: Why They Exist and How They Work</a></li><li><a href="https://blog.container-solutions.com/linux-capabilities-in-practice" target="_blank" rel="noopener">Linux Capabilities in Practice</a></li></ul><p>我就不对所有的进程和文件的 capabilities 集合参数和算法挨个做解释了，感兴趣的话你可以自己详细去看看。</p><p>这里你只要记住最重要的一点，<strong>文件中可以设置 capabilities 参数值，并且这个值会影响到最后运行它的进程</strong>。比如，我们如果把 iptables 的应用程序加上 CAP_NET_ADMIN 的 capability，那么即使是非 root 用户也有执行 iptables 的权限了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ id</span><br><span class="line">uid=1000(centos) gid=1000(centos) groups=1000(centos),10(wheel)</span><br><span class="line">$ sudo <span class="built_in">setcap</span> cap_net_admin+ep ./iptables</span><br><span class="line">$ <span class="built_in">getcap</span> ./iptables</span><br><span class="line">./iptables = cap_net_admin+ep</span><br><span class="line">$./iptables -L</span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"> </span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">DOCKER-USER  all  --  anywhere             anywhere</span><br><span class="line">DOCKER-ISOLATION-STAGE-1  all  --  anywhere             anywhere</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED</span><br><span class="line">DOCKER     all  --  anywhere             anywhere</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere</span><br><span class="line">…</span><br></pre></td></tr></table></figure><p>好了，关于 Linux capabilities 的内容到这里我们就讲完了，其实它就是把 Linux root 用户原来所有的特权做了细化，可以更加细粒度地给进程赋予不同权限。</p><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>我们搞懂了 Linux capabilities 之后，那么对 privileged 的容器也很容易理解了。<strong>Privileged 的容器也就是允许容器中的进程可以执行所有的特权操作</strong>。</p><p>因为安全方面的考虑，容器缺省启动的时候，哪怕是容器中 root 用户的进程，系统也只允许了 15 个 capabilities。这个你可以查看<a href="https://github.com/opencontainers/runc/blob/v1.0.0-rc92/libcontainer/SPEC.md#security" target="_blank" rel="noopener">runC spec 文档中的 security</a> 部分，你也可以查看容器 init 进程 status 里的 Cap 参数，看一下容器中缺省的 capabilities。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run --name iptables -it registry/iptables:v1 bash</span></span><br><span class="line">[root@e54694652a42 /]<span class="comment"># cat /proc/1/status  |grep Cap</span></span><br><span class="line">CapInh:            00000000a80425fb</span><br><span class="line">CapPrm:          00000000a80425fb</span><br><span class="line">CapEff:              00000000a80425fb</span><br><span class="line">CapBnd:          00000000a80425fb</span><br><span class="line">CapAmb:         0000000000000000</span><br></pre></td></tr></table></figure><p>我想提醒你，当我们发现容器中运行某个程序的权限不够的时候，并不能“偷懒”把容器设置为”privileged”，也就是把所有的 capabilities 都赋予了容器。</p><p>因为容器中的权限越高，对系统安全的威胁显然也是越大的。比如说，如果容器中的进程有了 CAP_SYS_ADMIN 的特权之后，那么这些进程就可以在容器里直接访问磁盘设备，直接可以读取或者修改宿主机上的所有文件了。</p><p>所以，在容器平台上是基本不允许把容器直接设置为”privileged”的，我们需要根据容器中进程需要的最少特权来赋予 capabilities。</p><p>我们结合这一讲开始的例子来说说。在开头的例子中，容器里需要使用 iptables。因为使用 iptables 命令，只需要设置 CAP_NET_ADMIN 这个 capability 就行。那么我们只要在运行 Docker 的时候，给这个容器再多加一个 NET_ADMIN 参数就可以了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run --name iptables --cap-add NET_ADMIN -it registry/iptables:v1 bash</span></span><br><span class="line">[root@cfedf124dcf1 /]<span class="comment"># iptables -L</span></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"> </span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"> </span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br></pre></td></tr></table></figure><!--### 重点小结这一讲我们主要学习了如何给容器赋予合理的 capabilities。那么，我们自然需要先来理解什么是 Linux capabilities。**其实 Linux capabilities 就是把 Linux root 用户原来所有的特权做了细化，可以更加细粒度地给进程赋予不同权限**。对于 Linux 中的每一个特权操作都有一个对应的 capability，对于一个 capability，有的对应一个特权操作，有的可以对应很多个特权操作。每个 Linux 进程有 5 个 capabilities 集合参数，其中 Effective 集合里的 capabilities 决定了当前进程可以做哪些特权操作，而其他集合参数会和应用程序文件的 capabilities 集合参数一起来决定新启动程序的 capabilities 集合参数。对于容器的 root 用户，缺省只赋予了 15 个 capabilities。如果我们发现容器中进程的权限不够，就需要分析它需要的最小 capabilities 集合，而不是直接赋予容器"privileged"。因为"privileged"包含了所有的 Linux capabilities, 这样"privileged"就可以轻易获取宿主机上的所有资源，这会对宿主机的安全产生威胁。所以，我们要根据容器中进程需要的最少特权来赋予 capabilities。--><h2 id="容器安全（2）：在容器中，我不以root用户来运行程序可以吗？"><a href="#容器安全（2）：在容器中，我不以root用户来运行程序可以吗？" class="headerlink" title="容器安全（2）：在容器中，我不以root用户来运行程序可以吗？"></a>容器安全（2）：在容器中，我不以root用户来运行程序可以吗？</h2><p>我们学习了 Linux capabilities 的概念，也知道了对于非 privileged 的容器，容器中 root 用户的 capabilities 是有限制的，因此容器中的 root 用户无法像宿主机上的 root 用户一样，拿到完全掌控系统的特权。</p><p>那么是不是让非 privileged 的容器以 root 用户来运行程序，这样就能保证安全了呢？这一讲，我们就来聊一聊容器中的 root 用户与安全相关的问题。</p><h3 id="问题再现-1"><a href="#问题再现-1" class="headerlink" title="问题再现"></a>问题再现</h3><p>说到容器中的用户（user），你可能会想到，在 Linux Namespace 中有一项隔离技术，也就是 User Namespace。</p><p>不过在容器云平台 Kubernetes 上目前还不支持 User Namespace，所以我们先来看看在没有 User Namespace 的情况下，容器中用 root 用户运行，会发生什么情况。</p><p>首先，我们可以用下面的命令启动一个容器，在这里，我们把宿主机上 /etc 目录以 volume 的形式挂载到了容器中的 /mnt 目录下面。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run -d --name root_example -v /etc:/mnt  centos sleep 3600</span></span><br></pre></td></tr></table></figure><p>然后，我们可以看一下容器中的进程”sleep 3600”，它在容器中和宿主机上的用户都是 root，也就是说，容器中用户的 uid/gid 和宿主机上的完全一样。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker exec -it root_example bash -c "ps -ef | grep sleep"</span></span><br><span class="line">root         1     0  0 01:14 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 3600</span><br><span class="line"> </span><br><span class="line"><span class="comment"># ps -ef | grep sleep</span></span><br><span class="line">root      5473  5443  0 18:14 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 3600</span><br></pre></td></tr></table></figure><p>虽然容器里 root 用户的 capabilities 被限制了一些，但是在容器中，对于被挂载上来的 /etc 目录下的文件，比如说 shadow 文件，以这个 root 用户的权限还是可以做修改的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker exec -it root_example bash</span></span><br><span class="line">[root@9c7b76232c19 /]<span class="comment"># ls /mnt/shadow -l</span></span><br><span class="line">---------- 1 root root 586 Nov 26 13:47 /mnt/shadow</span><br><span class="line">[root@9c7b76232c19 /]<span class="comment"># echo "hello" &gt;&gt; /mnt/shadow</span></span><br></pre></td></tr></table></figure><p>接着我们看看后面这段命令输出，可以确认在宿主机上文件被修改了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tail -n 3 /etc/shadow</span></span><br><span class="line">grafana:!!:18437::::::</span><br><span class="line">tcpdump:!!:18592::::::</span><br><span class="line">hello</span><br></pre></td></tr></table></figure><p>这个例子说明容器中的 root 用户也有权限修改宿主机上的关键文件。</p><p>当然在云平台上，比如说在 Kubernetes 里，我们是可以限制容器去挂载宿主机的目录的。</p><p>不过，由于容器和宿主机是共享 Linux 内核的，一旦软件有漏洞，那么容器中以 root 用户运行的进程就有机会去修改宿主机上的文件了。比如 2019 年发现的一个 RunC 的漏洞 <a href="https://nvd.nist.gov/vuln/detail/CVE-2019-5736" target="_blank" rel="noopener">CVE-2019-5736</a>， 这导致容器中 root 用户有机会修改宿主机上的 RunC 程序，并且容器中的 root 用户还会得到宿主机上的运行权限。</p><h3 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h3><p>对于前面的问题，接下来我们就来讨论一下解决办法，在讨论问题的过程中，也会涉及一些新的概念，主要有三个。</p><h3 id="方法一：Run-as-non-root-user（给容器指定一个普通用户）"><a href="#方法一：Run-as-non-root-user（给容器指定一个普通用户）" class="headerlink" title="方法一：Run as non-root user（给容器指定一个普通用户）"></a>方法一：Run as non-root user（给容器指定一个普通用户）</h3><p>我们如果不想让容器以 root 用户运行，最直接的办法就是给容器指定一个普通用户 uid。这个方法很简单，比如可以在 docker 启动容器的时候加上”-u”参数，在参数中指定 uid/gid。</p><p>具体的操作代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run -ti --name root_example -u 6667:6667 -v /etc:/mnt  centos bash</span></span><br><span class="line">bash-4.4$ id</span><br><span class="line">uid=6667 gid=6667 groups=6667</span><br><span class="line">bash-4.4$ ps -ef</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">6667         1     0  1 01:27 pts/0    00:00:00 bash</span><br><span class="line">6667         8     1  0 01:27 pts/0    00:00:00 ps -ef</span><br></pre></td></tr></table></figure><p>还有另外一个办法，就是我们在创建容器镜像的时候，用 Dockerfile 为容器镜像里建立一个用户。</p><p>为了方便你理解，我还是举例说明。就像下面例子中的 nonroot，它是一个用户名，我们用 USER 关键字来指定这个 nonroot 用户，这样操作以后，容器里缺省的进程都会以这个用户启动。</p><p>这样在运行 Docker 命令的时候就不用加”-u”参数来指定用户了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat Dockerfile</span></span><br><span class="line">FROM centos</span><br><span class="line"> </span><br><span class="line">RUN adduser -u 6667 nonroot</span><br><span class="line">USER nonroot</span><br><span class="line"> </span><br><span class="line"><span class="comment"># docker build -t registry/nonroot:v1 .</span></span><br><span class="line">…</span><br><span class="line"> </span><br><span class="line"><span class="comment"># docker run -d --name root_example -v /etc:/mnt registry/nonroot:v1 sleep 3600</span></span><br><span class="line">050809a716ab0a9481a6dfe711b332f74800eff5fea8b4c483fa370b62b4b9b3</span><br><span class="line"> </span><br><span class="line"><span class="comment"># docker exec -it root_example bash</span></span><br><span class="line">[nonroot@050809a716ab /]$ id</span><br><span class="line">uid=6667(nonroot) gid=6667(nonroot) groups=6667(nonroot)</span><br><span class="line">[nonroot@050809a716ab /]$ ps -ef</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">nonroot      1     0  0 01:43 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 3600</span><br></pre></td></tr></table></figure><p>好，在容器中使用普通用户运行之后，我们再看看，现在能否修改被挂载上来的 /etc 目录下的文件? 显然，现在不可以修改了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[nonroot@050809a716ab /]$ <span class="built_in">echo</span> <span class="string">"hello"</span> &gt;&gt; /mnt/shadow</span><br><span class="line">bash: /mnt/shadow: Permission denied</span><br></pre></td></tr></table></figure><p>那么是不是只要给容器中指定了一个普通用户，这个问题就圆满解决了呢？其实在云平台上，这么做还是会带来别的问题，我们一起来看看。</p><p>由于用户 uid 是整个节点中共享的，那么在容器中定义的 uid，也就是宿主机上的 uid，这样就很容易引起 uid 的冲突。</p><p>比如说，多个客户在建立自己的容器镜像的时候都选择了同一个 uid 6667。那么当多个客户的容器在同一个节点上运行的时候，其实就都使用了宿主机上 uid 6667。</p><p>我们都知道，在一台 Linux 系统上，每个用户下的资源是有限制的，比如打开文件数目（open files）、最大进程数目（max user processes）等等。一旦有很多个容器共享一个 uid，这些容器就很可能很快消耗掉这个 uid 下的资源，这样很容易导致这些容器都不能再正常工作。</p><p>要解决这个问题，必须要有一个云平台级别的 uid 管理和分配，但选择这个方法也要付出代价。因为这样做是可以解决问题，但是用户在定义自己容器中的 uid 的时候，他们就需要有额外的操作，而且平台也需要新开发对 uid 平台级别的管理模块，完成这些事情需要的工作量也不少。</p><h3 id="方法二：User-Namespace（用户隔离技术的支持）"><a href="#方法二：User-Namespace（用户隔离技术的支持）" class="headerlink" title="方法二：User Namespace（用户隔离技术的支持）"></a>方法二：User Namespace（用户隔离技术的支持）</h3><p>那么在没有使用 User Namespace 的情况，对于容器平台上的用户管理还是存在问题。你可能会想到，我们是不是应该去尝试一下 User Namespace?</p><p>好的，我们就一起来看看使用 User Namespace 对解决用户管理问题有没有帮助。首先，我们简单了解一下<a href="https://man7.org/linux/man-pages/man7/user_namespaces.7.html" target="_blank" rel="noopener">User Namespace</a>的概念。</p><p>User Namespace 隔离了一台 Linux 节点上的 User ID（uid）和 Group ID（gid），它给 Namespace 中的 uid/gid 的值与宿主机上的 uid/gid 值建立了一个映射关系。经过 User Namespace 的隔离，我们在 Namespace 中看到的进程的 uid/gid，就和宿主机 Namespace 中看到的 uid 和 gid 不一样了。</p><p>你可以看下面的这张示意图，应该就能很快知道 User Namespace 大概是什么意思了。比如 namespace_1 里的 uid 值是 0 到 999，但其实它在宿主机上对应的 uid 值是 1000 到 1999。</p><p>还有一点你要注意的是，User Namespace 是可以嵌套的，比如下面图里的 namespace_2 里可以再建立一个 namespace_3，这个嵌套的特性是其他 Namespace 没有的。</p><p><img src="/images/docker/docker-08/2.jpg" alt="2"></p><p>我们可以启动一个带 User Namespace 的容器来感受一下。这次启动容器，我们用一下<a href="https://podman.io/" target="_blank" rel="noopener">podman</a>这个工具，而不是 Docker。</p><p>跟 Docker 相比，podman 不再有守护进程 dockerd，而是直接通过 fork/execve 的方式来启动一个新的容器。这种方式启动容器更加简单，也更容易维护。</p><p>Podman 的命令参数兼容了绝大部分的 docker 命令行参数，用过 Docker 的同学也很容易上手 podman。你感兴趣的话，可以跟着这个<a href="https://podman.io/getting-started/installation" target="_blank" rel="noopener">手册</a>在你自己的 Linux 系统上装一下 podman。</p><p>那接下来，我们就用下面的命令来启动一个容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># podman run -ti  -v /etc:/mnt --uidmap 0:2000:1000 centos bash</span></span><br></pre></td></tr></table></figure><p>我们可以看到，其他参数和前面的 Docker 命令是一样的。</p><p>这里我们在命令里增加一个参数，”–uidmap 0:2000:1000”，这个是标准的 User Namespace 中 uid 的映射格式：”ns_uid:host_uid:amount”。</p><p>那这个例子里的”0:2000:1000”是什么意思呢？我给你解释一下。</p><p>第一个 0 是指在新的 Namespace 里 uid 从 0 开始，中间的那个 2000 指的是 Host Namespace 里被映射的 uid 从 2000 开始，最后一个 1000 是指总共需要连续映射 1000 个 uid。</p><p>所以，我们可以得出，<strong>这个容器里的 uid 0 是被映射到宿主机上的 uid 2000 的。这一点我们可以验证一下</strong>。</p><p>首先，我们先在容器中以用户 uid 0 运行一下 sleep 这个命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># id</span></span><br><span class="line">uid=0(root) gid=0(root) groups=0(root)</span><br><span class="line"><span class="comment"># sleep 3600</span></span><br></pre></td></tr></table></figure><p>然后就是第二步，到宿主机上查看一下这个进程的 uid。这里我们可以看到，进程 uid 的确是 2000 了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ps -ef |grep sleep</span></span><br><span class="line">2000     27021 26957  0 01:32 pts/0    00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 3600</span><br></pre></td></tr></table></figure><p>第三步，我们可以再回到容器中，仍然以容器中的 root 对被挂载上来的 /etc 目录下的文件做操作，这时可以看到操作是不被允许的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># echo "hello" &gt;&gt; /mnt/shadow</span></span><br><span class="line">bash: /mnt/shadow: Permission denied</span><br><span class="line"><span class="comment"># id</span></span><br><span class="line">uid=0(root) gid=0(root) groups=0(root)</span><br></pre></td></tr></table></figure><p>好了，通过这些操作以及和前面 User Namespace 的概念的解释，我们可以总结出容器使用 User Namespace 有两个好处。</p><p><strong>第一，它把容器中 root 用户（uid 0）映射成宿主机上的普通用户。</strong></p><p>作为容器中的 root，它还是可以有一些 Linux capabilities，那么在容器中还是可以执行一些特权的操作。而在宿主机上 uid 是普通用户，那么即使这个用户逃逸出容器 Namespace，它的执行权限还是有限的。</p><p><strong>第二，对于用户在容器中自己定义普通用户 uid 的情况，我们只要为每个容器在节点上分配一个 uid 范围，就不会出现在宿主机上 uid 冲突的问题了。</strong>Privileged</p><p>因为在这个时候，我们只要在节点上分配容器的 uid 范围就可以了，所以从实现上说，相比在整个平台层面给容器分配 uid，使用 User Namespace 这个办法要方便得多。</p><p>这里我额外补充一下，前面我们说了 Kubernetes 目前还不支持 User Namespace，如果你想了解相关工作的进展，可以看一下社区的这个<a href="https://github.com/kubernetes/enhancements/pull/2101" target="_blank" rel="noopener">PR</a>。</p><h3 id="方法三：rootless-container（以非-root-用户启动和管理容器）"><a href="#方法三：rootless-container（以非-root-用户启动和管理容器）" class="headerlink" title="方法三：rootless container（以非 root 用户启动和管理容器）"></a>方法三：rootless container（以非 root 用户启动和管理容器）</h3><p>前面我们已经讨论了，在容器中以非 root 用户运行进程可以降低容器的安全风险。除了在容器中使用非 root 用户，社区还有一个 rootless container 的概念。</p><p>这里 rootless container 中的”rootless”不仅仅指容器中以非 root 用户来运行进程，还指以非 root 用户来创建容器，管理容器。也就是说，启动容器的时候，Docker 或者 podman 是以非 root 用户来执行的。</p><p>这样一来，就能进一步提升容器中的安全性，我们不用再担心因为 containerd 或者 RunC 里的代码漏洞，导致容器获得宿主机上的权限。</p><p>我们可以参考 <a href="https://developers.redhat.com/blog/2020/09/25/rootless-containers-with-podman-the-basics" target="_blank" rel="noopener">redhat blog 里的这篇文档</a>， 在宿主机上用 redhat 这个用户通过 podman 来启动一个容器。在这个容器中也使用了 User Namespace，并且把容器中的 uid 0 映射为宿主机上的 redhat 用户了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ id</span><br><span class="line">uid=1001(redhat) gid=1001(redhat) groups=1001(redhat)</span><br><span class="line">$ podman run -it  ubi7/ubi bash   <span class="comment">### 在宿主机上以redhat用户启动容器</span></span><br><span class="line">[root@206f6d5cb033 /]<span class="comment"># id     ### 容器中的用户是root</span></span><br><span class="line">uid=0(root) gid=0(root) groups=0(root)</span><br><span class="line">[root@206f6d5cb033 /]<span class="comment"># sleep 3600   ### 在容器中启动一个sleep 进程</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ps -ef |grep sleep   ###在宿主机上查看容器sleep进程对应的用户</span></span><br><span class="line">redhat   29433 29410  0 05:14 pts/0    00:00:00 sleep 3600</span><br></pre></td></tr></table></figure><p>目前 Docker 和 podman 都支持了 rootless container，Kubernetes 对<a href="https://github.com/kubernetes/enhancements/issues/2033" target="_blank" rel="noopener">rootless container</a> 支持的工作也在进行中。</p><!--### 重点小结我们今天讨论的内容是 root 用户与容器安全的问题。尽管容器中 root 用户的 Linux capabilities 已经减少了很多，但是在没有 User Namespace 的情况下，容器中 root 用户和宿主机上的 root 用户的 uid 是完全相同的，一旦有软件的漏洞，容器中的 root 用户就可以操控整个宿主机。**为了减少安全风险，业界都是建议在容器中以非 root 用户来运行进程**。不过在没有 User Namespace 的情况下，在容器中使用非 root 用户，对于容器云平台来说，对 uid 的管理会比较麻烦。所以，我们还是要分析一下 User Namespace，它带来的好处有两个。一个是把容器中 root 用户（uid 0）映射成宿主机上的普通用户，另外一个好处是在云平台里对于容器 uid 的分配要容易些。除了在容器中以非 root 用户来运行进程外，Docker 和 podman 都支持了 rootless container，也就是说它们都可以以非 root 用户来启动和管理容器，这样就进一步降低了容器的安全风险。--><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《由浅入深吃透 Docker》</li><li>《容器实战高手课》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://www.docker-cn.com" target="_blank" rel="noopener">https://www.docker-cn.com</a></li><li><a href="https://docs.docker.com/compose/compose-file/compose-file-v3/" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/compose-file-v3/</a></li><li><a href="https://docs.docker.com/compose/reference/" target="_blank" rel="noopener">https://docs.docker.com/compose/reference/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;容器安全&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://blog.lichao.xin/categories/Docker/"/>
    
    
      <category term="docker" scheme="https://blog.lichao.xin/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>重学 Docker 之 容器进阶（四）</title>
    <link href="https://blog.lichao.xin/back-end/docker/docker-07/"/>
    <id>https://blog.lichao.xin/back-end/docker/docker-07/</id>
    <published>2021-04-18T11:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.383Z</updated>
    
    <content type="html"><![CDATA[<p>容器网络</p><a id="more"></a><h2 id="容器网络：我修改了-proc-sys-net下的参数，为什么在容器中不起效？"><a href="#容器网络：我修改了-proc-sys-net下的参数，为什么在容器中不起效？" class="headerlink" title="容器网络：我修改了/proc/sys/net下的参数，为什么在容器中不起效？"></a>容器网络：我修改了/proc/sys/net下的参数，为什么在容器中不起效？</h2><p>容器网络最明显的一个特征就是它有自己的 Network Namespace 了。之前我们就提到过 Network Namespace 负责管理网络环境的隔离。</p><p>今天呢，我们更深入地讨论一下和 Network Namespace 相关的一个问题——容器中的网络参数。</p><p>和之前的思路一样，我们先来看一个问题。然后在解决问题的过程中，更深入地理解容器的网络参数配置。</p><h3 id="问题再现"><a href="#问题再现" class="headerlink" title="问题再现"></a>问题再现</h3><p>在容器中运行的应用程序，如果需要用到 tcp/ip 协议栈的话，常常需要修改一些网络参数（内核中网络协议栈的参数）。</p><p>很大一部分网络参数都在 /proc 文件系统下的/proc/sys/net/目录里。</p><p><strong>修改这些参数主要有两种方法：一种方法是直接到 /proc 文件系统下的”/proc/sys/net/“目录里对参数做修改；还有一种方法是使用**</strong>sysctl<strong>**这个工具来修改。</strong></p><p>在启动容器之前呢，根据我们的需要我们在宿主机上已经修改过了几个参数，也就是说这些参数的值已经不是内核里原来的缺省值了.</p><p>比如我们改了下面的几个参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # The default value:</span></span><br><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/tcp_congestion_control</span></span><br><span class="line">cubic</span><br><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_time</span></span><br><span class="line">7200</span><br><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_intvl</span></span><br><span class="line">75</span><br><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_probes</span></span><br><span class="line">9</span><br><span class="line"> </span><br><span class="line"><span class="comment"># # To update the value:</span></span><br><span class="line"><span class="comment"># echo bbr &gt; /proc/sys/net/ipv4/tcp_congestion_control</span></span><br><span class="line"><span class="comment"># echo 600 &gt; /proc/sys/net/ipv4/tcp_keepalive_time</span></span><br><span class="line"><span class="comment"># echo 10 &gt; /proc/sys/net/ipv4/tcp_keepalive_intvl</span></span><br><span class="line"><span class="comment"># echo 6 &gt; /proc/sys/net/ipv4/tcp_keepalive_probes</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># # Double check the value after update:</span></span><br><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/tcp_congestion_control</span></span><br><span class="line">bbr</span><br><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_time</span></span><br><span class="line">600</span><br><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_intvl</span></span><br><span class="line">10</span><br><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_probes</span></span><br><span class="line">6</span><br></pre></td></tr></table></figure><p>然后我们启动一个容器， 再来查看一下容器里这些参数的值。</p><p>你可以先想想，容器里这些参数的值会是什么？我最初觉得容器里参数值应该会继承宿主机 Network Namesapce 里的值，实际上是不是这样呢？</p><p>我们还是先按下面的脚本，启动容器，然后运行 docker exec 命令一起看一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run -d --name net_para centos:8.1.1911 sleep 3600</span></span><br><span class="line">deec6082bac7b336fa28d0f87d20e1af21a784e4ef11addfc2b9146a9fa77e95</span><br><span class="line"><span class="comment"># docker exec -it net_para bash</span></span><br><span class="line">[root@deec6082bac7 /]<span class="comment"># cat /proc/sys/net/ipv4/tcp_congestion_control</span></span><br><span class="line">bbr</span><br><span class="line">[root@deec6082bac7 /]<span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_time</span></span><br><span class="line">7200</span><br><span class="line">[root@deec6082bac7 /]<span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_intvl</span></span><br><span class="line">75</span><br><span class="line">[root@deec6082bac7 /]<span class="comment"># cat /proc/sys/net/ipv4/tcp_keepalive_probes</span></span><br><span class="line">9</span><br></pre></td></tr></table></figure><p>从这个结果我们看到，tcp_congestion_control 的值是 bbr，和宿主机 Network Namespace 里的值是一样的，而其他三个 tcp keepalive 相关的值，都不是宿主机 Network Namespace 里设置的值，而是原来系统里的缺省值了。</p><p>那为什么会这样呢？在分析这个问题之前，我们需要先来看看 Network Namespace 这个概念。</p><h3 id="知识详解"><a href="#知识详解" class="headerlink" title="知识详解"></a>知识详解</h3><h3 id="如何理解-Network-Namespace？"><a href="#如何理解-Network-Namespace？" class="headerlink" title="如何理解 Network Namespace？"></a>如何理解 Network Namespace？</h3><p>对于 Network Namespace，我们从字面上去理解的话，可以知道它是在一台 Linux 节点上对网络的隔离，不过它具体到底隔离了哪部分的网络资源呢？</p><p>我们还是先来看看操作手册，在Linux Programmer’s Manual里对 Network Namespace 有一个段简短的描述，在里面就列出了最主要的几部分资源，它们都是通过 Network Namespace 隔离的。</p><p>我把这些资源给你做了一个梳理：</p><p>第一种，网络设备，这里指的是 lo，eth0 等网络设备。你可以可以通过 ip link命令看到它们。</p><p>第二种是 IPv4 和 IPv6 协议栈。从这里我们可以知道，IP 层以及上面的 TCP 和 UPD 协议栈也是每个 Namespace 独立工作的。</p><p>所以 IP、TCP、PUD 的很多协议，它们的相关参数也是每个 Namespace 独立的，这些参数大多数都在 /proc/sys/net/ 目录下面，同时也包括了 TCP 和 UPD 的 port 资源。</p><p>第三种，IP 路由表，这个资源也是比较好理解的，你可以在不同的 Network Namespace 运行 ip route 命令，就能看到不同的路由表了。</p><p>第四种是防火墙规则，其实这里说的就是 iptables 规则了，每个 Namespace 里都可以独立配置 iptables 规则。</p><p>最后一种是网络的状态信息，这些信息你可以从 /proc/net 和 /sys/class/net 里得到，这里的状态基本上包括了前面 4 种资源的的状态信息。</p><h3 id="Namespace-的操作"><a href="#Namespace-的操作" class="headerlink" title="Namespace 的操作"></a>Namespace 的操作</h3><p>那我们怎么建立一个新的 Network Namespace 呢？</p><p><strong>我们可以通过系统调用 clone() 或者 unshare() 这两个函数来建立新的 Network Namespace。</strong></p><p>下面我们会讲两个例子，带你体会一下这两个方法具体怎么用。</p><p>第一种方法呢，是在新的进程创建的时候，伴随新进程建立，同时也建立出新的 Network Namespace。这个方法，其实就是通过 clone() 系统调用带上 CLONE_NEWNET flag 来实现的。</p><p>Clone 建立出来一个新的进程，这个新的进程所在的 Network Namespace 也是新的。然后我们执行 ip link 命令查看 Namespace 里的网络设备，就可以确认一个新的 Network Namespace 已经建立好了。</p><p>具体操作你可以看一下这段代码。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">new_netns</span><span class="params">(<span class="keyword">void</span> *para)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"New Namespace Devices:\n"</span>);</span><br><span class="line">            system(<span class="string">"ip link"</span>);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"> </span><br><span class="line">            sleep(<span class="number">100</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">            <span class="keyword">pid_t</span> pid;</span><br><span class="line"> </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"Host Namespace Devices:\n"</span>);</span><br><span class="line">            system(<span class="string">"ip link"</span>);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"> </span><br><span class="line">            pid =</span><br><span class="line">                clone(new_netns, <span class="built_in">stack</span> + STACK_SIZE, CLONE_NEWNET | SIGCHLD, <span class="literal">NULL</span>);</span><br><span class="line">            <span class="keyword">if</span> (pid == <span class="number">-1</span>)</span><br><span class="line">                        errExit(<span class="string">"clone"</span>);</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> (waitpid(pid, <span class="literal">NULL</span>, <span class="number">0</span>) == <span class="number">-1</span>)</span><br><span class="line">                        errExit(<span class="string">"waitpid"</span>);</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二种方法呢，就是调用 unshare() 这个系统调用来直接改变当前进程的 Network Namespace，你可以看一下这段代码。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">            <span class="keyword">pid_t</span> pid;</span><br><span class="line"> </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"Host Namespace Devices:\n"</span>);</span><br><span class="line">            system(<span class="string">"ip link"</span>);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> (unshare(CLONE_NEWNET) == <span class="number">-1</span>)</span><br><span class="line">                        errExit(<span class="string">"unshare"</span>);</span><br><span class="line"> </span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"New Namespace Devices:\n"</span>);</span><br><span class="line">            system(<span class="string">"ip link"</span>);</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实呢，不仅是 Network Namespace，其它的 Namespace 也是通过 clone() 或者 unshare() 系统调用来建立的。</p><p>而创建容器的程序，比如runC也是用 unshare() 给新建的容器建立 Namespace 的。</p><p>这里我简单地说一下 runC 是什么，我们用 Docker 或者 containerd 去启动容器，最后都会调用 runC 在 Linux 中把容器启动起来。</p><p>除了在代码中用系统调用来建立 Network Namespace，我们也可以用命令行工具来建立 Network Namespace。比如用 ip netns 命令，在下一讲学习容器网络配置的时候呢，我们会用到 ip netns，这里你先有个印象就行。</p><p>在 Network Namespace 创建好了之后呢，我们可以在宿主机上运行 lsns -t net 这个命令来查看系统里已有的 Network Namespace。当然，lsns也可以用来查看其它 Namespace。</p><p>用 lsns 查看已有的 Namespace 后，我们还可以用 nsenter 这个命令进入到某个 Network Namespace 里，具体去查看这个 Namespace 里的网络配置。</p><p>比如下面的这个例子，用我们之前的 clone() 的例子里的代码，编译出 clone-ns 这个程序，运行后，再使用 lsns 查看新建的 Network Namespace，并且用nsenter进入到这个 Namespace，查看里面的 lo device。</p><p>具体操作你可以参考下面的代码：</p><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: clone-ns unshare-ns</span></span><br><span class="line"></span><br><span class="line"><span class="section">clone-ns: clone-ns.c</span></span><br><span class="line">gcc -o clone-ns clone-ns.c</span><br><span class="line"></span><br><span class="line"><span class="section">unshare-ns: unshare-ns.c</span></span><br><span class="line">gcc -o unshare-ns unshare-ns.c</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">rm -f *.o clone-ns unshare-ns</span><br></pre></td></tr></table></figure><p>clone-ns.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> errExit(msg)    do &#123; perror(msg); exit(EXIT_FAILURE); \</span></span><br><span class="line">                               &#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> STACK_SIZE (1024 * 1024)</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">char</span> <span class="built_in">stack</span>[STACK_SIZE];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">new_netns</span><span class="params">(<span class="keyword">void</span> *para)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"New Namespace Devices:\n"</span>);</span><br><span class="line">system(<span class="string">"ip link"</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"></span><br><span class="line">sleep(<span class="number">100</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">pid_t</span> pid;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Host Namespace Devices:\n"</span>);</span><br><span class="line">system(<span class="string">"ip link"</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"></span><br><span class="line">pid =</span><br><span class="line">    clone(new_netns, <span class="built_in">stack</span> + STACK_SIZE, CLONE_NEWNET | SIGCHLD, <span class="literal">NULL</span>);</span><br><span class="line"><span class="keyword">if</span> (pid == <span class="number">-1</span>)</span><br><span class="line">errExit(<span class="string">"clone"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (waitpid(pid, <span class="literal">NULL</span>, <span class="number">0</span>) == <span class="number">-1</span>)</span><br><span class="line">errExit(<span class="string">"waitpid"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>unshare-ns.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _GNU_SOURCE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> errExit(msg)    do &#123; perror(msg); exit(EXIT_FAILURE); \</span></span><br><span class="line">                               &#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">pid_t</span> pid;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Host Namespace Devices:\n"</span>);</span><br><span class="line">system(<span class="string">"ip link"</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (unshare(CLONE_NEWNET) == <span class="number">-1</span>)</span><br><span class="line">errExit(<span class="string">"unshare"</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"New Namespace Devices:\n"</span>);</span><br><span class="line">system(<span class="string">"ip link"</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\n\n"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ./clone-ns &amp;</span></span><br><span class="line">[1] 7732</span><br><span class="line"><span class="comment"># Host Namespace Devices:</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span><br><span class="line">    link/ether 74:db:d1:80:54:14 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default</span><br><span class="line">    link/ether 02:42:0c:ff:2b:77 brd ff:ff:ff:ff:ff:ff</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">New Namespace Devices:</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line"> </span><br><span class="line"><span class="comment"># lsns -t net</span></span><br><span class="line">        NS TYPE NPROCS   PID USER    NETNSID NSFS COMMAND</span><br><span class="line">4026531992 net     283     1 root unassigned      /usr/lib/systemd/systemd --switched-root --system --deserialize 16</span><br><span class="line">4026532241 net       1  7734 root unassigned      ./<span class="built_in">clone</span>-ns</span><br><span class="line"><span class="comment"># nsenter -t 7734 -n ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br></pre></td></tr></table></figure><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>那理解了 Network Namespace 之后，我们再来看看这一讲最开始的问题，我们应该怎么来设置容器里的网络相关参数呢？</p><p>首先你要避免走入误区。从我们一开始的例子里，也可以看到，容器里 Network Namespace 的网络参数并不是完全从宿主机 Host Namespace 里继承的，也不是完全在新的 Network Namespace 建立的时候重新初始化的。</p><p>其实呢，这一点我们只要看一下内核代码中对协议栈的初始化函数，很快就可以知道为什么会有这样的情况。</p><p>在我们的例子里 tcp_congestion_control 的值是从 Host Namespace 里继承的，而 tcp_keepalive 相关的几个值会被重新初始化了。</p><p>在函数tcp_sk_init() 里，tcp_keepalive 的三个参数都是重新初始化的，而 tcp_congestion_control 的值是从 Host Namespace 里复制过来的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> __net_init <span class="title">tcp_sk_init</span><span class="params">(struct net *net)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">…</span><br><span class="line">        net-&gt;ipv4.sysctl_tcp_keepalive_time = TCP_KEEPALIVE_TIME;</span><br><span class="line">        net-&gt;ipv4.sysctl_tcp_keepalive_probes = TCP_KEEPALIVE_PROBES;</span><br><span class="line">        net-&gt;ipv4.sysctl_tcp_keepalive_intvl = TCP_KEEPALIVE_INTVL;</span><br><span class="line"> </span><br><span class="line">…</span><br><span class="line">        <span class="comment">/* Reno is always built in */</span></span><br><span class="line">        <span class="keyword">if</span> (!net_eq(net, &amp;init_net) &amp;&amp;</span><br><span class="line">            try_module_get(init_net.ipv4.tcp_congestion_control-&gt;owner))</span><br><span class="line">                net-&gt;ipv4.tcp_congestion_control = init_net.ipv4.tcp_congestion_control;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">                net-&gt;ipv4.tcp_congestion_control = &amp;tcp_reno;</span><br><span class="line"> </span><br><span class="line">…</span><br><span class="line"> </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么我们现在知道 Network Namespace 的网络参数是怎么初始化的了，你可能会问了，我在容器里也可以修改这些参数吗？</p><p>我们可以启动一个普通的容器，这里的“普通”呢，我指的不是”privileged”的那种容器，也就是在这个容器中，有很多操作都是不允许做的，比如 mount 一个文件系统。这个 privileged 容器概念，我们会在后面容器安全这一讲里详细展开，这里你有个印象。</p><p>那么在启动完一个普通容器后，我们尝试一下在容器里去修改”/proc/sys/net/“下的参数。</p><p>这时候你会看到，容器中”/proc/sys/“是只读 mount 的，那么在容器里是不能修改”/proc/sys/net/“下面的任何参数了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run -d --name net_para centos:8.1.1911 sleep 3600</span></span><br><span class="line">977bf3f07da90422e9c1e89e56edf7a59fab5edff26317eeb253700c2fa657f7</span><br><span class="line"><span class="comment"># docker exec -it net_para bash</span></span><br><span class="line">[root@977bf3f07da9 /]<span class="comment"># echo 600 &gt; /proc/sys/net/ipv4/tcp_keepalive_time</span></span><br><span class="line">bash: /proc/sys/net/ipv4/tcp_keepalive_time: Read-only file system</span><br><span class="line">[root@977bf3f07da9 /]<span class="comment"># cat /proc/mounts | grep "proc/sys"</span></span><br><span class="line">proc /proc/sys proc ro,relatime 0 0</span><br></pre></td></tr></table></figure><p>为什么“/proc/sys/” 在容器里是只读 mount 呢？ 这是因为 runC 当初出于安全的考虑，把容器中所有 /proc 和 /sys 相关的目录缺省都做了 read-only mount 的处理。</p><p>那我们应该怎么来修改容器中 Network Namespace 的网络参数呢？</p><p>当然，如果你有宿主机上的 root 权限，最简单粗暴的方法就是用我们之前说的”nsenter”工具，用它修改容器里的网络参数的。不过这个方法在生产环境里显然是不会被允许的，因为我们不会允许用户拥有宿主机的登陆权限。</p><p>其次呢，一般来说在容器中的应用已经启动了之后，才会做这样的修改。也就是说，很多 tcp 链接已经建立好了，那么即使新改了参数，对已经建立好的链接也不会生效了。这就需要重启应用，我们都知道生产环境里通常要避免应用重启，那这样做显然也不合适。</p><p>通过刚刚的排除法，我们推理出了网络参数修改的“正确时机”：想修改 Network Namespace 里的网络参数，要选择容器刚刚启动，而容器中的应用程序还没启动之前进行。</p><p>其实，runC 也在对 /proc/sys 目录做 read-only mount 之前，预留出了修改接口，就是用来修改容器里 “/proc/sys”下参数的，同样也是 sysctl 的参数。</p><p>而 Docker 的–sysctl或者 Kubernetes 里的allowed-unsafe-sysctls特性也都利用了 runC 的 sysctl 参数修改接口，允许容器在启动时修改容器 Namespace 里的参数。</p><p>比如，我们可以试一下 docker –sysctl，这时候我们会发现，在容器的 Network Namespace 里，/proc/sys/net/ipv4/tcp_keepalive_time 这个网络参数终于被修改了！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run -d --name net_para --sysctl net.ipv4.tcp_keepalive_time=600 centos:8.1.1911 sleep 3600</span></span><br><span class="line">7efed88a44d64400ff5a6d38fdcc73f2a74a7bdc3dbc7161060f2f7d0be170d1</span><br><span class="line"><span class="comment"># docker exec net_para cat /proc/sys/net/ipv4/tcp_keepalive_time</span></span><br><span class="line">600</span><br></pre></td></tr></table></figure><!--### 重点总结好了，今天的课我们讲完了，那么下面我来给你做个总结。今天我们讨论问题是容器中网络参数的问题，因为是问题发生在容器里，又是网络的参数，那么自然就和 Network Namespace 有关，所以我们首先要理解 Network Namespace。Network Namespace 可以隔离网络设备，ip 协议栈，ip 路由表，防火墙规则，以及可以显示独立的网络状态信息。我们可以通过 clone() 或者 unshare() 系统调用来建立新的 Network Namespace。此外，还有一些工具"ip""netns""unshare""lsns"和"nsenter"，也可以用来操作 Network Namespace。这些工具的适用条件，我用表格的形式整理如下，你可以做个参考。![1][1]接着我们分析了如何修改普通容器（非 privileged）的网络参数。由于安全的原因，普通容器的 /proc/sys 是 read-only mount 的，所以在容器启动以后，我们无法在容器内部修改 /proc/sys/net 下网络相关的参数。这时可行的方法是**通过 runC sysctl 相关的接口，在容器启动的时候对容器内的网络参数做配置。**这样一来，想要修改网络参数就可以这么做：如果是使用 Docker，我们可以加上"—sysctl"这个参数；而如果使用 Kubernetes 的话，就需要用到"allowed unsaft sysctl"这个特性了。--><h2 id="容器网络配置（1）：容器网络不通了要怎么调试"><a href="#容器网络配置（1）：容器网络不通了要怎么调试" class="headerlink" title="容器网络配置（1）：容器网络不通了要怎么调试?"></a>容器网络配置（1）：容器网络不通了要怎么调试?</h2><p>前面我们讲 Network Namespace 隔离了网络设备，IP 协议栈和路由表，以及防火墙规则，那容器 Network Namespace 里的参数怎么去配置，我们现在已经很清楚了。</p><p>其实对于网络配置的问题，我们还有一个最需要关心的内容，那就是容器和外面的容器或者节点是怎么通讯的，这就涉及到了容器网络接口配置的问题了。</p><p>所以这一讲呢，我们就来聊一聊，容器 Network Namespace 里如何配置网络接口，还有当容器网络不通的时候，我们应该怎么去做一个简单调试。</p><h3 id="问题再现-1"><a href="#问题再现-1" class="headerlink" title="问题再现"></a>问题再现</h3><p>在前面，我们一直是用 docker run 这个命令来启动容器的。容器启动了之后，我们也可以看到，在容器里面有一个”eth0”的网络接口，接口上也配置了一个 IP 地址。</p><p>不过呢，如果我们想从容器里访问外面的一个 IP 地址，比如说 39.106.233.176（这个是极客时间网址对应的 IP），结果就发现是不能 ping 通的。</p><p>这时我们可能会想到，到底是不是容器内出了问题，在容器里无法访问，会不会宿主机也一样不行呢？</p><p>所以我们需要验证一下，首先我们退出容器，然后在宿主机的 Network Namespace 下，再运行 ping 39.106.233.176，结果就会发现在宿主机上，却是可以连通这个地址的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># docker run -d --name if-test centos:8.1.1911 sleep 36000</span></span><br><span class="line">244d44f94dc2931626194c6fd3f99cec7b7c4bf61aafc6c702551e2c5ca2a371</span><br><span class="line"><span class="comment"># docker exec -it if-test bash</span></span><br><span class="line"> </span><br><span class="line">[root@244d44f94dc2 /]<span class="comment"># ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">808: eth0@if809: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"> </span><br><span class="line">[root@244d44f94dc2 /]<span class="comment"># ping 39.106.233.176       ### 容器中无法ping通</span></span><br><span class="line">PING 39.106.233.176 (39.106.233.176) 56(84) bytes of data.</span><br><span class="line">^C</span><br><span class="line">--- 39.106.233.176 ping statistics ---</span><br><span class="line">9 packets transmitted, 0 received, 100% packet loss, time 185ms</span><br><span class="line"> </span><br><span class="line">[root@244d44f94dc2 /]<span class="comment"># exit             ###退出容器</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># ping 39.106.233.176                        ### 宿主机上可以ping通</span></span><br><span class="line">PING 39.106.233.176 (39.106.233.176) 56(84) bytes of data.</span><br><span class="line">64 bytes from 39.106.233.176: icmp_seq=1 ttl=78 time=296 ms</span><br><span class="line">64 bytes from 39.106.233.176: icmp_seq=2 ttl=78 time=306 ms</span><br><span class="line">64 bytes from 39.106.233.176: icmp_seq=3 ttl=78 time=303 ms</span><br><span class="line">^C</span><br><span class="line">--- 39.106.233.176 ping statistics ---</span><br><span class="line">4 packets transmitted, 3 received, 25% packet loss, time 7ms</span><br><span class="line">rtt min/avg/max/mdev = 296.059/301.449/305.580/4.037 ms</span><br></pre></td></tr></table></figure><p>那么碰到这种容器内网络不通的问题，我们应该怎么分析调试呢？我们还是需要先来理解一下，容器 Network Namespace 里的网络接口是怎么配置的。</p><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>在讲解容器的网络接口配置之前，我们需要先建立一个整体的认识，搞清楚容器网络接口在系统架构中处于哪个位置。</p><p>你可以看一下我给你画的这张图，图里展示的是容器有自己的 Network Namespace，eth0 是这个 Network Namespace 里的网络接口。而宿主机上也有自己的 eth0，宿主机上的 eth0 对应着真正的物理网卡，可以和外面通讯。</p><p><img src="/images/docker/docker-07/2.jpg" alt="2"></p><p>那你可以先想想，我们要让容器 Network Namespace 中的数据包最终发送到物理网卡上，需要完成哪些步骤呢？从图上看，我们大致可以知道应该包括这两步。</p><p><strong>第一步，就是要让数据包从容器的 Network Namespace 发送到 Host Network Namespace 上。</strong></p><p><strong>第二步，数据包发到了 Host Network Namespace 之后，还要解决数据包怎么从宿主机上的 eth0 发送出去的问题。</strong></p><p>好，整体的思路已经理清楚了，接下来我们做具体分析。我们先来看第一步，怎么让数据包从容器的 Network Namespace 发送到 Host Network Namespace 上面。</p><p>你可以查看一下<a href="https://docs.docker.com/network/" target="_blank" rel="noopener">Docker 网络的文档</a>或者<a href="https://kubernetes.io/docs/concepts/cluster-administration/networking/" target="_blank" rel="noopener">Kubernetes 网络的文档</a>，这些文档里面介绍了很多种容器网络配置的方式。</p><p>不过对于容器从自己的 Network Namespace 连接到 Host Network Namespace 的方法，一般来说就只有两类设备接口：一类是<a href="https://man7.org/linux/man-pages/man4/veth.4.html" target="_blank" rel="noopener">veth</a>，另外一类是 macvlan/ipvlan。</p><p>在这些方法中，我们使用最多的就是 veth 的方式，用 Docker 启动的容器缺省的网络接口用的也是这个 veth。既然它这么常见，所以我们就用 veth 作为例子来详细讲解。至于另外一类 macvlan/ipvlan 的方式，我们在下一讲里会讲到。</p><p>那什么是 veth 呢？为了方便你更好地理解，我们先来模拟一下 Docker 为容器建立 eth0 网络接口的过程，动手操作一下，这样呢，你就可以很快明白什么是 veth 了。</p><p>对于这个模拟操作呢，我们主要用到的是<a href="https://man7.org/linux/man-pages/man8/ip-netns.8.html" target="_blank" rel="noopener">ip netns</a> 这个命令，通过它来对 Network Namespace 做操作。</p><p>首先，我们先启动一个不带网络配置的容器，和我们之前的命令比较，主要是多加上了”–network none”参数。我们可以看到，这样在启动的容器中，Network Namespace 里就只有 loopback 一个网络设备，而没有了 eth0 网络设备了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run -d --name if-test --network none centos:8.1.1911 sleep 36000</span></span><br><span class="line">cf3d3105b11512658a025f5b401a09c888ed3495205f31e0a0d78a2036729472</span><br><span class="line"><span class="comment"># docker exec -it if-test ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>完成刚才的设置以后，我们就在这个容器的 Network Namespace 里建立 veth，你可以执行一下后面的这个脚本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">pid=$(ps -ef | grep <span class="string">"sleep 36000"</span> | grep -v grep | awk <span class="string">'&#123;print $2&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$pid</span></span><br><span class="line">ln -s /proc/<span class="variable">$pid</span>/ns/net /var/run/netns/<span class="variable">$pid</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># Create a pair of veth interfaces</span></span><br><span class="line">ip link add name veth_host <span class="built_in">type</span> veth peer name veth_container</span><br><span class="line"><span class="comment"># Put one of them in the new net ns</span></span><br><span class="line">ip link <span class="built_in">set</span> veth_container netns <span class="variable">$pid</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># In the container, setup veth_container</span></span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid</span> ip link <span class="built_in">set</span> veth_container name eth0</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid</span> ip addr add 172.17.1.2/16 dev eth0</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid</span> ip link <span class="built_in">set</span> eth0 up</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid</span> ip route add default via 172.17.0.1</span><br><span class="line"> </span><br><span class="line"><span class="comment"># In the host, set veth_host up</span></span><br><span class="line">ip link <span class="built_in">set</span> veth_host up</span><br></pre></td></tr></table></figure><p>我在这里解释一下，这个 veth 的建立过程是什么样的。</p><p>首先呢，我们先找到这个容器里运行的进程”sleep 36000”的 pid，通过 “/proc/$pid/ns/net”这个文件得到 Network Namespace 的 ID，这个 Network Namespace ID 既是这个进程的，也同时属于这个容器。</p><p>然后我们在”/var/run/netns/“的目录下建立一个符号链接，指向这个容器的 Network Namespace。完成这步操作之后，在后面的”ip netns”操作里，就可以用 pid 的值作为这个容器的 Network Namesapce 的标识了。</p><p>接下来呢，我们用 ip link 命令来建立一对 veth 的虚拟设备接口，分别是 veth_container 和 veth_host。从名字就可以看出来，veth_container 这个接口会被放在容器 Network Namespace 里，而 veth_host 会放在宿主机的 Host Network Namespace。</p><p>所以我们后面的命令也很好理解了，就是用 ip link set veth_container netns $pid 把 veth_container 这个接口放入到容器的 Network Namespace 中。</p><p>再然后我们要把 veth_container 重新命名为 eth0，因为这时候接口已经在容器的 Network Namesapce 里了，eth0 就不会和宿主机上的 eth0 冲突了。</p><p>最后对容器内的 eht0，我们还要做基本的网络 IP 和缺省路由配置。因为 veth_host 已经在宿主机的 Host Network Namespace 了，就不需要我们做什么了，这时我们只需要 up 一下这个接口就可以了。</p><p>那刚才这些操作完成以后，我们就建立了一对 veth 虚拟设备接口。我给你画了一张示意图，图里直观展示了这对接口在容器和宿主机上的位置。</p><p><img src="/images/docker/docker-07/3.jpg" alt="3"></p><p>现在，我们再来看看 veth 的定义了，其实它也很简单。veth 就是一个虚拟的网络设备，一般都是成对创建，而且这对设备是相互连接的。当每个设备在不同的 Network Namespaces 的时候，Namespace 之间就可以用这对 veth 设备来进行网络通讯了。</p><p>比如说，你可以执行下面的这段代码，试试在 veth_host 上加上一个 IP，172.17.1.1/16，然后从容器里就可以 ping 通这个 IP 了。这也证明了从容器到宿主机可以利用这对 veth 接口来通讯了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ip addr add 172.17.1.1/16 dev veth_host</span></span><br><span class="line"><span class="comment"># docker exec -it if-test ping 172.17.1.1</span></span><br><span class="line">PING 172.17.1.1 (172.17.1.1) 56(84) bytes of data.</span><br><span class="line">64 bytes from 172.17.1.1: icmp_seq=1 ttl=64 time=0.073 ms</span><br><span class="line">64 bytes from 172.17.1.1: icmp_seq=2 ttl=64 time=0.092 ms</span><br><span class="line">^C</span><br><span class="line">--- 172.17.1.1 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 30ms</span><br><span class="line">rtt min/avg/max/mdev = 0.073/0.082/0.092/0.013 ms</span><br></pre></td></tr></table></figure><p>好了，这样我们完成了第一步，通过一对 veth 虚拟设备，可以让数据包从容器的 Network Namespace 发送到 Host Network Namespace 上。</p><p>那下面我们再来看第二步， 数据包到了 Host Network Namespace 之后呢，怎么把它从宿主机上的 eth0 发送出去?</p><p>其实这一步呢，就是一个普通 Linux 节点上数据包转发的问题了。这里我们解决问题的方法有很多种，比如说用 nat 来做个转发，或者建立 Overlay 网络发送，也可以通过配置 proxy arp 加路由的方法来实现。</p><p>因为考虑到网络环境的配置，同时 Docker 缺省使用的是 bridge + nat 的转发方式， 那我们就在刚才讲的第一步基础上，再手动实现一下 bridge+nat 的转发方式。对于其他的配置方法，你可以看一下 Docker 或者 Kubernetes 相关的文档。</p><p>Docker 程序在节点上安装完之后，就会自动建立了一个 docker0 的 bridge interface。所以我们只需要把第一步中建立的 veth_host 这个设备，接入到 docker0 这个 bridge 上。</p><p>这里我要提醒你注意一下，如果之前你在 veth_host 上设置了 IP 的，就需先运行一下”ip addr delete 172.17.1.1/16 dev veth_host”，把 IP 从 veth_host 上删除。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ip addr delete 172.17.1.1/16 dev veth_host </span></span><br><span class="line">ip link <span class="built_in">set</span> veth_host master docker0</span><br></pre></td></tr></table></figure><p>这个命令执行完之后，容器和宿主机的网络配置就会发生变化，这种配置是什么样呢？你可以参考一下面这张图的描述。</p><p><img src="/images/docker/docker-07/4.jpg" alt="4"></p><p>从这张示意图中，我们可以看出来，容器和 docker0 组成了一个子网，docker0 上的 IP 就是这个子网的网关 IP。</p><p>如果我们要让子网通过宿主机上 eth0 去访问外网的话，那么加上 iptables 的规则就可以了，也就是下面这条规则。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure><p>好了，进行到这里，我们通过 bridge+nat 的配置，似乎已经完成了第二步——让数据从宿主机的 eth0 发送出去。</p><p>那么我们这样配置，真的可以让容器里发送数据包到外网了吗？这需要我们做个测试，再重新尝试下这一讲开始的操作，从容器里 ping 外网的 IP，这时候，你会发现还是 ping 不通。</p><p>其实呢，做到这一步，我们通过自己的逐步操作呢，重现了这一讲了最开始的问题。</p><h3 id="解决问题-1"><a href="#解决问题-1" class="headerlink" title="解决问题"></a>解决问题</h3><p>既然现在我们清楚了，在这个节点上容器和宿主机上的网络配置是怎么一回事。那么要调试这个问题呢，也有了思路，关键就是找到数据包传到哪个环节时发生了中断。</p><p>那最直接的方法呢，就是在容器中继续 ping 外网的 IP 39.106.233.176，然后在容器的 eth0 (veth_container)，容器外的 veth_host，docker0，宿主机的 eth0 这一条数据包的路径上运行 tcpdump。</p><p>这样就可以查到，到底在哪个设备接口上没有收到 ping 的 icmp 包。我把 tcpdump 运行的结果我列到了下面。</p><p>容器的 eth0：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ip netns exec $pid tcpdump -i eth0 host 39.106.233.176 -nn</span></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv <span class="keyword">for</span> full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">00:47:29.934294 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 1, length 64</span><br><span class="line">00:47:30.934766 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 2, length 64</span><br><span class="line">00:47:31.958875 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 3, length 64</span><br></pre></td></tr></table></figure><p>veth_host：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tcpdump -i veth_host host 39.106.233.176 -nn</span></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv <span class="keyword">for</span> full protocol decode</span><br><span class="line">listening on veth_host, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">00:48:01.654720 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 32, length 64</span><br><span class="line">00:48:02.678752 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 33, length 64</span><br><span class="line">00:48:03.702827 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 34, length 64</span><br></pre></td></tr></table></figure><p>docker0：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tcpdump -i docker0 host 39.106.233.176 -nn</span></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv <span class="keyword">for</span> full protocol decode</span><br><span class="line">listening on docker0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">00:48:20.086841 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 50, length 64</span><br><span class="line">00:48:21.110765 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 51, length 64</span><br><span class="line">00:48:22.134839 IP 172.17.1.2 &gt; 39.106.233.176: ICMP <span class="built_in">echo</span> request, id 71, seq 52, length 64</span><br></pre></td></tr></table></figure><p>host eth0：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tcpdump -i eth0 host 39.106.233.176 -nn</span></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv <span class="keyword">for</span> full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">^C</span><br><span class="line">0 packets captured</span><br><span class="line">0 packets received by filter</span><br><span class="line">0 packets dropped by kernel</span><br></pre></td></tr></table></figure><p>通过上面的输出结果，我们发现 icmp 包到达了 docker0，但是没有到达宿主机上的 eth0。</p><p>因为我们已经配置了 iptables nat 的转发，这个也可以通过查看 iptables 的 nat 表确认一下，是没有问题的，具体的操作命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># iptables -L  -t nat</span></span><br><span class="line">Chain PREROUTING (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">DOCKER     all  --  anywhere             anywhere             ADDRTYPE match dst-type LOCAL</span><br><span class="line"> </span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"> </span><br><span class="line">Chain POSTROUTING (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">MASQUERADE  all  --  172.17.0.0/16        anywhere</span><br><span class="line"> </span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">DOCKER     all  --  anywhere            !127.0.0.0/8          ADDRTYPE match dst-type LOCAL</span><br><span class="line"> </span><br><span class="line">Chain DOCKER (2 references)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">RETURN     all  --  anywhere             anywhere</span><br></pre></td></tr></table></figure><p>那么会是什么问题呢？因为这里需要做两个网络设备接口之间的数据包转发，也就是从 docker0 把数据包转发到 eth0 上，你可能想到了 Linux 协议栈里的一个常用参数 ip_forward。</p><p>我们可以看一下，它的值是 0，当我们把它改成 1 之后，那么我们就可以从容器中 ping 通外网 39.106.233.176 这个 IP 了！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /proc/sys/net/ipv4/ip_forward</span></span><br><span class="line">0</span><br><span class="line"><span class="comment"># echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># docker exec -it if-test ping 39.106.233.176</span></span><br><span class="line">PING 39.106.233.176 (39.106.233.176) 56(84) bytes of data.</span><br><span class="line">64 bytes from 39.106.233.176: icmp_seq=1 ttl=77 time=359 ms</span><br><span class="line">64 bytes from 39.106.233.176: icmp_seq=2 ttl=77 time=346 ms</span><br><span class="line">^C</span><br><span class="line">--- 39.106.233.176 ping statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 1ms</span><br><span class="line">rtt min/avg/max/mdev = 345.889/352.482/359.075/6.593 ms</span><br></pre></td></tr></table></figure><!--### 重点小结这一讲，我们主要解决的问题是如何给容器配置网络接口，让容器可以和外面通讯；同时我们还学习了当容器网络不通的时候，我们应该怎么来做一个简单调试。解决容器与外界通讯的问题呢，一共需要完成两步。第一步是，怎么让数据包从容器的 Network Namespace 发送到 Host Network Namespace 上；第二步，数据包到了 Host Network Namespace 之后，还需要让它可以从宿主机的 eth0 发送出去。我们想让数据从容器 Netowrk Namespace 发送到 Host Network Namespace，可以用配置一对 veth 虚拟网络设备的方法实现。而让数据包从宿主机的 eth0 发送出去，就用可 bridge+nat 的方式完成。这里我讲的是最基本的一种配置，但它也是很常用的一个网络配置。针对其他不同需要，容器网络还有很多种。那你学习完这一讲，了解了基本的概念和操作之后呢，还可以查看更多的网上资料，学习不同的网络配置。遇到容器中网络不通的情况，我们先要理解自己的容器以及容器在宿主机上的配置，通过对主要设备上做 tcpdump 可以找到具体在哪一步数据包停止了转发。然后我们结合内核网络配置参数，路由表信息，防火墙规则，一般都可以定位出根本原因，最终解决这种网络完全不通的问题。但是如果是网络偶尔丢包的问题，这个就需要用到其他的一些工具来做分析了，这个我们会在之后做讲解。--><h2 id="容器网络配置（2）：容器网络延时要比宿主机上的高吗"><a href="#容器网络配置（2）：容器网络延时要比宿主机上的高吗" class="headerlink" title="容器网络配置（2）：容器网络延时要比宿主机上的高吗?"></a>容器网络配置（2）：容器网络延时要比宿主机上的高吗?</h2><p>在前面，我们学习了在容器中的网络接口配置，重点讲解的是 veth 的接口配置方式，这也是绝大部分容器用的缺省的网络配置方式。</p><p>不过呢，从 veth 的这种网络接口配置上看，一个数据包要从容器里发送到宿主机外，需要先从容器里的 eth0 (veth_container) 把包发送到宿主机上 veth_host，然后再在宿主机上通过 nat 或者路由的方式，经过宿主机上的 eth0 向外发送。</p><p><img src="/images/docker/docker-07/5.jpg" alt="5"></p><p>这种容器向外发送数据包的路径，相比宿主机上直接向外发送数据包的路径，很明显要多了一次接口层的发送和接收。尽管 veth 是虚拟网络接口，在软件上还是会增加一些开销。</p><p>如果我们的应用程序对网络性能有很高的要求，特别是之前运行在物理机器上，现在迁移到容器上的，如果网络配置采用 veth 方式，就会出现网络延时增加的现象。</p><p>那今天我们就来聊一聊，容器网络接口对于容器中应用程序网络延时有怎样的影响，还有这个问题应该怎么解决。</p><h3 id="问题重现"><a href="#问题重现" class="headerlink" title="问题重现"></a>问题重现</h3><p>对于这种 veth 接口配置导致网络延时增加的现象，我们可以通过运行<a href="https://github.com/HewlettPackard/netperf" target="_blank" rel="noopener">netperf</a>（Netperf 是一个衡量网络性能的工具，它可以提供单向吞吐量和端到端延迟的测试）来模拟一下。</p><p>这里我们需要两台虚拟机或者物理机，这两台机器需要同处于一个二层的网络中。</p><p>具体的配置示意图如下：</p><p><img src="/images/docker/docker-07/6.jpg" alt="6"></p><p>首先，我们需要在第一台机器上启动一个 veth 接口的容器，容器的启动和宿主机上的配置你可以参考一下这里的脚本。在第二台机器上，我们只要启动一个 netserver 就可以了。</p><p>然后呢，我们分别在容器里和宿主机上运行与 netserver 交互的 netperf，再比较一下它们延时的差异。</p><p>我们可以运行 netperf 的 TCP_RR 测试用例，TCP_RR 是 netperf 里专门用来测试网络延时的，缺省每次运行 10 秒钟。运行以后，我们还要计算平均每秒钟 TCP request/response 的次数，这个次数越高，就说明延时越小。</p><p>接下来，我们先在第一台机器的宿主机上直接运行 netperf 的 TCP_RR 测试用例 3 轮，得到的值分别是 2504.92，2410.14 和 2422.81，计算一下可以得到三轮 Transactions 平均值是 2446/s。</p><p>Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> netperf /</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> netserver /</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y iperf3</span></span><br></pre></td></tr></table></figure><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: image</span></span><br><span class="line"></span><br><span class="line"><span class="section">image:</span></span><br><span class="line">docker build -t registry/latency-test:v1 .</span><br><span class="line"><span class="section">clean: </span></span><br><span class="line">docker rmi registry/latency-test:v1</span><br></pre></td></tr></table></figure><p>start_container.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">docker stop lat-test-1;docker rm lat-test-1</span><br><span class="line"></span><br><span class="line">docker run --init --name lat-test-1 -d registry/latency-test:v1 /netserver -D</span><br><span class="line"></span><br><span class="line">iptables -P FORWARD ACCEPT</span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># ./netperf -H 192.168.0.194 -t TCP_RR</span></span><br><span class="line">MIGRATED TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 192.168.0.194 () port 0 AF_INET : first burst 0</span><br><span class="line">Local /Remote</span><br><span class="line">Socket Size   Request  Resp.   Elapsed  Trans.</span><br><span class="line">Send   Recv   Size     Size    Time     Rate</span><br><span class="line">bytes  Bytes  bytes    bytes   secs.    per sec</span><br><span class="line"> </span><br><span class="line">16384  131072 1        1       10.00    2504.92</span><br><span class="line">16384  131072</span><br><span class="line"><span class="comment"># ./netperf -H 192.168.0.194 -t TCP_RR</span></span><br><span class="line">MIGRATED TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 192.168.0.194 () port 0 AF_INET : first burst 0</span><br><span class="line">Local /Remote</span><br><span class="line">Socket Size   Request  Resp.   Elapsed  Trans.</span><br><span class="line">Send   Recv   Size     Size    Time     Rate</span><br><span class="line">bytes  Bytes  bytes    bytes   secs.    per sec</span><br><span class="line"> </span><br><span class="line">16384  131072 1        1       10.00    2410.14</span><br><span class="line">16384  131072</span><br><span class="line"> </span><br><span class="line"><span class="comment"># ./netperf -H 192.168.0.194 -t TCP_RR</span></span><br><span class="line">MIGRATED TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 192.168.0.194 () port 0 AF_INET : first burst 0</span><br><span class="line">Local /Remote</span><br><span class="line">Socket Size   Request  Resp.   Elapsed  Trans.</span><br><span class="line">Send   Recv   Size     Size    Time     Rate</span><br><span class="line">bytes  Bytes  bytes    bytes   secs.    per sec</span><br><span class="line"> </span><br><span class="line">16384  131072 1        1       10.00    2422.81</span><br><span class="line">16384  131072</span><br></pre></td></tr></table></figure><p>同样，我们再在容器中运行一下 netperf 的 TCP_RR，也一样运行三轮，计算一下这三次的平均值，得到的值是 2141。</p><p>那么我们拿这次容器环境中的平均值和宿主机上得到的值 2446 做比较，会发现 Transactions 下降了大概 12.5%，也就是网络的延时超过了 10%。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@4150e2a842b5 /]<span class="comment"># ./netperf -H 192.168.0.194 -t TCP_RR</span></span><br><span class="line">MIGRATED TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 192.168.0.194 () port 0 AF_INET : first burst 0</span><br><span class="line">Local /Remote</span><br><span class="line">Socket Size   Request  Resp.   Elapsed  Trans.</span><br><span class="line">Send   Recv   Size     Size    Time     Rate</span><br><span class="line">bytes  Bytes  bytes    bytes   secs.    per sec</span><br><span class="line"> </span><br><span class="line">16384  131072 1        1       10.00    2104.68</span><br><span class="line">16384  131072</span><br><span class="line"> </span><br><span class="line">[root@4150e2a842b5 /]<span class="comment"># ./netperf -H 192.168.0.194 -t TCP_RR</span></span><br><span class="line">MIGRATED TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 192.168.0.194 () port 0 AF_INET : first burst 0</span><br><span class="line">Local /Remote</span><br><span class="line">Socket Size   Request  Resp.   Elapsed  Trans.</span><br><span class="line">Send   Recv   Size     Size    Time     Rate</span><br><span class="line">bytes  Bytes  bytes    bytes   secs.    per sec</span><br><span class="line"> </span><br><span class="line">16384  131072 1        1       10.00    2146.34</span><br><span class="line">16384  131072</span><br><span class="line"> </span><br><span class="line">[root@4150e2a842b5 /]<span class="comment"># ./netperf -H 192.168.0.194 -t TCP_RR</span></span><br><span class="line">MIGRATED TCP REQUEST/RESPONSE TEST from 0.0.0.0 (0.0.0.0) port 0 AF_INET to 192.168.0.194 () port 0 AF_INET : first burst 0</span><br><span class="line">Local /Remote</span><br><span class="line">Socket Size   Request  Resp.   Elapsed  Trans.</span><br><span class="line">Send   Recv   Size     Size    Time     Rate</span><br><span class="line">bytes  Bytes  bytes    bytes   secs.    per sec</span><br><span class="line"> </span><br><span class="line">16384  131072 1        1       10.00    2173.79</span><br><span class="line">16384  131072</span><br></pre></td></tr></table></figure><h3 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h3><p>刚才我们已经得到了测试的数值，我们发现 veth 方式的确带来了很高的网络延时。那现在我们先来分析一下，为什么 veth 会带来这么大的网络延时，然后再看看有什么方法可以降低容器里的网络延时。</p><p>我们先回顾一下容器里 veth 接口的配置，还是拿我们上一讲里容器 veth 的图作为例子。</p><p><img src="/images/docker/docker-07/3.jpg" alt="3"></p><p>veth 的虚拟网络接口一般都是成对出现，就像上面图里的 veth_container 和 veth_host 一样。</p><p>在每次网络传输的过程中，数据包都需要通过 veth_container 这个接口向外发送，而且必须保证 veth_host 先接收到这个数据包。</p><p>虽然 veth 是一个虚拟的网络接口，但是在接收数据包的操作上，这个虚拟接口和真实的网路接口并没有太大的区别。这里除了没有硬件中断的处理，其他操作都差不多，特别是软中断（softirq）的处理部分其实就和真实的网络接口是一样的。</p><p>我们可以通过阅读 Linux 内核里的 <a href="https://github.com/torvalds/linux/blob/v5.4/drivers/net/veth.c" target="_blank" rel="noopener">veth 的驱动代码（drivers/net/veth.c）</a>确认一下。</p><p>veth 发送数据的函数是 veth_xmit()，它里面的主要操作就是找到 veth peer 设备，然后触发 peer 设备去接收数据包。</p><p>比如 veth_container 这个接口调用了 veth_xmit() 来发送数据包，最后就是触发了它的 peer 设备 veth_host 去调用 netif_rx() 来接收数据包。主要的代码我列在下面了：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">netdev_tx_t</span> <span class="title">veth_xmit</span><span class="params">(struct sk_buff *skb, struct net_device *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">…</span><br><span class="line">       <span class="comment">/* 拿到veth peer设备的net_device */</span></span><br><span class="line">       rcv = rcu_dereference(priv-&gt;peer);</span><br><span class="line">…</span><br><span class="line">       <span class="comment">/* 将数据送到veth peer设备 */</span> </span><br><span class="line">       <span class="keyword">if</span> (likely(veth_forward_skb(rcv, skb, rq, rcv_xdp) == NET_RX_SUCCESS)) &#123;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">…</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">veth_forward_skb</span><span class="params">(struct net_device *dev, struct sk_buff *skb,</span></span></span><br><span class="line"><span class="function"><span class="params">                            struct veth_rq *rq, <span class="keyword">bool</span> xdp)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="comment">/* 这里最后调用了 netif_rx() */</span></span><br><span class="line">        <span class="keyword">return</span> __dev_forward_skb(dev, skb) ?: xdp ?</span><br><span class="line">                veth_xdp_rx(rq, skb) :</span><br><span class="line">                netif_rx(skb);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>而 netif_rx() 是一个网络设备驱动里面标准的接收数据包的函数，netif_rx() 里面会为这个数据包 raise 一个 softirq。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__raise_softirq_irqoff(NET_RX_SOFTIRQ);</span><br></pre></td></tr></table></figure><p>其实 softirq 这个概念，我们之前在CPU 的模块中也提到过。在处理网络数据的时候，一些运行时间较长而且不能在硬中断中处理的工作，就会通过 softirq 来处理。</p><p>一般在硬件中断处理结束之后，网络 softirq 的函数才会再去执行没有完成的包的处理工作。即使这里 softirq 的执行速度很快，还是会带来额外的开销。</p><p><strong>所以，根据 veth 这个虚拟网络设备的实现方式，我们可以看到它必然会带来额外的开销，这样就会增加数据包的网络延时。</strong></p><h3 id="解决问题-2"><a href="#解决问题-2" class="headerlink" title="解决问题"></a>解决问题</h3><p>那么我们有什么方法可以减少容器的网络延时呢？你可能会想到，我们可不可以不使用 veth 这个方式配置网络接口，而是换成别的方式呢？</p><p>的确是这样，其实除了 veth 之外，容器还可以选择其他的网络配置方式。在 Docker 的文档中提到了 macvlan 的配置方式，和 macvlan 很类似的方式还有 ipvlan。</p><p>那我们先来简单看一下 macvlan 和 ipvlan 的异同点。</p><p>我们先来看这两个方式的相同之处，无论是 macvlan 还是 ipvlan，它们都是在一个物理的网络接口上再配置几个虚拟的网络接口。在这些虚拟的网络接口上，都可以配置独立的 IP，并且这些 IP 可以属于不同的 Namespace。</p><p>然后我再说说它们的不同点。<strong>对于 macvlan，每个虚拟网络接口都有自己独立的 mac 地址；而 ipvlan 的虚拟网络接口是和物理网络接口共享同一个 mac 地址</strong>。而且它们都有自己的 L2/L3 的配置方式，不过我们主要是拿 macvlan/ipvlan 来和 veth 做比较，这里可以先忽略 macvlan/ipvlan 这些详细的特性。</p><p>我们就以 ipvlan 为例，运行下面的这个脚本，为容器手动配置上 ipvlan 的网络接口。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">docker run --init --name lat-test-1 --network none -d registry/latency-test:v1 sleep 36000</span><br><span class="line"> </span><br><span class="line">pid1=$(docker inspect lat-test-1 | grep -i Pid | head -n 1 | awk <span class="string">'&#123;print $2&#125;'</span> | awk -F <span class="string">","</span> <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$pid1</span></span><br><span class="line">ln -s /proc/<span class="variable">$pid1</span>/ns/net /var/run/netns/<span class="variable">$pid1</span></span><br><span class="line"> </span><br><span class="line">ip link add link eth0 ipvt1 <span class="built_in">type</span> ipvlan mode l2</span><br><span class="line">ip link <span class="built_in">set</span> dev ipvt1 netns <span class="variable">$pid1</span></span><br><span class="line"> </span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid1</span> ip link <span class="built_in">set</span> ipvt1 name eth0</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid1</span> ip addr add 172.17.3.2/16 dev eth0</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid1</span> ip link <span class="built_in">set</span> eth0 up</span><br></pre></td></tr></table></figure><p>在这个脚本里，我们先启动一个容器，这里我们用”—network none”的方式来启动，也就是在容器中没有配置任何的网络接口。</p><p>接着我们在宿主机 eth0 的接口上增加一个 ipvlan 虚拟网络接口 ipvt1，再把它加入到容器的 Network Namespace 里面，重命名为容器内的 eth0，并且配置上 IP。这样我们就配置好了第一个用 ipvlan 网络接口的容器。</p><p>我们可以用同样的方式配置第二个容器，这样两个容器可以相互 ping 一下 IP，看看网络是否配置成功了。</p><p>create_ipvlan.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">docker stop lat-test-1;docker rm lat-test-1</span><br><span class="line">docker stop lat-test-2;docker rm lat-test-2</span><br><span class="line"></span><br><span class="line">docker run --init --name lat-test-1 --network none -d registry/latency-test:v1 sleep 36000</span><br><span class="line"></span><br><span class="line">pid1=$(docker inspect lat-test-1 | grep -i Pid | head -n 1 | awk <span class="string">'&#123;print $2&#125;'</span> | awk -F <span class="string">","</span> <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$pid1</span></span><br><span class="line">ln -s /proc/<span class="variable">$pid1</span>/ns/net /var/run/netns/<span class="variable">$pid1</span></span><br><span class="line"></span><br><span class="line">ip link add link eth0 ipvt1 <span class="built_in">type</span> ipvlan mode l2</span><br><span class="line">ip link <span class="built_in">set</span> dev ipvt1 netns <span class="variable">$pid1</span></span><br><span class="line"></span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid1</span> ip link <span class="built_in">set</span> ipvt1 name eth0</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid1</span> ip addr add 172.17.3.2/16 dev eth0</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid1</span> ip link <span class="built_in">set</span> eth0 up</span><br><span class="line"></span><br><span class="line">docker run --init --name lat-test-2 --network none -d registry/latency-test:v1 sleep 36000</span><br><span class="line"></span><br><span class="line">pid2=$(docker inspect lat-test-2 | grep -i Pid | head -n 1 | awk <span class="string">'&#123;print $2&#125;'</span> | awk -F <span class="string">","</span> <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$pid2</span></span><br><span class="line">ln -s /proc/<span class="variable">$pid2</span>/ns/net /var/run/netns/<span class="variable">$pid2</span></span><br><span class="line"></span><br><span class="line">ip link add link eth0 ipvt2 <span class="built_in">type</span> ipvlan mode l2</span><br><span class="line">ip link <span class="built_in">set</span> dev ipvt2 netns <span class="variable">$pid2</span></span><br><span class="line"></span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid2</span> ip link <span class="built_in">set</span> ipvt2 name eth0</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid2</span> ip addr add 172.17.3.3/16 dev eth0</span><br><span class="line">ip netns <span class="built_in">exec</span> <span class="variable">$pid2</span> ip link <span class="built_in">set</span> eth0 up</span><br></pre></td></tr></table></figure><p>两个容器配置好之后，就像下面图中描述的一样了。从这张图里，你很容易就能看出 macvlan/ipvlan 与 veth 网络配置有什么不一样。容器的虚拟网络接口，直接连接在了宿主机的物理网络接口上了，形成了一个网络二层的连接。</p><p><img src="/images/docker/docker-07/7.jpg" alt="7"></p><p>如果从容器里向宿主机外发送数据，看上去通过的接口要比 veth 少了，那么实际情况是不是这样呢？我们先来看一下 ipvlan 接口发送数据的代码。</p><p>从下面的 ipvlan 接口的发送代码中，我们可以看到，如果是往宿主机外发送数据，发送函数会直接找到 ipvlan 虚拟接口对应的物理网络接口。</p><p>比如在我们的例子中，这个物理接口就是宿主机上的 eth0，然后直接调用 dev_queue_xmit()，通过物理接口把数据直接发送出去。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">ipvlan_xmit_mode_l2</span><span class="params">(struct sk_buff *skb, struct net_device *dev)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">…</span><br><span class="line">        <span class="keyword">if</span> (!ipvlan_is_vepa(ipvlan-&gt;port) &amp;&amp;</span><br><span class="line">            ether_addr_equal(eth-&gt;h_dest, eth-&gt;h_source)) &#123;</span><br><span class="line">…</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (is_multicast_ether_addr(eth-&gt;h_dest)) &#123;</span><br><span class="line">…</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* </span></span><br><span class="line"><span class="comment">         * 对于普通的对外发送数据，上面的if 和 else if中的条件都不成立，</span></span><br><span class="line"><span class="comment">         * 所以会执行到这一步，拿到ipvlan对应的物理网路接口设备，</span></span><br><span class="line"><span class="comment">         * 然后直接从这个设备发送数据。</span></span><br><span class="line"><span class="comment">         */</span> </span><br><span class="line">        skb-&gt;dev = ipvlan-&gt;phy_dev;</span><br><span class="line">        <span class="keyword">return</span> dev_queue_xmit(skb);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>和 veth 接口相比，我们用 ipvlan 发送对外数据就要简单得多，因为这种方式没有内部额外的 softirq 处理开销。</p><p>现在我们还可以看一下，在实际生产环境中，一个应用程序跑在使用 veth 接口的容器中，跟这个应用程序跑在使用 ipvlan 接口的容器中，两者的网络延时差异是怎样的。</p><p>下面这张图是网络延时的监控图，图里蓝色的线表示程序运行在 veth 容器中，黄色线表示程序运行在 ipvlan 的容器里，绿色的线代表程序直接运行在物理机上。</p><p>从这张延时（Latency）图里，我们可以看到，在 veth 容器里程序的网络延时要明显高一些，而程序在 ipvlan 容器里的网络延时已经比较接近物理机上的网络延时了。</p><p><img src="/images/docker/docker-07/8.jpg" alt="8"></p><p>所以对于网络延时敏感的应用程序，我们可以考虑使用 ipvlan/macvlan 的容器网络配置方式来替换缺省的 veth 网络配置。</p><!--### 重点小结好了，今天的内容讲完了，我们来做个总结。今天我们主要讨论了容器网络接口对容器中应用程序网络延时的影响。容器通常缺省使用 veth 虚拟网络接口，不过 veth 接口会有比较大的网络延时。我们可以使用 netperf 这个工具来比较网络延时，相比物理机上的网络延时，使用 veth 接口容器的网络延时会增加超过 10%。我们通过对 veth 实现的代码做分析，可以看到由于 veth 接口是成对工作，在对外发送数据的时候，peer veth 接口都会 raise softirq 来完成一次收包操作，这样就会带来数据包处理的额外开销。如果要减小容器网络延时，就可以给容器配置 ipvlan/macvlan 的网络接口来替代 veth 网络接口。Ipvlan/macvlan 直接在物理网络接口上虚拟出接口，在发送对外数据包的时候可以直接通过物理接口完成，没有节点内部类似 veth 的那种 softirq 的开销。容器使用 ipvlan/maclan 的网络接口，它的网络延时可以非常接近物理网络接口的延时。对于延时敏感的应用程序，我们可以考虑使用 ipvlan/macvlan 网络接口的容器。不过，由于 ipvlan/macvlan 网络接口直接挂载在物理网络接口上，对于需要使用 iptables 规则的容器，比如 Kubernetes 里使用 service 的容器，就不能工作了。这就需要你结合实际应用的需求做个判断，再选择合适的方案。--><h2 id="容器网络配置（3）：容器中的网络乱序包怎么这么高？"><a href="#容器网络配置（3）：容器中的网络乱序包怎么这么高？" class="headerlink" title="容器网络配置（3）：容器中的网络乱序包怎么这么高？"></a>容器网络配置（3）：容器中的网络乱序包怎么这么高？</h2><p>我们来聊一下容器中发包乱序的问题。这个问题也同样来自于工作实践，我们的用户把他们的应用程序从物理机迁移到容器之后，从网络监控中发现，容器中数据包的重传的数量要比在物理机里高了不少。</p><p>在前面，我们已经知道了容器网络缺省的接口是 veth，veth 接口都是成对使用的。容器通过 veth 接口向外发送数据，首先需要从 veth 的一个接口发送给跟它成对的另一个接口。</p><p>那么这种接口会不会引起更多的网络重传呢？如果会引起重传，原因是什么，我们又要如何解决呢？接下来我们就带着这三个问题开始今天的学习。</p><h3 id="问题重现-1"><a href="#问题重现-1" class="headerlink" title="问题重现"></a>问题重现</h3><p>我们可以在容器里运行一下 iperf3 命令，向容器外部发送一下数据，从 iperf3 的输出”Retr”列里，我们可以看到有多少重传的数据包。</p><p>比如下面的例子里，我们可以看到有 162 个重传的数据包。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># iperf3 -c 192.168.147.51</span></span><br><span class="line">Connecting to host 192.168.147.51, port 5201</span><br><span class="line">[  5] <span class="built_in">local</span> 192.168.225.12 port 51700 connected to 192.168.147.51 port 5201</span><br><span class="line">[ ID] Interval           Transfer     Bitrate                        Retr    Cwnd</span><br><span class="line">[  5]   0.00-1.00   sec  1001 MBytes  8.40 Gbits/sec  162    192 KBytes</span><br><span class="line">…</span><br><span class="line">- - - - - - - - - - - - - - - - - - - - - - - - -</span><br><span class="line">[ ID] Interval           Transfer     Bitrate         Retr</span><br><span class="line">[  5]   0.00-10.00  sec  9.85 GBytes  8.46 Gbits/sec  162             sender</span><br><span class="line">[  5]   0.00-10.04  sec  9.85 GBytes  8.42 Gbits/sec                  receiver</span><br><span class="line"> </span><br><span class="line">iperf Done.</span><br></pre></td></tr></table></figure><p><strong>网络中发生了数据包的重传，有可能是数据包在网络中丢了，也有可能是数据包乱序导致的</strong>。那么，我们怎么来判断到底是哪一种情况引起的重传呢？</p><p>最直接的方法就是用 tcpdump 去抓包，不过对于大流量的网络，用 tcpdump 抓包瞬间就会有几个 GB 的数据。可是这样做的话，带来的额外系统开销比较大，特别是在生产环境中这个方法也不太好用。</p><p>所以这里我们有一个简单的方法，那就是运行 netstat 命令来查看协议栈中的丢包和重传的情况。比如说，在运行上面的 iperf3 命令前后，我们都在容器的 Network Namespace 里运行一下 netstat 看看重传的情况。</p><p>我们会发现，一共发生了 162 次（604-442）快速重传（fast retransmits），这个数值和 iperf3 中的 Retr 列里的数值是一样的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-bash-4.2<span class="comment"># nsenter -t 51598 -n netstat -s | grep retran</span></span><br><span class="line">    454 segments retransmited</span><br><span class="line">    442 fast retransmits</span><br><span class="line">-bash-4.2<span class="comment"># nsenter -t 51598 -n netstat -s | grep retran</span></span><br><span class="line">    616 segments retransmited</span><br><span class="line">    604 fast retransmits</span><br></pre></td></tr></table></figure><h3 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h3><h3 id="快速重传（fast-retransmit）"><a href="#快速重传（fast-retransmit）" class="headerlink" title="快速重传（fast retransmit）"></a>快速重传（fast retransmit）</h3><p>在刚才的问题重现里，我们运行 netstat 命令后，统计了快速重传的次数。那什么是快速重传（fast retransmit）呢？这里我给你解释一下。</p><p>我们都知道 TCP 协议里，发送端（sender）向接受端（receiver）发送一个数据包，接受端（receiver）都回应 ACK。如果超过一个协议栈规定的时间（RTO），发送端没有收到 ACK 包，那么发送端就会重传（Retransmit）数据包，就像下面的示意图一样。</p><p><img src="/images/docker/docker-07/9.jpg" alt="9"></p><p>不过呢，这样等待一个超时之后再重传数据，对于实际应用来说太慢了，所以 TCP 协议又定义了快速重传 （fast retransmit）的概念。它的基本定义是这样的：<strong>如果发送端收到 3 个重复的 ACK，那么发送端就可以立刻重新发送 ACK 对应的下一个数据包</strong>。</p><p>就像下面示意图里描述的那样，接受端没有收到 Seq 2 这个包，但是收到了 Seq 3–5 的数据包，那么接收端在回应 Ack 的时候，Ack 的数值只能是 2。这是因为按顺序来说收到 Seq 1 的包之后，后面 Seq 2 一直没有到，所以接收端就只能一直发送 Ack 2。</p><p>那么当发送端收到 3 个重复的 Ack 2 后，就可以马上重新发送 Seq 2 这个数据包了，而不用再等到重传超时之后了。</p><p><img src="/images/docker/docker-07/10.jpg" alt="10"></p><p>虽然 TCP 快速重传的标准定义是需要收到 3 个重复的 Ack，不过你会发现在 Linux 中常常收到一个 Dup Ack（重复的 Ack）后，就马上重传数据了。这是什么原因呢？</p><p>这里先需要提到 <strong>SACK</strong> 这个概念，SACK 也就是选择性确认（Selective Acknowledgement）。其实跟普通的 ACK 相比呢，SACK 会把接收端收到的所有包的序列信息，都反馈给发送端。</p><p>你看看下面这张图，就能明白这是什么意思了。</p><p><img src="/images/docker/docker-07/11.jpg" alt="11"></p><p>那有了 SACK，对于发送端来说，在收到 SACK 之后就已经知道接收端收到了哪些数据，没有收到哪些数据。</p><p>在 Linux 内核中会有个判断（你可以看看下面的这个函数），大概意思是这样的：如果在接收端收到的数据和还没有收到的数据之间，两者数据量差得太大的话（超过了 reordering*mss_cache），也可以马上重传数据。</p><p>这里你需要注意一下，<strong>这里的数据量差是根据 bytes 来计算的，而不是按照包的数目来计算的，所以你会看到即使只收到一个 SACK，Linux 也可以重发数据包</strong>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">bool</span> <span class="title">tcp_force_fast_retransmit</span><span class="params">(struct sock *sk)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">tcp_sock</span> *<span class="title">tp</span> = <span class="title">tcp_sk</span>(<span class="title">sk</span>);</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">return</span> after(tcp_highest_sack_seq(tp),</span><br><span class="line">                     tp-&gt;snd_una + tp-&gt;reordering * tp-&gt;mss_cache);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好了，了解了快速重传的概念之后，我们再来看看，如果 netstat 中有大量的”fast retransmits”意味着什么？</p><p>如果你再用 netstat 查看”reordering”，就可以看到大量的 SACK 发现的乱序包。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-bash-4.2<span class="comment"># nsenter -t 51598 -n netstat -s  | grep reordering</span></span><br><span class="line">    Detected reordering 501067 <span class="built_in">times</span> using SACK</span><br></pre></td></tr></table></figure><p><strong>其实在云平台的这种网络环境里，网络包乱序 +SACK 之后，产生的数据包重传的量要远远高于网络丢包引起的重传</strong>。</p><p>比如说像下面这张图里展示的这样，Seq 2 与 Seq 3 这两个包如果乱序的话，那么就会引起 Seq 2 的立刻重传。</p><p><img src="/images/docker/docker-07/12.jpg" alt="12"></p><h3 id="Veth-接口的数据包的发送"><a href="#Veth-接口的数据包的发送" class="headerlink" title="Veth 接口的数据包的发送"></a>Veth 接口的数据包的发送</h3><p>现在我们知道了网络包乱序会造成数据包的重传，接着我们再来看看容器的 veth 接口配置有没有可能会引起数据包的乱序。</p><p>在上一讲里，我们讲过通过 veth 接口从容器向外发送数据包，会触发 peer veth 设备去接收数据包，这个接收的过程就是一个网络的 softirq 的处理过程。</p><p>在触发 softirq 之前，veth 接口会模拟硬件接收数据的过程，通过 enqueue_to_backlog() 函数把数据包放到某个 CPU 对应的数据包队列里（softnet_data）。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">netif_rx_internal</span><span class="params">(struct sk_buff *skb)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> ret;</span><br><span class="line"> </span><br><span class="line">        net_timestamp_check(netdev_tstamp_prequeue, skb);</span><br><span class="line"> </span><br><span class="line">        trace_netif_rx(skb);</span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_RPS</span></span><br><span class="line">        <span class="keyword">if</span> (static_branch_unlikely(&amp;rps_needed)) &#123;</span><br><span class="line">                <span class="class"><span class="keyword">struct</span> <span class="title">rps_dev_flow</span> <span class="title">voidflow</span>, *<span class="title">rflow</span> = &amp;<span class="title">voidflow</span>;</span></span><br><span class="line">                <span class="keyword">int</span> cpu;</span><br><span class="line"> </span><br><span class="line">                preempt_disable();</span><br><span class="line">                rcu_read_lock();</span><br><span class="line"> </span><br><span class="line">                cpu = get_rps_cpu(skb-&gt;dev, skb, &amp;rflow);</span><br><span class="line">                <span class="keyword">if</span> (cpu &lt; <span class="number">0</span>)</span><br><span class="line">                        cpu = smp_processor_id();</span><br><span class="line"> </span><br><span class="line">                ret = enqueue_to_backlog(skb, cpu, &amp;rflow-&gt;last_qtail);</span><br><span class="line"> </span><br><span class="line">                rcu_read_unlock();</span><br><span class="line">                preempt_enable();</span><br><span class="line">        &#125; <span class="keyword">else</span></span><br><span class="line">#endif</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="keyword">unsigned</span> <span class="keyword">int</span> qtail;</span><br><span class="line"> </span><br><span class="line">                ret = enqueue_to_backlog(skb, get_cpu(), &amp;qtail);</span><br><span class="line">                put_cpu();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的代码，我们可以看到，在缺省的状况下（也就是没有 RPS 的情况下），enqueue_to_backlog() 把数据包放到了“当前运行的 CPU”（get_cpu()）对应的数据队列中。如果是从容器里通过 veth 对外发送数据包，那么这个“当前运行的 CPU”就是容器中发送数据的进程所在的 CPU。</p><p>对于多核的系统，这个发送数据的进程可以在多个 CPU 上切换运行。进程在不同的 CPU 上把数据放入队列并且 raise softirq 之后，因为每个 CPU 上处理 softirq 是个异步操作，所以两个 CPU network softirq handler 处理这个进程的数据包时，处理的先后顺序并不能保证。</p><p>所以，veth 对的这种发送数据方式增加了容器向外发送数据出现乱序的几率。</p><p><img src="/images/docker/docker-07/12.jpg" alt="12"></p><h3 id="RSS-和-RPS"><a href="#RSS-和-RPS" class="headerlink" title="RSS 和 RPS"></a>RSS 和 RPS</h3><p>那么对于 veth 接口的这种发包方式，有办法减少一下乱序的几率吗？</p><p>其实，我们在上面 netif_rx_internal() 那段代码中，有一段在”#ifdef CONFIG_RPS”中的代码。</p><p>我们看到这段代码中在调用 enqueue_to_backlog() 的时候，传入的 CPU 并不是当前运行的 CPU，而是通过 get_rps_cpu() 得到的 CPU，那么这会有什么不同呢？这里的 RPS 又是什么意思呢？</p><p>要解释 RPS 呢，需要先看一下 RSS，这个 RSS 不是我们之前说的内存 RSS，而是和网卡硬件相关的一个感念，它是 Receive Side Scaling 的缩写。</p><p>现在的网卡性能越来越强劲了，从原来一条 RX 队列扩展到了 N 条 RX 队列，而网卡的硬件中断也从一个硬件中断，变成了每条 RX 队列都会有一个硬件中断。</p><p>每个硬件中断可以由一个 CPU 来处理，那么对于多核的系统，多个 CPU 可以并行的接收网络包，这样就大大地提高了系统的网络数据的处理能力.</p><p>同时，在网卡硬件中，可以根据数据包的 4 元组或者 5 元组信息来保证同一个数据流，比如一个 TCP 流的数据始终在一个 RX 队列中，这样也能保证同一流不会出现乱序的情况。</p><p>下面这张图，大致描述了一下 RSS 是怎么工作的。</p><p><img src="/images/docker/docker-07/14.jpg" alt="14"></p><p>RSS 的实现在网卡硬件和驱动里面，而 RPS（Receive Packet Steering）其实就是在软件层面实现类似的功能。它主要实现的代码框架就在上面的 netif_rx_internal() 代码里，原理也不难。</p><p>就像下面的这张示意图里描述的这样：在硬件中断后，CPU2 收到了数据包，再一次对数据包计算一次四元组的 hash 值，得到这个数据包与 CPU1 的映射关系。接着会把这个数据包放到 CPU1 对应的 softnet_data 数据队列中，同时向 CPU1 发送一个 IPI 的中断信号。</p><p>这样一来，后面 CPU1 就会继续按照 Netowrk softirq 的方式来处理这个数据包了。</p><p><img src="/images/docker/docker-07/15.jpg" alt="15"></p><p>RSS 和 RPS 的目的都是把数据包分散到更多的 CPU 上进行处理，使得系统有更强的网络包处理能力。在把数据包分散到各个 CPU 时，保证了同一个数据流在一个 CPU 上，这样就可以减少包的乱序。</p><p>明白了 RPS 的概念之后，我们再回头来看 veth 对外发送数据时候，在 enqueue_to_backlog() 的时候选择 CPU 的问题。显然，如果对应的 veth 接口上打开了 RPS 的配置以后，那么对于同一个数据流，就可以始终选择同一个 CPU 了。</p><p>其实我们打开 RPS 的方法挺简单的，只要去 /sys 目录下，在网络接口设备接收队列中修改队列里的 rps_cpus 的值，这样就可以了。rps_cpus 是一个 16 进制的数，每个 bit 代表一个 CPU。</p><p>比如说，我们在一个12CPU的节点上，想让 host 上的 veth 接口在所有的 12个CPU上，都可以通过 RPS 重新分配数据包。那么就可以执行下面这段命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat /sys/devices/virtual/net/veth57703b6/queues/rx-0/rps_cpus</span></span><br><span class="line">000</span><br><span class="line"><span class="comment"># echo fff &gt; /sys/devices/virtual/net/veth57703b6/queues/rx-0/rps_cpus</span></span><br><span class="line"><span class="comment"># cat /sys/devices/virtual/net/veth57703b6/queues/rx-0/rps_cpus</span></span><br><span class="line">fff</span><br></pre></td></tr></table></figure><!--### 重点小结由于在容器平台中看到大部分的重传是快速重传（fast retransmits），我们先梳理了什么是快速重传。快速重传的基本定义是：如果发送端收到 3 个重复的 ACK，那么发送端就可以立刻重新发送 ACK 对应的下一个数据包，而不用等待发送超时。不过我们在 Linux 系统上还会看到发送端收到一个重复的 ACK 就快速重传的，这是因为 Linux 下对 SACK 做了一个特别的判断之后，就可以立刻重传数据包。我们再对容器云平台中的快速重传做分析，就会发现这些重传大部分是由包的乱序触发的。通过对容器 veth 网络接口进一步研究，我们知道它可能会增加数据包乱序的几率。同时在这个分析过程中，我们也看到了 Linux 网络 RPS 的特性。**RPS 和 RSS 的作用类似，都是把数据包分散到更多的 CPU 上进行处理，使得系统有更强的网络包处理能力。它们的区别是 RSS 工作在网卡的硬件层，而 RPS 工作在 Linux 内核的软件层。**在把数据包分散到各个 CPU 时，RPS 保证了同一个数据流是在一个 CPU 上的，这样就可以有效减少包的乱序。那么我们可以把 RPS 的这个特性配置到 veth 网络接口上，来减少数据包乱序的几率。不过，我这里还要说明的是，RPS 的配置还是会带来额外的系统开销，在某些网络环境中会引起 softirq CPU 使用率的增大。那接口要不要打开 RPS 呢？这个问题你需要根据实际情况来做个权衡。同时你还要注意，TCP 的乱序包，并不一定都会产生数据包的重传。想要减少网络数据包的重传，我们还可以考虑协议栈中其他参数的设置，比如 /proc/sys/net/ipv4/tcp_reordering。--><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《由浅入深吃透 Docker》</li><li>《容器实战高手课》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://www.docker-cn.com" target="_blank" rel="noopener">https://www.docker-cn.com</a></li><li><a href="https://docs.docker.com/compose/compose-file/compose-file-v3/" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/compose-file-v3/</a></li><li><a href="https://docs.docker.com/compose/reference/" target="_blank" rel="noopener">https://docs.docker.com/compose/reference/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;容器网络&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://blog.lichao.xin/categories/Docker/"/>
    
    
      <category term="docker" scheme="https://blog.lichao.xin/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>重学 Docker 之 容器进阶（三）</title>
    <link href="https://blog.lichao.xin/back-end/docker/docker-06/"/>
    <id>https://blog.lichao.xin/back-end/docker/docker-06/</id>
    <published>2021-04-17T15:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.383Z</updated>
    
    <content type="html"><![CDATA[<p>容器存储</p><a id="more"></a><h2 id="容器文件系统：我在容器中读写文件怎么变慢了？"><a href="#容器文件系统：我在容器中读写文件怎么变慢了？" class="headerlink" title="容器文件系统：我在容器中读写文件怎么变慢了？"></a>容器文件系统：我在容器中读写文件怎么变慢了？</h2><p>这个问题具体是我们在宿主机上，把 Linux 从 ubuntu18.04 升级到 ubuntu20.04 之后发现的。</p><p>在我们做了宿主机的升级后，启动了一个容器，在容器里用 fio 这个磁盘性能测试工具，想看一下容器里文件的读写性能。结果我们很惊讶地发现，在 ubuntu 20.04 宿主机上的容器中文件读写的性能只有 ubuntu18.04 宿主机上的 1/8 左右了，那这是怎么回事呢？</p><h3 id="问题再现"><a href="#问题再现" class="headerlink" title="问题再现"></a>问题再现</h3><p>这里我提醒一下你，因为涉及到两个 Linux 的虚拟机，问题再现这里我为你列出了关键的结果输出截图，不方便操作的同学可以重点看其中的思路。</p><p>我们可以先启动一个 ubuntu18.04 的虚拟机，它的 Linux 内核版本是 4.15 的，然后在虚拟机上用命令 docker run -it ubuntu:18.04 bash 启动一个容器，接着在容器里运行 fio 这条命令，看一下在容器中读取文件的性能。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># fio -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=4k -size=10G -numjobs=1  -name=./fio.test</span></span><br></pre></td></tr></table></figure><p>这里我给你解释一下 fio 命令中的几个主要参数：</p><p>第一个参数是”-direct=1”，代表采用非 buffered I/O 文件读写的方式，避免文件读写过程中内存缓冲对性能的影响。</p><p>接着我们来看这”-iodepth=64”和”-ioengine=libaio”这两个参数，这里指文件读写采用异步 I/O（Async I/O）的方式，也就是进程可以发起多个 I/O 请求，并且不用阻塞地等待 I/O 的完成。稍后等 I/O 完成之后，进程会收到通知。</p><p>这种异步 I/O 很重要，因为它可以极大地提高文件读写的性能。在这里我们设置了同时发出 64 个 I/O 请求。</p><p>然后是”-rw=read，-bs=4k，-size=10G”，这几个参数指这个测试是个读文件测试，每次读 4KB 大小数块，总共读 10GB 的数据。</p><p>最后一个参数是”-numjobs=1”，指只有一个进程 / 线程在运行。</p><p>所以，这条 fio 命令表示我们通过异步方式读取了 10GB 的磁盘文件，用来计算文件的读取性能。</p><p>那我们看到在 ubuntu 18.04，内核 4.15 上的容器 I/O 性能是 584MB/s 的带宽，IOPS（I/O per second）是 150K 左右。</p><p><img src="/images/docker/docker-06/1.jpg" alt="1"></p><p>同样我们再启动一个 ubuntu 20.04，内核 5.4 的虚拟机，然后在它的上面也启动一个容器。</p><p>我们运行 docker run -it ubuntu:20.04 bash ，接着在容器中使用同样的 fio 命令，可以看到它的 I/O 性能是 70MB 带宽，IOPS 是 18K 左右。实践证明，这的确比老版本的 ubuntu 18.04 差了很多。</p><p><img src="/images/docker/docker-06/2.jpg" alt="2"></p><h3 id="知识详解"><a href="#知识详解" class="headerlink" title="知识详解"></a>知识详解</h3><h3 id="如何理解容器文件系统？"><a href="#如何理解容器文件系统？" class="headerlink" title="如何理解容器文件系统？"></a>如何理解容器文件系统？</h3><p>刚才我们对比了升级前后的容器读写性能差异，那想要分析刚刚说的这个性能的差异，我们需要先理解容器的文件系统。</p><p>我们在容器里，运行  df 命令，你可以看到在容器中根目录 (/) 的文件系统类型是”overlay”，它不是我们在普通 Linux 节点上看到的 Ext4 或者 XFS 之类常见的文件系统。</p><p>那么看到这里你肯定想问，Overlay 是一个什么样的文件系统呢，容器为什么要用这种文件系统？别急，我会一步一步带你分析。</p><p><img src="/images/docker/docker-06/3.jpg" alt="3"></p><p>在说容器文件系统前，我们先来想象一下如果没有文件系统管理的话会怎样。假设有这么一个场景，在一个宿主机上需要运行 100 个容器。</p><p>在前面，我们就说过每个容器都需要一个镜像，这个镜像就把容器中程序需要运行的二进制文件，库文件，配置文件，其他的依赖文件等全部都打包成一个镜像文件。</p><p>如果没有特别的容器文件系统，只是普通的 Ext4 或者 XFS 文件系统，那么每次启动一个容器，就需要把一个镜像文件下载并且存储在宿主机上。</p><p>我举个例子帮你理解，比如说，假设一个镜像文件的大小是 500MB，那么 100 个容器的话，就需要下载 500MB*100= 50GB 的文件，并且占用 50GB 的磁盘空间。</p><p>如果你再分析一下这 50GB 里的内容，你会发现，在绝大部分的操作系统里，库文件都是差不多的。而且，在容器运行的时候，这类文件也不会被改动，基本上都是只读的。</p><p>特别是这样的情况：假如这 100 个容器镜像都是基于”ubuntu:18.04”的，每个容器镜像只是额外复制了 50MB 左右自己的应用程序到”ubuntu: 18.04”里，那么就是说在总共 50GB 的数据里，有 90% 的数据是冗余的。</p><p>讲到这里，你不难推测出理想的情况应该是什么样的？</p><p>没错，当然是在一个宿主机上只要下载并且存储存一份”ubuntu:18.04”，所有基于”ubuntu:18.04”镜像的容器都可以共享这一份通用的部分。这样设置的话，不同容器启动的时候，只需要下载自己独特的程序部分就可以。就像下面这张图展示的这样。</p><p><img src="/images/docker/docker-06/4.jpg" alt="4"></p><p><strong>正是为了有效地减少磁盘上冗余的镜像数据，同时减少冗余的镜像数据在网络上的传输，选择一种针对于容器的文件系统是很有必要的，而这类的文件系统被称为 UnionFS。</strong></p><p>UnionFS 这类文件系统实现的主要功能是把多个目录（处于不同的分区）一起挂载（mount）在一个目录下。这种多目录挂载的方式，正好可以解决我们刚才说的容器镜像的问题。</p><p>比如，我们可以把 ubuntu18.04 这个基础镜像的文件放在一个目录 ubuntu18.04/ 下，容器自己额外的程序文件 app_1_bin 放在 app_1/ 目录下。</p><p>然后，我们把这两个目录挂载到 container_1/ 这个目录下，作为容器 1 看到的文件系统；对于容器 2，就可以把 ubuntu18.04/ 和 app_2/ 两个目录一起挂载到 container_2 的目录下。</p><p>这样在节点上我们只要保留一份 ubuntu18.04 的文件就可以了。</p><p>![5][50]</p><h3 id="OverlayFS"><a href="#OverlayFS" class="headerlink" title="OverlayFS"></a>OverlayFS</h3><p>UnionFS 类似的有很多种实现，包括在 Docker 里最早使用的 AUFS，还有目前我们使用的 OverlayFS。前面我们在运行df的时候，看到的文件系统类型”overlay”指的就是 OverlayFS。</p><p>在 Linux 内核 3.18 版本中，OverlayFS 代码正式合入 Linux 内核的主分支。在这之后，OverlayFS 也就逐渐成为各个主流 Linux 发行版本里缺省使用的容器文件系统了。</p><p>网上 Julia Evans 有个blog，里面有个的 OverlayFS 使用的例子，很简单，我们也拿这个例子来理解一下 OverlayFS 的一些基本概念。</p><p>你可以先执行一下这一组命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">umount ./merged</span><br><span class="line">rm upper lower merged work -r</span><br><span class="line">mkdir upper lower merged work</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"I'm from lower!"</span> &gt; lower/in_lower.txt</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"I'm from upper!"</span> &gt; upper/in_upper.txt</span><br><span class="line"><span class="comment"># `in_both` is in both directories</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"I'm from lower!"</span> &gt; lower/in_both.txt</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"I'm from upper!"</span> &gt; upper/in_both.txt</span><br><span class="line">sudo mount -t overlay overlay \</span><br><span class="line"> -o lowerdir=./lower,upperdir=./upper,workdir=./work \</span><br><span class="line"> ./merged</span><br></pre></td></tr></table></figure><p>我们可以看到，OverlayFS 的一个 mount 命令牵涉到四类目录，分别是 lower，upper，merged 和 work，那它们是什么关系呢？</p><p>我们看下面这张图，这和前面 UnionFS 的工作示意图很像，也不奇怪，OverlayFS 就是 UnionFS 的一种实现。接下来，我们从下往上依次看看每一层的功能。</p><p>首先，最下面的”lower/“，也就是被 mount 两层目录中底下的这层（lowerdir）。</p><p>在 OverlayFS 中，最底下这一层里的文件是不会被修改的，你可以认为它是只读的。我还想提醒你一点，在这个例子里我们只有一个 lower/ 目录，不过 OverlayFS 是支持多个 lowerdir 的。</p><p>然后我们看”uppder/“，它是被 mount 两层目录中上面的这层 （upperdir）。在 OverlayFS 中，如果有文件的创建，修改，删除操作，那么都会在这一层反映出来，它是可读写的。</p><p>接着是最上面的”merged”  ，它是挂载点（mount point）目录，也是用户看到的目录，用户的实际文件操作在这里进行。</p><p>其实还有一个”work/“，这个目录没有在这个图里，它只是一个存放临时文件的目录，OverlayFS 中如果有文件修改，就会在中间过程中临时存放文件到这里。</p><p><img src="/images/docker/docker-06/6.jpg" alt="6"></p><p>从这个例子我们可以看到，OverlayFS 会 mount 两层目录，分别是 lower 层和 upper 层，这两层目录中的文件都会映射到挂载点上。</p><p>从挂载点的视角看，upper 层的文件会覆盖 lower 层的文件，比如”in_both.txt”这个文件，在 lower 层和 upper 层都有，但是挂载点 merged/ 里看到的只是 upper 层里的 in_both.txt.</p><p>如果我们在 merged/ 目录里做文件操作，具体包括这三种。</p><p>第一种，新建文件，这个文件会出现在 upper/ 目录中。</p><p>第二种是删除文件，如果我们删除”in_upper.txt”，那么这个文件会在 upper/ 目录中消失。如果删除”in_lower.txt”, 在 lower/ 目录里的”in_lower.txt”文件不会有变化，只是在 upper/ 目录中增加了一个特殊文件来告诉 OverlayFS，”in_lower.txt’这个文件不能出现在 merged/ 里了，这就表示它已经被删除了。</p><p><img src="/images/docker/docker-06/7.jpg" alt="7"></p><p>还有一种操作是修改文件，类似如果修改”in_lower.txt”，那么就会在 upper/ 目录中新建一个”in_lower.txt”文件，包含更新的内容，而在 lower/ 中的原来的实际文件”in_lower.txt”不会改变。</p><p>通过这个例子，我们知道了 OverlayFS 是怎么工作了。那么我们可以再想一想，怎么把它运用到容器的镜像文件上？</p><p>其实也不难，从系统的 mounts 信息中，我们可以看到 Docker 是怎么用 OverlayFS 来挂载镜像文件的。容器镜像文件可以分成多个层（layer），每层可以对应 OverlayFS 里 lowerdir 的一个目录，lowerdir 支持多个目录，也就可以支持多层的镜像文件。</p><p>在容器启动后，对镜像文件中修改就会被保存在 upperdir 里了。</p><p><img src="/images/docker/docker-06/8.jpg" alt="8"></p><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>在理解了容器使用的 OverlayFS 文件系统后，我们再回到开始的问题，为什么在宿主机升级之后，在容器里读写文件的性能降低了？现在我们至少应该知道，在容器中读写文件性能降低了，那么应该是 OverlayFS 的性能在新的 ubuntu20.04 中降低了。</p><p>要找到问题的根因，我们还需要进一步的 debug。对于性能问题，我们需要使用 Linux 下的 perf 工具来查看一下，具体怎么使用 perf 来解决问题，我们会在后面讲解。</p><p>这里你只要看一下结果就可以了，自下而上是函数的一个调用顺序。通过 perf 工具，我们可以比较在容器中运行 fio 的时候，ubuntu 18.04 和 ubuntu 20.04 在内核函数调用上的不同。</p><p><img src="/images/docker/docker-06/9.jpg" alt="ubuntu 18.04 (Linux内核4.15)环境下使用perf输出的函数调用结果"></p><p><img src="/images/docker/docker-06/10.jpg" alt="ubuntu 20.04 (Linux内核 5.4)环境下使用perf输出的函数调用结果"></p><p>我们从系统调用框架之后的函数 aio_read() 开始比较：Linux 内核 4.15 里 aio_read() 之后调用的是 xfs_file_read_iter()，而在 Linux 内核 5.4 里，aio_read() 之后调用的是 ovl_read_iter() 这个函数，之后再调用 xfs_file_read_iter()。</p><p>这样我们就可以去查看一下，在内核 4.15 之后新加入的这个函数 ovl_read_iter() 的代码。</p><p>查看代码后我们就能明白，Linux 为了完善 OverlayFS，增加了 OverlayFS 自己的 read/write 函数接口，从而不再直接调用 OverlayFS 后端文件系统（比如 XFS，Ext4）的读写接口。但是它只实现了同步 I/O（sync I/O），并没有实现异步 I/O。</p><p>而在 fio 做文件系统性能测试的时候使用的是异步 I/O，这样才可以得到文件系统的性能最大值。所以，在内核 5.4 上就无法对 OverlayFS 测出最高的性能指标了。</p><p>在 Linux 内核 5.6 版本中，这个问题已经通过下面的这个补丁给解决了，有兴趣的同学可以看一下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">commit 2406a307ac7ddfd7effeeaff6947149ec6a95b4e</span><br><span class="line">Author: Jiufei Xue &lt;jiufei.xue@linux.alibaba.com&gt;</span><br><span class="line">Date:   Wed Nov 20 17:45:26 2019 +0800</span><br><span class="line"> </span><br><span class="line">    ovl: implement async IO routines</span><br><span class="line"> </span><br><span class="line">    A performance regression was observed since linux v4.19 with aio <span class="built_in">test</span> using</span><br><span class="line">    fio with iodepth 128 on overlayfs.  The queue depth of the device was</span><br><span class="line">    always 1 <span class="built_in">which</span> is unexpected.</span><br><span class="line"> </span><br><span class="line">    After investigation, it was found that commit 16914e6fc7e1 (<span class="string">"ovl: add</span></span><br><span class="line"><span class="string">    ovl_read_iter()"</span>) and commit 2a92e07edc5e (<span class="string">"ovl: add ovl_write_iter()"</span>)</span><br><span class="line">    resulted <span class="keyword">in</span> vfs_iter_&#123;<span class="built_in">read</span>,write&#125; being called on underlying filesystem,</span><br><span class="line">    <span class="built_in">which</span> always results <span class="keyword">in</span> syncronous IO.</span><br><span class="line"> </span><br><span class="line">    Implement async IO <span class="keyword">for</span> stacked reading and writing.  This resolves the</span><br><span class="line">    performance regresion.</span><br><span class="line"> </span><br><span class="line">    This is implemented by allocating a new kiocb <span class="keyword">for</span> submitting the AIO</span><br><span class="line">    request on the underlying filesystem.  When the request is completed, the</span><br><span class="line">    new kiocb is freed and the completion callback is called on the original</span><br><span class="line">    iocb.</span><br><span class="line"> </span><br><span class="line">    Signed-off-by: Jiufei Xue &lt;jiufei.xue@linux.alibaba.com&gt;</span><br><span class="line">    Signed-off-by: Miklos Szeredi &lt;mszeredi@redhat.com&gt;</span><br></pre></td></tr></table></figure><!--### 重点总结这一讲，我们最主要的内容是理解容器文件系统。为什么要有容器自己的文件系统？很重要的一点是**减少相同镜像文件在同一个节点上的数据冗余，可以节省磁盘空间，也可以减少镜像文件下载占用的网络资源。**作为容器文件系统，UnionFS 通过多个目录挂载的方式工作。OverlayFS 就是 UnionFS 的一种实现，是目前主流 Linux 发行版本中缺省使用的容器文件系统。OverlayFS 也是把多个目录合并挂载，被挂载的目录分为两大类：lowerdir 和 upperdir。lowerdir 允许有多个目录，在被挂载后，这些目录里的文件都是不会被修改或者删除的，也就是只读的；upperdir 只有一个，不过这个目录是可读写的，挂载点目录中的所有文件修改都会在 upperdir 中反映出来。容器的镜像文件中各层正好作为 OverlayFS 的 lowerdir 的目录，然后加上一个空的 upperdir 一起挂载好后，就组成了容器的文件系统。OverlayFS 在 Linux 内核中还在不断的完善，比如我们在这一讲看到的在 kenel 5.4 中对异步 I/O 操作的缺失，这也是我们在使用容器文件系统的时候需要注意的。--><h2 id="容器文件Quota：容器为什么把宿主机的磁盘写满了？"><a href="#容器文件Quota：容器为什么把宿主机的磁盘写满了？" class="headerlink" title="容器文件Quota：容器为什么把宿主机的磁盘写满了？"></a>容器文件Quota：容器为什么把宿主机的磁盘写满了？</h2><p>我们学习了容器文件系统 OverlayFS，这个 OverlayFS 有两层，分别是 lowerdir 和 upperdir。lowerdir 里是容器镜像中的文件，对于容器来说是只读的；upperdir 存放的是容器对文件系统里的所有改动，它是可读写的。</p><p>从宿主机的角度看，upperdir 就是一个目录，如果容器不断往容器文件系统中写入数据，实际上就是往宿主机的磁盘上写数据，这些数据也就存在于宿主机的磁盘目录中。</p><p>当然对于容器来说，如果有大量的写操作是不建议写入容器文件系统的，一般是需要给容器挂载一个 volume，用来满足大量的文件读写。</p><p>但是不能避免的是，用户在容器中运行的程序有错误，或者进行了错误的配置。</p><p>比如说，我们把 log 写在了容器文件系统上，并且没有做 log rotation，那么时间一久，就会导致宿主机上的磁盘被写满。这样影响的就不止是容器本身了，而是整个宿主机了。</p><p>那对于这样的问题，我们该怎么解决呢？</p><h3 id="问题再现-1"><a href="#问题再现-1" class="headerlink" title="问题再现"></a>问题再现</h3><p>我们可以自己先启动一个容器，一起试试不断地往容器文件系统中写入数据，看看是一个什么样的情况。</p><p>用 Docker 启动一个容器后，我们看到容器的根目录 (/) 也就是容器文件系统 OverlayFS，它的大小是 160G，已经使用了 100G。其实这个大小也是宿主机上的磁盘空间和使用情况。</p><p><img src="/images/docker/docker-06/11.jpg" alt="11"></p><p>这时候，我们可以回到宿主机上验证一下，就会发现宿主机的根目录 (/) 的大小也是 160G，同样是使用了 100G。</p><p><img src="/images/docker/docker-06/12.jpg" alt="12"></p><p>好，那现在我们再往容器的根目录里写入 10GB 的数据。</p><p>这里我们可以看到容器的根目录使用的大小增加了，从刚才的 100G 变成现在的 110G。而多写入的 10G 大小的数据，对应的是 test.log 这个文件。</p><p><img src="/images/docker/docker-06/13.jpg" alt="13"></p><p>接下来，我们再回到宿主机上，可以看到宿主机上的根目录 (/) 里使用的大小也是 110G 了。</p><p><img src="/images/docker/docker-06/14.jpg" alt="14"></p><p>我们还是继续看宿主机，看看 OverlayFS 里 upperdir 目录中有什么文件？</p><p>这里我们仍然可以通过 /proc/mounts 这个路径，找到容器 OverlayFS 对应的 lowerdir 和 upperdir。因为写入的数据都在 upperdir 里，我们就只要看 upperdir 对应的那个目录就行了。果然，里面存放着容器写入的文件 test.log，它的大小是 10GB。</p><p><img src="/images/docker/docker-06/15.jpg" alt="15"></p><p>通过这个例子，我们已经验证了在容器中对于 OverlayFS 中写入数据，<strong>其实就是往宿主机的一个目录（upperdir）里写数据。</strong>我们现在已经写了 10GB 的数据，如果继续在容器中写入数据，结果估计你也知道了，就是会写满宿主机的磁盘。</p><p>那遇到这种情况，我们该怎么办呢？</p><h3 id="知识详解-1"><a href="#知识详解-1" class="headerlink" title="知识详解"></a>知识详解</h3><p>容器写自己的 OverlayFS 根目录，结果把宿主机的磁盘写满了。发生这个问题，我们首先就会想到需要对容器做限制，限制它写入自己 OverlayFS 的数据量，比如只允许一个容器写 100MB 的数据。</p><p>不过我们实际查看 OverlayFS 文件系统的特性，就会发现没有直接限制文件写入量的特性。别担心，在没有现成工具的情况下，我们只要搞懂了原理，就能想出解决办法。</p><p>所以我们再来分析一下 OverlayFS，它是通过 lowerdir 和 upperdir 两层目录联合挂载来实现的，lowerdir 是只读的，数据只会写在 upperdir 中。</p><p>那我们是不是可以通过限制 upperdir 目录容量的方式，来限制一个容器 OverlayFS 根目录的写入数据量呢？</p><p>沿着这个思路继续往下想，因为 upperdir 在宿主机上也是一个普通的目录，这样就要看<strong>宿主机上的文件系统是否可以支持对一个目录限制容量了。</strong></p><p>对于 Linux 上最常用的两个文件系统 XFS 和 ext4，它们有一个特性 Quota，那我们就以 XFS 文件系统为例，学习一下这个 Quota 概念，然后看看这个特性能不能限制一个目录的使用量。</p><h3 id="XFS-Quota"><a href="#XFS-Quota" class="headerlink" title="XFS Quota"></a>XFS Quota</h3><p>在 Linux 系统里的 XFS 文件系统缺省都有 Quota 的特性，这个特性可以为 Linux 系统里的一个用户（user），一个用户组（group）或者一个项目（project）来限制它们使用文件系统的额度（quota），也就是限制它们可以写入文件系统的文件总量。</p><p>因为我们的目标是要限制一个目录中总体的写入文件数据量，那么显然给用户和用户组限制文件系统的写入数据量的模式，并不适合我们的这个需求。</p><p>因为同一个用户或者用户组可以操作多个目录，多个用户或者用户组也可以操作同一个目录，这样对一个用户或者用户组的限制，就很难用来限制一个目录。</p><p>那排除了限制用户或用户组的模式，我们再来看看 Project 模式。Project 模式是怎么工作的呢？</p><p>我举一个例子你会更好理解，对 Linux 熟悉的同学可以一边操作，一边体会一下它的工作方式。不熟悉的同学也没关系，可以重点关注我后面的讲解思路。</p><p>首先我们要使用 XFS Quota 特性，必须在文件系统挂载的时候加上对应的 Quota 选项，比如我们目前需要配置 Project Quota，那么这个挂载参数就是”pquota”。</p><p>对于根目录来说，<strong>这个参数必须作为一个内核启动的参数”rootflags=pquota”，这样设置就可以保证根目录在启动挂载的时候，带上 XFS Quota 的特性并且支持 Project 模式。</strong></p><p>我们可以从 /proc/mounts 信息里，看看根目录是不是带”prjquota”字段。如果里面有这个字段，就可以确保文件系统已经带上了支持 project 模式的 XFS quota 特性。</p><p><img src="/images/docker/docker-06/16.jpg" alt="16"></p><p>下一步，我们还需要给一个指定的目录打上一个 Project ID。这个步骤我们可以使用 XFS 文件系统自带的工具 xfs_quota 来完成，然后执行下面的这个命令就可以了。</p><p>执行命令之前，我先对下面的命令和输出做两点解释，让你理解这个命令的含义。</p><p>第一点，新建的目录 /tmp/xfs_prjquota，我们想对它做 Quota 限制。所以在这里要对它打上一个 Project ID。</p><p>第二点，通过 xfs_quota 这条命令，我们给 /tmp/xfs_prjquota 打上 Project ID 值 101，这个 101 是我随便选的一个数字，就是个 ID 标识，你先有个印象。在后面针对 Project 进行 Quota 限制的时候，我们还会用到这个 ID。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir -p  /tmp/xfs_prjquota</span></span><br><span class="line"><span class="comment"># xfs_quota -x -c 'project -s -p /tmp/xfs_prjquota 101' /</span></span><br><span class="line">Setting up project 101 (path /tmp/xfs_prjquota)...</span><br><span class="line">Processed 1 (/etc/projects and cmdline) paths <span class="keyword">for</span> project 101 with recursion depth infinite (-1).</span><br></pre></td></tr></table></figure><p>最后，我们还是使用 xfs_quota 命令，对 101（我们刚才建立的这个 Project ID）做 Quota 限制。</p><p>你可以执行下面这条命令，里面的”-p bhard=10m 101”就代表限制 101 这个 project ID，限制它的数据块写入量不能超过 10MB。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xfs_quota -x -c 'limit -p bhard=10m 101' /</span></span><br></pre></td></tr></table></figure><p>做好限制之后，我们可以尝试往 /tmp/xfs_prjquota 写数据，看看是否可以超过 10MB。比如说，我们尝试写入 20MB 的数据到 /tmp/xfs_prjquota 里。</p><p>我们可以看到，执行 dd 写入命令，就会有个出错返回信息”No space left on device”。这表示已经不能再往这个目录下写入数据了，而最后写入数据的文件 test.file 大小也停留在了 10MB。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># dd if=/dev/zero of=/tmp/xfs_prjquota/test.file bs=1024 count=20000</span></span><br><span class="line">dd: error writing <span class="string">'/tmp/xfs_prjquota/test.file'</span>: No space left on device</span><br><span class="line">10241+0 records <span class="keyword">in</span></span><br><span class="line">10240+0 records out</span><br><span class="line">10485760 bytes (10 MB, 10 MiB) copied, 0.0357122 s, 294 MB/s</span><br><span class="line"><span class="comment"># ls -l /tmp/xfs_prjquota/test.file</span></span><br><span class="line">-rw-r--r-- 1 root root 10485760 Oct 31 10:00 /tmp/xfs_prjquota/test.file</span><br></pre></td></tr></table></figure><p>好了，做到这里，我们发现使用 XFS Quota 的 Project 模式，确实可以限制一个目录里的写入数据量，它实现的方式其实也不难，就是下面这两步。</p><p>第一步，给目标目录打上一个 Project ID，这个 ID 最终是写到目录对应的 inode 上。</p><p>这里我解释一下，inode 是文件系统中用来描述一个文件或者一个目录的元数据，里面包含文件大小，数据块的位置，文件所属用户 / 组，文件读写属性以及其他一些属性。</p><p>那么一旦目录打上这个 ID 之后，在这个目录下的新建的文件和目录也都会继承这个 ID。</p><p>第二步，在 XFS 文件系统中，我们需要给这个 project ID 设置一个写入数据块的限制。</p><p>有了 ID 和限制值之后，文件系统就可以统计所有带这个 ID 文件的数据块大小总和，并且与限制值进行比较。一旦所有文件大小的总和达到限制值，文件系统就不再允许更多的数据写入了。</p><p>用一句话概括，XFS Quota 就是通过前面这两步限制了一个目录里写入的数据量。</p><h3 id="解决问题-1"><a href="#解决问题-1" class="headerlink" title="解决问题"></a>解决问题</h3><p>我们理解了 XFS Quota 对目录限流的机制之后，再回到我们最开始的问题，如何确保容器不会写满宿主机上的磁盘。</p><p>你应该已经想到了，方法就是<strong>对 OverlayFS 的 upperdir 目录做 XFS Quota 的限流</strong>，没错，就是这个解决办法！</p><p>其实 Docker 也已经实现了限流功能，也就是用 XFS Quota 来限制容器的 OverlayFS 大小。</p><p>我们在用 docker run 启动容器的时候，加上一个参数 –storage-opt size= <SIZE> ，就能限制住容器 OverlayFS 文件系统可写入的最大数据量了。</p><p>我们可以一起试一下，这里我们限制的 size 是 10MB。</p><p>进入容器之后，先运行 df -h 命令，这时候你可以看到根目录 (/)overlayfs 文件系统的大小就 10MB，而不是我们之前看到的 160GB 的大小了。这样容器在它的根目录下，最多只能写 10MB 数据，就不会把宿主机的磁盘给写满了。</p><p><img src="/images/docker/docker-06/17.jpg" alt="17"></p><p>完成了上面这个小试验之后，我们可以再看一下 Docker 的代码，看看它的实现是不是和我们想的一样。</p><p>Docker 里SetQuota()函数就是用来实现 XFS Quota 限制的，我们可以看到它里面最重要的两步，分别是 setProjectID 和 setProjectQuota 。</p><p>其实，这两步做的就是我们在基本概念中提到的那两步：</p><p>第一步，给目标目录打上一个 Project ID；第二步，为这个 Project ID 在 XFS 文件系统中，设置一个写入数据块的限制。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// SetQuota - assign a unique project id to directory and set the quota limits</span></span><br><span class="line"><span class="comment">// for that project id</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(q *Control)</span> <span class="title">SetQuota</span><span class="params">(targetPath <span class="keyword">string</span>, quota Quota)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">        q.RLock()</span><br><span class="line">        projectID, ok := q.quotas[targetPath]</span><br><span class="line">        q.RUnlock()</span><br><span class="line">        <span class="keyword">if</span> !ok &#123;</span><br><span class="line">                q.Lock()</span><br><span class="line">                projectID = q.nextProjectID</span><br><span class="line">                <span class="comment">//</span></span><br><span class="line">                <span class="comment">// assign project id to new container directory</span></span><br><span class="line">                <span class="comment">//</span></span><br><span class="line">                err := setProjectID(targetPath, projectID)</span><br><span class="line">                <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                        q.Unlock()</span><br><span class="line">                        <span class="keyword">return</span> err</span><br><span class="line">                &#125;</span><br><span class="line">                q.quotas[targetPath] = projectID</span><br><span class="line">                q.nextProjectID++</span><br><span class="line">                q.Unlock()</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// set the quota limit for the container's project id</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        logrus.Debugf(<span class="string">"SetQuota(%s, %d): projectID=%d"</span>, targetPath, quota.Size, projectID)</span><br><span class="line">        <span class="keyword">return</span> setProjectQuota(q.backingFsBlockDev, projectID, quota)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那 setProjectID 和  setProjectQuota 是如何实现的呢？</p><p>你可以进入到这两个函数里看一下，<strong>它们分别调用了 ioctl() 和 quotactl() 这两个系统调用来修改内核中 XFS 的数据结构，从而完成 project ID 的设置和 Quota 值的设置。</strong>具体的细节，我不在这里展开了，如果你有兴趣，可以继续去查看内核中对应的代码。</p><p>好了，Docker 里 XFS Quota 操作的步骤完全和我们先前设想的一样，那么还有最后一个问题要解决，XFS Quota 限制的目录是哪一个？</p><p>这个我们可以根据 /proc/mounts 中容器的 OverlayFS Mount 信息，再结合 Docker 的代码，就可以知道限制的目录是”/var/lib/docker/overlay2/<docker_id>“。那这个目录下有什么呢？果然 upperdir 目录中有对应的”diff”目录，就在里面！</p><p><img src="/images/docker/docker-06/18.jpg" alt="18"></p><p>讲到这里，我想你已经清楚了对于使用 OverlayFS 的容器，我们应该如何去防止它把宿主机的磁盘给写满了吧？<strong>方法就是对 OverlayFS 的 upperdir 目录做 XFS Quota 的限流。</strong></p><!--### 重点总结我们这一讲的问题是，容器写了大量数据到 OverlayFS 文件系统的根目录，在这个情况下，就会把宿主机的磁盘写满。由于 OverlayFS 自己没有专门的特性，可以限制文件数据写入量。这时我们通过实际试验找到了解决思路：依靠底层文件系统的 Quota 特性来限制 OverlayFS 的 upperdir 目录的大小，这样就能实现限制容器写磁盘的目的。底层文件系统 XFS Quota 的 Project 模式，能够限制一个目录的文件写入量，这个功能具体是通过这两个步骤实现：第一步，给目标目录打上一个 Project ID。第二步，给这个 Project ID 在 XFS 文件系统中设置一个写入数据块的限制。Docker 正是使用了这个方法，也就是**用 XFS Quota 来限制 OverlayFS 的 upperdir 目录**，通过这个方式控制容器 OverlayFS 的根目录大小。当我们理解了这个方法后，对于不是用 Docker 启动的容器，比如直接由 containerd 启动起来的容器，也可以自己实现 XFS Quota 限制 upperdir 目录。这样就能有效控制容器对 OverlayFS 的写数据操作，避免宿主机的磁盘被写满。--><h2 id="容器磁盘限速：我的容器里磁盘读写为什么不稳定"><a href="#容器磁盘限速：我的容器里磁盘读写为什么不稳定" class="headerlink" title="容器磁盘限速：我的容器里磁盘读写为什么不稳定?"></a>容器磁盘限速：我的容器里磁盘读写为什么不稳定?</h2><p>前面，我们讲了如何通过 XFS Quota 来限制容器文件系统的大小，这是静态容量大小的一个限制。</p><p>你也许会马上想到，磁盘除了容量的划分，还有一个读写性能的问题。</p><p>具体来说，就是如果多个容器同时读写节点上的同一块磁盘，那么它们的磁盘读写相互之间影响吗？如果容器之间读写磁盘相互影响，我们有什么办法解决呢？</p><h3 id="场景再现"><a href="#场景再现" class="headerlink" title="场景再现"></a>场景再现</h3><p>我们先用这里的代码，运行一下 make image 来做一个带 fio 的容器镜像，fio 在我们之前提到过，它是用来测试磁盘文件系统读写性能的工具。</p><p>有了这个带 fio 的镜像，我们可以用它启动一个容器，在容器中运行 fio，就可以得到只有一个容器读写磁盘时的性能数据。</p><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: image</span></span><br><span class="line"></span><br><span class="line"><span class="section">image:</span></span><br><span class="line">docker build -t registry/fio:v1 .</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">docker rmi registry/fio:v1</span><br></pre></td></tr></table></figure><p>Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y fio</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /tmp/test1</span><br><span class="line">docker stop fio_test1;docker rm fio_test1</span><br><span class="line">docker run --name fio_test1 --volume /tmp/test1:/tmp  registery/fio:v1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1  -name=/tmp/fio_test1.log</span><br></pre></td></tr></table></figure><p>上面的这个 Docker 命令，我给你简单地解释一下：在这里我们第一次用到了”–volume”这个参数。之前我们讲过容器文件系统，比如 OverlayFS。</p><p>不过容器文件系统并不适合频繁地读写。对于频繁读写的数据，容器需要把他们到放到”volume”中。这里的 volume 可以是一个本地的磁盘，也可以是一个网络磁盘。</p><p>在这个例子里我们就使用了宿主机本地磁盘，把磁盘上的 /tmp/test1 目录作为 volume 挂载到容器的 /tmp 目录下。</p><p>然后在启动容器之后，我们直接运行 fio 的命令，这里的参数和我们前面的例子差不多，只是这次我们运行的是 write，也就是写磁盘的操作，而写的目标盘就是挂载到 /tmp 目录的 volume。</p><p>可以看到，fio 的运行结果如下图所示，IOPS 是 18K，带宽 (BW) 是 70MB/s 左右。</p><p><img src="/images/docker/docker-06/19.jpg" alt="19"></p><p>好了，刚才我们模拟了一个容器写磁盘的性能。那么如果这时候有两个容器，都在往同一个磁盘上写数据又是什么情况呢？我们可以再用下面的这个脚本试一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /tmp/test1</span><br><span class="line">mkdir -p /tmp/test2</span><br><span class="line">docker stop fio_test1;docker rm fio_test1</span><br><span class="line">docker stop fio_test2;docker rm fio_test2</span><br><span class="line">docker run --name fio_test1 --volume /tmp/test1:/tmp  registery/fio:v1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1  -name=/tmp/fio_test1.log &amp;</span><br><span class="line">docker run --name fio_test2 --volume /tmp/test2:/tmp  registery/fio:v1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1  -name=/tmp/fio_test2.log &amp;</span><br></pre></td></tr></table></figure><p>这时候，我们看到的结果，在容器 fio_test1 里，IOPS 是 15K 左右，带宽是 59MB/s 了，比之前单独运行的时候性能下降了不少。</p><p><img src="/images/docker/docker-06/20.jpg" alt="20"></p><p>显然从这个例子中，我们可以看到多个容器同时写一块磁盘的时候，它的性能受到了干扰。那么有什么办法可以保证每个容器的磁盘读写性能呢？</p><p>之前，我们讨论过用 Cgroups 来保证容器的 CPU 使用率，以及控制 Memroy 的可用大小。那么你肯定想到了，我们是不是也可以用 Cgroups 来保证每个容器的磁盘读写性能？</p><p>没错，在 Cgroup v1 中有 blkio 子系统，它可以来限制磁盘的 I/O。不过 blkio 子系统对于磁盘 I/O 的限制，并不像 CPU，Memory 那么直接，下面我会详细讲解。</p><h3 id="知识详解-2"><a href="#知识详解-2" class="headerlink" title="知识详解"></a>知识详解</h3><h3 id="Blkio-Cgroup"><a href="#Blkio-Cgroup" class="headerlink" title="Blkio Cgroup"></a>Blkio Cgroup</h3><p>在讲解 blkio Cgroup 前，我们先简单了解一下衡量磁盘性能的<strong>两个常见的指标 IOPS 和吞吐量（Throughput）</strong>是什么意思，后面讲 Blkio Cgroup 的参数配置时会用到。</p><p>IOPS 是 Input/Output Operations Per Second 的简称，也就是每秒钟磁盘读写的次数，这个数值越大，当然也就表示性能越好。</p><p>吞吐量（Throughput）是指每秒钟磁盘中数据的读取量，一般以 MB/s 为单位。这个读取量可以叫作吞吐量，有时候也被称为带宽（Bandwidth）。刚才我们用到的 fio 显示结果就体现了带宽。</p><p>IOPS 和吞吐量之间是有关联的，在 IOPS 固定的情况下，如果读写的每一个数据块越大，那么吞吐量也越大，它们的关系大概是这样的：吞吐量 = 数据块大小 *IOPS。</p><p>好，那么我们再回到 blkio Cgroup 这个概念上，blkio Cgroup 也是 Cgroups 里的一个子系统。 在 Cgroups v1 里，blkio Cgroup 的虚拟文件系统挂载点一般在”/sys/fs/cgroup/blkio/“。</p><p>和我之前讲过的 CPU，memory Cgroup 一样，我们在这个”/sys/fs/cgroup/blkio/“目录下创建子目录作为控制组，再把需要做 I/O 限制的进程 pid 写到控制组的 cgroup.procs 参数中就可以了。</p><p>在 blkio Cgroup 中，有四个最主要的参数，它们可以用来限制磁盘 I/O 性能，我列在了下面。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">blkio.throttle.read_iops_device</span><br><span class="line">blkio.throttle.read_bps_device</span><br><span class="line">blkio.throttle.write_iops_device</span><br><span class="line">blkio.throttle.write_bps_device</span><br></pre></td></tr></table></figure><p>前面我们刚说了磁盘 I/O 的两个主要性能指标 IOPS 和吞吐量，在这里，根据这四个参数的名字，估计你已经大概猜到它们的意思了。</p><p>没错，它们分别表示：磁盘读取 IOPS 限制，磁盘读取吞吐量限制，磁盘写入 IOPS 限制，磁盘写入吞吐量限制。</p><p>对于每个参数写入值的格式，你可以参考内核blkio 的文档。为了让你更好地理解，在这里我给你举个例子。</p><p>如果我们要对一个控制组做限制，限制它对磁盘 /dev/vdb 的写入吞吐量不超过 10MB/s，那么我们对 blkio.throttle.write_bps_device 参数的配置就是下面这个命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"252:16 10485760"</span> &gt; <span class="variable">$CGROUP_CONTAINER_PATH</span>/blkio.throttle.write_bps_device</span><br></pre></td></tr></table></figure><p>在这个命令中，”252:16”是 /dev/vdb 的主次设备号，你可以通过 ls -l /dev/vdb 看到这两个值，而后面的”10485760”就是 10MB 的每秒钟带宽限制。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ls -l /dev/vdb -l</span></span><br><span class="line">brw-rw---- 1 root disk 252, 16 Nov  2 08:02 /dev/vdb</span><br></pre></td></tr></table></figure><p>了解了 blkio Cgroup 的参数配置，我们再运行下面的这个例子，限制一个容器 blkio 的读写磁盘吞吐量，然后在这个容器里运行一下 fio，看看结果是什么。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /tmp/test1</span><br><span class="line">rm -f /tmp/test1/*</span><br><span class="line">docker stop fio_test1;docker rm fio_test1</span><br><span class="line">docker run -d --name fio_test1 --volume /tmp/test1:/tmp  registery/fio:v1 sleep 3600</span><br><span class="line">sleep 2</span><br><span class="line">CONTAINER_ID=$(sudo docker ps --format <span class="string">"&#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Names&#125;&#125;"</span> | grep -i fio_test1 | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CONTAINER_ID</span></span><br><span class="line">CGROUP_CONTAINER_PATH=$(find /sys/fs/cgroup/blkio/ -name <span class="string">"*<span class="variable">$CONTAINER_ID</span>*"</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CGROUP_CONTAINER_PATH</span></span><br><span class="line"><span class="comment"># To get the device major and minor id from /dev for the device that /tmp/test1 is on.</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"253:0 10485760"</span> &gt; <span class="variable">$CGROUP_CONTAINER_PATH</span>/blkio.throttle.read_bps_device</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"253:0 10485760"</span> &gt; <span class="variable">$CGROUP_CONTAINER_PATH</span>/blkio.throttle.write_bps_device</span><br><span class="line">docker <span class="built_in">exec</span> fio_test1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=100MB -numjobs=1  -name=/tmp/fio_test1.log</span><br><span class="line">docker <span class="built_in">exec</span> fio_test1 fio -direct=1 -rw=<span class="built_in">read</span> -ioengine=libaio -bs=4k -size=100MB -numjobs=1  -name=/tmp/fio_test1.log</span><br></pre></td></tr></table></figure><p>在这里，我的机器上 /tmp/test1 所在磁盘主次设备号是”253:0”，你在自己运行这组命令的时候，需要把主次设备号改成你自己磁盘的对应值。</p><p>还有一点我要提醒一下，不同数据块大小，在性能测试中可以适用于不同的测试目的。但因为这里不是我们要讲的重点，所以为了方便你理解概念，这里就用固定值。</p><p>在我们后面的例子里，fio 读写的数据块都固定在 4KB。所以对于磁盘的性能限制，我们在 blkio Cgroup 里就只设置吞吐量限制了。</p><p>在加了 blkio Cgroup 限制 10MB/s 后，从 fio 运行后的输出结果里，我们可以看到这个容器对磁盘无论是读还是写，它的最大值就不会再超过 10MB/s 了。</p><p><img src="/images/docker/docker-06/21.jpg" alt="21"></p><p><img src="/images/docker/docker-06/22.jpg" alt="22"></p><p>在给每个容器都加了 blkio Cgroup 限制，限制为 10MB/s 后，即使两个容器同时在一个磁盘上写入文件，那么每个容器的写入磁盘的最大吞吐量，也不会互相干扰了。</p><p>我们可以用下面的这个脚本来验证一下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">mkdir -p /tmp/test1</span><br><span class="line">rm -f /tmp/test1/*</span><br><span class="line">docker stop fio_test1;docker rm fio_test1</span><br><span class="line">mkdir -p /tmp/test2</span><br><span class="line">rm -f /tmp/test2/*</span><br><span class="line">docker stop fio_test2;docker rm fio_test2</span><br><span class="line">docker run -d --name fio_test1 --volume /tmp/test1:/tmp  registery/fio:v1 sleep 3600</span><br><span class="line">docker run -d --name fio_test2 --volume /tmp/test2:/tmp  registery/fio:v1 sleep 3600</span><br><span class="line">sleep 2</span><br><span class="line">CONTAINER_ID1=$(sudo docker ps --format <span class="string">"&#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Names&#125;&#125;"</span> | grep -i fio_test1 | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CONTAINER_ID1</span></span><br><span class="line">CGROUP_CONTAINER_PATH1=$(find /sys/fs/cgroup/blkio/ -name <span class="string">"*<span class="variable">$CONTAINER_ID1</span>*"</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CGROUP_CONTAINER_PATH1</span></span><br><span class="line"><span class="comment"># To get the device major and minor id from /dev for the device that /tmp/test1 is on.</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"253:0 10485760"</span> &gt; <span class="variable">$CGROUP_CONTAINER_PATH1</span>/blkio.throttle.read_bps_device</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"253:0 10485760"</span> &gt; <span class="variable">$CGROUP_CONTAINER_PATH1</span>/blkio.throttle.write_bps_device</span><br><span class="line">CONTAINER_ID2=$(sudo docker ps --format <span class="string">"&#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Names&#125;&#125;"</span> | grep -i fio_test2 | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CONTAINER_ID2</span></span><br><span class="line">CGROUP_CONTAINER_PATH2=$(find /sys/fs/cgroup/blkio/ -name <span class="string">"*<span class="variable">$CONTAINER_ID2</span>*"</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CGROUP_CONTAINER_PATH2</span></span><br><span class="line"><span class="comment"># To get the device major and minor id from /dev for the device that /tmp/test1 is on.</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"253:0 10485760"</span> &gt; <span class="variable">$CGROUP_CONTAINER_PATH2</span>/blkio.throttle.read_bps_device</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"253:0 10485760"</span> &gt; <span class="variable">$CGROUP_CONTAINER_PATH2</span>/blkio.throttle.write_bps_device</span><br><span class="line">docker <span class="built_in">exec</span> fio_test1 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=100MB -numjobs=1  -name=/tmp/fio_test1.log &amp;</span><br><span class="line">docker <span class="built_in">exec</span> fio_test2 fio -direct=1 -rw=write -ioengine=libaio -bs=4k -size=100MB -numjobs=1  -name=/tmp/fio_test2.log &amp;</span><br></pre></td></tr></table></figure><p>我们还是看看 fio 运行输出的结果，这时候，fio_test1 和 fio_test2 两个容器里执行的结果都是 10MB/s 了。</p><p><img src="/images/docker/docker-06/23.jpg" alt="23"></p><p><img src="/images/docker/docker-06/24.jpg" alt="24"></p><p>那么做到了这一步，我们是不是就可以认为，blkio Cgroup 可以完美地对磁盘 I/O 做限制了呢？</p><p>你先别急，我们可以再做个试验，把前面脚本里 fio 命令中的 “-direct=1” 给去掉，也就是不让 fio 运行在 Direct I/O 模式了，而是用 Buffered I/O 模式再运行一次，看看 fio 执行的输出。</p><p>同时我们也可以运行 iostat 命令，查看实际的磁盘写入速度。</p><p>这时候你会发现，即使我们设置了 blkio Cgroup，也根本不能限制磁盘的吞吐量了。</p><h3 id="Direct-I-O-和-Buffered-I-O"><a href="#Direct-I-O-和-Buffered-I-O" class="headerlink" title="Direct I/O 和 Buffered I/O"></a>Direct I/O 和 Buffered I/O</h3><p>为什么会这样的呢？这就要提到 Linux 的两种文件 I/O 模式了：Direct I/O 和 Buffered I/O。</p><p>Direct I/O 模式，用户进程如果要写磁盘文件，就会通过 Linux 内核的文件系统层 (filesystem) -&gt; 块设备层 (block layer) -&gt; 磁盘驱动 -&gt; 磁盘硬件，这样一路下去写入磁盘。</p><p>而如果是 Buffered I/O 模式，那么用户进程只是把文件数据写到内存中（Page Cache）就返回了，而 Linux 内核自己有线程会把内存中的数据再写入到磁盘中。<strong>在 Linux 里，由于考虑到性能问题，绝大多数的应用都会使用 Buffered I/O 模式。</strong></p><p><img src="/images/docker/docker-06/25.jpg" alt="25"></p><p>我们通过前面的测试，发现 Direct I/O 可以通过 blkio Cgroup 来限制磁盘 I/O，但是 Buffered I/O 不能被限制。</p><p>那通过上面的两种 I/O 模式的解释，你是不是可以想到原因呢？是的，原因就是被 Cgroups v1 的架构限制了。</p><p>我们已经学习过了 v1 的 CPU Cgroup，memory Cgroup 和 blkio Cgroup，那么 Cgroup v1 的一个整体结构，你应该已经很熟悉了。它的每一个子系统都是独立的，资源的限制只能在子系统中发生。</p><p>就像下面图里的进程 pid_y，它可以分别属于 memory Cgroup 和 blkio Cgroup。但是在 blkio Cgroup 对进程 pid_y 做磁盘 I/O 做限制的时候，blkio 子系统是不会去关心 pid_y 用了哪些内存，哪些内存是不是属于 Page Cache，而这些 Page Cache 的页面在刷入磁盘的时候，产生的 I/O 也不会被计算到进程 pid_y 上面。</p><p>就是这个原因，导致了 blkio 在 Cgroups v1 里不能限制 Buffered I/O。</p><p><img src="/images/docker/docker-06/26.jpg" alt="26"></p><p>这个 Buffered I/O 限速的问题，在 Cgroup V2 里得到了解决，其实这个问题也是促使 Linux 开发者重新设计 Cgroup V2 的原因之一。</p><h2 id="Cgroup-V2"><a href="#Cgroup-V2" class="headerlink" title="Cgroup V2"></a>Cgroup V2</h2><p>Cgroup v2 相比 Cgroup v1 做的最大的变动就是一个进程属于一个控制组，而每个控制组里可以定义自己需要的多个子系统。</p><p>比如下面的 Cgroup V2 示意图里，进程 pid_y 属于控制组 group2，而在 group2 里同时打开了 io 和 memory 子系统 （Cgroup V2 里的 io 子系统就等同于 Cgroup v1 里的 blkio 子系统）。</p><p>那么，Cgroup 对进程 pid_y 的磁盘 I/O 做限制的时候，就可以考虑到进程 pid_y 写入到 Page Cache 内存的页面了，这样 buffered I/O 的磁盘限速就实现了。</p><p><img src="/images/docker/docker-06/27.jpg" alt="27"></p><p>下面我们在 Cgroup v2 里，尝试一下设置了 blkio Cgroup+Memory Cgroup 之后，是否可以对 Buffered I/O 进行磁盘限速。</p><p>我们要做的第一步，就是在 Linux 系统里打开 Cgroup v2 的功能。因为目前即使最新版本的 Ubuntu Linux 或者 Centos Linux，仍然在使用 Cgroup v1 作为缺省的 Cgroup。</p><p>打开方法就是配置一个 kernel 参数”cgroup_no_v1=blkio,memory”，这表示把 Cgroup v1 的 blkio 和 Memory 两个子系统给禁止，这样 Cgroup v2 的 io 和 Memory 这两个子系统就打开了。</p><p>我们可以把这个参数配置到 grub 中，然后我们重启 Linux 机器，这时 Cgroup v2 的 io 还有 Memory 这两个子系统，它们的功能就打开了。</p><p>系统重启后，我们会看到 Cgroup v2 的虚拟文件系统被挂载到了 /sys/fs/cgroup/unified 目录下。</p><p>然后，我们用下面的这个脚本做 Cgroup v2 io 的限速配置，并且运行 fio，看看 buffered I/O 是否可以被限速。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a new control group</span></span><br><span class="line">mkdir -p /sys/fs/cgroup/unified/iotest</span><br><span class="line"><span class="comment"># enable the io and memory controller subsystem</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"+io +memory"</span> &gt; /sys/fs/cgroup/unified/cgroup.subtree_control</span><br><span class="line"><span class="comment"># Add current bash pid in iotest control group.</span></span><br><span class="line"><span class="comment"># Then all child processes of the bash will be in iotest group too,</span></span><br><span class="line"><span class="comment"># including the fio</span></span><br><span class="line"><span class="built_in">echo</span> $$ &gt;/sys/fs/cgroup/unified/iotest/cgroup.procs</span><br><span class="line"><span class="comment"># 256:16 are device major and minor ids, /mnt is on the device.</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"252:16 wbps=10485760"</span> &gt; /sys/fs/cgroup/unified/iotest/io.max</span><br><span class="line"><span class="built_in">cd</span> /mnt</span><br><span class="line"><span class="comment">#Run the fio in non direct I/O mode</span></span><br><span class="line">fio -iodepth=1 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1  -name=./fio.test</span><br></pre></td></tr></table></figure><p>在这个例子里，我们建立了一个名叫 iotest 的控制组，并且在这个控制组里加入了 io 和 Memory 两个控制子系统，对磁盘最大吞吐量的设置为 10MB。运行 fio 的时候不加”-direct=1”，也就是让 fio 运行在 buffered I/O 模式下。</p><p>运行 fio 写入 1GB 的数据后，你会发现 fio 马上就执行完了，因为系统上有足够的内存，fio 把数据写入内存就返回了，不过只要你再运行”iostat -xz 10” 这个命令，你就可以看到磁盘 vdb 上稳定的写入速率是 10240wkB/s，也就是我们在 io Cgroup 里限制的 10MB/s。</p><p><img src="/images/docker/docker-06/28.jpg" alt="28"></p><p>看到这个结果，我们证实了 Cgoupv2 io+Memory 两个子系统一起使用，就可以对 buffered I/O 控制磁盘写入速率。</p><!--### 重点总结这一讲，我们主要想解决的问题是如何保证容器读写磁盘速率的稳定，特别是当多个容器同时读写同一个磁盘的时候，需要减少相互的干扰。Cgroup V1 的 blkiio 控制子系统，可以用来限制容器中进程的读写的 IOPS 和吞吐量（Throughput），但是它只能对于 Direct I/O 的读写文件做磁盘限速，对 Buffered I/O 的文件读写，它无法进行磁盘限速。**这是因为 Buffered I/O 会把数据先写入到内存 Page Cache 中，然后由内核线程把数据写入磁盘，而 Cgroup v1 blkio 的子系统独立于 memory 子系统，无法统计到由 Page Cache 刷入到磁盘的数据量。**这个 Buffered I/O 无法被限速的问题，在 Cgroup v2 里被解决了。Cgroup v2 从架构上允许一个控制组里有多个子系统协同运行，这样在一个控制组里只要同时有 io 和 Memory 子系统，就可以对 Buffered I/O 作磁盘读写的限速。虽然 Cgroup v2 解决了 Buffered I/O 磁盘读写限速的问题，但是在现实的容器平台上也不是能够立刻使用的，还需要等待一段时间。目前从 runC、containerd 到 Kubernetes 都是刚刚开始支持 Cgroup v2，而对生产环境中原有运行 Cgroup v1 的节点要迁移转化成 Cgroup v2 需要一个过程。--><h2 id="容器中的内存与I-O：容器写文件的延时为什么波动很大？"><a href="#容器中的内存与I-O：容器写文件的延时为什么波动很大？" class="headerlink" title="容器中的内存与I/O：容器写文件的延时为什么波动很大？"></a>容器中的内存与I/O：容器写文件的延时为什么波动很大？</h2><p>对于 Linux 的系统调用 write() 来说，Buffered I/O 是缺省模式，使用起来比较方便，而且从用户角度看，在大多数的应用场景下，用 Buffered I/O 的 write() 函数调用返回要快一些。所以，Buffered I/O 在程序中使用得更普遍一些。</p><p>当使用 Buffered I/O 的应用程序从虚拟机迁移到容器，这时我们就会发现多了 Memory Cgroup 的限制之后，write() 写相同大小的数据块花费的时间，延时波动会比较大。</p><h3 id="问题再现-2"><a href="#问题再现-2" class="headerlink" title="问题再现"></a>问题再现</h3><p>我们可以先动手写一个小程序，用来模拟刚刚说的现象。</p><p>这个小程序我们这样来设计：从一个文件中每次读取一个 64KB 大小的数据块，然后写到一个新文件中，它可以不断读写 10GB 大小的数据。同时我们在这个小程序中做个记录，记录写每个 64KB 的数据块需要花费的时间。</p><p>我们可以先在虚拟机里直接运行，虚拟机里内存大小是大于 10GB 的。接着，我们把这个程序放到容器中运行，因为这个程序本身并不需要很多的内存，我们给它做了一个 Memory Cgroup 的内存限制，设置为 1GB。</p><p>运行结束后，我们比较一下程序写数据块的时间。我把结果画了一张图，图里的纵轴是时间，单位 us；横轴是次数，在这里我们记录了 96 次。图中橘红色的线是在容器里运行的结果，蓝色的线是在虚拟机上运行的结果。</p><p>结果很明显，在容器中写入数据块的时间会时不时地增高到 200us；而在虚拟机里的写入数据块时间就比较平稳，一直在 30～50us 这个范围内。</p><p><img src="/images/docker/docker-06/29.jpg" alt="29"></p><p>通过这个小程序，我们再现了问题，那我们就来分析一下，为什么会产生这样的结果。</p><h3 id="时间波动是因为-Dirty-Pages-的影响么？"><a href="#时间波动是因为-Dirty-Pages-的影响么？" class="headerlink" title="时间波动是因为 Dirty Pages 的影响么？"></a>时间波动是因为 Dirty Pages 的影响么？</h3><p>我们对文件的写入操作是 Buffered I/O。在前一讲中，我们其实已经知道了，对于 Buffer I/O，用户的数据是先写入到 Page Cache 里的。而这些写入了数据的内存页面，在它们没有被写入到磁盘文件之前，就被叫作 dirty pages。</p><p>Linux 内核会有专门的内核线程（每个磁盘设备对应的 kworker/flush 线程）把 dirty pages 写入到磁盘中。那我们自然会这样猜测，也许是 Linux 内核对 dirty pages 的操作影响了 Buffered I/O 的写操作？</p><p>想要验证这个想法，我们需要先来看看 dirty pages 是在什么时候被写入到磁盘的。这里就要用到 <strong>/proc/sys/vm 里和 dirty page 相关的内核参数</strong>了，我们需要知道所有相关参数的含义，才能判断出最后真正导致问题发生的原因。</p><p>现在我们挨个来看一下。为了方便后面的讲述，我们可以设定一个比值 A，<strong>A 等于 dirty pages 的内存 / 节点可用内存 *100%</strong>。</p><p>第一个参数，dirty_background_ratio，这个参数里的数值是一个百分比值，缺省是 10%。如果比值 A 大于 dirty_background_ratio 的话，比如大于默认的 10%，内核 flush 线程就会把 dirty pages 刷到磁盘里。</p><p>第二个参数，是和 dirty_background_ratio 相对应一个参数，也就是 dirty_background_bytes，它和 dirty_background_ratio 作用相同。区别只是 dirty_background_bytes 是具体的字节数，它用来定义的是 dirty pages 内存的临界值，而不是比例值。</p><p>这里你还要注意，dirty_background_ratio 和 dirty_background_bytes 只有一个可以起作用，如果你给其中一个赋值之后，另外一个参数就归 0 了。</p><p>接下来我们看第三个参数，dirty_ratio，这个参数的数值也是一个百分比值，缺省是 20%。</p><p>如果比值 A，大于参数 dirty_ratio 的值，比如大于默认设置的 20%，这时候正在执行 Buffered I/O 写文件的进程就会被阻塞住，直到它写的数据页面都写到磁盘为止。</p><p>同样，第四个参数 dirty_bytes 与 dirty_ratio 相对应，它们的关系和 dirty_background_ratio 与 dirty_background_bytes 一样。我们给其中一个赋值后，另一个就会归零。</p><p>然后我们来看 dirty_writeback_centisecs，这个参数的值是个时间值，以百分之一秒为单位，缺省值是 500，也就是 5 秒钟。它表示每 5 秒钟会唤醒内核的 flush 线程来处理 dirty pages。</p><p>最后还有 dirty_expire_centisecs，这个参数的值也是一个时间值，以百分之一秒为单位，缺省值是 3000，也就是 30 秒钟。它定义了 dirty page 在内存中存放的最长时间，如果一个 dirty page 超过这里定义的时间，那么内核的 flush 线程也会把这个页面写入磁盘。</p><p>好了，从这些 dirty pages 相关的参数定义，你会想到些什么呢？</p><p>进程写操作上的时间波动，只有可能是因为 dirty pages 的数量很多，已经达到了第三个参数 dirty_ratio 的值。这时执行写文件功能的进程就会被暂停，直到写文件的操作将数据页面写入磁盘，写文件的进程才能继续运行，所以进程里一次写文件数据块的操作时间会增加。</p><p>刚刚说的是我们的推理，那情况真的会是这样吗？其实我们可以在容器中进程不断写入数据的时候，查看节点上 dirty pages 的实时数目。具体操作如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">watch -n 1 <span class="string">"cat /proc/vmstat | grep dirty"</span></span><br></pre></td></tr></table></figure><p>当我们的节点可用内存是 12GB 的时候，假设 dirty_ratio 是 20%，dirty_background_ratio 是 10%，那么我们在 1GB memory 容器中写 10GB 的数据，就会看到它实时的 dirty pages 数目，也就是 / proc/vmstat 里的 nr_dirty 的数值，这个数值对应的内存并不能达到 dirty_ratio 所占的内存值。</p><p><img src="/images/docker/docker-06/30.jpg" alt="30"></p><p>其实我们还可以再做个实验，就是在 dirty_bytes 和 dirty_background_bytes 里写入一个很小的值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> 8192 &gt; /proc/sys/vm/dirty_bytes</span><br><span class="line"><span class="built_in">echo</span> 4096 &gt; /proc/sys/vm/dirty_background_bytes</span><br></pre></td></tr></table></figure><p>然后再记录一下容器程序里每写入 64KB 数据块的时间，这时候，我们就会看到，时不时一次写入的时间就会达到 9ms，这已经远远高于我们之前看到的 200us 了。</p><p>因此，我们知道了这个时间的波动，并不是强制把 dirty page 写入到磁盘引起的。</p><h3 id="调试问题"><a href="#调试问题" class="headerlink" title="调试问题"></a>调试问题</h3><p>那接下来，我们还能怎么分析这个问题呢？</p><p>我们可以用 perf 和 ftrace 这两个工具，对容器里写数据块的进程做个 profile，看看到底是调用哪个函数花费了比较长的时间。顺便说一下，我们在专题加餐里会专门介绍如何使用 perf、ftrace 等工具以及它们的工作原理，在这里你只要了解我们的调试思路就行。</p><p>怎么使用这两个工具去定位耗时高的函数呢？我大致思路是这样的：我们发现容器中的进程用到了 write() 这个函数调用，然后写 64KB 数据块的时间增加了，而 write() 是一个系统调用，那我们需要进行下面这两步操作。</p><p><strong>第一步，我们要找到内核中 write() 这个系统调用函数下，又调用了哪些子函数。</strong>想找出主要的子函数我们可以查看代码，也可以用 perf 这个工具来得到。</p><p>然后是<strong>第二步，得到了 write() 的主要子函数之后，我们可以用 ftrace 这个工具来 trace 这些函数的执行时间，这样就可以找到花费时间最长的函数了。</strong></p><p>好，下面我们就按照刚才梳理的思路来做一下。首先是第一步，我们在容器启动写磁盘的进程后，在宿主机上得到这个进程的 pid，然后运行下面的 perf 命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perf record -a -g -p &lt;pid&gt;</span><br></pre></td></tr></table></figure><p>等写磁盘的进程退出之后，这个 perf record 也就停止了。</p><p>这时我们再执行 perf report 查看结果。把 vfs_write() 函数展开之后，我们就可以看到，write() 这个系统调用下面的调用到了哪些主要的子函数，到这里第一步就完成了。</p><p><img src="/images/docker/docker-06/31.jpg" alt="31"></p><p>下面再来做第二步，我们把主要的函数写入到 ftrace 的 set_ftrace_filter 里, 然后把 ftrace 的 tracer 设置为 function_graph，并且打开 tracing_on 开启追踪。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /sys/kernel/debug/tracing</span></span><br><span class="line"><span class="comment"># echo vfs_write &gt;&gt; set_ftrace_filter</span></span><br><span class="line"><span class="comment"># echo xfs_file_write_iter &gt;&gt; set_ftrace_filter</span></span><br><span class="line"><span class="comment"># echo xfs_file_buffered_aio_write &gt;&gt; set_ftrace_filter</span></span><br><span class="line"><span class="comment"># echo iomap_file_buffered_write</span></span><br><span class="line"><span class="comment"># echo iomap_file_buffered_write &gt;&gt; set_ftrace_filter</span></span><br><span class="line"><span class="comment"># echo pagecache_get_page &gt;&gt; set_ftrace_filter</span></span><br><span class="line"><span class="comment"># echo try_to_free_mem_cgroup_pages &gt;&gt; set_ftrace_filter</span></span><br><span class="line"><span class="comment"># echo try_charge &gt;&gt; set_ftrace_filter</span></span><br><span class="line"><span class="comment"># echo mem_cgroup_try_charge &gt;&gt; set_ftrace_filter</span></span><br><span class="line"><span class="comment"># echo function_graph &gt; current_tracer</span></span><br><span class="line"><span class="comment"># echo 1 &gt; tracing_on</span></span><br></pre></td></tr></table></figure><p>这些设置完成之后，我们再运行一下容器中的写磁盘程序，同时从 ftrace 的 trace_pipe 中读取出追踪到的这些函数。</p><p>这时我们可以看到，当需要申请 Page Cache 页面的时候，write() 系统调用会反复地调用 mem_cgroup_try_charge()，并且在释放页面的时候，函数 do_try_to_free_pages() 花费的时间特别长，有 50+us（时间单位，micro-seconds）这么多。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"> 1)               |  <span class="function"><span class="title">vfs_write</span></span>() &#123;</span><br><span class="line">  1)               |    xfs_file_write_iter [xfs]() &#123;</span><br><span class="line">  1)               |      xfs_file_buffered_aio_write [xfs]() &#123;</span><br><span class="line">  1)               |        <span class="function"><span class="title">iomap_file_buffered_write</span></span>() &#123;</span><br><span class="line">  1)               |          <span class="function"><span class="title">pagecache_get_page</span></span>() &#123;</span><br><span class="line">  1)               |            <span class="function"><span class="title">mem_cgroup_try_charge</span></span>() &#123;</span><br><span class="line">  1)   0.338 us    |              try_charge();</span><br><span class="line">  1)   0.791 us    |            &#125;</span><br><span class="line">  1)   4.127 us    |          &#125;</span><br><span class="line">…</span><br><span class="line">  1)               |          <span class="function"><span class="title">pagecache_get_page</span></span>() &#123;</span><br><span class="line">  1)               |            <span class="function"><span class="title">mem_cgroup_try_charge</span></span>() &#123;</span><br><span class="line">  1)               |              <span class="function"><span class="title">try_charge</span></span>() &#123;</span><br><span class="line">  1)               |                <span class="function"><span class="title">try_to_free_mem_cgroup_pages</span></span>() &#123;</span><br><span class="line">  1) + 52.798 us   |                  do_try_to_free_pages();</span><br><span class="line">  1) + 53.958 us   |                &#125;</span><br><span class="line">  1) + 54.751 us   |              &#125;</span><br><span class="line">  1) + 55.188 us   |            &#125;</span><br><span class="line">  1) + 56.742 us   |          &#125;</span><br><span class="line">…</span><br><span class="line">  1) ! 109.925 us  |        &#125;</span><br><span class="line">  1) ! 110.558 us  |      &#125;</span><br><span class="line">  1) ! 110.984 us  |    &#125;</span><br><span class="line">  1) ! 111.515 us  |  &#125;</span><br></pre></td></tr></table></figure><p>看到这个 ftrace 的结果，你是不是会想到，我们在容器内存中提到的 Page Cahe 呢？</p><p>是的，这个问题的确和 Page Cache 有关，Linux 会把所有的空闲内存利用起来，一旦有 Buffered I/O，这些内存都会被用作 Page Cache。</p><p>当容器加了 Memory Cgroup 限制了内存之后，对于容器里的 Buffered I/O，就只能使用容器中允许使用的最大内存来做 Page Cache。</p><p><strong>那么如果容器在做内存限制的时候，Cgroup 中 memory.limit_in_bytes 设置得比较小，而容器中的进程又有很大量的 I/O，这样申请新的 Page Cache 内存的时候，又会不断释放老的内存页面，这些操作就会带来额外的系统开销了。</strong></p><!--### 重点总结我们今天讨论的问题是在容器中用 Buffered I/O 方式写文件的时候，会出现写入时间波动的问题。由于这是 Buffered I/O 方式，对于写入文件会先写到内存里，这样就产生了 dirty pages，所以我们先研究了一下 Linux 对 dirty pages 的回收机制是否会影响到容器中写入数据的波动。在这里我们最主要的是理解这两个参数，**dirty_background_ratio 和 dirty_ratio**，这两个值都是相对于节点可用内存的百分比值。**当 dirty pages 数量超过 dirty_background_ratio 对应的内存量的时候，内核 flush 线程就会开始把 dirty pages 写入磁盘 ; 当 dirty pages 数量超过 dirty_ratio 对应的内存量，这时候程序写文件的函数调用 write() 就会被阻塞住，直到这次调用的 dirty pages 全部写入到磁盘。**在节点是大内存容量，并且 dirty_ratio 为系统缺省值 20%，dirty_background_ratio 是系统缺省值 10% 的情况下，我们通过观察 /proc/vmstat 中的 nr_dirty 数值可以发现，dirty pages 不会阻塞进程的 Buffered I/O 写文件操作。所以我们做了另一种尝试，使用 perf 和 ftrace 工具对容器中的写文件进程进行 profile。我们用 perf 得到了系统调用 write() 在内核中的一系列子函数调用，再用 ftrace 来查看这些子函数的调用时间。**根据 ftrace 的结果，我们发现写数据到 Page Cache 的时候，需要不断地去释放原有的页面，这个时间开销是最大的。造成容器中 Buffered I/O write() 不稳定的原因，正是容器在限制内存之后，Page Cache 的数量较小并且不断申请释放。**其实这个问题也提醒了我们：在对容器做 Memory Cgroup 限制内存大小的时候，不仅要考虑容器中进程实际使用的内存量，还要考虑容器中程序 I/O 的量，合理预留足够的内存作为 Buffered I/O 的 Page Cache。比如，如果知道需要反复读写文件的大小，并且在内存足够的情况下，那么 Memory Cgroup 的内存限制可以超过这个文件的大小。还有一个解决思路是，我们在程序中自己管理文件的 cache 并且调用 Direct I/O 来读写文件，这样才会对应用程序的性能有一个更好的预期。--><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《由浅入深吃透 Docker》</li><li>《容器实战高手课》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://www.docker-cn.com" target="_blank" rel="noopener">https://www.docker-cn.com</a></li><li><a href="https://docs.docker.com/compose/compose-file/compose-file-v3/" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/compose-file-v3/</a></li><li><a href="https://docs.docker.com/compose/reference/" target="_blank" rel="noopener">https://docs.docker.com/compose/reference/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;容器存储&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://blog.lichao.xin/categories/Docker/"/>
    
    
      <category term="docker" scheme="https://blog.lichao.xin/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>重学 Docker 之 容器进阶（二）</title>
    <link href="https://blog.lichao.xin/back-end/docker/docker-05/"/>
    <id>https://blog.lichao.xin/back-end/docker/docker-05/</id>
    <published>2021-04-10T10:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.383Z</updated>
    
    <content type="html"><![CDATA[<p>容器CPU、容器内存</p><a id="more"></a><h2 id="容器CPU（1）：怎么限制容器的CPU使用？"><a href="#容器CPU（1）：怎么限制容器的CPU使用？" class="headerlink" title="容器CPU（1）：怎么限制容器的CPU使用？"></a>容器CPU（1）：怎么限制容器的CPU使用？</h2><p>容器在 Linux 系统中最核心的两个概念是 Namespace 和 Cgroups。我们可以通过 Cgroups 技术限制资源。这个资源可以分为很多类型，比如 CPU，Memory，Storage，Network 等等。而计算资源是最基本的一种资源，所有的容器都需要这种资源。</p><p>那么，今天我们就先聊一聊，怎么限制容器的 CPU 使用？</p><p>我们拿 Kubernetes 平台做例子，具体来看下面这个 pod/container 里的 spec 定义，在 CPU 资源相关的定义中有两项内容，分别是 <strong>Request CPU</strong> 和 <strong>Limit CPU</strong>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">app</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">images.my-company.example/app:v4</span></span><br><span class="line">    <span class="attr">env:</span></span><br><span class="line">    <span class="attr">resources:</span></span><br><span class="line">      <span class="attr">requests:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">"64Mi"</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">"1"</span></span><br><span class="line">      <span class="attr">limits:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">"128Mi"</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">"2"</span></span><br><span class="line"><span class="string">…</span></span><br></pre></td></tr></table></figure><p>很多刚刚使用 Kubernetes 的同学，可能一开始并不理解这两个参数有什么作用。</p><p>这里我先给你说结论，在 Pod Spec 里的”Request CPU”和”Limit CPU”的值，最后会通过 CPU Cgroup 的配置，来实现控制容器 CPU 资源的作用。</p><p>那接下来我会先从进程的 CPU 使用讲起，然后带你在 CPU Cgroup 子系统中建立几个控制组，用这个例子为你讲解 CPU Cgroup 中的三个最重要的参数”cpu.cfs_quota_us””cpu.cfs_period_us””cpu.shares”。</p><p>相信理解了这三个参数后，你就会明白我们要怎样限制容器 CPU 的使用了。</p><h3 id="如何理解-CPU-使用和-CPU-Cgroup？"><a href="#如何理解-CPU-使用和-CPU-Cgroup？" class="headerlink" title="如何理解 CPU 使用和 CPU Cgroup？"></a>如何理解 CPU 使用和 CPU Cgroup？</h3><p>既然我们需要理解 CPU  Cgroup，那么就有必要先来看一下 Linux 里的 CPU 使用的概念，这是因为 CPU Cgroup 最大的作用就是限制 CPU 使用。</p><h4 id="CPU-使用的分类"><a href="#CPU-使用的分类" class="headerlink" title="CPU 使用的分类"></a>CPU 使用的分类</h4><p>如果你想查看 Linux 系统的 CPU 使用的话，会用什么方法呢？最常用的肯定是运行 Top 了。</p><p>我们对照下图的 Top 运行界面，在截图第三行，”%Cpu(s)”开头的这一行，你会看到一串数值，也就是”0.0 us, 0.0 sy, 0.0 ni, 99.9 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st”，那么这里的每一项值都是什么含义呢？</p><p><img src="/images/docker/docker-05/1.jpg" alt="1"></p><p>下面这张图里最长的带箭头横轴，我们可以把它看成一个时间轴。同时，它的上半部分代表 Linux 用户态（User space），下半部分代表内核态（Kernel space）。这里为了方便你理解，我们先假设只有一个 CPU 吧。</p><p><img src="/images/docker/docker-05/2.jpg" alt="2"></p><p>我们可以用上面这张图，把这些值挨个解释一下。</p><p>假设一个用户程序开始运行了，那么就对应着第一个”us”框，”us”是”user”的缩写，代表 Linux 的用户态 CPU Usage。普通用户程序代码中，只要不是调用系统调用（System Call），这些代码的指令消耗的 CPU 就都属于”us”。</p><p>当这个用户程序代码中调用了系统调用，比如说 read() 去读取一个文件，这时候这个用户进程就会从用户态切换到内核态。</p><p>内核态 read() 系统调用在读到真正 disk 上的文件前，就会进行一些文件系统层的操作。那么这些代码指令的消耗就属于”sy”，这里就对应上面图里的第二个框。”sy”是 “system”的缩写，代表内核态 CPU 使用。</p><p>接下来，这个 read() 系统调用会向 Linux 的 Block Layer 发出一个 I/O Request，触发一个真正的磁盘读取操作。</p><p>这时候，这个进程一般会被置为 TASK_UNINTERRUPTIBLE。而 Linux 会把这段时间标示成”wa”，对应图中的第三个框。”wa”是”iowait”的缩写，代表等待 I/O 的时间，这里的 I/O 是指 Disk I/O。</p><p>紧接着，当磁盘返回数据时，进程在内核态拿到数据，这里仍旧是内核态的 CPU 使用中的”sy”，也就是图中的第四个框。</p><p>然后，进程再从内核态切换回用户态，在用户态得到文件数据，这里进程又回到用户态的 CPU 使用，”us”，对应图中第五个框。</p><p>好，这里我们假设一下，这个用户进程在读取数据之后，没事可做就休眠了。并且我们可以进一步假设，这时在这个 CPU 上也没有其他需要运行的进程了，那么系统就会进入”id”这个步骤，也就是第六个框。”id”是”idle”的缩写，代表系统处于空闲状态。</p><p>如果这时这台机器在网络收到一个网络数据包，网卡就会发出一个中断（interrupt）。相应地，CPU 会响应中断，然后进入中断服务程序。</p><p>这时，CPU 就会进入”hi”，也就是第七个框。”hi”是”hardware irq”的缩写，代表 CPU 处理硬中断的开销。由于我们的中断服务处理需要关闭中断，所以这个硬中断的时间不能太长。</p><p>但是，发生中断后的工作是必须要完成的，如果这些工作比较耗时那怎么办呢？Linux 中有一个软中断的概念（softirq），它可以完成这些耗时比较长的工作。</p><p>你可以这样理解这个软中断，从网卡收到数据包的大部分工作，都是通过软中断来处理的。那么，CPU 就会进入到第八个框，”si”。这里”si”是”softirq”的缩写，代表 CPU 处理软中断的开销。</p><p>这里你要注意，无论是”hi”还是”si”，它们的 CPU 时间都不会计入进程的 CPU 时间。<strong>这是因为本身它们在处理的时候就不属于任何一个进程。</strong></p><p>好了，通过这个场景假设，我们介绍了大部分的 Linux CPU 使用。</p><p>不过，我们还剩两个类型的 CPU 使用没讲到，我想给你做个补充，一次性带你做个全面了解。这样以后你解决相关问题时，就不会再犹豫，这些值到底影不影响 CPU Cgroup 中的限制了。下面我给你具体讲一下。</p><p>一个是”ni”，是”nice”的缩写，这里表示如果进程的 nice 值是正值（1-19），代表优先级比较低的进程运行时所占用的 CPU。</p><p>另外一个是”st”，”st”是”steal”的缩写，是在虚拟机里用的一个 CPU 使用类型，表示有多少时间是被同一个宿主机上的其他虚拟机抢走的。</p><p>综合前面的内容，我再用表格为你总结一下：</p><p><img src="/images/docker/docker-05/3.jpg" alt="3"></p><h3 id="CPU-Cgroup"><a href="#CPU-Cgroup" class="headerlink" title="CPU Cgroup"></a>CPU Cgroup</h3><p>在前面，我们提到过 Cgroups 是对指定进程做计算机资源限制的，CPU  Cgroup 是 Cgroups 其中的一个 Cgroups 子系统，它是用来限制进程的 CPU 使用的。</p><p>对于进程的 CPU 使用, 通过前面的 Linux CPU 使用分类的介绍，我们知道它只包含两部分: 一个是用户态，这里的用户态包含了 us 和 ni；还有一部分是内核态，也就是 sy。</p><p>至于 wa、hi、si，这些 I/O 或者中断相关的 CPU 使用，CPU Cgroup 不会去做限制，那么接下来我们就来看看 CPU  Cgoup 是怎么工作的？</p><p>每个 Cgroups 子系统都是通过一个虚拟文件系统挂载点的方式，挂到一个缺省的目录下，CPU  Cgroup 一般在 Linux 发行版里会放在 /sys/fs/cgroup/cpu 这个目录下。</p><p>在这个子系统的目录下，每个控制组（Control Group） 都是一个子目录，各个控制组之间的关系就是一个树状的层级关系（hierarchy）。</p><p>比如说，我们在子系统的最顶层开始建立两个控制组（也就是建立两个目录）group1 和 group2，然后再在 group2 的下面再建立两个控制组 group3 和 group4。</p><p>这样操作以后，我们就建立了一个树状的控制组层级，你可以参考下面的示意图。</p><p><img src="/images/docker/docker-05/4.jpg" alt="4"></p><p>那么我们的每个控制组里，都有哪些 CPU  Cgroup 相关的控制信息呢？这里我们需要看一下每个控制组目录中的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># pwd</span></span><br><span class="line">/sys/fs/cgroup/cpu</span><br><span class="line"><span class="comment"># mkdir group1 group2</span></span><br><span class="line"><span class="comment"># cd group2</span></span><br><span class="line"><span class="comment"># mkdir group3 group4</span></span><br><span class="line"><span class="comment"># cd group3</span></span><br><span class="line"><span class="comment"># ls cpu.*</span></span><br><span class="line">cpu.cfs_period_us  cpu.cfs_quota_us  cpu.rt_period_us  cpu.rt_runtime_us  cpu.shares  cpu.stat</span><br></pre></td></tr></table></figure><p>考虑到在云平台里呢，大部分程序都不是实时调度的进程，而是普通调度（SCHED_NORMAL）类型进程，那什么是普通调度类型呢？</p><p>因为普通调度的算法在 Linux 中目前是 CFS （Completely Fair Scheduler，即完全公平调度器）。为了方便你理解，我们就直接来看 CPU Cgroup 和 CFS 相关的参数，一共有三个。</p><p>第一个参数是 <strong>cpu.cfs_period_us</strong>，它是 CFS 算法的一个调度周期，一般它的值是 100000，以 microseconds 为单位，也就 100ms。</p><p>第二个参数是 <strong>cpu.cfs_quota_us</strong>，它“表示 CFS 算法中，在一个调度周期里这个控制组被允许的运行时间，比如这个值为 50000 时，就是 50ms。</p><p>如果用这个值去除以调度周期（也就是 cpu.cfs_period_us），50ms/100ms = 0.5，这样这个控制组被允许使用的 CPU 最大配额就是 0.5 个 CPU。</p><p>从这里能够看出，cpu.cfs_quota_us 是一个绝对值。如果这个值是 200000，也就是 200ms，那么它除以 period，也就是 200ms/100ms=2。</p><p>你看，结果超过了 1 个 CPU，这就意味着这时控制组需要 2 个 CPU 的资源配额。</p><p>我们再来看看第三个参数， <strong>cpu.shares</strong>。这个值是 CPU  Cgroup 对于控制组之间的 CPU 分配比例，它的缺省值是 1024。</p><p>假设我们前面创建的 group3 中的 cpu.shares 是 1024，而 group4 中的 cpu.shares 是 3072，那么 group3:group4=1:3。</p><p>这个比例是什么意思呢？我还是举个具体的例子来说明吧。</p><p>在一台 4 个 CPU 的机器上，当 group3 和 group4 都需要 4 个 CPU 的时候，它们实际分配到的 CPU 分别是这样的：group3 是 1 个，group4 是 3 个。</p><p>我们刚才讲了 CPU Cgroup 里的三个关键参数，接下来我们就通过几个例子来进一步理解一下。</p><p>第一个例子，我们启动一个消耗 2 个 CPU（200%）的程序 threads-cpu，然后把这个程序的 pid 加入到 group3 的控制组里：</p><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: threads-cpu</span></span><br><span class="line"><span class="section">threads-cpu: threads-cpu.c</span></span><br><span class="line">gcc -o threads-cpu threads-cpu.c -lpthread</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">rm -f *.o threads-cpu</span><br></pre></td></tr></table></figure><p>threads-cpu.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pthread.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">doSomeThing</span><span class="params">(<span class="keyword">void</span> *arg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">unsigned</span> <span class="keyword">long</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">pthread_t</span> id = pthread_self();</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Thread%d, %x\n"</span>, i++, id);</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line"><span class="keyword">int</span> sum;</span><br><span class="line">sum += <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">int</span> total;</span><br><span class="line"><span class="keyword">pthread_attr_t</span> tattr;</span><br><span class="line"><span class="keyword">int</span> err;</span><br><span class="line"><span class="keyword">int</span> stack_size = (<span class="number">20</span> * <span class="number">1024</span> * <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (argc &lt; <span class="number">2</span>) &#123;</span><br><span class="line">total = <span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">total = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">err = pthread_attr_init(&amp;tattr);</span><br><span class="line"><span class="keyword">if</span> (err != <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"pthread_attr_init err\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">err = pthread_attr_setstacksize(&amp;tattr, stack_size);</span><br><span class="line"><span class="keyword">if</span> (err != <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Set stack to %d\n"</span>, stack_size);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"To create %d threads\n"</span>, total);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line"><span class="keyword">pthread_t</span> tid;</span><br><span class="line">err = pthread_create(&amp;tid, &amp;tattr, &amp;doSomeThing, <span class="literal">NULL</span>);</span><br><span class="line"><span class="keyword">if</span> (err != <span class="number">0</span>)</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\ncan't create thread :[%s]"</span>, strerror(err));</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"\nThread %d created successfully\n"</span>, i);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">usleep(<span class="number">1000000</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"All threads are created\n"</span>);</span><br><span class="line">usleep(<span class="number">1000000000</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./threads-cpu/threads-cpu 2 &amp;</span><br><span class="line"><span class="built_in">echo</span> $! &gt; /sys/fs/cgroup/cpu/group2/group3/cgroup.procs</span><br></pre></td></tr></table></figure><p>在我们没有修改 cpu.cfs_quota_us 前，用 top 命令可以看到 threads-cpu 这个进程的 CPU  使用是 199%，近似 2 个 CPU。</p><p><img src="/images/docker/docker-05/5.jpg" alt="5"></p><p>然后，我们更新这个控制组里的 cpu.cfs_quota_us，把它设置为 150000（150ms）。把这个值除以 cpu.cfs_period_us，计算过程是 150ms/100ms=1.5, 也就是 1.5 个 CPU，同时我们也把 cpu.shares 设置为 1024。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> 150000 &gt; /sys/fs/cgroup/cpu/group2/group3/cpu.cfs_quota_us</span><br><span class="line"><span class="built_in">echo</span> 1024 &gt; /sys/fs/cgroup/cpu/group2/group3/cpu.shares</span><br></pre></td></tr></table></figure><p>这时候我们再运行 top，就会发现 threads-cpu 进程的 CPU 使用减小到了 150%。这是因为我们设置的 cpu.cfs_quota_us 起了作用，限制了进程 CPU 的绝对值。</p><p>但这时候 cpu.shares 的作用还没有发挥出来，因为 cpu.shares 是几个控制组之间的 CPU 分配比例，而且一定要到整个节点中所有的 CPU 都跑满的时候，它才能发挥作用。</p><p><img src="/images/docker/docker-06/5.jpg" alt="6"></p><p>好，下面我们再来运行第二个例子来理解 cpu.shares。我们先把第一个例子里的程序启动，同时按前面的内容，一步步设置好 group3 里 cpu.cfs_quota_us 和 cpu.shares。</p><p>设置完成后，我们再启动第二个程序，并且设置好 group4 里的 cpu.cfs_quota_us 和 cpu.shares。</p><p>group3：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./threads-cpu/threads-cpu 2 &amp;  <span class="comment"># 启动一个消耗2个CPU的程序</span></span><br><span class="line"><span class="built_in">echo</span> $! &gt; /sys/fs/cgroup/cpu/group2/group3/cgroup.procs <span class="comment">#把程序的pid加入到控制组</span></span><br><span class="line"><span class="built_in">echo</span> 150000 &gt; /sys/fs/cgroup/cpu/group2/group3/cpu.cfs_quota_us <span class="comment">#限制CPU为1.5CPU</span></span><br><span class="line"><span class="built_in">echo</span> 1024 &gt; /sys/fs/cgroup/cpu/group2/group3/cpu.shares</span><br></pre></td></tr></table></figure><p>group4：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./threads-cpu/threads-cpu 4 &amp;  <span class="comment"># 启动一个消耗4个CPU的程序</span></span><br><span class="line"><span class="built_in">echo</span> $! &gt; /sys/fs/cgroup/cpu/group2/group4/cgroup.procs <span class="comment">#把程序的pid加入到控制组</span></span><br><span class="line"><span class="built_in">echo</span> 350000 &gt; /sys/fs/cgroup/cpu/group2/group4/cpu.cfs_quota_us  <span class="comment">#限制CPU为3.5CPU</span></span><br><span class="line"><span class="built_in">echo</span> 3072 &gt; /sys/fs/cgroup/cpu/group2/group3/cpu.shares <span class="comment"># shares 比例 group4: group3 = 3:1</span></span><br></pre></td></tr></table></figure><p>好了，现在我们的节点上总共有 4 个 CPU，而 group3 的程序需要消耗 2 个 CPU，group4 里的程序要消耗 4 个 CPU。</p><p>即使 cpu.cfs_quota_us 已经限制了进程 CPU 使用的绝对值，group3 的限制是 1.5CPU，group4 是 3.5CPU，1.5+3.5=5，这个结果还是超过了节点上的 4 个 CPU。</p><p>好了，说到这里，我们发现在这种情况下，cpu.shares 终于开始起作用了。</p><p>在这里 shares 比例是 group4:group3=3:1，在总共 4 个 CPU 的节点上，按照比例，group4 里的进程应该分配到 3 个 CPU，而 group3 里的进程会分配到 1 个 CPU。</p><p>我们用 top 可以看一下，结果和我们预期的一样。</p><p><img src="/images/docker/docker-05/7.jpg" alt="7"></p><p>好了，我们对 CPU Cgroup 的参数做一个梳理。</p><p>第一点，cpu.cfs_quota_us 和 cpu.cfs_period_us 这两个值决定了<strong>每个控制组中所有进程的可使用 CPU 资源的最大值。</strong></p><p>第二点，cpu.shares 这个值决定了 <strong>CPU Cgroup 子系统下控制组可用 CPU 的相对比例</strong>，不过只有当系统上 CPU 完全被占满的时候，这个比例才会在各个控制组间起作用。</p><h3 id="现象解释"><a href="#现象解释" class="headerlink" title="现象解释"></a>现象解释</h3><p>在解释了 Linux CPU Usage 和 CPU Cgroup 这两个基本概念之后，我们再回到我们最初的问题 “怎么限制容器的 CPU 使用”。有了基础知识的铺垫，这个问题就比较好解释了。</p><p>首先，Kubernetes 会为每个容器都在 CPUCgroup 的子系统中建立一个控制组，然后把容器中进程写入到这个控制组里。</p><p>这时候”Limit CPU”就需要为容器设置可用 CPU 的上限。结合前面我们讲的几个参数么，我们就能知道容器的 CPU 上限具体如何计算了。</p><p>容器 CPU 的上限由 cpu.cfs_quota_us 除以 cpu.cfs_period_us 得出的值来决定的。而且，在操作系统里，cpu.cfs_period_us 的值一般是个固定值，Kubernetes 不会去修改它，所以我们就是只修改 cpu.cfs_quota_us。</p><p>而”Request CPU”就是无论其他容器申请多少 CPU 资源，即使运行时整个节点的 CPU 都被占满的情况下，我的这个容器还是可以保证获得需要的 CPU 数目，那么这个设置具体要怎么实现呢？</p><p>显然我们需要设置 cpu.shares 这个参数：<strong>在 CPU Cgroup 中 cpu.shares == 1024 表示 1 个 CPU 的比例，那么 Request CPU 的值就是 n，给 cpu.shares 的赋值对应就是 n*1024。</strong></p><!--### 重点总结这里你要注意的是**每个进程的 CPU Usage 只包含用户态（us 或 ni）和内核态（sy）两部分，其他的系统 CPU 开销并不包含在进程的 CPU 使用中，而 CPU Cgroup 只是对进程的 CPU 使用做了限制。**其实这一讲我们开篇的问题“怎么限制容器的 CPU 使用”，这个问题背后隐藏了另一个问题，也就是容器是如何设置它的 CPU Cgroup 中参数值的？想解决这个问题，就要先知道 CPU Cgroup 都有哪些参数。所以，我详细给你介绍了 CPU Cgroup 中的主要参数，包括这三个：**cpu.cfs_quota_us，cpu.cfs_period_us 还有 cpu.shares。**其中，cpu.cfs_quota_us（一个调度周期里这个控制组被允许的运行时间）除以 cpu.cfs_period_us（用于设置调度周期）得到的这个值决定了 CPU  Cgroup 每个控制组中 CPU 使用的上限值。你还需要掌握一个 cpu.shares 参数，正是这个值决定了 CPU  Cgroup 子系统下控制组可用 CPU 的相对比例，当系统上 CPU 完全被占满的时候，这个比例才会在各个控制组间起效。最后，我们明白了 CPU Cgroup 关键参数是什么含义后，Kubernetes 中"Limit CPU"和 "Request CPU"也就很好解释了: **Limit CPU 就是容器所在 Cgroup 控制组中的 CPU 上限值，Request CPU 的值就是控制组中的 cpu.shares 的值。**--><h2 id="容器CPU（2）：如何正确地拿到容器CPU的开销？"><a href="#容器CPU（2）：如何正确地拿到容器CPU的开销？" class="headerlink" title="容器CPU（2）：如何正确地拿到容器CPU的开销？"></a>容器CPU（2）：如何正确地拿到容器CPU的开销？</h2><h3 id="问题重现"><a href="#问题重现" class="headerlink" title="问题重现"></a>问题重现</h3><p>实际上，你在使用容器的时候，如果运行 top 命令来查看当前容器总共使用了多少 CPU，你肯定马上就会失望了。</p><p>这是因为我们在容器中运行 top 命令，虽然可以看到容器中每个进程的 CPU 使用率，但是 top 中”%Cpu(s)”那一行中显示的数值，并不是这个容器的 CPU 整体使用率，而是容器宿主机的 CPU 使用率。</p><p>就像下面的这个例子，我们在一个 12 个 CPU 的宿主机上，启动一个容器，然后在容器里运行 top 命令。</p><p>这时我们可以看到，容器里有两个进程 threads-cpu，总共消耗了 200% 的 CPU（2 CPU  Usage），而”%Cpu(s)”那一行的”us cpu”是 58.5%。对于 12CPU 的系统来说，12 * 58.5%=7.02，也就是说这里显示总共消耗了 7 个 CPU，远远大于容器中 2 个 CPU 的消耗。</p><p><img src="/images/docker/docker-05/8.jpg" alt="8"></p><p>这个例子说明，top 这个工具虽然在物理机或者虚拟机上看得到系统 CPU 开销，但是如果是放在容器环境下，运行 top 就无法得到容器中总的 CPU 使用率。那么，我们还有什么其他的办法吗？</p><h2 id="进程-CPU-使用率和系统-CPU-使用率"><a href="#进程-CPU-使用率和系统-CPU-使用率" class="headerlink" title="进程 CPU 使用率和系统 CPU 使用率"></a>进程 CPU 使用率和系统 CPU 使用率</h2><p>通过问题重现，我们发现 top 工具主要显示了宿主机系统整体的 CPU 使用率，以及单个进程的 CPU 使用率。既然没有现成的工具可以得到容器 CPU 开销，那我们需要自己开发一个工具来解决问题了。</p><p>其实我们自己推导，也没有那么难。我认为，最有效的思路还是从原理上去理解问题。</p><p>所以，在解决怎样得到单个容器整体的 CPU 使用率这个问题之前，我们先来学习一下，在 Linux 中到底是如何计算单个进程的 CPU 使用率，还有整个系统的 CPU 使用率的。</p><h3 id="进程-CPU-使用率"><a href="#进程-CPU-使用率" class="headerlink" title="进程 CPU 使用率"></a>进程 CPU 使用率</h3><p>Linux 中每个进程的 CPU 使用率，我们都可以用 top 命令查看。</p><p>对照我们前面的那张示意图，我们可以发现，每个进程在 top 命令输出中都有对应的一行，然后“%CPU”的那一列就是这个进程的实时 CPU 使用率了。</p><p>比如说，100% 就表示这个进程在这个瞬时使用了 1 个 CPU，200% 就是使用了 2 个 CPU。那么这个百分比的数值是怎么得到呢？</p><p>最直接的方法，就是从源头开始寻找答案。因为是 top 命令的输出，我们可以去看一下 top 命令的源代码。在代码中你会看到对于每个进程，top 都会从 proc 文件系统中每个进程对应的 stat 文件中读取 2 个数值。我们先来看这个文件，再来解读文件中具体的两个数值。</p><p>这个 stat 文件就是 /proc/[pid]/stat ， [pid] 就是替换成具体一个进程的 PID 值。比如 PID 值为 1 的进程，这个文件就是 /proc/1/stat ，那么这个 /proc/[pid]/stat 文件里有什么信息呢？</p><p>其实这个 stat 文件实时输出了进程的状态信息，比如进程的运行态（Running 还是 Sleeping）、父进程 PID、进程优先级、进程使用的内存等等总共 50 多项。</p><p>完整的 stat 文件内容和格式在 proc 文件系统的 Linux programmer’s manual 里定义了。在这里，我们只需要重点关注这两项数值，stat 文件中的第 14 项 utime 和第 15 项 stime。</p><p><img src="/images/docker/docker-05/9.jpg" alt="9"></p><p>那么这两项数值 utime 和 stime 是什么含义呢？utime 是表示进程的用户态部分在 Linux 调度中获得 CPU 的 ticks，stime 是表示进程的内核态部分在 Linux 调度中获得 CPU 的 ticks。</p><p>看到这个解释，你可能又冒出一个新问题，疑惑 ticks 是什么? 这个 ticks 就是 Linux 操作系统中的一个时间单位，你可以理解成类似秒，毫秒的概念。</p><p>在 Linux 中有个自己的时钟，它会周期性地产生中断。每次中断都会触发 Linux 内核去做一次进程调度，而这一次中断就是一个 tick。因为是周期性的中断，比如 1 秒钟 100 次中断，那么一个 tick 作为一个时间单位看的话，也就是 1/100 秒。</p><p>我给你举个例子说明，假如进程的 utime 是 130ticks，就相当于 130 * 1/100=1.3 秒，也就是进程从启动开始在用户态总共运行了 1.3 秒钟。</p><p>这里需要你注意，utime 和 stime 都是一个累计值，也就是说从进程启动开始，这两个值就是一直在累积增长的。</p><p>那么我们怎么计算，才能知道某一进程在用户态和内核态中，分别获得了多少 CPU 的 ticks 呢？</p><p>首先，我们可以假设这个瞬时是 1 秒钟，这 1 秒是 T1 时刻到 T2 时刻之间的，那么这样我们就能获得 T1 时刻的 utime_1 和 stime_1，同时获得 T2 时刻的 utime_2 和 stime_2。</p><p>在这 1 秒的瞬时，进程用户态获得的 CPU ticks 就是 (utime_2 – utime_1), 进程内核态获得的 CPU ticks 就是 (stime_2 – stime_1)。</p><p>那么我们可以推导出，进程 CPU 总的开销就是用户态加上内核态，也就是在 1 秒瞬时进程总的 CPU ticks 等于 (utime_2 – utime_1) + (stime_2 – stime_1)。</p><p>好了，现在我们得到了进程以 ticks 为单位的 CPU 开销，接下来还要做个转化。我们怎样才能把这个值转化成我们熟悉的百分比值呢？其实也不难，我们还是可以去 top 的源代码里得到这个百分比的计算公式。</p><p>简单总结一下，这个公式是这样的：</p><p><strong>进程的 CPU 使用率 =((utime_2 – utime_1) + (stime_2 – stime_1)) * 100.0 / (HZ * et * 1 )</strong></p><p>接下来，我再给你讲一下，这个公式里每一个部分的含义。</p><p>首先， ((utime_2 – utime_1) + (stime_2 – stime_1)) 是瞬时进程总的 CPU ticks。这个我们已经在前面解释过了。</p><p>其次，我们来看 100.0，这里乘以 100.0 的目的是产生百分比数值。</p><p>最后，我再讲一下  <strong>(HZ * et * 1)</strong>。这是被除数这里的三个参数，我给你详细解释一下。</p><p>第一个 HZ 是什么意思呢？前面我们介绍 ticks 里说了，ticks 是按照固定频率发生的，在我们的 Linux 系统里 1 秒钟是 100 次，那么 HZ 就是 1 秒钟里 ticks 的次数，这里值是 100。</p><p>第二个参数 et 是我们刚才说的那个“瞬时”的时间，也就是得到 utime_1 和 utime_2 这两个值的时间间隔。</p><p>第三个“1”, 就更容易理解了，就是 1 个 CPU。那么这三个值相乘，你是不是也知道了它的意思呢？就是在这“瞬时”的时间（et）里，1 个 CPU 所包含的 ticks 数目。</p><p>解释了这些参数，我们可以把这个公式简化一下，就是下面这样：</p><p>进程的 CPU 使用率 =（进程的 ticks/ 单个 CPU 总 ticks）*100.0</p><p>知道了这个公式，就需要上手来验证一下这个方法对不对，怎么验证呢？我们可以启动一个消耗 CPU 的小程序，然后读取一下进程对应的 /proc/[pid]/stat 中的 utime 和 stime，然后用这个方法来计算一下进程使用率这个百分比值，并且和 top 的输出对比一下，看看是否一致。</p><p>先启动一个消耗 200% 的小程序，它的 PID 是 10021，CPU 使用率是 200%。</p><p><img src="/images/docker/docker-05/10.jpg" alt="10"></p><p>然后，我们查看这个进程对应的 stat 文件 /proc/10021/stat，间隔 1 秒钟输出第二次，因为 stat 文件内容很多，我们知道 utime 和 stime 第 14 和 15 项，所以我们这里只截取了前 15 项的输出。这里可以看到，utime_1 = 399，stime_1=0，utime_2=600，stime_2=0。</p><p><img src="/images/docker/docker-05/11.jpg" alt="11"></p><p>根据前面的公式，我们计算一下进程 threads-cpu 的 CPU 使用率。套用前面的公式，计算的过程是：</p><p>((600 – 399) + (0 – 0)) * 100.0 / (100 * 1 * 1) =201，也就是 201%。你会发现这个值和我们运行 top 里的值是一样的。同时，我们也就验证了这个公式是没问题的。</p><h3 id="系统-CPU-使用率"><a href="#系统-CPU-使用率" class="headerlink" title="系统 CPU 使用率"></a>系统 CPU 使用率</h3><p>前面我们介绍了 Linux 中如何获取单个进程的 CPU 使用率，下面我们再来看看 Linux 里是怎么计算系统的整体 CPU 使用率的。</p><p>其实知道了如何计算单个进程的 CPU 使用率之后，要理解系统整体的 CPU 使用率计算方法就简单多了。</p><p>同样，我们要计算 CPU 使用率，首先需要拿到数据，数据源也同样可以从 proc 文件系统里得到，对于整个系统的 CPU 使用率，这个文件就是 /proc/stat。</p><p>在 /proc/stat 文件的 cpu 这行有 10 列数据，同样我们可以在 proc 文件系统的 Linux programmer’s manual 里，找到每一列数据的定义，而前 8 列数据正好对应 top 输出中”%Cpu(s)”那一行里的 8 项数据，也就是在上一讲中，我们介绍过的 user/system/nice/idle/iowait/irq/softirq/steal 这 8 项。</p><p><img src="/images/docker/docker-05/12.jpg" alt="12"></p><p>而在 /proc/stat 里的每一项的数值，就是系统自启动开始的 ticks。那么要计算出“瞬时”的 CPU 使用率，首先就要算出这个“瞬时”的 ticks，比如 1 秒钟的“瞬时”，我们可以记录开始时刻 T1 的 ticks, 然后再记录 1 秒钟后 T2 时刻的 ticks，再把这两者相减，就可以得到这 1 秒钟的 ticks 了。</p><p><img src="/images/docker/docker-05/13.jpg" alt="13"></p><p>这里我们可以得到，在这 1 秒钟里每个 CPU 使用率的 ticks：</p><p><img src="/images/docker/docker-05/14.jpg" alt="14"></p><p>我们想要计算每一种 CPU 使用率的百分比，其实也很简单。我们只需要把所有在这 1 秒里的 ticks 相加得到一个总值，然后拿某一项的 ticks 值，除以这个总值。比如说计算 idle CPU 的使用率就是：</p><p>（1203 / 0 + 0 + 0 + 1203 + 0 + 0 + 0 + 0）=100%</p><p>好了，我们现在来整体梳理一下，我们通过 Linux 里的工具，要怎样计算进程的 CPU 使用率和系统的 CPU 使用率。</p><p>对于单个进程的 CPU 使用率计算，我们需要读取对应进程的 /proc/[pid]/stat 文件，将进程瞬时用户态和内核态的 ticks 数相加，就能得到进程的总 ticks。</p><p>然后我们运用公式“(进程的 ticks / 单个 CPU 总 ticks) * 100.0”计算出进程 CPU 使用率的百分比值。</p><p>对于系统的 CPU 使用率，需要读取 /proc/stat 文件，得到瞬时各项 CPU 使用率的 ticks 值，相加得到一个总值，单项值除以总值就是各项 CPU 的使用率。</p><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>前面我们学习了在 Linux 中，top 工具是怎样计算每个进程的 CPU 使用率，以及系统总的 CPU 使用率。现在我们再来看最初的问题：为什么在容器中运行 top 命令不能得到容器中总的 CPU 使用率？</p><p>这就比较好解释了，对于系统总的 CPU 使用率，需要读取 /proc/stat 文件，但是这个文件中的各项 CPU ticks 是反映整个节点的，并且这个 /proc/stat 文件也不包含在任意一个 Namespace 里。</p><p>那么，<strong>对于 top 命令来说，它只能显示整个节点中各项 CPU 的使用率，不能显示单个容器的各项 CPU 的使用率</strong>。既然 top 命令不行，我们还有没有办法得到整个容器的 CPU 使用率呢？</p><p>我们之前已经学习过了 CPU Cgroup，每个容器都会有一个 CPU Cgroup 的控制组。在这个控制组目录下面有很多参数文件，有的参数可以决定这个控制组里最大的 CPU 可使用率外，除了它们之外，目录下面还有一个可读项 cpuacct.stat。</p><p>这里包含了两个统计值，这两个值分别是<strong>这个控制组里所有进程的内核态 ticks 和用户态的 ticks</strong>，那么我们就可以用前面讲过的公式，也就是计算进程 CPU 使用率的公式，去计算整个容器的 CPU 使用率：</p><p>CPU 使用率 =((utime_2 – utime_1) + (stime_2 – stime_1)) * 100.0 / (HZ * et * 1 )</p><p>我们还是以问题重现中的例子说明，也就是最开始启动容器里的那两个容器 threads-cpu 进程。</p><p>就像下图显示的这样，整个容器的 CPU 使用率的百分比就是 ( (174021 - 173820) + (4 – 4)) * 100.0 / (100 * 1 * 1) = 201, 也就是 201%。<strong>所以，我们从每个容器的 CPU Cgroup 控制组里的 cpuacct.stat 的统计值中，</strong>可以比较快地得到整个容器的 CPU 使用率。</p><p><img src="/images/docker/docker-05/15.jpg" alt="15"></p><!--## 重点总结Linux 里获取 CPU 使用率的工具，比如 top，都是通过读取 proc 文件系统下的 stat 文件来得到 CPU 使用了多少 ticks。而这里的 ticks，是 Linux 操作系统里的一个时间单位，可以理解成类似秒，毫秒的概念。对于每个进程来说，它的 stat 文件是 /proc/[pid]/stat，里面包含了进程用户态和内核态的 ticks 数目；对于整个节点，它的 stat 文件是 /proc/stat，里面包含了 user/system/nice/idle/iowait 等不同 CPU 开销类型的 ticks。**由于 /proc/stat 文件是整个节点全局的状态文件，不属于任何一个 Namespace，因此在容器中无法通过读取 /proc/stat 文件来获取单个容器的 CPU 使用率。**所以要得到单个容器的 CPU 使用率，我们可以从 CPU Cgroup 每个控制组里的统计文件 cpuacct.stat 中获取。**单个容器 CPU 使用率 =((utime_2 – utime_1) + (stime_2 – stime_1)) \* 100.0 / (HZ \* et \* 1 )。**得到单个容器的 CPU 的使用率，那么当宿主机上负载变高的时候，就可以很快知道是哪个容器引起的问题。同时，用户在管理自己成百上千的容器的时候，也可以很快发现 CPU 使用率异常的容器，这样就能及早地介入去解决问题。--><h2 id="Load-Average：加了CPU-Cgroup限制，为什么我的容器还是很慢？"><a href="#Load-Average：加了CPU-Cgroup限制，为什么我的容器还是很慢？" class="headerlink" title="Load Average：加了CPU Cgroup限制，为什么我的容器还是很慢？"></a>Load Average：加了CPU Cgroup限制，为什么我的容器还是很慢？</h2><h3 id="问题再现"><a href="#问题再现" class="headerlink" title="问题再现"></a>问题再现</h3><p>在 Linux 的系统维护中，我们需要经常查看 CPU 使用情况，再根据这个情况分析系统整体的运行状态。有时候你可能会发现，明明容器里所有进程的 CPU 使用率都很低，甚至整个宿主机的 CPU 使用率都很低，而机器的 Load Average 里的值却很高，容器里进程运行得也很慢。</p><p>这么说有些抽象，我们一起动手再现一下这个情况，这样你就能更好地理解这个问题了。</p><p>比如说下面的 top 输出，第三行可以显示当前的 CPU 使用情况，我们可以看到整个机器的 CPU Usage 几乎为 0，因为”id”显示 99.9%，这说明 CPU 是处于空闲状态的。</p><p>但是请你注意，这里 1 分钟的”load average”的值却高达 9.09，这里的数值 9 几乎就意味着使用了 9 个 CPU 了，这样 CPU Usage 和 Load Average 的数值看上去就很矛盾了。</p><p><img src="/images/docker/docker-05/16.jpg" alt="16"></p><p>那问题来了，我们在看一个系统里 CPU 使用情况时，到底是看 CPU Usage 还是 Load Average 呢？</p><p>这里就涉及到今天要解决的两大问题：</p><ol><li>Load Average 到底是什么，CPU Usage 和 Load Average 有什么差别？</li><li>如果 Load Average 值升高，应用的性能下降了，这背后的原因是什么呢？</li></ol><p>好了，这一讲我们就带着这两个问题，一起去揭开谜底。</p><h3 id="什么是-Load-Average"><a href="#什么是-Load-Average" class="headerlink" title="什么是 Load Average?"></a>什么是 Load Average?</h3><p>要回答前面的问题，很显然我们要搞明白这个 Linux 里的”load average”这个值是什么意思，又是怎样计算的。</p><p>Load Average 这个概念，你可能在使用 Linux 的时候就已经注意到了，无论你是运行 uptime, 还是 top，都可以看到类似这个输出”load average：2.02, 1.83, 1.20”。那么这一串输出到底是什么意思呢？</p><p>最直接的办法当然是看手册了，如果我们用”Linux manual page”搜索 uptime 或者 top，就会看到对这个”load average”和后面三个数字的解释是”the system load averages for the past 1, 5, and 15 minutes”。</p><p>这个解释就是说，后面的三个数值分别代表过去 1 分钟，5 分钟，15 分钟在这个节点上的 Load Average，但是看了手册上的解释，我们还是不能理解什么是 Load Average。</p><p>这个时候，你如果再去网上找资料，就会发现 Load Average 是一个很古老的概念了。上个世纪 70 年代，早期的 Unix 系统上就已经有了这个 Load Average，IETF 还有一个RFC546定义了 Load Average，这里定义的 Load Average 是<strong>一种 CPU 资源需求的度量。</strong></p><p>举个例子，对于一个单个 CPU 的系统，如果在 1 分钟的时间里，处理器上始终有一个进程在运行，同时操作系统的进程可运行队列中始终都有 9 个进程在等待获取 CPU 资源。那么对于这 1 分钟的时间来说，系统的”load average”就是 1+9=10，这个定义对绝大部分的 Unix 系统都适用。</p><p>对于 Linux 来说，如果只考虑 CPU 的资源，Load Averag 等于单位时间内正在运行的进程加上可运行队列的进程，这个定义也是成立的。通过这个定义和我自己的观察，我给你归纳了下面三点对 Load Average 的理解。</p><p>第一，不论计算机 CPU 是空闲还是满负载，Load Average 都是 Linux 进程调度器中<strong>可运行队列（Running Queue）里的一段时间的平均进程数目。</strong></p><p>第二，计算机上的 CPU 还有空闲的情况下，CPU Usage 可以直接反映到”load average”上，什么是 CPU 还有空闲呢？具体来说就是可运行队列中的进程数目小于 CPU 个数，这种情况下，单位时间进程 CPU Usage 相加的平均值应该就是”load average”的值。</p><p>第三，计算机上的 CPU 满负载的情况下，计算机上的 CPU 已经是满负载了，同时还有更多的进程在排队需要 CPU 资源。这时”load average”就不能和 CPU Usage 等同了。</p><p>比如对于单个 CPU 的系统，CPU Usage 最大只是有 100%，也就 1 个 CPU；而”load average”的值可以远远大于 1，因为”load average”看的是操作系统中可运行队列中进程的个数。</p><p>这样的解释可能太抽象了，为了方便你理解，我们一起动手验证一下。</p><p>怎么验证呢？我们可以执行个程序来模拟一下, 先准备好一个可以消耗任意 CPU Usage 的程序，在执行这个程序的时候，后面加个数字作为参数，</p><p>比如下面的设置，参数是 2，就是说这个进程会创建出两个线程，并且每个线程都跑满 100% 的 CPU，2 个线程就是 2 * 100% = 200% 的 CPU Usage，也就是消耗了整整两个 CPU 的资源。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ./threads-cpu 2</span></span><br></pre></td></tr></table></figure><p>准备好了这个 CPU Usage 的模拟程序，我们就可以用它来查看 CPU Usage 和 Load Average 之间的关系了。</p><p>接下来我们一起跑两个例子，第一个例子是执行 2 个满负载的线程，第二个例子执行 6 个满负载的线程，同样都是在一台 4 个 CPU 的节点上。</p><p>先来看第一个例子，我们在一台 4 个 CPU 的计算机节点上运行刚才这个模拟程序，还是设置参数为 2，也就是使用 2 个 CPU Usage。在这个程序运行了几分钟之后，我们运行 top 来查看一下 CPU Usage 和 Load Average。</p><p>我们可以看到两个 threads-cpu 各自都占了将近 100% 的 CPU，两个就是 200%，2 个 CPU，对于 4 个 CPU 的计算机来说，CPU Usage 占了 50%，空闲了一半，这个我们也可以从 idle （id）：49.9% 得到印证。</p><p>这时候，Load Average 里第一项（也就是前 1 分钟的数值）为 1.98，近似于 2。这个值和我们一直运行的 200%CPU  Usage 相对应，也验证了我们之前归纳的第二点——<strong>CPU Usage 可以反映到 Load Average 上。</strong></p><p>因为运行的时间不够，前 5 分钟，前 15 分钟的 Load Average 还没有到 2，而且后面我们的例子程序一般都只会运行几分钟，所以这里我们只看前 1 分钟的 Load Average 值就行。</p><p>另外，Linux 内核中不使用浮点计算，这导致 Load Average 里的 1 分钟，5 分钟，15 分钟的时间值并不精确，但这不影响我们查看 Load Average 的数值，所以先不用管这个时间的准确性。</p><p><img src="/images/docker/docker-05/17.jpg" alt="17"></p><p>那我们再来跑第二个例子，同样在这个 4 个 CPU 的计算机节点上，如果我们执行 CPU Usage 模拟程 threads-cpu，设置参数为 6，让这个进程建出 6 个线程，这样每个线程都会尽量去抢占 CPU，但是计算机总共只有 4 个 CPU，所以这 6 个线程的 CPU Usage 加起来只是 400%。</p><p>显然这时候 4 个 CPU 都被占满了，我们可以看到整个节点的 idle（id）也已经是 0.0% 了。</p><p>但这个时候，我们看看前 1 分钟的 Load Average，数值不是 4 而是 5.93 接近 6，我们正好模拟了 6 个高 CPU 需求的线程。这也告诉我们，Load Average 表示的是一段时间里运行队列中需要被调度的进程 / 线程平均数目。</p><p><img src="/images/docker/docker-05/18.jpg" alt="18"></p><p>讲到这里，我们是不是就可以认定 Load Average 就代表一段时间里运行队列中需要被调度的进程或者线程平均数目了呢? 或许对其他的 Unix 系统来说，这个理解已经够了，但是对于 Linux 系统还不能这么认定。</p><p>为什么这么说呢？故事还要从 Linux 早期的历史说起，那时开发者 Matthias 有这么一个发现，比如把快速的磁盘换成了慢速的磁盘，运行同样的负载，系统的性能是下降的，但是 Load Average 却没有反映出来。</p><p>他发现这是因为 Load Average 只考虑运行态的进程数目，而没有考虑等待 I/O 的进程。所以，他认为 Load Average 如果只是考虑进程运行队列中需要被调度的进程或线程平均数目是不够的，因为对于处于 I/O 资源等待的进程都是处于 TASK_UNINTERRUPTIBLE 状态的。</p><p>那他是怎么处理这件事的呢？估计你也猜到了，他给内核加一个 patch（补丁），把处于 TASK_UNINTERRUPTIBLE 状态的进程数目也计入了 Load Average 中。</p><p>在这里我们又提到了 TASK_UNINTERRUPTIBLE 状态的进程，在前面的章节中我们介绍过，我再给你强调一下，<strong>TASK_UNINTERRUPTIBLE 是 Linux 进程状态的一种，是进程为等待某个系统资源而进入了睡眠的状态，并且这种睡眠的状态是不能被信号打断的。</strong></p><p>下面就是 1993 年 Matthias 的 kernel patch，你有兴趣的话，可以读一下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">From: Matthias Urlichs &lt;urlichs@smurf.sub.org&gt;</span><br><span class="line">Subject: Load average broken ?</span><br><span class="line">Date: Fri, <span class="number">29</span> Oct <span class="number">1993</span> <span class="number">11</span>:<span class="number">37</span>:<span class="number">23</span> +<span class="number">0200</span></span><br><span class="line">The kernel only counts <span class="string">"runnable"</span> processes when computing the load average.</span><br><span class="line">I don<span class="number">'</span>t like that; the problem is that processes which are swapping <span class="keyword">or</span></span><br><span class="line">waiting on <span class="string">"fast"</span>, i.e. noninterruptible, I/O, also consume resources.</span><br><span class="line">It seems somewhat nonintuitive that the load average goes down when you</span><br><span class="line">replace your fast swap disk with a slow swap disk...</span><br><span class="line">Anyway, the following patch seems to make the load average much more</span><br><span class="line">consistent WRT the subjective speed of the system. And, most important, the</span><br><span class="line">load is still zero when nobody is doing anything. ;-)</span><br><span class="line">--- kernel/sched.c.orig Fri Oct <span class="number">29</span> <span class="number">10</span>:<span class="number">31</span>:<span class="number">11</span> <span class="number">1993</span></span><br><span class="line">+++ kernel/sched.c Fri Oct <span class="number">29</span> <span class="number">10</span>:<span class="number">32</span>:<span class="number">51</span> <span class="number">1993</span></span><br><span class="line">@@ <span class="number">-414</span>,<span class="number">7</span> +<span class="number">414</span>,<span class="number">9</span> @@</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">long</span> nr = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(p = &amp;LAST_TASK; p &gt; &amp;FIRST_TASK; --p)</span><br><span class="line">-       <span class="keyword">if</span> (*p &amp;&amp; (*p)-&gt;state == TASK_RUNNING)</span><br><span class="line">+       <span class="keyword">if</span> (*p &amp;&amp; ((*p)-&gt;state == TASK_RUNNING) ||</span><br><span class="line">+                  (*p)-&gt;state == TASK_UNINTERRUPTIBLE) ||</span><br><span class="line">+                  (*p)-&gt;state == TASK_SWAPPING))</span><br><span class="line">            nr += FIXED_1;</span><br><span class="line">    <span class="keyword">return</span> nr;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>那么对于 Linux 的 Load Average 来说，除了可运行队列中的进程数目，等待队列中的 UNINTERRUPTIBLE 进程数目也会增加 Load Average。</p><p>为了验证这一点，我们可以模拟一下 UNINTERRUPTIBLE 的进程，来看看 Load Average 的变化。</p><p>这里我们做一个kernel module，通过一个 /proc 文件系统给用户程序提供一个读取的接口，只要用户进程读取了这个接口就会进入 UNINTERRUPTIBLE。这样我们就可以模拟两个处于 UNINTERRUPTIBLE 状态的进程，然后查看一下 Load Average 有没有增加。</p><p>我们发现程序跑了几分钟之后，前 1 分钟的 Load Average 差不多从 0 增加到了 2.16，节点上 CPU  Usage 几乎为 0，idle 为 99.8%。</p><p>可以看到，可运行队列（Running Queue）中的进程数目是 0，只有休眠队列（Sleeping Queue）中有两个进程，并且这两个进程显示为 D state 进程，这个 D state 进程也就是我们模拟出来的 TASK_UNINTERRUPTIBLE 状态的进程。</p><p>这个例子证明了 Linux 将 TASK_UNINTERRUPTIBLE 状态的进程数目计入了 Load Average 中，所以即使 CPU 上不做任何的计算，Load Average 仍然会升高。如果 TASK_UNINTERRUPTIBLE 状态的进程数目有几百几千个，那么 Load Average 的数值也可以达到几百几千。</p><p>proc-d-state.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/module.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/moduleparam.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/init.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/kernel.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/proc_fs.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/uaccess.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/sched.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/delay.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/version.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BUFSIZE  100</span></span><br><span class="line"></span><br><span class="line">MODULE_LICENSE(<span class="string">"GPL"</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">proc_dir_entry</span> *<span class="title">ent</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">ssize_t</span> <span class="title">mywrite</span><span class="params">(struct file *file, <span class="keyword">const</span> <span class="keyword">char</span> __user * ubuf,</span></span></span><br><span class="line"><span class="function"><span class="params">       <span class="keyword">size_t</span> count, <span class="keyword">loff_t</span> * ppos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">printk(KERN_DEBUG <span class="string">"write handler\n"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">ssize_t</span> <span class="title">myread</span><span class="params">(struct file *file, <span class="keyword">char</span> __user * ubuf, <span class="keyword">size_t</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">loff_t</span> * ppos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">printk(KERN_DEBUG <span class="string">"read handler\n"</span>);</span><br><span class="line"><span class="comment">/* The process is in UNINTERRUPTIBLE state */</span></span><br><span class="line">msleep(<span class="number">300000</span>);</span><br><span class="line">printk(KERN_DEBUG <span class="string">"read exit\n"</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> LINUX_VERSION_CODE &gt;= KERNEL_VERSION(5, 6, 0)</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">proc_ops</span> <span class="title">myops</span> = &#123;</span></span><br><span class="line">        .proc_read     = myread,</span><br><span class="line">        .proc_write    = mywrite,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">file_operations</span> <span class="title">myops</span> = &#123;</span></span><br><span class="line">.owner = THIS_MODULE,</span><br><span class="line">.<span class="built_in">read</span> = myread,</span><br><span class="line">.<span class="built_in">write</span> = mywrite,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">simple_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">ent = proc_create(<span class="string">"mydev"</span>, <span class="number">0660</span>, <span class="literal">NULL</span>, &amp;myops);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">simple_cleanup</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">proc_remove(ent);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">module_init(simple_init);</span><br><span class="line">module_exit(simple_cleanup);</span><br></pre></td></tr></table></figure><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">obj-m := proc-d-state.o</span><br><span class="line"></span><br><span class="line">KDIR := /lib/modules/`uname -r`/build/</span><br><span class="line">PWD := <span class="variable">$(<span class="built_in">shell</span> pwd)</span></span><br><span class="line"></span><br><span class="line"><span class="section">default:</span></span><br><span class="line"><span class="variable">$(MAKE)</span> -C <span class="variable">$(KDIR)</span> M=<span class="variable">$(PWD)</span> modules</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line"><span class="variable">$(MAKE)</span> -C <span class="variable">$(KDIR)</span> M=<span class="variable">$(PWD)</span> clean</span><br></pre></td></tr></table></figure><p><img src="/images/docker/docker-05/19.jpg" alt="19"></p><p>好了，到这里我们就可以准确定义 Linux 系统里的 Load Average 了，其实也很简单，你只需要记住，平均负载统计了这两种情况的进程：</p><p>第一种是 Linux 进程调度器中可运行队列（Running Queue）一段时间（1 分钟，5 分钟，15 分钟）的进程平均数。</p><p>第二种是 Linux 进程调度器中休眠队列（Sleeping Queue）里的一段时间的 TASK_UNINTERRUPTIBLE 状态下的进程平均数。</p><p>所以，最后的公式就是：<strong>Load Average= 可运行队列进程平均数 + 休眠队列中不可打断的进程平均数</strong></p><p>如果打个比方来说明 Load Average 的统计原理。你可以想象每个 CPU 就是一条道路，每个进程都是一辆车，怎么科学统计道路的平均负载呢？就是看单位时间通过的车辆，一条道上的车越多，那么这条道路的负载也就越高。</p><p>此外，Linux 计算系统负载的时候，还额外做了个补丁把 TASK_UNINTERRUPTIBLE 状态的进程也考虑了，这个就像道路中要把红绿灯情况也考虑进去。一旦有了红灯，汽车就要停下来排队，那么即使道路很空，但是红灯多了，汽车也要排队等待，也开不快。</p><h3 id="现象解释：为什么-Load-Average-会升高？"><a href="#现象解释：为什么-Load-Average-会升高？" class="headerlink" title="现象解释：为什么 Load Average 会升高？"></a>现象解释：为什么 Load Average 会升高？</h3><p>解释了 Load Average 这个概念，我们再回到这一讲最开始的问题，为什么对容器已经用 CPU  Cgroup 限制了它的 CPU  Usage，容器里的进程还是可以造成整个系统很高的 Load Average。</p><p>我们理解了 Load Average 这个概念之后，就能区分出 Load Averge 和 CPU 使用率的区别了。那么这个看似矛盾的问题也就很好回答了，因为 <strong>Linux 下的 Load Averge 不仅仅计算了 CPU Usage 的部分，它还计算了系统中 TASK_UNINTERRUPTIBLE 状态的进程数目。</strong></p><p>讲到这里为止，我们找到了第一个问题的答案，那么现在我们再看第二个问题：如果 Load Average 值升高，应用的性能已经下降了，真正的原因是什么？问题就出在 TASK_UNINTERRUPTIBLE 状态的进程上了。</p><p>怎么验证这个判断呢？这时候我们只要运行 ps aux | grep “ D ” ，就可以看到容器中有多少 TASK_UNINTERRUPTIBLE 状态（在 ps 命令中这个状态的进程标示为”D”状态）的进程，为了方便理解，后面我们简称为 D 状态进程。而正是这些 D 状态进程引起了 Load Average 的升高。</p><p>找到了 Load Average 升高的问题出在 D 状态进程了，我们想要真正解决问题，还有必要了解 D 状态进程产生的本质是什么？</p><p>在 Linux 内核中有数百处调用点，它们会把进程设置为 D 状态，主要集中在 disk I/O 的访问和信号量（Semaphore）锁的访问上，因此 D 状态的进程在 Linux 里是很常见的。</p><p><strong>无论是对 disk I/O 的访问还是对信号量的访问，都是对 Linux 系统里的资源的一种竞争。</strong>当进程处于 D 状态时，就说明进程还没获得资源，这会在应用程序的最终性能上体现出来，也就是说用户会发觉应用的性能下降了。</p><p>那么 D 状态进程导致了性能下降，我们肯定是想方设法去做调试的。但目前 D 状态进程引起的容器中进程性能下降问题，Cgroups 还不能解决，这也就是为什么我们用 Cgroups 做了配置，即使保证了容器的 CPU 资源， 容器中的进程还是运行很慢的根本原因。</p><p>这里我们进一步做分析，为什么 CPU Cgroups 不能解决这个问题呢？就是因为 Cgroups 更多的是以进程为单位进行隔离，而 D 状态进程是内核中系统全局资源引入的，所以 Cgroups 影响不了它。</p><p>所以我们可以做的是，在生产环境中监控容器的宿主机节点里 D 状态的进程数量，然后对 D 状态进程数目异常的节点进行分析，比如磁盘硬件出现问题引起 D 状态进程数目增加，这时就需要更换硬盘。</p><!-- ### 重点总结这一讲我们从 CPU  Usage 和 Load Average 差异这个现象讲起，最主要的目的是讲清楚 Linux 下的 Load Average 这个概念。在其他 Unix 操作系统里 Load Average 只考虑 CPU 部分，Load Average 计算的是进程调度器中可运行队列（Running Queue）里的一段时间（1 分钟，5 分钟，15 分钟）的平均进程数目，而 Linux 在这个基础上，又加上了进程调度器中休眠队列（Sleeping Queue）里的一段时间的 TASK_UNINTERRUPTIBLE 状态的平均进程数目。这里你需要重点掌握 Load Average 的计算公式，如下图。![20][20]因为 TASK_UNINTERRUPTIBLE 状态的进程同样也会竞争系统资源，所以它会影响到应用程序的性能。我们可以在容器宿主机的节点对 D 状态进程做监控，定向分析解决。最后，我还想强调一下，这一讲中提到的对 D 状态进程进行监控也很重要，因为这是通用系统性能的监控方法。--><h2 id="容器内存：我的容器为什么被杀了？"><a href="#容器内存：我的容器为什么被杀了？" class="headerlink" title="容器内存：我的容器为什么被杀了？"></a>容器内存：我的容器为什么被杀了？</h2><h3 id="问题再现-1"><a href="#问题再现-1" class="headerlink" title="问题再现"></a>问题再现</h3><p>容器在系统中被杀掉，其实只有一种情况，那就是容器中的进程使用了太多的内存。具体来说，就是容器里所有进程使用的内存量，超过了容器所在 Memory Cgroup 里的内存限制。这时 Linux 系统就会主动杀死容器中的一个进程，往往这会导致整个容器的退出。</p><p>我们可以做个简单的容器，模拟一下这种容器被杀死的场景。</p><p>接下来，我们用下面的这个脚本来启动容器，我们先把这个容器的 Cgroup 内存上限设置为 512MB（536870912 bytes）。</p><p>mem_alloc.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BLOCK_SIZE (1024*1024)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> thr, i;</span><br><span class="line"><span class="keyword">char</span> *p1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Usage: mem_alloc &lt;num (MB)&gt;\n"</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">thr = atoi(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Allocating,"</span> <span class="string">"set to %d Mbytes\n"</span>, thr);</span><br><span class="line">sleep(<span class="number">30</span>);</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; thr; i++) &#123;</span><br><span class="line">p1 = <span class="built_in">malloc</span>(BLOCK_SIZE);</span><br><span class="line"><span class="built_in">memset</span>(p1, <span class="number">0x00</span>, BLOCK_SIZE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sleep(<span class="number">600</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: image</span></span><br><span class="line"></span><br><span class="line"><span class="section">mem_alloc: mem-alloc/mem_alloc.c</span></span><br><span class="line">gcc -o mem-alloc/mem_alloc mem-alloc/mem_alloc.c</span><br><span class="line"><span class="section">image: mem_alloc</span></span><br><span class="line">docker build -t registry/mem_alloc:v1 .</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">rm mem-alloc/mem_alloc -f</span><br><span class="line">docker stop mem_alloc;docker rm mem_alloc;docker rmi registry/mem_alloc:v1</span><br></pre></td></tr></table></figure><p>Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./mem-alloc/mem_alloc /</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"/mem_alloc"</span>, <span class="string">"2000"</span>]</span></span><br></pre></td></tr></table></figure><p>start_container.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">docker stop mem_alloc;docker rm mem_alloc</span><br><span class="line"></span><br><span class="line">docker run -d --name mem_alloc registry/mem_alloc:v1</span><br><span class="line"></span><br><span class="line">sleep 2</span><br><span class="line">CONTAINER_ID=$(sudo docker ps --format <span class="string">"&#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Names&#125;&#125;"</span> | grep -i mem_alloc | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CONTAINER_ID</span></span><br><span class="line"></span><br><span class="line">CGROUP_CONTAINER_PATH=$(find /sys/fs/cgroup/memory/ -name <span class="string">"*<span class="variable">$CONTAINER_ID</span>*"</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CGROUP_CONTAINER_PATH</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 536870912 &gt; <span class="variable">$CGROUP_CONTAINER_PATH</span>/memory.limit_in_bytes</span><br><span class="line">cat <span class="variable">$CGROUP_CONTAINER_PATH</span>/memory.limit_in_bytes</span><br></pre></td></tr></table></figure><p>好了，容器启动后，里面有一个小程序 mem_alloc 会不断地申请内存。当它申请的内存超过 512MB 的时候，你就会发现，我们启动的这个容器消失了。</p><p><img src="/images/docker/docker-05/21.jpg" alt="21"></p><p>这时候，如果我们运行docker inspect 命令查看容器退出的原因，就会看到容器处于”exited”状态，并且”OOMKilled”是 true。</p><p><img src="/images/docker/docker-05/22.jpg" alt="22"></p><p>那么问题来了，什么是 OOM Killed 呢？它和之前我们对容器 Memory Cgroup 做的设置有什么关系，又是怎么引起容器退出的？想搞清楚这些问题，我们就需要先理清楚基本概念。</p><h3 id="如何理解-OOM-Killer？"><a href="#如何理解-OOM-Killer？" class="headerlink" title="如何理解 OOM Killer？"></a>如何理解 OOM Killer？</h3><p>我们先来看一看 OOM Killer 是什么意思。</p><p>OOM 是 Out of Memory 的缩写，顾名思义就是内存不足的意思，而 Killer 在这里指需要杀死某个进程。那么 OOM Killer 就是<strong>在 Linux 系统里如果内存不足时，就需要杀死一个正在运行的进程来释放一些内存。</strong></p><p>那么讲到这里，你可能会有个问题了，Linux 里的程序都是调用 malloc() 来申请内存，如果内存不足，直接 malloc() 返回失败就可以，为什么还要去杀死正在运行的进程呢？</p><p>其实，这个和 Linux 进程的内存申请策略有关，Linux 允许进程在申请内存的时候是 overcommit 的，这是什么意思呢？就是说允许进程申请超过实际物理内存上限的内存。</p><p>为了让你更好地理解，我给你举个例子说明。比如说，节点上的空闲物理内存只有 512MB 了，但是如果一个进程调用 malloc() 申请了 600MB，那么 malloc() 的这次申请还是被允许的。</p><p>这是因为 malloc() 申请的是内存的虚拟地址，系统只是给了程序一个地址范围，由于没有写入数据，所以程序并没有得到真正的物理内存。物理内存只有程序真的往这个地址写入数据的时候，才会分配给程序。</p><p>可以看得出来，这种 overcommit 的内存申请模式可以带来一个好处，它可以有效提高系统的内存利用率。不过这也带来了一个问题，也许你已经猜到了，就是物理内存真的不够了，又该怎么办呢？</p><p>为了方便你理解，我给你打个比方，这个有点像航空公司在卖飞机票。售卖飞机票的时候往往是超售的。比如说实际上有 100 个位子，航空公司会卖 105 张机票，在登机的时候如果实际登机的乘客超过了 100 个，那么就需要按照一定规则，不允许多出的几位乘客登机了。</p><p>同样的道理，遇到内存不够的这种情况，Linux 采取的措施就是杀死某个正在运行的进程。</p><p>那么你一定会问了，在发生 OOM 的时候，Linux 到底是根据什么标准来选择被杀的进程呢？这就要提到一个在 Linux 内核里有一个 <strong>oom_badness() 函数</strong>，就是它定义了选择进程的标准。其实这里的判断标准也很简单，函数中涉及两个条件：</p><p>第一，进程已经使用的物理内存页面数。</p><p>第二，每个进程的 OOM 校准值 oom_score_adj。在 /proc 文件系统中，每个进程都有一个 /proc//oom_score_adj 的接口文件。我们可以在这个文件中输入 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">adj = (<span class="keyword">long</span>)p-&gt;signal-&gt;oom_score_adj;</span><br><span class="line">      points = get_mm_rss(p-&gt;mm) + get_mm_counter(p-&gt;mm, MM_SWAPENTS) +mm_pgtables_bytes(p-&gt;mm) / PAGE_SIZE;</span><br><span class="line">      adj *= totalpages / <span class="number">1000</span>;</span><br><span class="line">      points += adj;</span><br></pre></td></tr></table></figure><p>结合前面说的两个条件，函数 oom_badness() 里的最终计算方法是这样的：</p><p><strong>用系统总的可用页面数，去乘以 OOM 校准值 oom_score_adj，再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大。</strong></p><h3 id="如何理解-Memory-Cgroup？"><a href="#如何理解-Memory-Cgroup？" class="headerlink" title="如何理解 Memory Cgroup？"></a>如何理解 Memory Cgroup？</h3><p>前面我们介绍了 OOM Killer，容器发生 OOM Kill 大多是因为 Memory Cgroup 的限制所导致的，所以在我们还需要理解 Memory Cgroup 的运行机制。</p><p>在前面我们讲过 Cgroups 是容器的两大支柱技术之一，在 CPU 的章节中，我们也讲到了 CPU Cgroups。那么按照同样的思路，我们想理解容器 Memory，自然要讨论一下 Memory Cgroup 了。</p><p>Memory Cgroup 也是 Linux Cgroups 子系统之一，它的作用是对一组进程的 Memory 使用做限制。Memory Cgroup 的虚拟文件系统的挂载点一般在”/sys/fs/cgroup/memory”这个目录下，这个和 CPU Cgroup 类似。我们可以在 Memory Cgroup 的挂载点目录下，创建一个子目录作为控制组。</p><p>每一个控制组下面有不少参数，在这一讲里，这里我们只讲跟 OOM 最相关的 3 个参数：<strong>memory.limit_in_bytes，memory.oom_control 和 memory.usage_in_bytes</strong>。其他参数如果你有兴趣了解，可以参考内核的文档说明。</p><p>首先我们来看第一个参数，叫作 memory.limit_in_bytes。请你注意，这个 memory.limit_in_bytes 是每个控制组里最重要的一个参数了。这是因为一个控制组里所有进程可使用内存的最大值，就是由这个参数的值来直接限制的。</p><p>那么一旦达到了最大值，在这个控制组里的进程会发生什么呢？</p><p>这就涉及到我要给你讲的第二个参数 memory.oom_control 了。这个 memory.oom_control 又是干啥的呢？当控制组中的进程内存使用达到上限值时，这个参数能够决定会不会触发 OOM Killer。</p><p>如果没有人为设置的话，memory.oom_control 的缺省值就会触发 OOM Killer。这是一个控制组内的 OOM Killer，和整个系统的 OOM Killer 的功能差不多，差别只是被杀进程的选择范围：控制组内的 OOM Killer 当然只能杀死控制组内的进程，而不能选节点上的其他进程。</p><p>如果我们要改变缺省值，也就是不希望触发 OOM Killer，只要执行 echo 1 &gt; memory.oom_control  就行了，这时候即使控制组里所有进程使用的内存达到 memory.limit_in_bytes 设置的上限值，控制组也不会杀掉里面的进程。</p><p>但是，我想提醒你，这样操作以后，就会影响到控制组中正在申请物理内存页面的进程。这些进程会处于一个停止状态，不能往下运行了。</p><p>最后，我们再来学习一下第三个参数，也就是 memory.usage_in_bytes。这个参数是只读的，它里面的数值是当前控制组里所有进程实际使用的内存总和。</p><p>我们可以查看这个值，然后把它和 memory.limit_in_bytes 里的值做比较，根据接近程度来可以做个预判。这两个值越接近，OOM 的风险越高。通过这个方法，我们就可以得知，当前控制组内使用总的内存量有没有 OOM 的风险了。</p><p>控制组之间也同样是树状的层级结构，在这个结构中，父节点的控制组里的 memory.limit_in_bytes 值，就可以限制它的子节点中所有进程的内存使用。</p><p>我用一个具体例子来说明，比如像下面图里展示的那样，group1 里的 memory.limit_in_bytes 设置的值是 200MB，它的子控制组 group3 里 memory.limit_in_bytes 值是 500MB。那么，我们在 group3 里所有进程使用的内存总值就不能超过 200MB，而不是 500MB。</p><p><img src="/images/docker/docker-05/23.jpg" alt="23"></p><p>好了，我们这里介绍了 Memory Cgroup 最基本的概念，简单总结一下：</p><p>第一，Memory Cgroup 中每一个控制组可以为一组进程限制内存使用量，一旦所有进程使用内存的总量达到限制值，缺省情况下，就会触发 OOM Killer。这样一来，控制组里的“某个进程”就会被杀死。</p><p>第二，这里杀死“某个进程”的选择标准是，<strong>控制组中总的可用页面乘以进程的 oom_score_adj，加上进程已经使用的物理内存页面，所得值最大的进程，就会被系统选中杀死。</strong></p><h3 id="解决问题-1"><a href="#解决问题-1" class="headerlink" title="解决问题"></a>解决问题</h3><p>我们解释了 Memory Cgroup 和 OOM Killer 后，你应该明白了为什么容器在运行过程中会突然消失了。</p><p>对于每个容器创建后，系统都会为它建立一个 Memory Cgroup 的控制组，容器的所有进程都在这个控制组里。</p><p>一般的容器云平台，比如 Kubernetes 都会为容器设置一个内存使用的上限。这个内存的上限值会被写入 Cgroup 里，具体来说就是容器对应的 Memory Cgroup 控制组里 memory.limit_in_bytes 这个参数中。</p><p>所以，一旦容器中进程使用的内存达到了上限值，OOM Killer 会杀死进程使容器退出。</p><p><strong>那么我们怎样才能快速确定容器发生了 OOM 呢？这个可以通过查看内核日志及时地发现。</strong></p><p>还是拿我们这一讲最开始发生 OOM 的容器作为例子。我们通过查看内核的日志，使用用 journal -k 命令，或者直接查看日志文件 /var/log/message，我们会发现当容器发生 OOM Kill 的时候，内核会输出下面的这段信息，大致包含下面这三部分的信息：</p><p>第一个部分就是<strong>容器里每一个进程使用的内存页面数量。</strong>在”rss”列里，”rss’是 Resident Set Size 的缩写，指的就是进程真正在使用的物理内存页面数量。</p><p>比如下面的日志里，我们看到 init 进程的”rss”是 1 个页面，mem_alloc 进程的”rss”是 130801 个页面，内存页面的大小一般是 4KB，我们可以做个估算，130801 * 4KB 大致等于 512MB。</p><p><img src="/images/docker/docker-05/24.jpg" alt="24"></p><p>第二部分我们来看上面图片的 <strong>“oom-kill:”</strong> 这行，这一行里列出了发生 OOM 的 Memroy Cgroup 的控制组，我们可以从控制组的信息中知道 OOM 是在哪个容器发生的。</p><p>第三部分是图中 <strong>“Killed process 7445 (mem_alloc)” 这行，它显示了最终被 OOM Killer 杀死的进程。</strong></p><p>我们通过了解内核日志里的这些信息，可以很快地判断出容器是因为 OOM 而退出的，并且还可以知道是哪个进程消耗了最多的 Memory。</p><p>那么知道了哪个进程消耗了最大内存之后，我们就可以有针对性地对这个进程进行分析了，一般有这两种情况：</p><p>第一种情况是<strong>这个进程本身的确需要很大的内存</strong>，这说明我们给 memory.limit_in_bytes 里的内存上限值设置小了，那么就需要增大内存的上限值。</p><p>第二种情况是<strong>进程的代码中有 Bug，会导致内存泄漏，进程内存使用到达了 Memory Cgroup 中的上限。</strong>如果是这种情况，就需要我们具体去解决代码里的问题了。</p><!--### 重点总结这一讲我们从容器在系统中被杀的问题，学习了 OOM Killer 和 Memory Cgroup 这两个概念。OOM Killer 这个行为在 Linux 中很早就存在了，它其实是一种内存过载后的保护机制，通过牺牲个别的进程，来保证整个节点的内存不会被全部消耗掉。在 Cgroup 的概念出现后，Memory Cgroup 中每一个控制组可以对一组进程限制内存使用量，一旦所有进程使用内存的总量达到限制值，在缺省情况下，就会触发 OOM Killer，控制组里的“某个进程”就会被杀死。请注意，这里 Linux 系统肯定不能随心所欲地杀掉进程，那具体要用什么选择标准呢？杀掉“某个进程”的选择标准，涉及到内核函数 oom_badness()。具体的计算方法是  ：**系统总的可用页面数乘以进程的 OOM 校准值 oom_score_adj，再加上进程已经使用的物理页面数，计算出来的值越大，那么这个进程被 OOM Kill 的几率也就越大。**接下来，我给你讲解了 Memory Cgroup 里最基本的三个参数，分别是 **memory.limit_in_bytes， memory.oom_control 和 memory.usage_in_bytes。**我把这三个参数的作用，给你总结成了一张图。第一个和第三个参数，下一讲中我们还会用到，这里你可以先有个印象。![25][25]容器因为 OOM 被杀，要如何处理呢？我们可以通过内核日志做排查，查看容器里内存使用最多的进程，然后对它进行分析。根据我的经验，解决思路要么是提高容器的最大内存限制，要么需要我们具体去解决进程代码的 BUG。--><h2 id="Page-Cache：为什么我的容器内存使用量总是在临界点"><a href="#Page-Cache：为什么我的容器内存使用量总是在临界点" class="headerlink" title="Page Cache：为什么我的容器内存使用量总是在临界点?"></a>Page Cache：为什么我的容器内存使用量总是在临界点?</h2><h3 id="问题再现-2"><a href="#问题再现-2" class="headerlink" title="问题再现"></a>问题再现</h3><p>我们可以用这里的代码做个容器镜像，然后用下面的这个脚本启动容器，并且设置容器 Memory Cgroup 里的内存上限值是 100MB（104857600bytes）。</p><p>mem_alloc.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BLOCK_SIZE (1024*1024)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> thr, i;</span><br><span class="line"><span class="keyword">char</span> *p1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (argc != <span class="number">2</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Usage: mem_alloc &lt;num (MB)&gt;\n"</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">thr = atoi(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Allocating,"</span> <span class="string">"set to %d Mbytes\n"</span>, thr);</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; thr; i++) &#123;</span><br><span class="line">p1 = <span class="built_in">malloc</span>(BLOCK_SIZE);</span><br><span class="line"><span class="built_in">memset</span>(p1, <span class="number">0x00</span>, BLOCK_SIZE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">sleep(<span class="number">600</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>read_file.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt; </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt; </span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt; </span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BUFFER_SIZE (1024 * 1024)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BLOCKS800</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">char</span> buf[BUFFER_SIZE];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> fd;</span><br><span class="line"><span class="keyword">int</span> i, ret = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">char</span> *p1;</span><br><span class="line"><span class="keyword">int</span> blocks;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (argc != <span class="number">3</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Usage: read_file &lt;filename&gt; &lt;blocks&gt;"</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">blocks = atoi(argv[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">fd = <span class="built_in">open</span>(argv[<span class="number">1</span>], O_RDONLY);</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; blocks; i++) &#123;</span><br><span class="line">ret = <span class="built_in">read</span>(fd, buf, BUFFER_SIZE);</span><br><span class="line"><span class="keyword">if</span> (ret &lt; <span class="number">0</span>)</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d read error \n"</span>, i);</span><br><span class="line">&#125;</span><br><span class="line">sleep(<span class="number">2</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Read again\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">close</span>(fd);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./mem-alloc/mem_alloc /</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./<span class="built_in">read</span>-file/read_file /</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"/read_file"</span>, <span class="string">"/mnt/test.file"</span>, <span class="string">"100"</span>]</span></span><br></pre></td></tr></table></figure><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: image</span></span><br><span class="line"></span><br><span class="line"><span class="section">mem_alloc: mem-alloc/mem_alloc.c</span></span><br><span class="line">gcc -o mem-alloc/mem_alloc mem-alloc/mem_alloc.c</span><br><span class="line"><span class="section">read_file: read-file/read_file.c</span></span><br><span class="line">gcc -o read-file/read_file read-file/read_file.c</span><br><span class="line"><span class="section">image: mem_alloc read_file</span></span><br><span class="line">docker build -t registry/page_cache_test:v1 .</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">rm mem-alloc/mem_alloc -f</span><br><span class="line">rm read-file/read_file -f</span><br><span class="line">docker rmi registry/page_cache_test:v1</span><br></pre></td></tr></table></figure><p>start_container.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">docker stop page_cache;docker rm page_cache</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -f ./test.file ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">dd <span class="keyword">if</span>=/dev/zero of=./test.file bs=4096 count=30000</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Please run start_container.sh again "</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">echo</span> 3 &gt; /proc/sys/vm/drop_caches</span><br><span class="line">sleep 10</span><br><span class="line"></span><br><span class="line">docker run -d --init --name page_cache -v $(<span class="built_in">pwd</span>):/mnt registry/page_cache_test:v1</span><br><span class="line">CONTAINER_ID=$(sudo docker ps --format <span class="string">"&#123;&#123;.ID&#125;&#125;\t&#123;&#123;.Names&#125;&#125;"</span> | grep -i page_cache | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$CONTAINER_ID</span></span><br><span class="line">CGROUP_CONTAINER_PATH=$(find /sys/fs/cgroup/memory/ -name <span class="string">"*<span class="variable">$CONTAINER_ID</span>*"</span>)</span><br><span class="line"><span class="built_in">echo</span> 104857600 &gt; <span class="variable">$CGROUP_CONTAINER_PATH</span>/memory.limit_in_bytes</span><br><span class="line">cat <span class="variable">$CGROUP_CONTAINER_PATH</span>/memory.limit_in_bytes</span><br></pre></td></tr></table></figure><p>把容器启动起来后，我们查看一下容器的 Memory Cgroup 下的 memory.limit_in_bytes 和 memory.usage_in_bytes 这两个值。</p><p>如下图所示，我们可以看到容器内存的上限值设置为 104857600bytes（100MB），而这时整个容器的已使用内存显示为 104767488bytes，这个值已经非常接近上限值了。</p><p>我们把容器内存上限值和已使用的内存数值做个减法，104857600–104767488= 90112bytes，只差大概 90KB 左右的大小。</p><p><img src="/images/docker/docker-05/26.jpg" alt="26"></p><p>但是，如果这时候我们继续启动一个程序，让这个程序申请并使用 50MB 的物理内存，就会发现这个程序还是可以运行成功，这时候容器并没有发生 OOM 的情况。</p><p>这时我们再去查看参数 memory.usage_in_bytes，就会发现它的值变成了 103186432bytes，比之前还少了一些。那这是怎么回事呢？</p><p><img src="/images/docker/docker-05/27.jpg" alt="27"></p><h3 id="知识详解：Linux-系统有那些内存类型？"><a href="#知识详解：Linux-系统有那些内存类型？" class="headerlink" title="知识详解：Linux 系统有那些内存类型？"></a>知识详解：Linux 系统有那些内存类型？</h3><p>要解释刚才我们看到的容器里内存分配的现象，就需要先理解 Linux 操作系统里有哪几种内存的类型。</p><p>因为我们只有知道了内存的类型，才能明白每一种类型的内存，容器分别使用了多少。而且，对于不同类型的内存，一旦总内存增高到容器里内存最高限制的数值，相应的处理方式也不同。</p><h3 id="Linux-内存类型"><a href="#Linux-内存类型" class="headerlink" title="Linux 内存类型"></a>Linux 内存类型</h3><p>Linux 的各个模块都需要内存，比如内核需要分配内存给页表，内核栈，还有 slab，也就是内核各种数据结构的 Cache Pool；用户态进程里的堆内存和栈的内存，共享库的内存，还有文件读写的 Page Cache。</p><p>在这一讲里，我们讨论的 Memory Cgroup 里都不会对内核的内存做限制（比如页表，slab 等）。所以我们今天主要讨论<strong>与用户态相关的两个内存类型，RSS 和 Page Cache。</strong></p><h3 id="RSS"><a href="#RSS" class="headerlink" title="RSS"></a>RSS</h3><p>先看什么是 RSS。RSS 是 Resident Set Size 的缩写，简单来说它就是指进程真正申请到物理页面的内存大小。这是什么意思呢？</p><p>应用程序在申请内存的时候，比如说，调用 malloc() 来申请 100MB 的内存大小，malloc() 返回成功了，这时候系统其实只是把 100MB 的虚拟地址空间分配给了进程，但是并没有把实际的物理内存页面分配给进程。</p><p>上一讲中，我给你讲过，当进程对这块内存地址开始做真正读写操作的时候，系统才会把实际需要的物理内存分配给进程。而这个过程中，进程真正得到的物理内存，就是这个 RSS 了。</p><p>比如下面的这段代码，我们先用 malloc 申请 100MB 的内存。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">p = <span class="built_in">malloc</span>(<span class="number">100</span> * MB);</span><br><span class="line">        <span class="keyword">if</span> (p == <span class="literal">NULL</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure><p>然后，我们运行 top 命令查看这个程序在运行了 malloc() 之后的内存，我们可以看到这个程序的虚拟地址空间（VIRT）已经有了 106728KB（～100MB)，但是实际的物理内存 RSS（top 命令里显示的是 RES，就是 Resident 的简写，和 RSS 是一个意思）在这里只有 688KB。</p><p><img src="/images/docker/docker-05/28.jpg" alt="28"></p><p>接着我们在程序里等待 30 秒之后，我们再对这块申请的空间里写入 20MB 的数据。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sleep(<span class="number">30</span>);</span><br><span class="line"><span class="built_in">memset</span>(p, <span class="number">0x00</span>, <span class="number">20</span> * MB)</span><br></pre></td></tr></table></figure><p>当我们用 memset() 函数对这块地址空间写入 20MB 的数据之后，我们再用 top 查看，这时候可以看到虚拟地址空间（VIRT）还是 106728，不过物理内存 RSS（RES）的值变成了 21432（大小约为 20MB）， 这里的单位都是 KB。</p><p><img src="/images/docker/docker-05/29.jpg" alt="29"></p><p>所以，通过刚才上面的小实验，我们可以验证 RSS 就是进程里真正获得的物理内存大小。</p><p>对于进程来说，RSS 内存包含了进程的代码段内存，栈内存，堆内存，共享库的内存, 这些内存是进程运行所必须的。刚才我们通过 malloc/memset 得到的内存，就是属于堆内存。</p><p>具体的每一部分的 RSS 内存的大小，你可以查看 /proc/[pid]/smaps 文件。</p><h3 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h3><p>每个进程除了各自独立分配到的 RSS 内存外，如果进程对磁盘上的文件做了读写操作，Linux 还会分配内存，把磁盘上读写到的页面存放在内存中，这部分的内存就是 Page Cache。</p><p>Page Cache 的主要作用是提高磁盘文件的读写性能，因为系统调用 read() 和 write() 的缺省行为都会把读过或者写过的页面存放在 Page Cache 里。</p><p>还是用我们这一讲最开始的的例子：代码程序去读取 100MB 的文件，在读取文件前，系统中 Page Cache 的大小是 388MB，读取后 Page Cache 的大小是 506MB，增长了大约 100MB 左右，多出来的这 100MB，正是我们读取文件的大小。</p><p><img src="/images/docker/docker-05/30.jpg" alt="30"></p><p>在 Linux 系统里只要有空闲的内存，系统就会自动地把读写过的磁盘文件页面放入到 Page Cache 里。那么这些内存都被 Page Cache 占用了，一旦进程需要用到更多的物理内存，执行 malloc() 调用做申请时，就会发现剩余的物理内存不够了，那该怎么办呢？</p><p>这就要提到 Linux 的内存管理机制了。 <strong>Linux 的内存管理有一种内存页面回收机制（page frame reclaim），会根据系统里空闲物理内存是否低于某个阈值（wartermark），来决定是否启动内存的回收。</strong></p><p>内存回收的算法会根据不同类型的内存以及内存的最近最少用原则，就是 LRU（Least Recently Used）算法决定哪些内存页面先被释放。因为 Page Cache 的内存页面只是起到 Cache 作用，自然是会被优先释放的。</p><p>所以，Page Cache 是一种为了提高磁盘文件读写性能而利用空闲物理内存的机制。同时，内存管理中的页面回收机制，又能保证 Cache 所占用的页面可以及时释放，这样一来就不会影响程序对内存的真正需求了。</p><h3 id="RSS-amp-Page-Cache-in-Memory-Cgroup"><a href="#RSS-amp-Page-Cache-in-Memory-Cgroup" class="headerlink" title="RSS &amp; Page Cache in Memory Cgroup"></a>RSS &amp; Page Cache in Memory Cgroup</h3><p>学习了 RSS 和 Page Cache 的基本概念之后，我们下面来看不同类型的内存，特别是 RSS 和 Page Cache 是如何影响 Memory Cgroup 的工作的。</p><p>我们先从 Linux 的内核代码看一下，从 mem_cgroup_charge_statistics() 这个函数里，我们可以看到 Memory Cgroup 也的确只是统计了 RSS 和 Page Cache 这两部分的内存。</p><p>RSS 的内存，就是在当前 Memory Cgroup 控制组里所有进程的 RSS 的总和；而 Page Cache 这部分内存是控制组里的进程读写磁盘文件后，被放入到 Page Cache 里的物理内存。</p><p><img src="/images/docker/docker-05/31.jpg" alt="31"></p><p>Memory Cgroup 控制组里 RSS 内存和 Page Cache 内存的和，正好是 memory.usage_in_bytes 的值。</p><p>当控制组里的进程需要申请新的物理内存，而且 memory.usage_in_bytes 里的值超过控制组里的内存上限值 memory.limit_in_bytes，这时我们前面说的 Linux 的内存回收（page frame reclaim）就会被调用起来。</p><p>那么在这个控制组里的 page cache 的内存会根据新申请的内存大小释放一部分，这样我们还是能成功申请到新的物理内存，整个控制组里总的物理内存开销 memory.usage_in_bytes 还是不会超过上限值 memory.limit_in_bytes。</p><h3 id="解决问题-2"><a href="#解决问题-2" class="headerlink" title="解决问题"></a>解决问题</h3><p>明白了 Memory Cgroup 中内存类型的统计方法，我们再回过头看这一讲开头的问题，为什么 memory.usage_in_bytes 与 memory.limit_in_bytes 的值只相差了 90KB，我们在容器中还是可以申请出 50MB 的物理内存？</p><p>我想你应该已经知道答案了，容器里肯定有大于 50MB 的内存是 Page Cache，因为作为 Page Cache 的内存在系统需要新申请物理内存的时候（作为 RSS）是可以被释放的。</p><p>知道了这个答案，那么我们怎么来验证呢？验证的方法也挺简单的，在 Memory Cgroup 中有一个参数 memory.stat，可以显示在当前控制组里各种内存类型的实际的开销。</p><p>那我们还是拿这一讲的容器例子，再跑一遍代码，这次要查看一下 memory.stat 里的数据。</p><p>第一步，我们还是用同样的脚本来启动容器，并且设置好容器的 Memory Cgroup 里的 memory.limit_in_bytes 值为 100MB。</p><p>启动容器后，这次我们不仅要看 memory.usage_in_bytes 的值，还要看一下 memory.stat。虽然 memory.stat 里的参数有不少，但我们目前只需要关注”cache”和”rss”这两个值。</p><p>我们可以看到，容器启动后，cache，也就是 Page Cache 占的内存是 99508224bytes，大概是 99MB，而 RSS 占的内存只有 1826816bytes，也就是 1MB 多一点。</p><p>这就意味着，在这个容器的 Memory Cgroup 里大部分的内存都被用作了 Page Cache，而这部分内存是可以被回收的。</p><p><img src="/images/docker/docker-05/32.jpg" alt="32"></p><p>那么我们再执行一下我们的mem_alloc 程序，申请 50MB 的物理内存。</p><p>我们可以再来查看一下 memory.stat，这时候 cache 的内存值降到了 46632960bytes，大概 46MB，而 rss 的内存值到了 54759424bytes，54MB 左右吧。总的 memory.usage_in_bytes 值和之前相比，没有太多的变化。</p><p><img src="/images/docker/docker-05/33.jpg" alt="33"></p><p>从这里我们发现，Page Cache 内存对我们判断容器实际内存使用率的影响，目前 Page Cache 完全就是 Linux 内核的一个自动的行为，只要读写磁盘文件，只要有空闲的内存，就会被用作 Page Cache。</p><p>所以，判断容器真实的内存使用量，我们不能用 Memory Cgroup 里的 memory.usage_in_bytes，而需要用 memory.stat 里的 rss 值。这个很像我们用 free 命令查看节点的可用内存，不能看”free”字段下的值，而要看除去 Page Cache 之后的”available”字段下的值。</p><!--### 重点总结这一讲我想让你知道，每个容器的 Memory Cgroup 在统计每个控制组的内存使用时包含了两部分，RSS 和 Page Cache。RSS 是每个进程实际占用的物理内存，它包括了进程的代码段内存，进程运行时需要的堆和栈的内存，这部分内存是进程运行所必须的。Page Cache 是进程在运行中读写磁盘文件后，作为 Cache 而继续保留在内存中的，它的目的是**为了提高磁盘文件的读写性能。**当节点的内存紧张或者 Memory Cgroup 控制组的内存达到上限的时候，Linux 会对内存做回收操作，这个时候 Page Cache 的内存页面会被释放，这样空出来的内存就可以分配给新的内存申请。正是 Page Cache 内存的这种 Cache 的特性，对于那些有频繁磁盘访问容器，我们往往会看到它的内存使用率一直接近容器内存的限制值（memory.limit_in_bytes）。但是这时候，我们并不需要担心它内存的不够， 我们在判断一个容器的内存使用状况的时候，可以把 Page Cache 这部分内存使用量忽略，而更多的考虑容器中 RSS 的内存使用量。--><h2 id="Swap：容器可以使用Swap空间吗？"><a href="#Swap：容器可以使用Swap空间吗？" class="headerlink" title="Swap：容器可以使用Swap空间吗？"></a>Swap：容器可以使用Swap空间吗？</h2><p>用过 Linux 的同学应该都很熟悉 Swap 空间了，简单来说它就是就是一块磁盘空间。</p><p>当内存写满的时候，就可以把内存中不常用的数据暂时写到这个 Swap 空间上。这样一来，内存空间就可以释放出来，用来满足新的内存申请的需求。</p><p>它的好处是可以应对一些瞬时突发的内存增大需求，不至于因为内存一时不够而触发 OOM Killer，导致进程被杀死。<br>那么对于一个容器，特别是容器被设置了 Memory Cgroup 之后，它还可以使用 Swap 空间吗？会不会出现什么问题呢？</p><h3 id="问题再现-3"><a href="#问题再现-3" class="headerlink" title="问题再现"></a>问题再现</h3><p>接下来，我们就结合一个小例子，一起来看看吧。</p><p>首先，我们在一个有 Swap 空间的节点上启动一个容器，设置好它的 Memory Cgroup 的限制，一起来看看接下来会发生什么。</p><p>如果你的节点上没有 Swap 分区，也没有关系，你可以用下面的这组命令来新建一个。</p><p>这个例子里，Swap 空间的大小是 20G，你可以根据自己磁盘空闲空间来决定这个 Swap 的大小。执行完这组命令之后，我们来运行 free 命令，就可以看到 Swap 空间有 20G。</p><p>create_swap.sh</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">fallocate -l 20G ./swapfile</span><br><span class="line">dd <span class="keyword">if</span>=/dev/zero of=./swapfile bs=1024 count=20971520</span><br><span class="line">chmod 600 ./swapfile</span><br><span class="line">mkswap ./swapfile</span><br><span class="line">swapon swapfile</span><br></pre></td></tr></table></figure><p>输出的结果你可以参考下面的截图。</p><p><img src="/images/docker/docker-05/34.jpg" alt="34"></p><p>然后我们再启动一个容器，和 OOM 那一讲里的例子差不多，容器的 Memory Cgroup 限制为 512MB，容器中的 mem_alloc 程序去申请 2GB 内存。</p><p>你会发现，这次和上次 OOM 那一讲里的情况不一样了，并没有发生 OOM 导致容器退出的情况，容器运行得好好的。</p><p>从下面的图中，我们可以看到，mem_alloc 进程的 RSS 内存一直在 512MB（RES: 515596）左右。</p><p><img src="/images/docker/docker-05/35.jpg" alt="35"></p><p>那我们再看一下 Swap 空间，使用了 1.5GB (used 1542144KB)。输出的结果如下图，简单计算一下，1.5GB + 512MB，结果正好是 mem_alloc 这个程序申请的 2GB 内存。</p><p><img src="/images/docker/docker-05/36.jpg" alt="36"></p><p>通过刚刚的例子，你也许会这么想，因为有了 Swap 空间，本来会被 OOM Kill 的容器，可以好好地运行了。初看这样似乎也挺好的，不过你仔细想想，这样一来，Memory Cgroup 对内存的限制不就失去了作用么？</p><p>我们再进一步分析，如果一个容器中的程序发生了内存泄漏（Memory leak），那么本来 Memory Cgroup 可以及时杀死这个进程，让它不影响整个节点中的其他应用程序。结果现在这个内存泄漏的进程没被杀死，还会不断地读写 Swap 磁盘，反而影响了整个节点的性能。</p><p>你看，这样一分析，对于运行容器的节点，你是不是又觉得应该禁止使用 Swap 了呢?</p><p>我想提醒你，不能一刀切地下结论，我们总是说，具体情况要具体分析，我们落地到具体的场景里，就会发现情况又没有原先我们想得那么简单。</p><p>比如说，某一类程序就是需要 Swap 空间，才能防止因为偶尔的内存突然增加而被 OOM Killer 杀死。因为这类程序重新启动的初始化时间会很长，这样程序重启的代价就很大了，也就是说，打开 Swap 对这类程序是有意义的。</p><p>这一类程序一旦放到容器中运行，就意味着它会和“别的容器”在同一个宿主机上共同运行，那如果这个“别的容器” 如果不需要 Swap，而是希望 Memory Cgroup 的严格内存限制。</p><p>这样一来，在这一个宿主机上的两个容器就会有冲突了，我们应该怎么解决这个问题呢？要解决这个问题，我们先来看看 Linux 里的 Swappiness 这个概念，后面它可以帮到我们。</p><h3 id="如何正确理解-swappiness-参数？"><a href="#如何正确理解-swappiness-参数？" class="headerlink" title="如何正确理解 swappiness 参数？"></a>如何正确理解 swappiness 参数？</h3><p>在普通 Linux 系统上，如果你使用过 Swap 空间，那么你可能配置过 proc 文件系统下的 swappiness 这个参数 (/proc/sys/vm/swappiness)。swappiness 的定义在Linux 内核文档中可以找到，就是下面这段话。</p><blockquote><p>swappiness<br>This control is used to define how aggressive the kernel will swap memory pages.  Higher values will increase aggressiveness, lower values decrease the amount of swap.  A value of 0 instructs the kernel not to initiate swap until the amount of free and file-backed pages is less than the high water mark in a zone.<br>The default value is 60.</p></blockquote><p>前面两句话大致翻译过来，意思就是 <strong>swappiness 可以决定系统将会有多频繁地使用交换分区。</strong></p><p>一个较高的值会使得内核更频繁地使用交换分区，而一个较低的取值，则代表着内核会尽量避免使用交换分区。swappiness 的取值范围是 0–100，缺省值 60。</p><p>我第一次读到这个定义，再知道了这个取值范围后，我觉得这是一个百分比值，也就是定义了使用 Swap 空间的频率。</p><p>当这个值是 100 的时候，哪怕还有空闲内存，也会去做内存交换，尽量把内存数据写入到 Swap 空间里；值是 0 的时候，基本上就不做内存交换了，也就不写 Swap 空间了。</p><p>后来再回顾的时候，我发现这个想法不能说是完全错的，但是想得简单了些。那这段 swappiness 的定义，应该怎么正确地理解呢？</p><p>你还记得，我们在上一讲里说过的两种内存类型 Page Cache 和 RSS 么?</p><p>在有磁盘文件访问的时候，Linux 会尽量把系统的空闲内存用作 Page Cache 来提高文件的读写性能。在没有打开 Swap 空间的情况下，一旦内存不够，这种情况下就只能把 Page Cache 释放了，而 RSS 内存是不能释放的。</p><p>在 RSS 里的内存，大部分都是没有对应磁盘文件的内存，比如用 malloc() 申请得到的内存，这种内存也被称为<strong>匿名内存（Anonymous memory）</strong>。那么当 Swap 空间打开后，可以写入 Swap 空间的，就是这些匿名内存。</p><p>所以在 Swap 空间打开的时候，问题也就来了，在内存紧张的时候，Linux 系统怎么决定是先释放 Page Cache，还是先把匿名内存释放并写入到 Swap 空间里呢？</p><p>我们一起来分析分析，都可能发生怎样的情况。最可能发生的是下面两种情况：</p><p>第一种情况是，如果系统先把 Page Cache 都释放了，那么一旦节点里有频繁的文件读写操作，系统的性能就会下降。</p><p>还有另一种情况，如果 Linux 系统先把匿名内存都释放并写入到 Swap，那么一旦这些被释放的匿名内存马上需要使用，又需要从 Swap 空间读回到内存中，这样又会让 Swap（其实也是磁盘）的读写频繁，导致系统性能下降。</p><p>显然，我们在释放内存的时候，需要平衡 Page Cache 的释放和匿名内存的释放，而 swappiness，就是用来定义这个平衡的参数。</p><p>那么 swappiness 具体是怎么来控制这个平衡的？我们看一下在 Linux 内核代码里是怎么用这个 swappiness 参数。</p><p>我们前面说了 swappiness 的这个值的范围是 0 到 100，但是请你一定要注意，<strong>它不是一个百分比，更像是一个权重</strong>。它是用来定义 Page Cache 内存和匿名内存的释放的一个比例。</p><p>我结合下面的这段代码具体给你讲一讲。</p><p>我们可以看到，这个比例是 anon_prio: file_prio，这里 anon_prio 的值就等于 swappiness。下面我们分三个情况做讨论：</p><p>第一种情况，当 swappiness 的值是 100 的时候，匿名内存和 Page Cache 内存的释放比例就是 100: 100，也就是等比例释放了。</p><p>第二种情况，就是 swappiness 缺省值是 60 的时候，匿名内存和 Page Cache 内存的释放比例就是 60 : 140，Page Cache 内存的释放要优先于匿名内存。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">      * With swappiness at 100, anonymous and file have the same priority.</span></span><br><span class="line"><span class="comment">      * This scanning priority is essentially the inverse of IO cost.</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">     anon_prio = swappiness;</span><br><span class="line">     file_prio = <span class="number">200</span> - anon_prio;</span><br></pre></td></tr></table></figure><p>还有一种情况， 当 swappiness 的值是 0 的时候，会发生什么呢？这种情况下，Linux 系统是不允许匿名内存写入 Swap 空间了吗？</p><p>我们可以回到前面，再看一下那段 swappiness 的英文定义，里面特别强调了 swappiness 为 0 的情况。</p><p>当空闲内存少于内存一个 zone 的”high water mark”中的值的时候，Linux 还是会做内存交换，也就是把匿名内存写入到 Swap 空间后释放内存。</p><p>在这里 zone 是 Linux 划分物理内存的一个区域，里面有 3 个水位线（water mark），水位线可以用来警示空闲内存的紧张程度。</p><p>这里我们可以再做个试验来验证一下，先运行 echo 0 &gt; /proc/sys/vm/swappiness 命令把 swappiness 设置为 0， 然后用我们之前例子里的 mem_alloc 程序来申请内存。</p><p>比如我们的这个节点上内存有 12GB，同时有 2GB 的 Swap，用 mem_alloc 申请 12GB 的内存，我们可以看到 Swap 空间在 mem_alloc 调用之前，used=0，输出结果如下图所示。</p><p><img src="/images/docker/docker-05/37.jpg" alt="37"></p><p>接下来，调用 mem_alloc 之后，Swap 空间就被使用了。</p><p><img src="/images/docker/docker-05/38.jpg" alt="38"></p><p>因为 mem_alloc 申请 12GB 内存已经和节点最大内存差不多了，我们如果查看 cat /proc/zoneinfo ，也可以看到 normal zone 里 high （water mark）的值和 free 的值差不多，这样在 <code>free&lt;high</code> 的时候，系统就会回收匿名内存页面并写入 Swap 空间。</p><p><img src="/images/docker/docker-05/39.jpg" alt="39"></p><p>好了，在这里我们介绍了 Linux 系统里 swappiness 的概念，它是用来决定在内存紧张时候，回收匿名内存和 Page Cache 内存的比例。</p><p><strong>swappiness 的取值范围在 0 到 100，值为 100 的时候系统平等回收匿名内存和 Page Cache 内存；一般缺省值为 60，就是优先回收 Page Cache；即使 swappiness 为 0，也不能完全禁止 Swap 分区的使用，就是说在内存紧张的时候，也会使用 Swap 来回收匿名内存。</strong></p><h3 id="解决问题-3"><a href="#解决问题-3" class="headerlink" title="解决问题"></a>解决问题</h3><p>那么运行了容器，使用了 Memory Cgroup 之后，swappiness 怎么工作呢？</p><p>如果你查看一下 Memory Cgroup 控制组下面的参数，你会看到有一个 memory.swappiness 参数。这个参数是干啥的呢？</p><p>memory.swappiness 可以控制这个 Memroy Cgroup 控制组下面匿名内存和 page cache 的回收，取值的范围和工作方式和全局的 swappiness 差不多。这里有一个优先顺序，在 Memory Cgorup 的控制组里，如果你设置了 memory.swappiness 参数，它就会覆盖全局的 swappiness，让全局的 swappiness 在这个控制组里不起作用。</p><p>不过，这里有一点不同，需要你留意：<strong>当 memory.swappiness = 0 的时候，对匿名页的回收是始终禁止的，也就是始终都不会使用 Swap 空间。</strong></p><p>这时 Linux 系统不会再去比较 free 内存和 zone 里的 high water mark 的值，再决定一个 Memory Cgroup 中的匿名内存要不要回收了。</p><p>请你注意，当我们设置了”memory.swappiness=0 时，在 Memory Cgroup 中的进程，就不会再使用 Swap 空间，知道这一点很重要。</p><p>我们可以跑个容器试一试，还是在一个有 Swap 空间的节点上运行，运行和这一讲开始一样的容器，唯一不同的是把容器对应 Memory Cgroup 里的 memory.swappiness 设置为 0。</p><p><img src="/images/docker/docker-05/40.jpg" alt="40"></p><p>这次我们在容器中申请内存之后，Swap 空间就没有被使用了，而当容器申请的内存超过 memory.limit_in_bytes 之后，就发生了 OOM Kill。</p><p>好了，有了”memory.swappiness = 0”的配置和功能，就可以解决我们在这一讲里最开始提出的问题了。</p><p>在同一个宿主机上，假设同时存在容器 A 和其他容器，容器 A 上运行着需要使用 Swap 空间的应用，而别的容器不需要使用 Swap 空间。</p><p>那么，我们还是可以在宿主机节点上打开 Swap 空间，同时在其他容器对应的 Memory Cgroups 控制组里，把 memory.swappiness 这个参数设置为 0。这样一来，我们不但满足了容器 A 的需求，而且别的容器也不会受到影响，仍然可以严格按照 Memory Cgroups 里的 memory.limit_in_bytes 来限制内存的使用。</p><p>总之，memory.swappiness 这个参数很有用，通过它可以让需要使用 Swap 空间的容器和不需要 Swap 的容器，同时运行在同一个宿主机上。</p><!--### 重点总结这一讲，我们主要讨论的问题是在容器中是否可以使用 Swap？这个问题没有看起来那么简单。当然了，只要在宿主机节点上打开 Swap 空间，在容器中就是可以用到 Swap 的。但出现的问题是在同一个宿主机上，对于不需要使用 swap 的容器， 它的 Memory Cgroups 的限制也失去了作用。针对这个问题，我们学习了 Linux 中的 swappiness 这个参数。swappiness 参数值的作用是，在系统里有 Swap 空间之后，当系统需要回收内存的时候，是优先释放 Page Cache 中的内存，还是优先释放匿名内存（也就是写入 Swap）。swappiness 的取值范围在 0 到 100 之间，我们可以记住下面三个值：- 值为 100 的时候， 释放 Page Cache 和匿名内存是同等优先级的。- 值为 60，这是大多数 Linux 系统的缺省值，这时候 Page Cache 的释放优先级高于匿名内存的释放。- 值为 0 的时候，当系统中空闲内存低于一个临界值的时候，仍然会释放匿名内存并把页面写入 Swap 空间。![41][41]swappiness 参数除了在 proc 文件系统下有个全局的值外，在每个 Memory Cgroup 控制组里也有一个 memory.swappiness，那它们有什么不同呢？不同就是每个 Memory Cgroup 控制组里的 swappiness 参数值为 0 的时候，就可以让控制组里的内存停止写入 Swap。这样一来，有了 memory.swappiness 这个参数后，需要使用 Swap 和不需要 Swap 的容器就可以在同一个宿主机上同时运行了，这样对于硬件资源的利用率也就更高了。--><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《由浅入深吃透 Docker》</li><li>《容器实战高手课》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://www.docker-cn.com" target="_blank" rel="noopener">https://www.docker-cn.com</a></li><li><a href="https://docs.docker.com/compose/compose-file/compose-file-v3/" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/compose-file-v3/</a></li><li><a href="https://docs.docker.com/compose/reference/" target="_blank" rel="noopener">https://docs.docker.com/compose/reference/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;容器CPU、容器内存&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://blog.lichao.xin/categories/Docker/"/>
    
    
      <category term="docker" scheme="https://blog.lichao.xin/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>重学 Docker 之 容器进阶（一）</title>
    <link href="https://blog.lichao.xin/back-end/docker/docker-04/"/>
    <id>https://blog.lichao.xin/back-end/docker/docker-04/</id>
    <published>2021-04-03T15:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.383Z</updated>
    
    <content type="html"><![CDATA[<p>容器是什么、理解进程</p><a id="more"></a><h2 id="认识容器：容器的基本操作和实现原理"><a href="#认识容器：容器的基本操作和实现原理" class="headerlink" title="认识容器：容器的基本操作和实现原理"></a>认识容器：容器的基本操作和实现原理</h2><h3 id="做个镜像"><a href="#做个镜像" class="headerlink" title="做个镜像"></a>做个镜像</h3><p>其实，镜像就是一个特殊的文件系统，它提供了容器中程序执行需要的所有文件。具体来说，就是应用程序想启动，需要三类文件：相关的程序可执行文件、库文件和配置文件，这三类文件都被容器打包做好了。</p><p>这样，在容器运行的时候就不再依赖宿主机上的文件操作系统类型和配置了，做到了想在哪个节点上运行，就可以在哪个节点上立刻运行。</p><p>Docker 为用户自己定义镜像提供了一个叫做 Dockerfile 的文件，在这个 Dockerfile 文件里，你可以设定自己镜像的创建步骤。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y httpd</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> file1 /var/www/html/</span></span><br><span class="line"><span class="keyword">ADD</span><span class="bash">  file2.tar.gz /var/www/html/</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"/sbin/httpd"</span>, <span class="string">"-D"</span>, <span class="string">"FOREGROUND"</span>]</span></span><br></pre></td></tr></table></figure><p>我们看下它做了哪几件事：在一个 centos 的基准镜像上安装好 httpd 的包，然后在 httpd 提供文件服务的配置目录下，把需要对外提供的文件 file1 和 file2 拷贝过去，最后指定容器启动以后，需要自动启动的 httpd 服务。</p><p>有了这个镜像，我们希望容器启动后，就运行这个 httpd 服务，让用户可以下载 file1 还有 file2 这两个文件。</p><p>下面这个命令中 -f ./Dockerfile 指定 Dockerfile 文件，-t registry/httpd:v1 指定了生成出来的镜像名，它的格式是”name:tag”，这个镜像名也是后面启动容器需要用到的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t registry/httpd:v1 -f ./Dockerfile .</span><br></pre></td></tr></table></figure><h3 id="启动一个容器-Container"><a href="#启动一个容器-Container" class="headerlink" title="启动一个容器 (Container)"></a>启动一个容器 (Container)</h3><p>做完一个镜像之后，你就可以用这个镜像来启动一个容器了，我们刚才做的镜像名字是 registry/httpd:v1，那么还是用 docker run 这个命令来启动容器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d registry/httpd:v1</span><br></pre></td></tr></table></figure><p>容器启动完成后，我们可以用 <code>docker ps</code> 命令来查看这个已经启动的容器</p><p>在前面介绍 Dockerfile 的时候，我们说过做这个镜像是用来提供 HTTP 服务的，也就是让用户可以下载 file1、file2 这两个文件。</p><p>那怎样来验证我们建起来的容器是不是正常工作的呢？可以通过这两步来验证：</p><ul><li>第一步，我们可以进入容器的运行空间，查看 httpd 服务是不是启动了，配置文件是不是正确的。</li><li>第二步，对于 HTTP 文件服务，如果我们能用 curl 命令下载文件，就可以证明这个容器提供了我们预期的 httpd 服务。</li></ul><p>我们先来做第一步验证，我们可以运行 docker exec 这个命令进入容器的运行空间，至于什么是容器的运行空间，它的标准说法是容器的命名空间（Namespace），这个概念我们等会儿再做介绍。</p><p>进入容器运行空间之后，我们怎么确认 httpd 的服务进程已经在容器里启动了呢？</p><p>我们运行下面这个 docker exec 命令，也就是执行 <code>docker exec c5a9ff78d9c1 ps -ef</code> ，可以看到 httpd 的服务进程正在容器的空间中运行。</p><p>这里我解释一下，在这个 docker exec 后面紧跟着的 ID 表示容器的 ID，这个 ID 就是我们之前运行 docker ps 查看过那个容器，容器的 ID 值是 c5a9ff78d9c1 。在这个 ID 值的后面，就是我们要在容器空间里运行的 ps -ef 命令。</p><p>接下来我们再来确认一下，httpd 提供文件服务的目录中 file1 和 file2 文件是否存在。</p><p>我们同样可以用 docker exec 来查看一下容器的文件系统中，httpd 提供文件服务的目录 /var/www/html 是否有这两个文件。</p><p>很好，我们可以看到 file1、file2 这两个文件也都放在指定目录中了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> c5a9ff78d9c1 ls /var/www/html</span><br><span class="line">file1</span><br><span class="line">file2</span><br></pre></td></tr></table></figure><p>到这里我们完成了第一步的验证，进入到容器的运行空间里，验证了 httpd 服务已经启动，配置文件也是正确的。</p><p>那下面我们要做第二步的验证，用 curl 命令来验证是否可以从容器的 httpd 服务里下载到文件。</p><p>如果要访问 httpd 服务，我们就需要知道这个容器的 IP 地址。容器的网络空间也是独立的，有一个它自己的 IP。我们还是可以用 docker exec 进入到容器的网络空间，查看一下这个容器的 IP。</p><p>运行下面的这条 <code>docker exec c5a9ff78d9c1 ip addr</code> 命令，我们可以看到容器里网络接口 eth0 上配置的 IP 是 172.17.0.2 。</p><p>这个 IP 目前只能在容器的宿主机上访问，在别的机器上目前是不能访问的。</p><p>我们在宿主机上运行 curl ，就可以下载这个文件了，操作如下。很好，文件下载成功了，这证明了我们这个提供 httpd 服务的容器正常运行了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ curl -L -O http://172.17.0.2/file2</span><br></pre></td></tr></table></figure><p>上面的步骤完成之后，我们的第二步验证，用 curl 下载 httpd 服务提供的文件也成功了。</p><p>好了，我们刚才自己做了容器镜像，用这个镜像启动了容器，并且用 docker exec 命令检查了容器运行空间里的进程、文件和网络设置。</p><p>通过这上面的这些操作练习，估计你已经初步感知到，容器的文件系统是独立的，运行的进程环境是独立的，网络的设置也是独立的。但是它们和宿主机上的文件系统，进程环境以及网络感觉都已经分开了。</p><p>我想和你说，这个感觉没错，的确是这样。我们刚才启动的容器，已经从宿主机环境里被分隔出来了，就像下面这张图里的描述一样。</p><p><img src="/images/docker/docker-04/1.jpg" alt="1"></p><p>从用户使用的角度来看，容器和一台独立的机器或者虚拟机没有什么太大的区别，但是它和虚拟机相比，却没有各种复杂的硬件虚拟层，没有独立的 Linux 内核。</p><p>容器所有的进程调度，内存访问，文件的读写都直接跑在宿主机的内核之上，这是怎么做到的呢？</p><h3 id="容器是什么"><a href="#容器是什么" class="headerlink" title="容器是什么"></a>容器是什么</h3><p>要回答这个问题，你可以先记住这两个术语 Namespace 和 Cgroups。如果有人问你 Linux 上的容器是什么，最简单直接的回答就是 Namesapce 和 Cgroups。Namespace 和 Cgroups 可以让程序在一个资源可控的独立（隔离）环境中运行，这个就是容器了。</p><p>我们现在已经发现：容器的进程、网络还有文件系统都是独立的。那问题来了，容器的独立运行环境到底是怎么创造的呢？这就要提到 Namespace 这个概念了。所以接下来，就先从我们已经有点感觉的 Namespace 开始分析。</p><h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><p>接着前面的例子，我们正好有了一个正在运行的容器，那我们就拿这个运行的容器来看看 Namespace 到底是什么？</p><p>在前面我们运行 <code>docker exec c5a9ff78d9c1 ps -ef</code>，看到了 5 个 httpd 进程，而且也只有这 5 个进程。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> c5a9ff78d9c1 ps -ef</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 01:59 ?        00:00:00 /sbin/httpd -D FOREGROUND</span><br><span class="line">apache       6     1  0 01:59 ?        00:00:00 /sbin/httpd -D FOREGROUND</span><br><span class="line">apache       7     1  0 01:59 ?        00:00:00 /sbin/httpd -D FOREGROUND</span><br><span class="line">apache       8     1  0 01:59 ?        00:00:00 /sbin/httpd -D FOREGROUND</span><br><span class="line">apache       9     1  0 01:59 ?        00:00:00 /sbin/httpd -D FOREGROUND</span><br></pre></td></tr></table></figure><p>如果我们不用 docker exec，直接在宿主机上运行 ps -ef，就会看到很多进程。如果我们运行一下 grep httpd ，同样可以看到这 5 个 httpd 的进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ ps -ef | grep httpd</span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root     20731 20684  0 18:59 ?        00:00:01 /sbin/httpd -D FOREGROUND</span><br><span class="line">48       20787 20731  0 18:59 ?        00:00:00 /sbin/httpd -D FOREGROUND</span><br><span class="line">48       20788 20731  0 18:59 ?        00:00:06 /sbin/httpd -D FOREGROUND</span><br><span class="line">48       20789 20731  0 18:59 ?        00:00:05 /sbin/httpd -D FOREGROUND</span><br><span class="line">48       20791 20731  0 18:59 ?        00:00:05 /sbin/httpd -D FOREGROUN</span><br></pre></td></tr></table></figure><p>这两组输出结果到底有什么差别呢，你可以仔细做个对比，最大的不同就是进程的 PID 不一样。那为什么 PID 会不同呢？或者说，运行 docker exec c5a9ff78d9c1 ps -ef 和 ps -ef 实质的区别在哪里呢？</p><p>如果理解了 PID 为何不同，我们就能搞清楚 Linux Namespace 的概念了，为了方便后文的讲解，我们先用下面这张图来梳理一下我们看到的 PID。</p><p><img src="/images/docker/docker-04/2.jpg" alt="2"></p><p>Linux 在创建容器的时候，就会建出一个 PID Namespace，PID 其实就是进程的编号。这个 PID Namespace，就是指每建立出一个 Namespace，就会单独对进程进行 PID 编号，每个 Namespace 的 PID 编号都从 1 开始。</p><p>同时在这个 PID Namespace 中也只能看到 Namespace 中的进程，而且看不到其他 Namespace 里的进程。</p><p>这也就是说，如果有另外一个容器，那么它也有自己的一个 PID Namespace，而这两个 PID Namespace 之间是不能看到对方的进程的，这里就体现出了 Namespace 的作用：<strong>相互隔离</strong>。</p><p>而在宿主机上的 Host PID Namespace，它是其他 Namespace 的父亲 Namespace，可以看到在这台机器上的所有进程，不过进程 PID 编号不是 Container PID Namespace 里的编号了，而是把所有在宿主机运行的进程放在一起，再进行编号。</p><p>讲了 PID Namespace 之后，我们了解到 <strong>Namespace 其实就是一种隔离机制，主要目的是隔离运行在同一个宿主机上的容器，让这些容器之间不能访问彼此的资源。</strong></p><p>这种隔离有两个作用：<strong>第一是可以充分地利用系统的资源，也就是说在同一台宿主机上可以运行多个用户的容器；第二是保证了安全性，因为不同用户之间不能访问对方的资源。</strong></p><p>除了 PID Namespace，还有其他常见的 Namespace 类型，比如我们之前运行了 docker exec c5a9ff78d9c1 ip addr 这个命令去查看容器内部的 IP 地址，这里其实就是在查看 Network Namespace。</p><p>在 Network Namespace 中都有一套独立的网络接口比如这里的 lo，eth0，还有独立的 TCP/IP 的协议栈配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> c5a9ff78d9c1 ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">168: eth0@if169: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>我们还可以运行 docker exec c5a9ff78d9c1 ls/ 查看容器中的根文件系统（rootfs）。然后，你会发现，它和宿主机上的根文件系统也是不一样的。<strong>容器中的根文件系统，其实就是我们做的镜像。</strong></p><p>那容器自己的根文件系统完全独立于宿主机上的根文件系统，这一点是怎么做到的呢？其实这里依靠的是 <strong>Mount Namespace</strong>，Mount Namespace 保证了每个容器都有自己独立的文件目录结构。</p><p>Namespace 的类型还有很多，我们查看”Linux Programmer’s Manual”，可以看到 Linux 中所有的 Namespace：cgroup/ipc/network/mount/pid/time/user/uts。</p><p>在这里呢，你需要记住的是 <strong>Namespace 是 Linux 中实现容器的两大技术之一，它最重要的作用是保证资源的隔离。</strong>在后面讲解到具体问题时，我会不断地提到 Namespace 这个概念。</p><p><img src="/images/docker/docker-04/3.jpg" alt="3"></p><p>我们刚才说了 Namespace，这些 Namespace 尽管类型不同，其实都是为了隔离容器资源：<strong>PID Namespace 负责隔离不同容器的进程，Network Namespace 又负责管理网络环境的隔离，Mount Namespace 管理文件系统的隔离。</strong></p><p>正是通过这些 Namespace，我们才隔离出一个容器，这里你也可以把它看作是一台“计算机”。</p><p>既然是一台“计算机”，你肯定会问这个“计算机”有多少 CPU，有多少 Memory 啊？那么 Linux 如何为这些“计算机”来定义 CPU，定义 Memory 的容量呢？</p><h3 id="Cgroups"><a href="#Cgroups" class="headerlink" title="Cgroups"></a>Cgroups</h3><p>想要定义“计算机”各种容量大小，就涉及到支撑容器的第二个技术 <strong>Cgroups （Control Groups）</strong>了。Cgroups 可以对指定的进程做各种计算机资源的限制，比如限制 CPU 的使用率，内存使用量，IO 设备的流量等等。</p><p>Cgroups 究竟有什么好处呢？要知道，在 Cgroups 出现之前，任意一个进程都可以创建出成百上千个线程，可以轻易地消耗完一台计算机的所有 CPU 资源和内存资源。</p><p>但是有了 Cgroups 这个技术以后，我们就可以对一个进程或者一组进程的计算机资源的消耗进行限制了。</p><p>Cgroups 通过不同的子系统限制了不同的资源，每个子系统限制一种资源。每个子系统限制资源的方式都是类似的，就是把相关的一组进程分配到一个控制组里，然后通过<strong>树结构</strong>进行管理，每个控制组都设有自己的资源控制参数。</p><p>完整的 Cgroups 子系统的介绍，你可以查看<a href="https://man7.org/linux/man-pages/man7/cgroups.7.html" target="_blank" rel="noopener">Linux Programmer’s Manual</a> 中 Cgroups 的定义。</p><p>这里呢，我们只需要了解几种比较常用的 Cgroups 子系统：</p><ul><li>CPU 子系统，用来限制一个控制组（一组进程，你可以理解为一个容器里所有的进程）可使用的最大 CPU。</li><li>memory 子系统，用来限制一个控制组最大的内存使用量。</li><li>pids 子系统，用来限制一个控制组里最多可以运行多少个进程。</li><li>cpuset 子系统， 这个子系统来限制一个控制组里的进程可以在哪几个物理 CPU 上运行。</li></ul><p>因为 memory 子系统的限制参数最简单，所以下面我们就用 memory 子系统为例，一起看看 Cgroups 是怎么对一个容器做资源限制的。</p><p>对于启动的每个容器，都会在 Cgroups 子系统下建立一个目录，在 Cgroups 中这个目录也被称作控制组，比如下图里的”docker-<id1>“”docker-<id2>“等。然后我们设置这个控制组的参数，通过这个方式，来限制这个容器的内存资源。</p><p><img src="/images/docker/docker-04/4.jpg" alt="4"></p><p>还记得，我们之前用 Docker 创建的那个容器吗？在每个 Cgroups 子系统下，对应这个容器就会有一个目录 docker-<strong>c5a9ff78d9c1……</strong>这个容器的 ID 号，容器中所有的进程都会储存在这个控制组中  cgroup.procs 这个参数里。</p><p>你看下面的这些进程号是不是很熟悉呢？没错，它们就是前面我们用 ps 看到的进程号。</p><p>我们实际看一下这个例子里的 memory Cgroups，它可以控制 Memory 的使用量。比如说，我们将这个控制组 Memory 的最大用量设置为 2GB。</p><p>具体操作是这样的，我们把（2* 1024 * 1024 * 1024 = 2147483648）这个值，写入 memory Cgroup 控制组中的 memory.limit_in_bytes 里，<strong>这样设置后，cgroup.procs 里面所有进程 Memory 使用量之和，最大也不会超过 2GB。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /sys/fs/cgroup/memory/system.slice/docker-c5a9ff78d9c1fedd52511e18fdbd26357250719fa0d128349547a50fad7c5de9.scope</span><br><span class="line">$ cat cgroup.procs</span><br><span class="line">20731</span><br><span class="line">20787</span><br><span class="line">20788</span><br><span class="line">20789</span><br><span class="line">20791</span><br><span class="line">$ <span class="built_in">echo</span> 2147483648 &gt; memory.limit_in_bytes</span><br><span class="line">$ cat memory.limit_in_bytes</span><br><span class="line">2147483648</span><br></pre></td></tr></table></figure><p>刚刚我们通过 memory Cgroups 定义了容器的 memory 可以使用的最大值。其他的子系统稍微复杂一些，但用法也和 memory 类似，我们在后面会结合具体的实例来详细解释其他的 Cgroups。</p><p>这里我们还要提一下 <strong>Cgroups 有 v1 和 v2 两个版本</strong>：</p><p>Cgroups v1 在 Linux 中很早就实现了，各种子系统比较独立，每个进程在各个 Cgroups 子系统中独立配置，可以属于不同的 group。</p><p>虽然这样比较灵活，但是也存在问题，会导致对<strong>同一进程的资源协调比较困难</strong>（比如 memory Cgroup 与 blkio Cgroup 之间就不能协作）。虽然 v1 有缺陷，但是在主流的生产环境中，大部分使用的还是 v1。</p><p>Cgroups v2 做了设计改进，<strong>解决了 v1 的问题，使各个子系统可以协调统一地管理资源。</strong></p><p>不过 Cgroups v2 在生产环境的应用还很少，因为该版本很多子系统的实现需要较新版本的 Linux 内核，还有无论是主流的 Linux 发行版本还是容器云平台，比如 Kubernetes，对 v2 的支持也刚刚起步。</p><p>所以啊，我们在后面 Cgroups 的讲解里呢，主要还是用 <strong>Cgroups v1 这个版本</strong>，在磁盘 I/O 的这一章中，我们也会介绍一下 Cgroups v2。</p><p>好了，上面我们解读了 Namespace 和 Cgroups 两大技术，它们是 Linux 下实现容器的两个基石，后面中要讨论的容器相关问题，或多或少都和 Namespace 或者 Cgroups 相关，我们会结合具体问题做深入的分析。</p><p>目前呢，你只需要先记住这两个技术的作用，<strong>Namespace 帮助容器来实现各种计算资源的隔离，Cgroups 主要限制的是容器能够使用的某种资源量。</strong></p><h2 id="理解进程（1）：为什么我在容器中不能kill-1号进程？"><a href="#理解进程（1）：为什么我在容器中不能kill-1号进程？" class="headerlink" title="理解进程（1）：为什么我在容器中不能kill 1号进程？"></a>理解进程（1）：为什么我在容器中不能kill 1号进程？</h2><p>接下来，我们用 kill 1 命令重启容器的问题。</p><p>我猜你肯定想问，为什么要在容器中执行 kill 1 或者 kill -9 1 的命令呢？其实这是我们团队里的一位同学提出的问题。</p><p>这位同学当时遇到的情况是这样的，他想修改容器镜像里的一个 bug，但因为网路配置的问题，这个同学又不想为了重建 pod 去改变 pod IP。</p><p>如果你用过 Kubernetes 的话，你也肯定知道，Kubernetes 上是没有 restart pod 这个命令的。这样看来，他似乎只能让 pod 做个原地重启了。<strong>当时我首先想到的，就是在容器中使用 kill pid 1 的方式重启容器。</strong></p><p>为了模拟这个过程，我们可以进行下面的这段操作。 我们用 Docker 构建一个容器。</p><p>最后，我们在容器中运行 kill 1 和 kill -9 1 ，看看会发生什么。</p><p><strong>init.sh</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">sleep 100</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p><strong>Dockerfile</strong></p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./init.sh /</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ docker stop sig-proc;docker rm sig-proc</span><br><span class="line">$ docker run --name sig-proc -d registry/sig-proc:v1 /init.sh</span><br><span class="line">$ docker <span class="built_in">exec</span> -it sig-proc bash</span><br><span class="line">[root@5cc69036b7b2 /]<span class="comment"># ps -ef</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 07:23 ?        00:00:00 /bin/bash /init.sh</span><br><span class="line">root         8     1  0 07:25 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 100</span><br><span class="line">root         9     0  6 07:27 pts/0    00:00:00 bash</span><br><span class="line">root        22     9  0 07:27 pts/0    00:00:00 ps -ef</span><br><span class="line">[root@5cc69036b7b2 /]<span class="comment"># kill 1</span></span><br><span class="line">[root@5cc69036b7b2 /]<span class="comment"># kill -9 1</span></span><br><span class="line">[root@5cc69036b7b2 /]<span class="comment"># ps -ef</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 07:23 ?        00:00:00 /bin/bash /init.sh</span><br><span class="line">root         9     0  0 07:27 pts/0    00:00:00 bash</span><br><span class="line">root        23     1  0 07:27 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 100</span><br><span class="line">root        24     9  0 07:27 pts/0    00:00:00 ps -ef</span><br></pre></td></tr></table></figure><p>当我们完成前面的操作，就会发现无论运行 kill 1 （对应 Linux 中的 SIGTERM 信号）还是 kill -9 1（对应 Linux 中的 SIGKILL 信号），都无法让进程终止。</p><p>那么问题来了，这两个常常用来终止进程的信号，都对容器中的 init 进程不起作用，这是怎么回事呢？</p><p>要解释这个问题，我们就要回到容器的两个最基本概念——init 进程和 Linux 信号中寻找答案。</p><h3 id="如何理解-init-进程？"><a href="#如何理解-init-进程？" class="headerlink" title="如何理解 init 进程？"></a>如何理解 init 进程？</h3><p>使用容器的理想境界是<strong>一个容器只启动一个进程</strong>，但这在现实应用中有时是做不到的。</p><p>比如说，在一个容器中除了主进程之外，我们可能还会启动辅助进程，做监控或者 rotate logs；再比如说，我们需要把原来运行在虚拟机（VM）的程序移到容器里，这些原来跑在虚拟机上的程序本身就是多进程的。</p><p>一旦我们启动了多个进程，那么容器里就会出现一个 pid 1，也就是我们常说的 1 号进程或者 init 进程，然后<strong>由这个进程创建出其他的子进程。</strong></p><p>接下来，我带你梳理一下 init 进程是怎么来的。</p><p>一个 Linux 操作系统，在系统打开电源，执行 BIOS/boot-loader 之后，就会由 boot-loader 负责加载 Linux 内核。</p><p>Linux 内核执行文件一般会放在 /boot 目录下，文件名类似 vmlinuz<em>。在内核完成了操作系统的各种初始化之后，*</em>这个程序需要执行的第一个用户态程就是 init 进程。**</p><p>内核代码启动 1 号进程的时候，在没有外面参数指定程序路径的情况下，一般会从几个缺省路径尝试执行 1 号进程的代码。这几个路径都是 Unix 常用的可执行代码路径。</p><p>系统启动的时候先是执行内核态的代码，然后在内核中调用 1 号进程的代码，从内核态切换到用户态。</p><p>目前主流的 Linux 发行版，无论是 RedHat 系的还是 Debian 系的，都会把 /sbin/init 作为符号链接指向 Systemd。Systemd 是目前最流行的 Linux init 进程，在它之前还有 SysVinit、UpStart 等 Linux init 进程。</p><p><strong>但无论是哪种 Linux init 进程，它最基本的功能都是创建出 Linux 系统中其他所有的进程，并且管理这些进程。</strong>具体在 kernel 里的代码实现如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">init/main.c</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * We try each of these until one succeeds.</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * The Bourne shell can be used instead of init if we are</span></span><br><span class="line"><span class="comment">         * trying to recover a really broken machine.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (execute_command) &#123;</span><br><span class="line">                ret = run_init_process(execute_command);</span><br><span class="line">                <span class="keyword">if</span> (!ret)</span><br><span class="line">                        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">                panic(<span class="string">"Requested init %s failed (error %d)."</span>,</span><br><span class="line">                      execute_command, ret);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!try_to_run_init_process(<span class="string">"/sbin/init"</span>) ||</span><br><span class="line">            !try_to_run_init_process(<span class="string">"/etc/init"</span>) ||</span><br><span class="line">            !try_to_run_init_process(<span class="string">"/bin/init"</span>) ||</span><br><span class="line">            !try_to_run_init_process(<span class="string">"/bin/sh"</span>))</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        panic(<span class="string">"No working init found.  Try passing init= option to kernel. "</span></span><br><span class="line">              <span class="string">"See Linux Documentation/admin-guide/init.rst for guidance."</span>);</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls -l /sbin/init</span><br><span class="line">lrwxrwxrwx 1 root root 20 Feb  5 01:07 /sbin/init -&gt; /lib/systemd/systemd</span><br></pre></td></tr></table></figure><p>在 Linux 上有了容器的概念之后，一旦容器建立了自己的 Pid Namespace（进程命名空间），这个 Namespace 里的进程号也是从 1 开始标记的。所以，容器的 init 进程也被称为 1 号进程。</p><p>怎么样，1 号进程是不是不难理解？关于这个知识点，你只需要记住： <strong>1 号进程是第一个用户态的进程，由它直接或者间接创建了 Namespace 中的其他进程。</strong></p><h3 id="如何理解-Linux-信号？"><a href="#如何理解-Linux-信号？" class="headerlink" title="如何理解 Linux 信号？"></a>如何理解 Linux 信号？</h3><p>刚才我给你讲了什么是 1 号进程，要想解决“为什么我在容器中不能 kill 1 号进程”这个问题，我们还得看看 kill 命令起到的作用。</p><p>我们运行 kill 命令，其实在 Linux 里就是发送一个信号，那么信号到底是什么呢？这就涉及到 Linux 信号的概念了。</p><p>其实信号这个概念在很早期的 Unix 系统上就有了。它一般会从 1 开始编号，通常来说，信号编号是 1 到 31，这个编号在所有的 Unix 系统上都是一样的。</p><p>在 Linux 上我们可以用 kill -l 来看这些信号的编号和名字，具体的编号和名字我给你列在了下面，你可以看一看。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">kill</span> -l</span><br><span class="line"> 1) SIGHUP      2) SIGINT    3) SIGQUIT    4) SIGILL    5) SIGTRAP</span><br><span class="line"> 6) SIGABRT     7) SIGBUS    8) SIGFPE     9) SIGKILL  10) SIGUSR1</span><br><span class="line">11) SIGSEGV    12) SIGUSR2  13) SIGPIPE   14) SIGALRM  15) SIGTERM</span><br><span class="line">16) SIGSTKFLT  17) SIGCHLD  18) SIGCONT   19) SIGSTOP  20) SIGTSTP</span><br><span class="line">21) SIGTTIN    22) SIGTTOU  23) SIGURG    24) SIGXCPU  25) SIGXFSZ</span><br><span class="line">26) SIGVTALRM  27) SIGPROF  28) SIGWINCH  29) SIGIO    30) SIGPWR</span><br><span class="line">31) SIGSYS</span><br></pre></td></tr></table></figure><p>用一句话来概括，<strong>信号（Signal）其实就是 Linux 进程收到的一个通知。</strong>这些通知产生的源头有很多种，通知的类型也有很多种。</p><p>比如下面这几个典型的场景，你可以看一下：</p><ul><li>如果我们按下键盘“Ctrl+C”，当前运行的进程就会收到一个信号 SIGINT 而退出；</li><li>如果我们的代码写得有问题，导致内存访问出错了，当前的进程就会收到另一个信号 SIGSEGV；</li><li>我们也可以通过命令 kill <pid>，直接向一个进程发送一个信号，缺省情况下不指定信号的类型，那么这个信号就是 SIGTERM。也可以指定信号类型，比如命令 “kill -9 <pid>”, 这里的 9，就是编号为 9 的信号，SIGKILL 信号。</li></ul><p>我们主要用到 <strong>SIGTERM（15）和 SIGKILL（9）这两个信号</strong>，所以这里你主要了解这两个信号就可以了，其他信号以后用到时再做介绍。</p><p>进程在收到信号后，就会去做相应的处理。怎么处理呢？对于每一个信号，进程对它的处理都有下面三个选择。</p><p>第一个选择是<strong>忽略（Ignore）</strong>，就是对这个信号不做任何处理，但是有两个信号例外，对于 SIGKILL 和 SIGSTOP 这个两个信号，进程是不能忽略的。这是因为它们的主要作用是为 Linux kernel 和超级用户提供删除任意进程的特权。</p><p>第二个选择，就是<strong>捕获（Catch）</strong>，这个是指让用户进程可以注册自己针对这个信号的 handler。具体怎么做我们目前暂时涉及不到，你先知道就行，我们在后面会进行详细介绍。</p><p><strong>对于捕获，SIGKILL 和 SIGSTOP 这两个信号也同样例外，这两个信号不能有用户自己的处理代码，只能执行系统的缺省行为。</strong></p><p>还有一个选择是<strong>缺省行为（Default）</strong>，Linux 为每个信号都定义了一个缺省的行为，你可以在 Linux 系统中运行 man 7 signal来查看每个信号的缺省行为。</p><p>对于大部分的信号而言，应用程序不需要注册自己的 handler，使用系统缺省定义行为就可以了。</p><p><img src="/images/docker/docker-04/5.jpg" alt="5"></p><p>我刚才说了，SIGTERM（15）和 SIGKILL（9）这两个信号是我们重点掌握的。现在我们已经讲解了信号的概念和处理方式，我就拿这两个信号为例，再带你具体分析一下。</p><p>首先我们来看 SIGTERM（15），这个信号是 Linux 命令 kill 缺省发出的。前面例子里的命令 kill 1 ，就是通过 kill 向 1 号进程发送一个信号，在没有别的参数时，这个信号类型就默认为 SIGTERM。</p><p>SIGTERM 这个信号是可以被捕获的，这里的“捕获”指的就是用户进程可以为这个信号注册自己的 handler，而这个 handler，我们后面会看到，它可以处理进程的 graceful-shutdown 问题。</p><p>我们再来了解一下 SIGKILL (9)，这个信号是 Linux 里两个<strong>特权信号</strong>之一。什么是特权信号呢？</p><p>前面我们已经提到过了，<strong>特权信号就是 Linux 为 kernel 和超级用户去删除任意进程所保留的，不能被忽略也不能被捕获。</strong>那么进程一旦收到 SIGKILL，就要退出。</p><p>在前面的例子里，我们运行的命令 kill -9 1 里的参数“-9”，其实就是指发送编号为 9 的这个 SIGKILL 信号给 1 号进程。</p><h3 id="现象解释"><a href="#现象解释" class="headerlink" title="现象解释"></a>现象解释</h3><p>现在，你应该理解 init 进程和 Linux 信号这两个概念了，让我们回到开头的问题上来：“为什么我在容器中不能 kill 1 号进程，甚至 SIGKILL 信号也不行？”</p><p>你还记得么，在最开始，我们已经尝试过用 bash 作为容器 1 号进程，这样是无法把 1 号进程杀掉的。那么我们再一起来看一看，用别的编程语言写的 1 号进程是否也杀不掉。</p><p>我们现在<strong>用 C 程序作为 init 进程</strong>，尝试一下杀掉 1 号进程。和 bash init 进程一样，无论 SIGTERM 信号还是 SIGKILL 信号，在容器里都不能杀死这个 1 号进程。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat c-init-nosig.c</span></span><br><span class="line"><span class="comment">#include &lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;unistd.h&gt;</span></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">"Process is sleeping\n"</span>);</span><br><span class="line">       <span class="keyword">while</span> (1) &#123;</span><br><span class="line">              sleep(100);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker stop sig-proc;docker rm sig-proc</span></span><br><span class="line"><span class="comment"># docker run --name sig-proc -d registry/sig-proc:v1 /c-init-nosig</span></span><br><span class="line"><span class="comment"># docker exec -it sig-proc bash</span></span><br><span class="line">[root@5d3d42a031b1 /]<span class="comment"># ps -ef</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 07:48 ?        00:00:00 /c-init-nosig</span><br><span class="line">root         6     0  5 07:48 pts/0    00:00:00 bash</span><br><span class="line">root        19     6  0 07:48 pts/0    00:00:00 ps -ef</span><br><span class="line">[root@5d3d42a031b1 /]<span class="comment"># kill 1</span></span><br><span class="line">[root@5d3d42a031b1 /]<span class="comment"># kill -9 1</span></span><br><span class="line">[root@5d3d42a031b1 /]<span class="comment"># ps -ef</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 07:48 ?        00:00:00 /c-init-nosig</span><br><span class="line">root         6     0  0 07:48 pts/0    00:00:00 bash</span><br><span class="line">root        20     6  0 07:49 pts/0    00:00:00 ps -ef</span><br></pre></td></tr></table></figure><p>我们是不是这样就可以得出结论——“容器里的 1 号进程，完全忽略了 SIGTERM 和 SIGKILL 信号了”呢？你先别着急，我们再拿其他语言试试。</p><p>接下来，我们用 <strong>Golang 程序作为 1 号进程</strong>，我们再在容器中执行 kill -9 1 和 kill 1 。</p><p>这次，我们发现 kill -9 1 这个命令仍然不能杀死 1 号进程，也就是说，SIGKILL 信号和之前的两个测试一样不起作用。</p><p><strong>但是，我们执行</strong> <strong>kill 1</strong> <strong>以后，SIGTERM 这个信号把 init 进程给杀了，容器退出了。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat go-init.go</span></span><br><span class="line">package main</span><br><span class="line">import (</span><br><span class="line">       <span class="string">"fmt"</span></span><br><span class="line">       <span class="string">"time"</span></span><br><span class="line">)</span><br><span class="line">func <span class="function"><span class="title">main</span></span>() &#123;</span><br><span class="line">       fmt.Println(<span class="string">"Start app\n"</span>)</span><br><span class="line">       time.Sleep(time.Duration(100000) * time.Millisecond)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker stop sig-proc;docker rm sig-proc</span></span><br><span class="line"><span class="comment"># docker run --name sig-proc -d registry/sig-proc:v1 /go-init</span></span><br><span class="line"><span class="comment"># docker exec -it sig-proc bash</span></span><br><span class="line">[root@234a23aa597b /]<span class="comment"># ps -ef</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  1 08:04 ?        00:00:00 /go-init</span><br><span class="line">root        10     0  9 08:04 pts/0    00:00:00 bash</span><br><span class="line">root        23    10  0 08:04 pts/0    00:00:00 ps -ef</span><br><span class="line">[root@234a23aa597b /]<span class="comment"># kill -9 1</span></span><br><span class="line">[root@234a23aa597b /]<span class="comment"># kill 1</span></span><br><span class="line">[root@234a23aa597b /]<span class="comment"># [~]# docker ps</span></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br></pre></td></tr></table></figure><p>对于这个测试结果，你是不是反而觉得更加困惑了？</p><p>为什么使用不同程序，结果就不一样呢？接下来我们就看看 kill 命令下达之后，Linux 里究竟发生了什么事，我给你系统地梳理一下整个过程。</p><p>在我们运行 kill 1 这个命令的时候，希望把 SIGTERM 这个信号发送给 1 号进程，就像下面图里的<strong>带箭头虚线</strong>。</p><p>在 Linux 实现里，kill 命令调用了 <strong>kill() 的这个系统调用</strong>（所谓系统调用就是内核的调用接口）而进入到了内核函数 sys_kill()， 也就是下图里的<strong>实线箭头</strong>。</p><p>而内核在决定把信号发送给 1 号进程的时候，会调用 sig_task_ignored() 这个函数来做个判断，这个判断有什么用呢？</p><p>它会决定内核在哪些情况下会把发送的这个信号给忽略掉。如果信号被忽略了，那么 init 进程就不能收到指令了。</p><p>所以，我们想要知道 init 进程为什么收到或者收不到信号，都要去看看 <strong>sig_task_ignored() 的这个内核函数的实现。</strong></p><p><img src="/images/docker/docker-04/6.jpg" alt="sig_task_ignored()内核函数实现示意图"></p><p>在 sig_task_ignored() 这个函数中有三个 if{}判断，第一个和第三个 if{}判断和我们的问题没有关系，并且代码有注释，我们就不讨论了。</p><p>我们重点来看第二个 if{}。我来给你分析一下，在容器中执行 kill 1 或者 kill -9 1 的时候，这第二个 if{}里的三个子条件是否可以被满足呢？</p><p>我们来看下面这串代码，这里表示<strong>一旦这三个子条件都被满足，那么这个信号就不会发送给进程。</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">kernel/signal.c</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">bool</span> <span class="title">sig_task_ignored</span><span class="params">(struct task_struct *t, <span class="keyword">int</span> sig, <span class="keyword">bool</span> force)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">void</span> __user *handler;</span><br><span class="line">        handler = sig_handler(t, sig);</span><br><span class="line">        <span class="comment">/* SIGKILL and SIGSTOP may not be sent to the global init */</span></span><br><span class="line">        <span class="keyword">if</span> (unlikely(is_global_init(t) &amp;&amp; sig_kernel_only(sig)))</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">if</span> (unlikely(t-&gt;signal-&gt;flags &amp; SIGNAL_UNKILLABLE) &amp;&amp;</span><br><span class="line">            handler == SIG_DFL &amp;&amp; !(force &amp;&amp; sig_kernel_only(sig)))</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="comment">/* Only allow kernel generated signals to this kthread */</span></span><br><span class="line">        <span class="keyword">if</span> (unlikely((t-&gt;flags &amp; PF_KTHREAD) &amp;&amp;</span><br><span class="line">                     (handler == SIG_KTHREAD_KERNEL) &amp;&amp; !force))</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">return</span> sig_handler_ignored(handler, sig);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来，我们就逐一分析一下这三个子条件，我们来说说这个”!(force &amp;&amp; sig_kernel_only(sig))” 。</p><p>第一个条件里 force 的值，对于同一个 Namespace 里发出的信号来说，调用值是 0，所以这个条件总是满足的。</p><p>我们再来看一下第二个条件 “handler == SIG_DFL”，第二个条件判断信号的 handler 是否是 SIG_DFL。</p><p>那么什么是 SIG_DFL 呢？<strong>对于每个信号，用户进程如果不注册一个自己的 handler，就会有一个系统缺省的 handler，这个缺省的 handler 就叫作 SIG_DFL。</strong></p><p>对于 SIGKILL，我们前面介绍过它是特权信号，是不允许被捕获的，所以它的 handler 就一直是 SIG_DFL。这第二个条件对 SIGKILL 来说总是满足的。</p><p>对于 SIGTERM，它是可以被捕获的。也就是说如果用户不注册 handler，那么这个条件对 SIGTERM 也是满足的。</p><p>最后再来看一下第三个条件，“t-&gt;signal-&gt;flags &amp; SIGNAL_UNKILLABLE”，这里的条件判断是这样的，进程必须是 SIGNAL_UNKILLABLE 的。</p><p>这个 SIGNAL_UNKILLABLE flag 是在哪里置位的呢？</p><p>可以参考我们下面的这段代码，在每个 Namespace 的 init 进程建立的时候，就会打上 <strong>SIGNAL_UNKILLABLE</strong> 这个标签，也就是说只要是 1 号进程，就会有这个 flag，这个条件也是满足的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kernel/fork.c</span><br><span class="line">                       <span class="keyword">if</span> (is_child_reaper(pid)) &#123;</span><br><span class="line">                                ns_of_pid(pid)-&gt;child_reaper = p;</span><br><span class="line">                                p-&gt;signal-&gt;flags |= SIGNAL_UNKILLABLE;</span><br><span class="line">                        &#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * is_child_reaper returns true if the pid is the init process</span></span><br><span class="line"><span class="comment"> * of the current namespace. As this one could be checked before</span></span><br><span class="line"><span class="comment"> * pid_ns-&gt;child_reaper is assigned in copy_process, we check</span></span><br><span class="line"><span class="comment"> * with the pid number.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">bool</span> <span class="title">is_child_reaper</span><span class="params">(struct pid *pid)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> pid-&gt;numbers[pid-&gt;level].nr == <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们可以看出来，其实<strong>最关键的一点就是</strong> <strong>handler == SIG_DFL</strong> <strong>。Linux 内核针对每个 Nnamespace 里的 init 进程，把只有 default handler 的信号都给忽略了。</strong></p><p>如果我们自己注册了信号的 handler（应用程序注册信号 handler 被称作”Catch the Signal”），那么这个信号 handler 就不再是 SIG_DFL 。即使是 init 进程在接收到 SIGTERM 之后也是可以退出的。</p><p>不过，由于 SIGKILL 是一个特例，因为 SIGKILL 是不允许被注册用户 handler 的（还有一个不允许注册用户 handler 的信号是 SIGSTOP），那么它只有 SIG_DFL handler。</p><p>所以 init 进程是永远不能被 SIGKILL 所杀，但是可以被 SIGTERM 杀死。</p><p>说到这里，我们该怎么证实这一点呢？我们可以做下面两件事来验证。</p><p><strong>第一件事，你可以查看 1 号进程状态中 SigCgt Bitmap。</strong></p><p>我们可以看到，在 Golang 程序里，很多信号都注册了自己的 handler，当然也包括了 SIGTERM(15)，也就是 bit 15。</p><p>而 C 程序里，缺省状态下，一个信号 handler 都没有注册；bash 程序里注册了两个 handler，bit 2 和 bit 17，也就是 SIGINT 和 SIGCHLD，但是没有注册 SIGTERM。</p><p>所以，C 程序和 bash 程序里 SIGTERM 的 handler 是 SIG_DFL（系统缺省行为），那么它们就不能被 SIGTERM 所杀。</p><p>具体我们可以看一下这段 /proc 系统的进程状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### golang init</span></span><br><span class="line"><span class="comment"># cat /proc/1/status | grep -i SigCgt</span></span><br><span class="line">SigCgt:     fffffffe7fc1feff</span><br><span class="line"><span class="comment">### C init</span></span><br><span class="line"><span class="comment"># cat /proc/1/status | grep -i SigCgt</span></span><br><span class="line">SigCgt:     0000000000000000</span><br><span class="line"><span class="comment">### bash init</span></span><br><span class="line"><span class="comment"># cat /proc/1/status | grep -i SigCgt</span></span><br><span class="line">SigCgt:     0000000000010002</span><br></pre></td></tr></table></figure><p><strong>第二件事，给 C 程序注册一下 SIGTERM handler，捕获 SIGTERM。</strong></p><p>我们调用 signal() 系统调用注册 SIGTERM 的 handler，在 handler 里主动退出，再看看容器中 kill 1 的结果。</p><p>这次我们就可以看到，<strong>在进程状态的 SigCgt bitmap 里，bit 15 (SIGTERM) 已经置位了。同时，运行</strong> <strong>kill 1</strong> <strong>也可以把这个 C 程序的 init 进程给杀死了。</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sig_handler</span><span class="params">(<span class="keyword">int</span> signo)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (signo == SIGTERM) &#123;</span><br><span class="line">           <span class="built_in">printf</span>(<span class="string">"received SIGTERM\n"</span>);</span><br><span class="line">           <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    signal(SIGTERM, sig_handler);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Process is sleeping\n"</span>);</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">           sleep(<span class="number">100</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker stop sig-proc;docker rm sig-proc</span></span><br><span class="line"><span class="comment"># docker run --name sig-proc -d registry/sig-proc:v1 /c-init-sig</span></span><br><span class="line"><span class="comment"># docker exec -it sig-proc bash</span></span><br><span class="line">[root@043f4f717cb5 /]<span class="comment"># ps -ef</span></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root         1     0  0 09:05 ?        00:00:00 /c-init-sig</span><br><span class="line">root         6     0 18 09:06 pts/0    00:00:00 bash</span><br><span class="line">root        19     6  0 09:06 pts/0    00:00:00 ps -ef</span><br><span class="line">[root@043f4f717cb5 /]<span class="comment"># cat /proc/1/status | grep SigCgt</span></span><br><span class="line">SigCgt: 0000000000004000</span><br><span class="line">[root@043f4f717cb5 /]<span class="comment"># kill 1</span></span><br><span class="line"><span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br></pre></td></tr></table></figure><p>好了，到这里我们可以确定这两点：</p><ol><li>kill -9 1 在容器中是不工作的，内核阻止了 1 号进程对 SIGKILL 特权信号的响应。</li><li>kill 1 分两种情况，如果 1 号进程没有注册 SIGTERM 的 handler，那么对 SIGTERM 信号也不响应，如果注册了 handler，那么就可以响应 SIGTERM 信号。</li></ol><!--**重点总结**这一讲我们主要讲了 init 进程。围绕这个知识点，我提出了一个真实发生的问题：“为什么我在容器中不能 kill 1 号进程?”。想要解决这个问题，我们需要掌握两个基本概念。第一个概念是 Linux 1 号进程。**它是第一个用户态的进程。它直接或者间接创建了 Namespace 中的其他进程。**第二个概念是 Linux 信号。Linux 有 31 个基本信号，进程在处理大部分信号时有三个选择：**忽略、捕获和缺省行为。其中两个特权信号 SIGKILL 和 SIGSTOP 不能被忽略或者捕获。**只知道基本概念还不行，我们还要去解决问题。我带你尝试了用 bash, C 语言还有 Golang 程序作为容器 init 进程，发现它们对 kill 1 的反应是不同的。因为信号的最终处理都是在 Linux 内核中进行的，因此，我们需要对 Linux 内核代码进行分析。容器里 1 号进程对信号处理的两个要点，这也是这一讲里我想让你记住的两句话：**在容器中，1 号进程永远不会响应 SIGKILL 和 SIGSTOP 这两个特权信号；****对于其他的信号，如果用户自己注册了 handler，1 号进程可以响应。**很多介绍容器的文章可能都会强调容器是进程，不过它们讨论的背景应该是和虚拟机做比较之后这么说的，因为在容器之前虚拟机是云平台上最流行的技术。强调容器是进程的目的是区分容器与虚拟机的差别，但是我不认为这个是容器的本质。其实无论是namespace (pid namespace)还是cgroups都是在管理进程， 容器中运行是进程，这个是个明显的特征了，但不是本质。我们如果换一个角度去思考，如果容器流行先于虚拟机技术， 我们是否还会强调容器是进程了呢？--><h2 id="理解进程（2）：为什么我的容器里有这么多僵尸进程？"><a href="#理解进程（2）：为什么我的容器里有这么多僵尸进程？" class="headerlink" title="理解进程（2）：为什么我的容器里有这么多僵尸进程？"></a>理解进程（2）：为什么我的容器里有这么多僵尸进程？</h2><p><strong>问题再现</strong></p><p>我们平时用容器的时候，有的同学会发现，自己的容器运行久了之后，运行 ps 命令会看到一些进程，进程名后面加了 <defunct> 标识。那么你自然会有这样的疑问，这些是什么进程呢？</p><p>你可以自己做个容器镜像来模拟一下，运行 make image 之后，再启动容器。</p><p>在容器里我们可以看到，1 号进程 fork 出 1000 个子进程。当这些子进程运行结束后，它们的进程名字后面都加了标识。</p><p>从它们的 Z stat（进程状态）中我们可以知道，这些都是僵尸进程（Zombie Process）。运行 top 命令，我们也可以看到输出的内容显示有 1000 zombie 进程。</p><p><strong>Makefile</strong></p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: app-test image</span></span><br><span class="line"><span class="section">app-test: app-test.c</span></span><br><span class="line">gcc -o app-test app-test.c</span><br><span class="line"></span><br><span class="line"><span class="section">image: app-test</span></span><br><span class="line">docker build -t registry/zombie-proc:v1 .</span><br><span class="line"><span class="section">clean: </span></span><br><span class="line">rm -f *.o app-test</span><br><span class="line">docker rmi registry/zombie-proc:v1</span><br></pre></td></tr></table></figure><p><strong>Dockerfile</strong></p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./app-test /</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"/app-test"</span>, <span class="string">"1000"</span>]</span></span><br></pre></td></tr></table></figure><p><strong>app-test-nowait.c</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">int</span> total;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (argc &lt; <span class="number">2</span>) &#123;</span><br><span class="line">total = <span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">total = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"To create %d processes\n"</span>, total);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line"><span class="keyword">pid_t</span> pid = fork();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (pid == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Child =&gt; PPID: %d PID: %d\n"</span>, getppid(),</span><br><span class="line">       getpid());</span><br><span class="line">sleep(<span class="number">60</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Child process eixts\n"</span>);</span><br><span class="line"><span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (pid &gt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Parent created child %d\n"</span>, i);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Unable to create child process. %d\n"</span>, i);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Paraent is sleeping\n"</span>);</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">sleep(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>app-test-wait.c</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">int</span> total;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (argc &lt; <span class="number">2</span>) &#123;</span><br><span class="line">total = <span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">total = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"To create %d processes\n"</span>, total);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line"><span class="keyword">pid_t</span> pid = fork();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (pid == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Child =&gt; PPID: %d PID: %d\n"</span>, getppid(),</span><br><span class="line">       getpid());</span><br><span class="line">sleep(<span class="number">60</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Child process eixts\n"</span>);</span><br><span class="line"><span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (pid &gt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Parent created child %d\n"</span>, i);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Unable to create child process. %d\n"</span>, i);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line"><span class="keyword">int</span> status;</span><br><span class="line">wait(&amp;status);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Paraent is sleeping\n"</span>);</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">sleep(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>app-test.c</strong>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">int</span> total;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (argc &lt; <span class="number">2</span>) &#123;</span><br><span class="line">total = <span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">total = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"To create %d processes\n"</span>, total);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line"><span class="keyword">pid_t</span> pid = fork();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (pid == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Child =&gt; PPID: %d PID: %d\n"</span>, getppid(),</span><br><span class="line">       getpid());</span><br><span class="line">sleep(<span class="number">60</span>);</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Child process eixts\n"</span>);</span><br><span class="line"><span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (pid &gt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Parent created child %d\n"</span>, i);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Unable to create child process. %d\n"</span>, i);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Paraent is sleeping\n"</span>);</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">sleep(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># docker run --name zombie-proc -d registry/zombie-proc:v1</span></span><br><span class="line">02dec161a9e8b18922bd3599b922dbd087a2ad60c9b34afccde7c91a463bde8a</span><br><span class="line"><span class="comment"># docker exec -it zombie-proc bash</span></span><br><span class="line"><span class="comment"># ps aux</span></span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.0   4324  1436 ?        Ss   01:23   0:00 /app-test 1000</span><br><span class="line">root         6  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root         7  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root         8  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root         9  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root        10  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">…</span><br><span class="line">root       999  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root      1000  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root      1001  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root      1002  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root      1003  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root      1004  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root      1005  0.0  0.0      0     0 ?        Z    01:23   0:00 [app-test] &lt;defunct&gt;</span><br><span class="line">root      1023  0.0  0.0  12020  3392 pts/0    Ss   01:39   0:00 bash</span><br><span class="line"><span class="comment"># top</span></span><br><span class="line">top - 02:18:57 up 31 days, 15:17,  0 users,  load average: 0.00, 0.01, 0.00</span><br><span class="line">Tasks: 1003 total,   1 running,   2 sleeping,   0 stopped, 1000 zombie</span><br><span class="line">…</span><br></pre></td></tr></table></figure><p>那么问题来了，什么是僵尸进程？它们是怎么产生的？僵尸进程太多会导致什么问题？想要回答这些问题，我们就要从进程状态的源头学习，看看僵尸进程到底处于进程整个生命周期里的哪一环。</p><h3 id="Linux-的进程状态"><a href="#Linux-的进程状态" class="headerlink" title="Linux 的进程状态"></a>Linux 的进程状态</h3><p>无论进程还是线程，在 Linux 内核里其实都是用 <strong>task_struct{}这个结构</strong>来表示的。它其实就是任务（task），也就是 Linux 里基本的调度单位。为了方便讲解，我们在这里暂且称它为进程。</p><p>那一个进程从创建（fork）到退出（exit），这个过程中的状态转化还是很简单的。</p><p>下面这个图是 《Linux Kernel Development》这本书里的 Linux 进程状态转化图。</p><p>我们从这张图中可以看出来，在进程“活着”的时候就只有两个状态：运行态（TASK_RUNNING）和睡眠态（TASK_INTERRUPTIBLE，TASK_UNINTERRUPTIBLE）。</p><p><img src="/images/docker/docker-04/7.jpg" alt="7"></p><p>那运行态和睡眠态这两种状态分别是什么意思呢？</p><p>运行态的意思是，无论进程是正在运行中（也就是获得了 CPU 资源），还是进程在 run queue 队列里随时可以运行，都处于这个状态。</p><p>我们想要查看进程是不是处于运行态，其实也很简单，比如使用 ps 命令，可以看到处于这个状态的进程显示的是 R stat。</p><p>睡眠态是指，进程需要等待某个资源而进入的状态，要等待的资源可以是一个信号量（Semaphore）, 或者是磁盘 I/O，这个状态的进程会被放入到 wait queue 队列里。</p><p>这个睡眠态具体还包括两个子状态：一个是可以被打断的（TASK_INTERRUPTIBLE），我们用 ps 查看到的进程，显示为 S stat。还有一个是不可被打断的（TASK_UNINTERRUPTIBLE），用 ps 查看进程，就显示为 D stat。</p><p>这两个子状态，我们在后面碰到新的问题时，会再做详细介绍，这里你只要知道这些就行了。</p><p>除了上面进程在活的时候的两个状态，进程在调用 do_exit() 退出的时候，还有两个状态。</p><p>一个是 EXIT_DEAD，也就是进程在真正结束退出的那一瞬间的状态；第二个是 <strong>EXIT_ZOMBIE 状态，这是进程在 EXIT_DEAD 前的一个状态，而我们今天讨论的僵尸进程，也就是处于这个状态中。</strong></p><h3 id="限制容器中进程数目"><a href="#限制容器中进程数目" class="headerlink" title="限制容器中进程数目"></a>限制容器中进程数目</h3><p>理解了 Linux 进程状态之后，我们还需要知道，在 Linux 系统中怎么限制进程数目。因为弄清楚这个问题，我们才能更深入地去理解僵尸进程的危害。</p><p>一台 Linux 机器上的进程总数目是有限制的。如果超过这个最大值，那么系统就无法创建出新的进程了，比如你想 SSH 登录到这台机器上就不行了。</p><p>这个最大值可以我们在 /proc/sys/kernel/pid_max 这个参数中看到。</p><p>Linux 内核在初始化系统的时候，会根据机器 CPU 的数目来设置 pid_max 的值。</p><p>比如说，如果机器中 CPU 数目小于等于 32，那么 pid_max 就会被设置为 32768（32K）；如果机器中的 CPU 数目大于 32，那么 pid_max 就被设置为 N*1204 （N 就是 CPU 数目）。</p><p>对于 Linux 系统而言，容器就是一组进程的集合。如果容器中的应用创建过多的进程或者出现 bug，就会产生类似 fork bomb 的行为。</p><p>这个 fork bomb 就是指在计算机中，通过不断建立新进程来消耗系统中的进程资源，它是一种黑客攻击方式。这样，容器中的进程数就会把整个节点的可用进程总数给消耗完。</p><p>这样，不但会使同一个节点上的其他容器无法工作，还会让宿主机本身也无法工作。所以对于每个容器来说，我们都需要限制它的最大进程数目，而这个功能由 pids Cgroup 这个子系统来完成。</p><p>而这个功能的实现方法是这样的：pids Cgroup 通过 Cgroup 文件系统的方式向用户提供操作接口，一般它的 Cgroup 文件系统挂载点在 /sys/fs/cgroup/pids。</p><p>在一个容器建立之后，创建容器的服务会在 /sys/fs/cgroup/pids 下建立一个子目录，就是一个控制组，控制组里<strong>最关键的一个文件就是 pids.max</strong>。我们可以向这个文件写入数值，而这个值就是这个容器中允许的最大进程数目。</p><p>我们对这个值做好限制，容器就不会因为创建出过多进程而影响到其他容器和宿主机了。思路讲完了，接下来我们就实际上手试一试。</p><p>下面是对一个 Docker 容器的 pids Cgroup 的操作，你可以跟着操作一下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">pwd</span></span><br><span class="line">/sys/fs/cgroup/pids</span><br><span class="line">$ df ./</span><br><span class="line">Filesystem     1K-blocks  Used Available Use% Mounted on</span><br><span class="line">cgroup                 0     0         0    - /sys/fs/cgroup/pids</span><br><span class="line">$ docker ps</span><br><span class="line">CONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">7ecd3aa7fdc1        registry/zombie-proc:v1   <span class="string">"/app-test 1000"</span>         37 hours ago        Up 37 hours                             frosty_yalow</span><br><span class="line">$ <span class="built_in">pwd</span></span><br><span class="line">/sys/fs/cgroup/pids/system.slice/docker-7ecd3aa7fdc15a1e183813b1899d5d939beafb11833ad6c8b0432536e5b9871c.scope</span><br><span class="line">$ ls</span><br><span class="line">cgroup.clone_children  cgroup.procs  notify_on_release  pids.current  pids.events  pids.max  tasks</span><br><span class="line">$ <span class="built_in">echo</span> 1002 &gt; pids.max</span><br><span class="line">$ cat pids.max</span><br><span class="line">1002</span><br></pre></td></tr></table></figure><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>刚才我给你解释了两个基本概念，进程状态和进程数目限制，那我们现在就可以解决容器中的僵尸进程问题了。</p><p>在前面 Linux 进程状态的介绍里，我们知道了，僵尸进程是 Linux 进程退出状态的一种。</p><p>从内核进程的 do_exit() 函数我们也可以看到，这时候进程 task_struct 里的 mm/shm/sem/files 等文件资源都已经释放了，只留下了一个 stask_struct instance 空壳。</p><p>就像下面这段代码显示的一样，从进程对应的 /proc/<pid> 文件目录下，我们也可以看出来，对应的资源都已经没有了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/6/cmdline</span><br><span class="line">$ cat /proc/6/smaps</span><br><span class="line">$ cat /proc/6/maps</span><br><span class="line">$ ls /proc/6/fd</span><br></pre></td></tr></table></figure><p>并且，这个进程也已经不响应任何的信号了，无论 SIGTERM(15) 还是 SIGKILL(9)。例如上面 pid 6 的僵尸进程，这两个信号都已经被响应了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">kill</span> -15 6</span><br><span class="line">$ <span class="built_in">kill</span> -9 6</span><br><span class="line">$ ps -ef | grep 6</span><br><span class="line">root         6     1  0 13:59 ?        00:00:00 [app-test] &lt;defunct&gt;</span><br></pre></td></tr></table></figure><p>当多个容器运行在同一个宿主机上的时候，为了避免一个容器消耗完我们整个宿主机进程号资源，我们会配置 pids Cgroup 来限制每个容器的最大进程数目。也就是说，进程数目在每个容器中也是有限的，是一种很宝贵的资源。</p><p>既然进程号资源在宿主机上是有限的，显然残留的僵尸进程多了以后，给系统带来最大问题就是它占用了进程号。<strong>这就意味着，残留的僵尸进程，在容器里仍然占据着进程号资源，很有可能会导致新的进程不能运转。</strong></p><p>这里我再次借用开头的那个例子，也就是一个产生了 1000 个僵尸进程的容器，带你理解一下这个例子中进程数的上限。我们可以看一下，1 个 init 进程 +1000 个僵尸进程 +1 个 bash 进程 ，总共就是 1002 个进程。</p><p>如果 pids Cgroup 也限制了这个容器的最大进程号的数量，限制为 1002 的话，我们在 pids Cgroup 里可以看到，pids.current == pids.max，也就是已经达到了容器进程号数的上限。</p><p>这时候，如果我们在容器里想再启动一个进程，例如运行一下 ls 命令，就会看到 Resource temporarily unavailable 的错误消息。已经退出的无用进程，却阻碍了有用进程的启动，显然这样是不合理的。</p><p>具体代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### On host</span></span><br><span class="line"><span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID        IMAGE                      COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line">09e6e8e16346        registry/zombie-proc:v1   <span class="string">"/app-test 1000"</span>    29 minutes ago      Up 29 minutes                           peaceful_ritchie</span><br><span class="line"><span class="comment"># pwd</span></span><br><span class="line">/sys/fs/cgroup/pids/system.slice/docker-09e6e8e1634612580a03dd3496d2efed2cf2a510b9688160b414ce1d1ea3e4ae.scope</span><br><span class="line"><span class="comment"># cat pids.max</span></span><br><span class="line">1002</span><br><span class="line"><span class="comment"># cat pids.current</span></span><br><span class="line">1002</span><br><span class="line"><span class="comment">### On Container</span></span><br><span class="line">[root@09e6e8e16346 /]<span class="comment"># ls</span></span><br><span class="line">bash: fork: retry: Resource temporarily unavailable</span><br><span class="line">bash: fork: retry: Resource temporarily unavailable</span><br></pre></td></tr></table></figure><p>所以，接下来我们还要看看这些僵尸进程到底是怎么产生的。因为只有理解它的产生机制，我们才能想明白怎么避免僵尸进程的出现。</p><p>我们先看一下刚才模拟僵尸进程的那段小程序。这段程序里，父进程在创建完子进程之后就不管了，这就是造成子进程变成僵尸进程的原因。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">       <span class="keyword">int</span> i;</span><br><span class="line">       <span class="keyword">int</span> total;</span><br><span class="line">       <span class="keyword">if</span> (argc &lt; <span class="number">2</span>) &#123;</span><br><span class="line">              total = <span class="number">1</span>;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              total = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">"To create %d processes\n"</span>, total);</span><br><span class="line">       <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line">              <span class="keyword">pid_t</span> pid = fork();</span><br><span class="line"> </span><br><span class="line">              <span class="keyword">if</span> (pid == <span class="number">0</span>) &#123;</span><br><span class="line">                      <span class="built_in">printf</span>(<span class="string">"Child =&gt; PPID: %d PID: %d\n"</span>, getppid(),</span><br><span class="line">                             getpid());</span><br><span class="line">                      sleep(<span class="number">60</span>);</span><br><span class="line">                      <span class="built_in">printf</span>(<span class="string">"Child process exits\n"</span>);</span><br><span class="line">                      <span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">              &#125; <span class="keyword">else</span> <span class="keyword">if</span> (pid &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                      <span class="built_in">printf</span>(<span class="string">"Parent created child %d\n"</span>, i);</span><br><span class="line">              &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                      <span class="built_in">printf</span>(<span class="string">"Unable to create child process. %d\n"</span>, i);</span><br><span class="line">                      <span class="keyword">break</span>;</span><br><span class="line">              &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">"Paraent is sleeping\n"</span>);</span><br><span class="line">       <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">              sleep(<span class="number">100</span>);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>前面我们通过分析，发现子进程变成僵尸进程的原因在于父进程“不负责”，那找到原因后，我们再想想，如何来解决。</p><p>其实解决思路很好理解，就好像熊孩子犯了事儿，你要去找他家长来管教，那子进程在容器里“赖着不走”，我们就需要让父进程出面处理了。</p><p>所以，在 Linux 中的进程退出之后，如果进入僵尸状态，我们就需要父进程调用 wait() 这个系统调用，去回收僵尸进程的最后的那些系统资源，比如进程号资源。</p><p>那么，我们在刚才那段代码里，主进程进入 sleep(100) 之前，加上一段 wait() 函数调用，就不会出现僵尸进程的残留了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> status;</span><br><span class="line">            wait(&amp;status);</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p>而容器中所有进程的最终父进程，就是我们所说的 init 进程，由它负责生成容器中的所有其他进程。因此，容器的 init 进程有责任回收容器中的所有僵尸进程。</p><p>前面我们知道了 wait() 系统调用可以回收僵尸进程，但是 wait() 系统调用有一个问题，需要你注意。</p><p>wait() 系统调用是一个阻塞的调用，也就是说，如果没有子进程是僵尸进程的话，这个调用就一直不会返回，那么整个进程就会被阻塞住，而不能去做别的事了。</p><p>不过这也没有关系，我们还有另一个方法处理。Linux 还提供了一个类似的系统调用 waitpid()，这个调用的参数更多。</p><p>其中就有一个参数 WNOHANG，它的含义就是，如果在调用的时候没有僵尸进程，那么函数就马上返回了，而不会像 wait() 调用那样一直等待在那里。</p><p>比如社区的一个容器 init 项目 tini。在这个例子中，它的主进程里，就是不断在调用带 WNOHANG 参数的 waitpid()，通过这个方式清理容器中所有的僵尸进程。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">reap_zombies</span><span class="params">(<span class="keyword">const</span> <span class="keyword">pid_t</span> child_pid, <span class="keyword">int</span>* <span class="keyword">const</span> child_exitcode_ptr)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">pid_t</span> current_pid;</span><br><span class="line">        <span class="keyword">int</span> current_status;</span><br><span class="line">        <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">                current_pid = waitpid(<span class="number">-1</span>, &amp;current_status, WNOHANG);</span><br><span class="line">                <span class="keyword">switch</span> (current_pid) &#123;</span><br><span class="line">                        <span class="keyword">case</span> <span class="number">-1</span>:</span><br><span class="line">                                <span class="keyword">if</span> (errno == ECHILD) &#123;</span><br><span class="line">                                        PRINT_TRACE(<span class="string">"No child to wait"</span>);</span><br><span class="line">                                        <span class="keyword">break</span>;</span><br><span class="line">                                &#125;</span><br><span class="line">…</span><br></pre></td></tr></table></figure><!--### 重点总结今天我们讨论的问题是容器中的僵尸进程。首先，我们先用代码来模拟了这个情况，还原了在一个容器中大量的僵尸进程是如何产生的。为了理解它的产生原理和危害，我们先要掌握两个知识点：Linux 进程状态中，僵尸进程处于 EXIT_ZOMBIE 这个状态；容器需要对最大进程数做限制。具体方法是这样的，我们可以向 Cgroup 中 **pids.max** 这个文件写入数值（这个值就是这个容器中允许的最大进程数目）。掌握了基本概念之后，我们找到了僵尸进程的产生原因。父进程在创建完子进程之后就不管了。所以，我们需要父进程调用 wait() 或者 waitpid() 系统调用来避免僵尸进程产生。关于本节内容，你只要记住下面三个主要的知识点就可以了：1. 每一个 Linux 进程在退出的时候都会进入一个僵尸状态（EXIT_ZOMBIE）；2. 僵尸进程如果不清理，就会消耗系统中的进程数资源，最坏的情况是导致新的进程无法启动；3. 僵尸进程一定需要父进程调用 wait() 或者 waitpid() 系统调用来清理，这也是容器中 init 进程必须具备的一个功能。--><h2 id="理解进程（3）：为什么我在容器中的进程被强制杀死了？"><a href="#理解进程（3）：为什么我在容器中的进程被强制杀死了？" class="headerlink" title="理解进程（3）：为什么我在容器中的进程被强制杀死了？"></a>理解进程（3）：为什么我在容器中的进程被强制杀死了？</h2><p>我先给你说说，为什么进程管理中做到这点很重要。在实际生产环境中，我们有不少应用在退出的时候需要做一些清理工作，比如清理一些远端的链接，或者是清除一些本地的临时数据。</p><p>这样的清理工作，可以尽可能避免远端或者本地的错误发生，比如减少丢包等问题的出现。而这些退出清理的工作，通常是在 SIGTERM 这个信号用户注册的 handler 里进行的。</p><p>但是，如果我们的进程收到了 SIGKILL，那应用程序就没机会执行这些清理工作了。这就意味着，一旦进程不能 graceful shutdown，就会增加应用的出错率。</p><h3 id="场景再现"><a href="#场景再现" class="headerlink" title="场景再现"></a>场景再现</h3><p>在容器平台上，你想要停止一个容器，无论是在 Kubernetes 中去删除一个 pod，或者用 Docker 停止一个容器，最后都会用到 Containerd 这个服务。</p><p>而 Containerd 在停止容器的时候，就会向容器的 init 进程发送一个 SIGTERM 信号。</p><p>我们会发现，在 init 进程退出之后，容器内的其他进程也都立刻退出了。不过不同的是，init 进程收到的是 SIGTERM 信号，而其他进程收到的是 SIGKILL 信号。</p><p>在理解进程的第一讲中，我们提到过 SIGKILL 信号是不能被捕获的（catch）的，也就是用户不能注册自己的 handler，而 SIGTERM 信号却允许用户注册自己的 handler，这样的话差别就很大了。</p><p>那么，我们就一起来看看当容器退出的时候，如何才能让容器中的进程都收到 SIGTERM 信号，而不是 SIGKILL 信号。</p><p>延续前面课程中处理问题的思路，我们同样可以运行一个简单的容器，来重现这个问题，用这里的代码执行一下 make image ，然后用 Docker 启动这个容器镜像。</p><p>Dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">8.1</span>.<span class="number">1911</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./c-init-sig /</span></span><br></pre></td></tr></table></figure><p>c-init-sig.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sig_handler</span><span class="params">(<span class="keyword">int</span> signo)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (signo == SIGTERM) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"received SIGTERM\n"</span>);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"><span class="keyword">int</span> total;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (argc &lt; <span class="number">2</span>) &#123;</span><br><span class="line">total = <span class="number">1</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">total = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">signal(SIGTERM, sig_handler);</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"To create %d processes\n"</span>, total);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; total; i++) &#123;</span><br><span class="line"><span class="keyword">pid_t</span> pid = fork();</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (pid == <span class="number">0</span>) &#123;</span><br><span class="line"><span class="keyword">pid_t</span> m_pid, p_pid;</span><br><span class="line">m_pid = getpid();</span><br><span class="line">p_pid = getppid();</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Child =&gt; PPID: %d PID: %d\n"</span>, p_pid, m_pid);</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">sleep(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Child process eixts\n"</span>);</span><br><span class="line"><span class="built_in">exit</span>(EXIT_SUCCESS);</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (pid &gt; <span class="number">0</span>) &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Parent created child %d\n"</span>, i);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Unable to create child process. %d\n"</span>, i);</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"Paraent is sleeping\n"</span>);</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">sleep(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> EXIT_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Makefile</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">all: c-init-sig image</span></span><br><span class="line"><span class="section">c-init-sig: c-init-sig.c</span></span><br><span class="line">gcc -o c-init-sig c-init-sig.c</span><br><span class="line"></span><br><span class="line"><span class="section">image: c-init-sig</span></span><br><span class="line">docker build -t registry/fwd_sig:v1 .</span><br><span class="line"><span class="section">clean: </span></span><br><span class="line">rm -f *.o c-init-sig</span><br><span class="line">docker rmi registry/fwd_sig:v1</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name fwd_sig registry/fwd_sig:v1 /c-init-sig</span><br></pre></td></tr></table></figure><p>你会发现，在我们用 docker stop 停止这个容器的时候，如果用 strace 工具来监控，就能看到容器里的 init 进程和另外一个进程收到的信号情况。</p><p>在下面的例子里，进程号为 15909 的就是容器里的 init 进程，而进程号为 15959 的是容器里另外一个进程。</p><p>在命令输出中我们可以看到，<strong>init 进程（15909）收到的是 SIGTERM 信号，而另外一个进程（15959）收到的果然是 SIGKILL 信号。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ps -ef | grep c-init-sig</span></span><br><span class="line">root     15857 14391  0 06:23 pts/0    00:00:00 docker run -it registry/fwd_sig:v1 /c-init-sig</span><br><span class="line">root     15909 15879  0 06:23 pts/0    00:00:00 /c-init-sig</span><br><span class="line">root     15959 15909  0 06:23 pts/0    00:00:00 /c-init-sig</span><br><span class="line">root     16046 14607  0 06:23 pts/3    00:00:00 grep --color=auto c-init-sig</span><br><span class="line"><span class="comment"># strace -p 15909</span></span><br><span class="line">strace: Process 15909 attached</span><br><span class="line">restart_syscall(&lt;... resuming interrupted <span class="built_in">read</span> ...&gt;) = ? ERESTART_RESTARTBLOCK (Interrupted by signal)</span><br><span class="line">--- SIGTERM &#123;si_signo=SIGTERM, si_code=SI_USER, si_pid=0, si_uid=0&#125; ---</span><br><span class="line">write(1, <span class="string">"received SIGTERM\n"</span>, 17)      = 17</span><br><span class="line">exit_group(0)                           = ?</span><br><span class="line">+++ exited with 0 +++</span><br><span class="line"><span class="comment"># strace -p 15959</span></span><br><span class="line">strace: Process 15959 attached</span><br><span class="line">restart_syscall(&lt;... resuming interrupted <span class="built_in">read</span> ...&gt;) = ?</span><br><span class="line">+++ killed by SIGKILL +++</span><br></pre></td></tr></table></figure><h3 id="知识详解：信号的两个系统调用"><a href="#知识详解：信号的两个系统调用" class="headerlink" title="知识详解：信号的两个系统调用"></a>知识详解：信号的两个系统调用</h3><p>我们想要理解刚才的例子，就需要搞懂信号背后的两个系统调用，它们分别是 kill() 系统调用和 signal() 系统调用。</p><p>这里呢，我们可以结合前面讲过的信号来理解这两个系统调用。在容器 init 进程的第一讲里，我们介绍过信号的基本概念了，<strong>信号就是 Linux 进程收到的一个通知。</strong></p><p>等你学完如何使用这两个系统调用之后，就会更清楚 Linux 信号是怎么一回事，遇到容器里信号相关的问题，你就能更好地理清思路了。</p><p>我还会再给你举个使用函数的例子，帮助你进一步理解进程是如何实现 graceful shutdown 的。</p><p>进程对信号的处理其实就包括两个问题，<strong>一个是进程如何发送信号，另一个是进程收到信号后如何处理。</strong></p><p>我们在 Linux 中发送信号的系统调用是 kill()，之前很多例子里面我们用的命令 kill ，它内部的实现就是调用了 kill() 这个函数。</p><p>下面是 Linux Programmer’s Manual 里对 kill() 函数的定义。</p><p>这个函数有两个参数，一个是 sig，代表需要发送哪个信号，比如 sig 的值是 15 的话，就是指发送 SIGTERM；另一个参数是 pid，也就是指信号需要发送给哪个进程，比如值是 1 的话，就是指发送给进程号是 1 的进程。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NAME</span><br><span class="line">       kill - send signal to a <span class="built_in">process</span></span><br><span class="line">SYNOPSIS</span><br><span class="line">       <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line">       <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line">       <span class="function"><span class="keyword">int</span> <span class="title">kill</span><span class="params">(<span class="keyword">pid_t</span> pid, <span class="keyword">int</span> sig)</span></span>;</span><br></pre></td></tr></table></figure><p>我们知道了发送信号的系统调用之后，再来看另一个系统调用，也就是 signal() 系统调用这个函数，它可以给信号注册 handler。</p><p>下面是 signal() 在 Linux Programmer’s Manual 里的定义，参数 signum 也就是信号的编号，例如数值 15，就是信号 SIGTERM；参数 handler 是一个函数指针参数，用来注册用户的信号 handler。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NAME</span><br><span class="line">       signal - ANSI C signal handling</span><br><span class="line">SYNOPSIS</span><br><span class="line">       <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line">       <span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*<span class="keyword">sighandler_t</span>)</span><span class="params">(<span class="keyword">int</span>)</span></span>;</span><br><span class="line">       <span class="function"><span class="keyword">sighandler_t</span> <span class="title">signal</span><span class="params">(<span class="keyword">int</span> signum, <span class="keyword">sighandler_t</span> handler)</span></span>;</span><br></pre></td></tr></table></figure><p>在容器 init 进程的第一讲里，<strong>我们学过进程对每种信号的处理，包括三个选择：调用系统缺省行为、捕获、忽略。</strong>而这里的选择，其实就是程序中如何去调用 signal() 这个系统调用。</p><p>第一个选择就是缺省，如果我们在代码中对某个信号，比如 SIGTERM 信号，不做任何 signal() 相关的系统调用，那么在进程运行的时候，如果接收到信号 SIGTERM，进程就会执行内核中 SIGTERM 信号的缺省代码。</p><p>对于 SIGTERM 这个信号来说，它的缺省行为就是进程退出（terminate）。</p><p>内核中对不同的信号有不同的缺省行为，一般会采用退出（terminate），暂停（stop），忽略（ignore）这三种行为中的一种。</p><p>那第二个选择捕获又是什么意思呢?</p><p>捕获指的就是我们在代码中为某个信号，调用 signal() 注册自己的 handler。这样进程在运行的时候，一旦接收到信号，就不会再去执行内核中的缺省代码，而是会执行通过 signal() 注册的 handler。</p><p>比如下面这段代码，我们为 SIGTERM 这个信号注册了一个 handler，在 handler 里只是做了一个打印操作。</p><p>那么这个程序在运行的时候，如果收到 SIGTERM 信号，它就不会退出了，而是只在屏幕上显示出”received SIGTERM”。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sig_handler</span><span class="params">(<span class="keyword">int</span> signo)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (signo == SIGTERM) &#123;</span><br><span class="line">          <span class="built_in">printf</span>(<span class="string">"received SIGTERM\n"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">  signal(SIGTERM, sig_handler);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们再来看看第三个选择，如果要让进程“忽略”一个信号，我们就要通过 signal() 这个系统调用，为这个信号注册一个特殊的 handler，也就是 SIG_IGN 。</p><p>比如下面的这段代码，就是为 SIGTERM 这个信号注册SIG_IGN。</p><p>这样操作的效果，就是在程序运行的时候，如果收到 SIGTERM 信号，程序既不会退出，也不会在屏幕上输出 log，而是什么反应也没有，就像完全没有收到这个信号一样。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">  signal(SIGTERM, SIG_IGN);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line">```  </span><br><span class="line"></span><br><span class="line">好了，我们通过讲解 signal() 这个系统调用，帮助你回顾了信号处理的三个选择：缺省行为、捕获和忽略。</span><br><span class="line"></span><br><span class="line">这里我还想要提醒你一点， **SIGKILL 和 SIGSTOP 信号是两个特权信号，它们不可以被捕获和忽略，这个特点也反映在 signal() 调用上。**</span><br><span class="line"></span><br><span class="line">我们可以运行下面的这段代码，如果我们用 signal() 为 SIGKILL 注册 handler，那么它就会返回 SIG_ERR，不允许我们做捕获操作。</span><br><span class="line"></span><br><span class="line">Makefile</span><br><span class="line"></span><br><span class="line">```Makefile</span><br><span class="line">all: basic-sig reg-sigkill</span><br><span class="line"></span><br><span class="line">basic-sig: basic-sig.c</span><br><span class="line">gcc -o basic-sig basic-sig.c</span><br><span class="line"></span><br><span class="line">reg-sigkill: reg-sigkill.c</span><br><span class="line">gcc -o reg-sigkill reg-sigkill.c</span><br><span class="line"></span><br><span class="line">clean:</span><br><span class="line">rm -f *.o basic-sig reg-sigkill</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat reg_sigkill.c</span></span><br><span class="line"><span class="comment">#include &lt;stdio.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;stdlib.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;unistd.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;errno.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;signal.h&gt;</span></span><br><span class="line">typedef void (*sighandler_t)(int);</span><br><span class="line">void sig_handler(int signo)</span><br><span class="line">&#123;</span><br><span class="line">            <span class="keyword">if</span> (signo == SIGKILL) &#123;</span><br><span class="line">                        <span class="built_in">printf</span>(<span class="string">"received SIGKILL\n"</span>);</span><br><span class="line">                        <span class="built_in">exit</span>(0);</span><br><span class="line">            &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">            sighandler_t h_ret;</span><br><span class="line">            h_ret = signal(SIGKILL, sig_handler);</span><br><span class="line">            <span class="keyword">if</span> (h_ret == SIG_ERR) &#123;</span><br><span class="line">                        perror(<span class="string">"SIG_ERR"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">return</span> 0;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># ./reg_sigkill</span></span><br><span class="line">SIG_ERR: Invalid argument</span><br></pre></td></tr></table></figure><p>最后，我用下面这段代码来做个小结。</p><p>这段代码里，我们用 signal() 对 SIGTERM 这个信号做了忽略，捕获以及恢复它的缺省行为，并且每一次都用 kill() 系统调用向进程自己发送 SIGTERM 信号，这样做可以确认进程对 SIGTERM 信号的选择。</p><p>basic-sig.c</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;signal.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*<span class="keyword">sighandler_t</span>)</span><span class="params">(<span class="keyword">int</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sig_handler</span><span class="params">(<span class="keyword">int</span> signo)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (signo == SIGTERM) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">"received SIGTERM\n\n"</span>);</span><br><span class="line">                <span class="comment">// Set SIGTERM handler to default</span></span><br><span class="line">                signal(SIGTERM, SIG_DFL);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="comment">//Ignore SIGTERM, and send SIGTERM</span></span><br><span class="line">        <span class="comment">// to process itself.</span></span><br><span class="line">        signal(SIGTERM, SIG_IGN);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Ignore SIGTERM\n\n"</span>);</span><br><span class="line">        kill(<span class="number">0</span>, SIGTERM);</span><br><span class="line">        <span class="comment">//Catch SIGERM, and send SIGTERM</span></span><br><span class="line">        <span class="comment">// to process itself.</span></span><br><span class="line">        signal(SIGTERM, sig_handler);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Catch SIGTERM\n"</span>);</span><br><span class="line">        kill(<span class="number">0</span>, SIGTERM);</span><br><span class="line"> </span><br><span class="line">        <span class="comment">//Default SIGTERM. In sig_handler, it sets</span></span><br><span class="line">        <span class="comment">//SIGTERM handler back to default one.</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"Default SIGTERM\n"</span>);</span><br><span class="line">        kill(<span class="number">0</span>, SIGTERM);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们一起来总结一下刚才讲的两个系统调用：</p><p>先说说 kill() 这个系统调用，它其实很简单，输入两个参数：进程号和信号，就把特定的信号发送给指定的进程了。</p><p>再说说 signal() 这个调用，它决定了进程收到特定的信号如何来处理，SIG_DFL 参数把对应信号恢复为缺省 handler，也可以用自定义的函数作为 handler，或者用 SIG_IGN 参数让进程忽略信号。</p><p>对于 SIGKILL 信号，如果调用 signal() 函数，为它注册自定义的 handler，系统就会拒绝。</p><h3 id="解决问题-1"><a href="#解决问题-1" class="headerlink" title="解决问题"></a>解决问题</h3><p>我们在学习了 kill() 和 signal() 这个两个信号相关的系统调用之后，再回到这一讲最初的问题上，为什么在停止一个容器的时候，容器 init 进程收到的 SIGTERM 信号，而容器中其他进程却会收到 SIGKILL 信号呢？</p><p>当 Linux 进程收到 SIGTERM 信号并且使进程退出，这时 Linux 内核对处理进程退出的入口点就是 do_exit() 函数，do_exit() 函数中会释放进程的相关资源，比如内存，文件句柄，信号量等等。</p><p>Linux 内核对处理进程退出的入口点就是 do_exit() 函数，do_exit() 函数中会释放进程的相关资源，比如内存，文件句柄，信号量等等。</p><p>在做完这些工作之后，它会调用一个 exit_notify() 函数，用来通知和这个进程相关的父子进程等。</p><p>对于容器来说，还要考虑 Pid Namespace 里的其他进程。这里调用的就是 zap_pid_ns_processes() 这个函数，而在这个函数中，如果是处于退出状态的 init 进程，它会向 Namespace 中的其他进程都发送一个 SIGKILL 信号。</p><p>整个流程如下图所示。</p><p><img src="/images/docker/docker-04/8.jpg" alt="8"></p><p>你还可以看一下，内核代码是这样的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        * The last thread in the cgroup-init thread group is terminating.</span></span><br><span class="line"><span class="comment">        * Find remaining pid_ts in the namespace, signal and wait for them</span></span><br><span class="line"><span class="comment">        * to exit.</span></span><br><span class="line"><span class="comment">        *</span></span><br><span class="line"><span class="comment">        * Note:  This signals each threads in the namespace - even those that</span></span><br><span class="line"><span class="comment">        *        belong to the same thread group, To avoid this, we would have</span></span><br><span class="line"><span class="comment">        *        to walk the entire tasklist looking a processes in this</span></span><br><span class="line"><span class="comment">        *        namespace, but that could be unnecessarily expensive if the</span></span><br><span class="line"><span class="comment">        *        pid namespace has just a few processes. Or we need to</span></span><br><span class="line"><span class="comment">        *        maintain a tasklist for each pid namespace.</span></span><br><span class="line"><span class="comment">        *</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">       rcu_read_lock();</span><br><span class="line">       read_lock(&amp;tasklist_lock);</span><br><span class="line">       nr = <span class="number">2</span>;</span><br><span class="line">       idr_for_each_entry_continue(&amp;pid_ns-&gt;idr, pid, nr) &#123;</span><br><span class="line">               task = pid_task(pid, PIDTYPE_PID);</span><br><span class="line">               <span class="keyword">if</span> (task &amp;&amp; !__fatal_signal_pending(task))</span><br><span class="line">                       group_send_sig_info(SIGKILL, SEND_SIG_PRIV, task, PIDTYPE_MAX);</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><p>说到这里，我们也就明白为什么容器 init 进程收到的 SIGTERM 信号，而容器中其他进程却会收到 SIGKILL 信号了。</p><p>前面我讲过，SIGKILL 是个特权信号（特权信号是 Linux 为 kernel 和超级用户去删除任意进程所保留的，不能被忽略也不能被捕获）。</p><p>所以进程收到这个信号后，就立刻退出了，没有机会调用一些释放资源的 handler 之后，再做退出动作。</p><p>而 SIGTERM 是可以被捕获的，用户是可以注册自己的 handler 的。因此，容器中的程序在 stop container 的时候，我们更希望进程收到 SIGTERM 信号而不是 SIGKILL 信号。</p><p>那在容器被停止的时候，我们该怎么做，才能让容器中的进程收到 SIGTERM 信号呢？</p><p>你可能已经想到了，就是让容器 init 进程来转发 SIGTERM 信号。的确是这样，比如 Docker Container 里使用的 tini 作为 init 进程，tini 的代码中就会调用 sigtimedwait() 这个函数来查看自己收到的信号，然后调用 kill() 把信号发给子进程。</p><p>我给你举个具体的例子说明，从下面的这段代码中，我们可以看到除了 SIGCHLD 这个信号外，tini 会把其他所有的信号都转发给它的子进程。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">wait_and_forward_signal</span><span class="params">(<span class="keyword">sigset_t</span> <span class="keyword">const</span>* <span class="keyword">const</span> parent_sigset_ptr, <span class="keyword">pid_t</span> <span class="keyword">const</span> child_pid)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">siginfo_t</span> sig;</span><br><span class="line">        <span class="keyword">if</span> (sigtimedwait(parent_sigset_ptr, &amp;sig, &amp;ts) == <span class="number">-1</span>) &#123;</span><br><span class="line">                <span class="keyword">switch</span> (errno) &#123;</span><br><span class="line">…</span><br><span class="line">                &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">/* There is a signal to handle here */</span></span><br><span class="line">                <span class="keyword">switch</span> (sig.si_signo) &#123;</span><br><span class="line">                        <span class="keyword">case</span> SIGCHLD:</span><br><span class="line">                                <span class="comment">/* Special-cased, as we don't forward SIGCHLD. Instead, we'll</span></span><br><span class="line"><span class="comment">                                 * fallthrough to reaping processes.</span></span><br><span class="line"><span class="comment">                                 */</span></span><br><span class="line">                                PRINT_DEBUG(<span class="string">"Received SIGCHLD"</span>);</span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line">                        <span class="keyword">default</span>:</span><br><span class="line">                                PRINT_DEBUG(<span class="string">"Passing signal: '%s'"</span>, strsignal(sig.si_signo));</span><br><span class="line">                                <span class="comment">/* Forward anything else */</span></span><br><span class="line">                                <span class="keyword">if</span> (kill(kill_process_group ? -child_pid : child_pid, sig.si_signo)) &#123;</span><br><span class="line">                                        <span class="keyword">if</span> (errno == ESRCH) &#123;</span><br><span class="line">                                                PRINT_WARNING(<span class="string">"Child was dead when forwarding signal"</span>);</span><br><span class="line">                                        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                                                PRINT_FATAL(<span class="string">"Unexpected error when forwarding signal: '%s'"</span>, strerror(errno));</span><br><span class="line">                                                <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">                                        &#125;</span><br><span class="line">                                &#125;</span><br><span class="line">                                <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么我们在这里明确一下，怎么解决停止容器的时候，容器内应用程序被强制杀死的问题呢？</p><p><strong>解决的方法就是在容器的 init 进程中对收到的信号做个转发，发送到容器中的其他子进程，这样容器中的所有进程在停止时，都会收到 SIGTERM，而不是 SIGKILL 信号了。</strong></p><!--### 重点小结这一讲我们要解决的问题是让容器中的进程，在容器停止的时候，有机会 graceful shutdown，而不是收到 SIGKILL 信号而被强制杀死。首先我们通过对 kill() 和 signal() 这个两个系统调用的学习，进一步理解了进程是怎样处理 Linux 信号的，重点是信号在接收处理的三个选择：**忽略，捕获和缺省行为**。通过代码例子，我们知道 SIGTERM 是可以被忽略和捕获的，但是 SIGKILL 是不可以被忽略和捕获的。了解这一点以后，我们就找到了问题的解决方向，也就是我们需要在停止容器时，让容器中的应用收到 SIGTERM，而不是 SIGKILL。具体怎么操作呢？我们可以在容器的 init 进程中对收到的信号做个转发，发送到容器中的其他子进程。这样一来，容器中的所有进程在停止容器时，都会收到 SIGTERM，而不是 SIGKILL 信号了。我认为，解决 init 进程信号的这类问题其实并不难。我们只需要先梳理一下和这个问题相关的几个知识点，再写个小程序，让它跑在容器里，稍微做几个试验。然后，我们再看一下内核和 Docker 的源代码，就可以很快得出结论了。--><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《由浅入深吃透 Docker》</li><li>《容器实战高手课》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://www.docker-cn.com" target="_blank" rel="noopener">https://www.docker-cn.com</a></li><li><a href="https://docs.docker.com/compose/compose-file/compose-file-v3/" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/compose-file-v3/</a></li><li><a href="https://docs.docker.com/compose/reference/" target="_blank" rel="noopener">https://docs.docker.com/compose/reference/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;容器是什么、理解进程&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://blog.lichao.xin/categories/Docker/"/>
    
    
      <category term="docker" scheme="https://blog.lichao.xin/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>重学 Docker 之 容器编排三剑客</title>
    <link href="https://blog.lichao.xin/back-end/docker/docker-03/"/>
    <id>https://blog.lichao.xin/back-end/docker/docker-03/</id>
    <published>2021-03-27T14:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.383Z</updated>
    
    <content type="html"><![CDATA[<p>Docker Compose 、Docker Swarm 、Kubernetes。</p><a id="more"></a><h2 id="如何使用-Docker-Compose-解决开发环境的依赖？"><a href="#如何使用-Docker-Compose-解决开发环境的依赖？" class="headerlink" title="如何使用 Docker Compose 解决开发环境的依赖？"></a>如何使用 Docker Compose 解决开发环境的依赖？</h2><h3 id="Docker-Compose-的前世今生"><a href="#Docker-Compose-的前世今生" class="headerlink" title="Docker Compose 的前世今生"></a>Docker Compose 的前世今生</h3><p>Docker Compose 的前身是 Orchard 公司开发的 Fig，2014 年 Docker 收购了 Orchard 公司，然后将 Fig 重命名为 Docker Compose。现阶段 Docker Compose 是 Docker 官方的单机多容器管理系统，它本质是一个 Python 脚本，它通过解析用户编写的 yaml 文件，调用 Docker API 实现动态的创建和管理多个容器。</p><p>要想使用 Docker Compose，需要我们先安装一个 Docker Compose。</p><h3 id="安装-Docker-Compose"><a href="#安装-Docker-Compose" class="headerlink" title="安装 Docker Compose"></a>安装 Docker Compose</h3><p>Docker Compose 可以安装在 macOS、 Windows 和 Linux 系统中，其中在 macOS 和 Windows 系统下 ，Docker Compose 都是随着 Docker 的安装一起安装好的，这里就不再详细介绍。 下面我重点介绍下如何在 Linux 系统下安装 Docker Compose。</p><h4 id="Linux-系统下安装-Docker-Compose"><a href="#Linux-系统下安装-Docker-Compose" class="headerlink" title="Linux 系统下安装 Docker Compose"></a>Linux 系统下安装 Docker Compose</h4><p>在安装 Docker Compose 之前，请确保你的机器已经正确运行了 Docker，如果你的机器还没有安装 Docker，请参考<a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener">官方网站</a>安装 Docker。</p><p>要在 Linux 平台上安装 Docker Compose，我们需要到 Compose 的 Github 页面下载对应版本的安装包。这里我以 1.27.3 版本为例，带你安装一个 Docker Compose。</p><p>（1）使用 curl 命令（一种发送 http 请求的命令行工具）下载 Docker Compose 的安装包：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo curl -L <span class="string">"https://github.com/docker/compose/releases/download/1.27.3/docker-compose-<span class="variable">$(uname -s)</span>-<span class="variable">$(uname -m)</span>"</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br></pre></td></tr></table></figure><blockquote><p>如果你想要安装其他版本的 Docker Compose，将 1.27.3 替换为你想要安装的版本即可。</p></blockquote><p>（2）修改 Docker Compose 执行权限：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br></pre></td></tr></table></figure><p>（3）检查 Docker Compose 是否安装成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose --version</span><br><span class="line">docker-compose version 1.27.3, build 1110ad01</span><br></pre></td></tr></table></figure><p>当我们执行完上述命令后，如果 Docker Compose 输出了当前版本号，就表示我们的 Docker Compose 已经安装成功。 Docker Compose 安装成功后，我们就可以很方便地使用它了。</p><p>在使用 Docker Compose 之前，我们首先需要先编写 Docker Compose 模板文件，因为 Docker Compose 运行的时候是根据 Docker Compose 模板文件中的定义来运行的。</p><p>下面我们首先来学习一下如何编写一个 Docker Compose 模板文件。</p><h3 id="编写-Docker-Compose-模板文件"><a href="#编写-Docker-Compose-模板文件" class="headerlink" title="编写 Docker Compose 模板文件"></a>编写 Docker Compose 模板文件</h3><p>在使用 Docker Compose 启动容器时， Docker Compose 会默认使用 docker-compose.yml 文件， docker-compose.yml 文件的格式为 yaml（类似于 json，一种标记语言）。</p><p>Docker Compose 模板文件一共有三个版本： v1、v2 和 v3。目前最新的版本为 v3，也是功能最全面的一个版本，下面我主要围绕 v3 版本介绍一下如何编写 Docker Compose 文件。</p><p>Docker Compose 文件主要分为三部分： services（服务）、networks（网络） 和 volumes（数据卷）。</p><ul><li>services（服务）：服务定义了容器启动的各项配置，就像我们执行<code>docker run</code>命令时传递的容器启动的参数一样，指定了容器应该如何启动，例如容器的启动参数，容器的镜像和环境变量等。</li><li>networks（网络）：网络定义了容器的网络配置，就像我们执行<code>docker network create</code>命令创建网络配置一样。</li><li>volumes（数据卷）：数据卷定义了容器的卷配置，就像我们执行<code>docker volume create</code>命令创建数据卷一样。</li></ul><p>一个典型的 Docker Compose 文件结构如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">nginx:</span></span><br><span class="line">    <span class="comment">## ... 省略部分配置</span></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">frontend:</span></span><br><span class="line">  <span class="attr">backend:</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">db-data:</span></span><br></pre></td></tr></table></figure><p>下面我们首先来学习一下如何编写 services 部分的配置。</p><h4 id="编写-Service-配置"><a href="#编写-Service-配置" class="headerlink" title="编写 Service 配置"></a>编写 Service 配置</h4><p>services 下，首先需要定义服务名称，例如你这个服务是 nginx 服务，你可以定义 service 名称为 nginx，格式如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3.8"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">nginx:</span></span><br></pre></td></tr></table></figure><p>服务名称定义完毕后，我们需要在服务名称的下一级定义当前服务的各项配置，使得我们的服务可以按照配置正常启动。常用的 16 种 service 配置如下。如果你比较了解，可以直接跳过看 Volume 配置和后续实操即可。</p><p>build： 用于构建 Docker 镜像，类似于docker build命令，build 可以指定 Dockerfile 文件路径，然后根据 Dockerfile 命令来构建文件。使用方法如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">build:</span></span><br><span class="line">  <span class="comment">## 构建执行的上下文目录</span></span><br><span class="line">  <span class="attr">context:</span> <span class="string">.</span></span><br><span class="line">  <span class="comment">## Dockerfile 名称</span></span><br><span class="line">  <span class="attr">dockerfile:</span> <span class="string">Dockerfile-name</span></span><br></pre></td></tr></table></figure><p>cap_add、cap_drop： 指定容器可以使用到哪些内核能力（capabilities）。使用格式如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">cap_add:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">NET_ADMIN</span></span><br><span class="line"><span class="attr">cap_drop:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">SYS_ADMIN</span></span><br></pre></td></tr></table></figure><p>command： 用于覆盖容器默认的启动命令，它和 Dockerfile 中的 CMD 用法类似，也有两种使用方式：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">command:</span> <span class="string">sleep</span> <span class="number">3000</span></span><br></pre></td></tr></table></figure><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">command:</span> <span class="string">["sleep",</span> <span class="string">"3000"</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>container_name： 用于指定容器启动时容器的名称。使用格式如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">container_name:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure><p>depends_on： 用于指定服务间的依赖关系，这样可以先启动被依赖的服务。例如，我们的服务依赖数据库服务 db，可以指定 depends_on 为 db。使用格式如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3.8"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">my-web:</span></span><br><span class="line">    <span class="attr">build:</span> <span class="string">.</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">db</span></span><br><span class="line">  <span class="attr">db:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql</span></span><br></pre></td></tr></table></figure><p>devices： 挂载主机的设备到容器中。使用格式如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">devices:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"/dev/sba:/dev/sda"</span></span><br></pre></td></tr></table></figure><p>dns： 自定义容器中的 dns 配置。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dns:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">8.8</span><span class="number">.8</span><span class="number">.8</span></span><br><span class="line">  <span class="bullet">-</span> <span class="number">114.114</span><span class="number">.114</span><span class="number">.114</span></span><br></pre></td></tr></table></figure><p>dns_search： 配置 dns 的搜索域。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dns_search:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">svc.cluster.com</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">svc1.cluster.com</span></span><br></pre></td></tr></table></figure><p>entrypoint： 覆盖容器的 entrypoint 命令。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">entrypoint:</span> <span class="string">sleep</span> <span class="number">3000</span></span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">entrypoint:</span> <span class="string">["sleep",</span> <span class="string">"3000"</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>env_file： 指定容器的环境变量文件，启动时会把该文件中的环境变量值注入容器中。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">env_file:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">./dbs.env</span></span><br></pre></td></tr></table></figure><p>env 文件的内容格式如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">KEY_ENV=values</span></span><br></pre></td></tr></table></figure><p>environment： 指定容器启动时的环境变量。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">environment:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">KEY_ENV=values</span></span><br></pre></td></tr></table></figure><p>image： 指定容器镜像的地址。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">image:</span> <span class="string">busybox:latest</span></span><br></pre></td></tr></table></figure><p>pid： 共享主机的进程命名空间，像在主机上直接启动进程一样，可以看到主机的进程信息。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">pid:</span> <span class="string">"host"</span></span><br></pre></td></tr></table></figure><p>ports： 暴露端口信息，使用格式为 HOST:CONTAINER，前面填写要映射到主机上的端口，后面填写对应的容器内的端口。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"1000"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"1000-1005"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"8080:8080"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"8888-8890:8888-8890"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"2222:22"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"127.0.0.1:9999:9999"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"127.0.0.1:3000-3005:3000-3005"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">"6789:6789/udp"</span></span><br></pre></td></tr></table></figure><p>networks： 这是服务要使用的网络名称，对应顶级的 networks 中的配置。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">my-service:</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">hello-network</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">hello1-network</span></span><br></pre></td></tr></table></figure><p>volumes： 不仅可以挂载主机数据卷到容器中，也可以直接挂载主机的目录到容器中，使用方式类似于使用docker run启动容器时添加 -v 参数。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">db:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">mysql:5.6</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">volume</span></span><br><span class="line">        <span class="attr">source:</span> <span class="string">/var/lib/mysql</span></span><br><span class="line">        <span class="attr">target:</span> <span class="string">/var/lib/mysql</span></span><br></pre></td></tr></table></figure><h4 id="编写-Volume-配置"><a href="#编写-Volume-配置" class="headerlink" title="编写 Volume 配置"></a>编写 Volume 配置</h4><p>如果你想在多个容器间共享数据卷，则需要在外部声明数据卷，然后在容器里声明使用数据卷。例如我想在两个服务间共享日志目录，则使用以下配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">my-service1:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">service:v1</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">volume</span></span><br><span class="line">        <span class="attr">source:</span> <span class="string">logdata</span></span><br><span class="line">        <span class="attr">target:</span> <span class="string">/var/log/mylog</span></span><br><span class="line">  <span class="attr">my-service2:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">service:v2</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">type:</span> <span class="string">volume</span></span><br><span class="line">        <span class="attr">source:</span> <span class="string">logdata</span></span><br><span class="line">        <span class="attr">target:</span> <span class="string">/var/log/mylog</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="attr">logdata:</span></span><br></pre></td></tr></table></figure><h4 id="编写-Network-配置"><a href="#编写-Network-配置" class="headerlink" title="编写 Network 配置"></a>编写 Network 配置</h4><p>Docker Compose 文件顶级声明的 networks 允许你创建自定义的网络，类似于<code>docker network create</code>命令。</p><p>例如你想声明一个自定义 bridge 网络配置，并且在服务中使用它，使用格式如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">web:</span></span><br><span class="line">    <span class="attr">networks:</span></span><br><span class="line">      <span class="attr">mybridge:</span> </span><br><span class="line">        <span class="attr">ipv4_address:</span> <span class="number">172.16</span><span class="number">.1</span><span class="number">.11</span></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line">  <span class="attr">mybridge:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">bridge</span></span><br><span class="line">    <span class="attr">ipam:</span> </span><br><span class="line">      <span class="attr">driver:</span> <span class="string">default</span></span><br><span class="line">      <span class="attr">config:</span></span><br><span class="line">        <span class="attr">subnet:</span> <span class="number">172.16</span><span class="number">.1</span><span class="number">.0</span><span class="string">/24</span></span><br></pre></td></tr></table></figure><p>编写完 Docker Compose 模板文件后，需要使用 docker-compose 命令来运行这些文件。下面我们来学习下 docker-compose 都有哪些操作命令。</p><h3 id="Docker-Compose-操作命令"><a href="#Docker-Compose-操作命令" class="headerlink" title="Docker Compose 操作命令"></a>Docker Compose 操作命令</h3><p>我们可以使用<code>docker-compose -h</code>命令来查看 docker-compose 的用法，docker-compose 的基本使用格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose [-f &lt;arg&gt;...] [options] [--] [COMMAND] [ARGS...]</span><br></pre></td></tr></table></figure><p>其中 options 是 docker-compose 的参数，支持的参数和功能说明如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">  -f, --file FILE             指定 docker-compose 文件，默认为 docker-compose.yml</span><br><span class="line">  -p, --project-name NAME     指定项目名称，默认使用当前目录名称作为项目名称</span><br><span class="line">  --verbose                   输出调试信息</span><br><span class="line">  --<span class="built_in">log</span>-level LEVEL           日志级别 (DEBUG, INFO, WARNING, ERROR, CRITICAL)</span><br><span class="line">  -v, --version               输出当前版本并退出</span><br><span class="line">  -H, --host HOST             指定要连接的 Docker 地址</span><br><span class="line">  --tls                       启用 TLS 认证</span><br><span class="line">  --tlscacert CA_PATH         TLS CA 证书路径</span><br><span class="line">  --tlscert CLIENT_CERT_PATH  TLS 公钥证书问价</span><br><span class="line">  --tlskey TLS_KEY_PATH       TLS 私钥证书文件</span><br><span class="line">  --tlsverify                 使用 TLS 校验对端</span><br><span class="line">  --skip-hostname-check       不校验主机名</span><br><span class="line">  --project-directory PATH    指定工作目录，默认是 Compose 文件所在路径。</span><br></pre></td></tr></table></figure><p>COMMAND 为 docker-compose 支持的命令。支持的命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">  build              构建服务</span><br><span class="line">  config             校验和查看 Compose 文件</span><br><span class="line">  create             创建服务</span><br><span class="line">  down               停止服务，并且删除相关资源</span><br><span class="line">  events             实时监控容器的时间信息</span><br><span class="line">  <span class="built_in">exec</span>               在一个运行的容器中运行指定命令</span><br><span class="line">  <span class="built_in">help</span>               获取帮助</span><br><span class="line">  images             列出镜像</span><br><span class="line">  <span class="built_in">kill</span>               杀死容器</span><br><span class="line">  logs               查看容器输出</span><br><span class="line">  pause              暂停容器</span><br><span class="line">  port               打印容器端口所映射出的公共端口</span><br><span class="line">  ps                 列出项目中的容器列表</span><br><span class="line">  pull               拉取服务中的所有镜像</span><br><span class="line">  push               推送服务中的所有镜像</span><br><span class="line">  restart            重启服务</span><br><span class="line">  rm                 删除项目中已经停止的容器</span><br><span class="line">  run                在指定服务上运行一个命令</span><br><span class="line">  scale              设置服务运行的容器个数</span><br><span class="line">  start              启动服务</span><br><span class="line">  stop               停止服务</span><br><span class="line">  top                限制服务中正在运行中的进程信息</span><br><span class="line">  unpause            恢复暂停的容器</span><br><span class="line">  up                 创建并且启动服务</span><br><span class="line">  version            打印版本信息并退出</span><br></pre></td></tr></table></figure><p>好了，学习完 Docker Compose 模板的编写和 docker-compose 命令的使用方法，下面我们编写一个 Docker Compose 模板文件，实现一键启动 WordPress 服务（一种博客系统），来搭建一个属于我们自己的博客系统。</p><h3 id="使用-Docker-Compose-管理-WordPress"><a href="#使用-Docker-Compose-管理-WordPress" class="headerlink" title="使用 Docker Compose 管理 WordPress"></a>使用 Docker Compose 管理 WordPress</h3><h4 id="启动-WordPress"><a href="#启动-WordPress" class="headerlink" title="启动 WordPress"></a>启动 WordPress</h4><p>第一步，创建项目目录。首先我们在 /tmp 目录下创建一个 WordPress 的目录，这个目录将作为我们的工作目录。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir /tmp/wordpress</span><br></pre></td></tr></table></figure><p>第二步，进入工作目录。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /tmp/wordpress</span><br></pre></td></tr></table></figure><p>第三步，创建 docker-compose.yml 文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ touch docker-compose.yml</span><br></pre></td></tr></table></figure><p>然后写入以下内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'3'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">   <span class="attr">mysql:</span></span><br><span class="line">     <span class="attr">image:</span> <span class="string">mysql:5.7</span></span><br><span class="line">     <span class="attr">volumes:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">mysql_data:/var/lib/mysql</span></span><br><span class="line">     <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">     <span class="attr">environment:</span></span><br><span class="line">       <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">root</span></span><br><span class="line">       <span class="attr">MYSQL_DATABASE:</span> <span class="string">mywordpress</span></span><br><span class="line">       <span class="attr">MYSQL_USER:</span> <span class="string">mywordpress</span></span><br><span class="line">       <span class="attr">MYSQL_PASSWORD:</span> <span class="string">mywordpress</span></span><br><span class="line">   <span class="attr">wordpress:</span></span><br><span class="line">     <span class="attr">depends_on:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">mysql</span></span><br><span class="line">     <span class="attr">image:</span> <span class="string">wordpress:php7.4</span></span><br><span class="line">     <span class="attr">ports:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">"8080:80"</span></span><br><span class="line">     <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">     <span class="attr">environment:</span></span><br><span class="line">       <span class="attr">WORDPRESS_DB_HOST:</span> <span class="string">mysql:3306</span></span><br><span class="line">       <span class="attr">WORDPRESS_DB_USER:</span> <span class="string">mywordpress</span></span><br><span class="line">       <span class="attr">WORDPRESS_DB_PASSWORD:</span> <span class="string">mywordpress</span></span><br><span class="line">       <span class="attr">WORDPRESS_DB_NAME:</span> <span class="string">mywordpress</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">    <span class="attr">mysql_data:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><p>第四步，启动 MySQL 数据库和 WordPress 服务。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose up -d</span><br><span class="line">Starting wordpress_mysql_1 ... <span class="keyword">done</span></span><br><span class="line">Starting wordpress_wordpress_1 ... <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>执行完以上命令后，Docker Compose 首先会为我们启动一个 MySQL 数据库，按照 MySQL 服务中声明的环境变量来设置 MySQL 数据库的用户名和密码。然后等待 MySQL 数据库启动后，再启动 WordPress 服务。WordPress 服务启动后，我们就可以通过 <a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a> 访问它了，访问成功后，我们就可以看到以下界面，然后按照提示一步一步设置就可以拥有属于自己的专属博客系统了。</p><h4 id="停止-WordPress"><a href="#停止-WordPress" class="headerlink" title="停止 WordPress"></a>停止 WordPress</h4><p>如果你不再需要 WordPress 服务了，可以使用<code>docker-compose stop</code>命令来停止已启动的服务。</p><blockquote><p>Docker Compose 是一个用来定义复杂应用的单机编排工具，通常用于服务依赖关系复杂的开发和测试环境，如果你还在为配置复杂的开发环境而烦恼，Docker Compose 可以轻松帮你搞定复杂的开发环境。你只需要把复杂的开发环境使用 Docker Compose 模板文件描述出来，之后无论你在哪里可以轻松的一键启动开发和测试环境，极大地提高了我们的开发效率，同时也避免了污染我们开发机器的配置。</p></blockquote><h2 id="如何在生产环境中使用-Docker-Swarm-调度容器？"><a href="#如何在生产环境中使用-Docker-Swarm-调度容器？" class="headerlink" title="如何在生产环境中使用 Docker Swarm 调度容器？"></a>如何在生产环境中使用 Docker Swarm 调度容器？</h2><p>Docker 的单节点引擎工具 Docker Compose，它能够在单一节点上管理和编排多个容器，当我们的服务和容器数量较小时可以使用 Docker Compose 来管理容器。</p><p>然而随着我们的业务规模越来越大，我们的容器规模也逐渐增大时，数量庞大的容器管理将给我们带来许多挑战。Docker 官方为了解决多容器管理的问题推出了 Docker Swarm ，我们可以用它来管理规模更大的容器集群。</p><h3 id="Swarm-的前生今世"><a href="#Swarm-的前生今世" class="headerlink" title="Swarm 的前生今世"></a>Swarm 的前生今世</h3><p>2014 年 Docker 在容器界越来越火，这时容器的编排工具 Mesos 和 Kubernetes 也开始崭露头角。此时，Docker 公司也开始筹划容器的编排和集群管理工具，推出了自己的通信协议项目 Beam。后来，通过改进 Beam，Beam 成为一个允许使用 Docker API 来控制的一种分布式系统，之后项目被重命名为 libswarm。然而在 2014 年 11 月，Docker 公司又对 libswarm 进行了重新设计，支持了远程调用 API，并且被重新命名为 Swarm。到此我们称之为 Swarm V1。</p><p>在 2016 年，为了解决中央服务可扩展性的问题，Docker 团队重新设计了 Swarm，并称之为 Swarm V2。此时的 Docker Swarm 已经可以支持超过 1000 多个节点的集群规模，并且 Docker 团队在发布 Docker 1.12 版本时，将 Docker Swarm 默认集成到了 Docker 引擎中。</p><p>由于 Swarm 是 Docker 官方推出的容器集群管理工具，因此 Swarm 最大的优势之一就是原生支持 Docker API，给用户带来了极大的便利，原来的 Docker 用户可以很方便地将服务迁移到 Swarm 中来。</p><p>与此同时，Swarm 还内置了对 Docker 网络插件的支持，因此用户可以很方便地部署需要跨主机通信的容器集群。其实 Swarm 的优点远远不止这些，还有很多，例如以下优点。</p><ul><li><strong>分布式：</strong> Swarm 使用<a href="https://raft.github.io/" target="_blank" rel="noopener">Raft</a>（一种分布式一致性协议）协议来做集群间数据一致性保障，使用多个容器节点组成管理集群，从而避免单点故障。</li><li><strong>安全：</strong> Swarm 使用 TLS 双向认证来确保节点之间通信的安全，它可以利用双向 TLS 进行节点之间的身份认证，角色授权和加密传输，并且可以自动执行证书的颁发和更换。</li><li><strong>简单：</strong> Swarm 的操作非常简单，并且除 Docker 外基本无其他外部依赖，而且从 Docker 1.12 版本后， Swarm 直接被内置到了 Docker 中，可以说真正做到了开箱即用。</li></ul><p>Swarm 的这些优点得益于它优美的架构设计，下面我们来了解一下 Swarm 的架构。</p><h3 id="Swarm-的架构"><a href="#Swarm-的架构" class="headerlink" title="Swarm 的架构"></a>Swarm 的架构</h3><p>Swarm 的架构整体分为<strong>管理节点</strong>（Manager Nodes）和<strong>工作节点</strong>（Worker Nodes），整体架构如下图：</p><p><img src="/images/docker/docker-03/1.jpg" alt="Swarm 架构图"></p><p><strong>管理节点：</strong> 管理节点负责接受用户的请求，用户的请求中包含用户定义的容器运行状态描述，然后 Swarm 负责调度和管理容器，并且努力达到用户所期望的状态。</p><p><strong>工作节点：</strong> 工作节点运行执行器（Executor）负责执行具体的容器管理任务（Task），例如容器的启动、停止、删除等操作。</p><blockquote><p>管理节点和工作节点的角色并不是一成不变的，你可以手动将工作节点转换为管理节点，也可以将管理节点转换为工作节点。</p></blockquote><h3 id="Swarm-核心概念"><a href="#Swarm-核心概念" class="headerlink" title="Swarm 核心概念"></a>Swarm 核心概念</h3><p>在真正使用 Swarm 之前，我们需要了解几个 Swarm 的核心概念，这些核心概念可以帮助我们更好地学习和理解 Swarm 的设计理念。</p><h4 id="Swarm-集群"><a href="#Swarm-集群" class="headerlink" title="Swarm 集群"></a>Swarm 集群</h4><p>Swarm 集群是一组被 Swarm 统一管理和调度的节点，被 Swarm纳管的节点可以是物理机或者虚拟机。其中一部分节点作为管理节点，负责集群状态的管理和协调，另一部分作为工作节点，负责执行具体的任务来管理容器，实现用户服务的启停等功能。</p><h4 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h4><p>Swarm 集群中的每一台物理机或者虚拟机称为节点。节点按照工作职责分为<strong>管理节点</strong>和<strong>工作节点</strong>，管理节点由于需要使用 Raft 协议来协商节点状态，生产环境中通常建议将管理节点的数量设置为奇数个，一般为 3 个、5 个或 7 个。</p><h4 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h4><p>服务是为了支持容器编排所提出的概念，它是一系列复杂容器环境互相协作的统称。一个服务的声明通常包含容器的启动方式、启动的副本数、环境变量、存储、配置、网络等一系列配置，用户通过声明一个服务，将它交给 Swarm，Swarm 负责将用户声明的服务实现。</p><p>服务分为全局服务（global services）和副本服务（replicated services）。</p><ul><li>全局服务：每个工作节点上都会运行一个任务，类似于 Kubernetes 中的 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener">Daemonset</a>。</li><li>副本服务：按照指定的副本数在整个集群中调度运行。</li></ul><h4 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h4><p>任务是集群中的最小调度单位，它包含一个真正运行中的 Docker 容器。当管理节点根据服务中声明的副本数将任务调度到节点时，任务则开始在该节点启动和运行，当节点出现异常时，任务会运行失败。此时调度器会把失败的任务重新调度到其他正常的节点上正常运行，以确保运行中的容器副本数满足用户所期望的副本数。</p><h4 id="服务外部访问"><a href="#服务外部访问" class="headerlink" title="服务外部访问"></a>服务外部访问</h4><p>由于容器的 IP 只能在集群内部访问到，而且容器又是用后马上销毁，这样容器的 IP 也会动态变化，因此容器集群内部的服务想要被集群外部的用户访问到，服务必须要映射到主机上的固定端口。Swarm 使用入口负载均衡（ingress load balancing）的模式将服务暴露在主机上，该模式下，每一个服务会被分配一个公开端口（PublishedPort），你可以指定使用某个未被占用的公开端口，也可以让 Swarm 自动分配一个。</p><p>Swarm 集群的公开端口可以从集群内的任意节点上访问到，当请求达到集群中的一个节点时，如果该节点没有要请求的服务，则会将请求转发到实际运行该服务的节点上，从而响应用户的请求。公有云的云负载均衡器（cloud load balancers）可以利用这一特性将流量导入到集群中的一个或多个节点，从而实现利用公有云的云负载均衡器将流量导入到集群中的服务。</p><h3 id="搭建-Swarm-集群"><a href="#搭建-Swarm-集群" class="headerlink" title="搭建 Swarm 集群"></a>搭建 Swarm 集群</h3><p>要想使用 Swarm 集群有如下一些要求：</p><ul><li>Docker 版本大于 1.12，推荐使用最新稳定版 Docker；</li><li>主机需要开放一些端口（TCP：2377 UDP:4789 TCP 和 UDP:7946）。</li></ul><p>下面我通过四台机器来搭建一个 Swarm 集群，演示的节点规划如下：</p><table><thead><tr><th align="center">节点名词</th><th align="center">节点IP</th><th align="center">角色</th></tr></thead><tbody><tr><td align="center">swarm-manager</td><td align="center">192.168.31.100</td><td align="center">manager</td></tr><tr><td align="center">swarm-node1</td><td align="center">192.168.31.101</td><td align="center">node</td></tr><tr><td align="center">swarm-node2</td><td align="center">192.168.31.102</td><td align="center">node</td></tr><tr><td align="center">swarm-node3</td><td align="center">192.168.31.103</td><td align="center">node</td></tr></tbody></table><blockquote><p>生产环境中推荐使用至少三个 manager 作为管理节点。</p></blockquote><ul><li>第一步：初始化集群</li></ul><p>Docker 1.12 版本后， Swarm 已经默认集成到了 Docker 中，因此我们可以直接使用 Docker 命令来初始化 Swarm，集群初始化的命令格式如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker swarm init --advertise-addr &lt;YOUR-IP&gt;</span><br></pre></td></tr></table></figure><blockquote><p>advertise-addr 一般用于主机有多块网卡的情况，如果你的主机只有一块网卡，可以忽略此参数。</p></blockquote><p>在管理节点上，通过以下命令初始化集群：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ docker swarm init</span><br><span class="line">Swarm initialized: current node (1ehtnlcf3emncktgjzpoux5ga) is now a manager.</span><br><span class="line"></span><br><span class="line">To add a worker to this swarm, run the following <span class="built_in">command</span>:</span><br><span class="line"></span><br><span class="line">    docker swarm join --token SWMTKN-1-1kal5b1iozbfmnnhx3kjfd3y6yqcjjjpcftrlg69pm2g8hw5vx-8j4l0t2is9ok9jwwc3tovtxbp 192.168.31.100:2377</span><br><span class="line"></span><br><span class="line">To add a manager to this swarm, run <span class="string">'docker swarm join-token manager'</span> and follow the instructions.</span><br></pre></td></tr></table></figure><p>集群初始化后， Swarm 会提示我们当前节点已经作为一个管理节点了，并且提示了如何把一台主机加入集群成为工作节点。</p><ul><li>第二步：加入工作节点</li></ul><p>按照第一步集群初始化后输出的提示，只需要复制其中的命令即可，然后在剩余的三台工作节点上分别执行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker swarm join --token SWMTKN-1-1kal5b1iozbfmnnhx3kjfd3y6yqcjjjpcftrlg69pm2g8hw5vx-8j4l0t2is9ok9jwwc3tovtxbp 192.168.31.100:2377</span><br><span class="line">This node joined a swarm as a worker.</span><br></pre></td></tr></table></figure><p>默认加入的节点为工作节点，如果是生产环境，我们可以使用docker swarm join-token manager命令来查看如何加入管理节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker swarm join-to ken manager</span><br><span class="line">To add a manager to this swarm, run the following <span class="built_in">command</span>:</span><br><span class="line"></span><br><span class="line">    docker swarm join --token SWMTKN-1-1kal5b1iozbfmnnhx3kjfd3y6yqcjjjpcftrlg69pm2g8hw5vx-8fq89jxo2axwggryvom5a337t 192.168.31.100:2377</span><br></pre></td></tr></table></figure><p>复制 Swarm 输出的结果即可加入管理节点到集群中。</p><blockquote><p>注意：管理节点的数量必须为奇数，生产环境推荐使用3个、5个或7个管理节点来管理 Swarm 集群。</p></blockquote><ul><li>第三步：节点查看</li></ul><p>节点添加完成后，我们使用以下命令可以查看当前节点的状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ ]<span class="comment"># docker node ls</span></span><br><span class="line">ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION</span><br><span class="line">1ehtnlcf3emncktgjzpoux5ga *   swarm-manager       Ready               Active              Leader              19.03.12</span><br><span class="line">pn7gdm847sfzydqhcv3vma97y *   swarm-node1         Ready               Active                                        19.03.12</span><br><span class="line">4dtc9pw5quyjs5yf25ccgr8uh *   swarm-node2         Ready               Active                                        19.03.12</span><br><span class="line">est7ww3gngna4u7td22g9m2k5 *   swarm-node3         Ready               Active                                        19.03.12</span><br></pre></td></tr></table></figure><p>到此，一个包含 1 个管理节点，3 个工作节点的 Swarm 集群已经搭建完成。</p><h3 id="使用-Swarm"><a href="#使用-Swarm" class="headerlink" title="使用 Swarm"></a>使用 Swarm</h3><p>集群搭建完成后，我们就可以在 Swarm 集群中创建服务了，Swarm 集群中常用的服务部署方式有以下两种。</p><h4 id="（1）通过-docker-service-命令创建服务"><a href="#（1）通过-docker-service-命令创建服务" class="headerlink" title="（1）通过 docker service 命令创建服务"></a>（1）通过 docker service 命令创建服务</h4><p>使用<code>docker service create</code>命令可以创建服务，创建服务的命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker service create --replicas 1 --name hello-world nginx</span><br><span class="line">24f9ng83m9sq4ml3e92k4g5by</span><br><span class="line">overall progress: 1 out of 1 tasks</span><br><span class="line">1/1: running   [==================================================&gt;]</span><br><span class="line">verify: Service converged</span><br></pre></td></tr></table></figure><p>此时我们已经创建好了一个服务，使用docker service ls命令可以查看已经启动的服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker service ls</span><br><span class="line">ID                  NAME                  MODE                REPLICAS            IMAGE               PORTS</span><br><span class="line">24f9ng83m9sq        hello-world           replicated          1/1                 nginx:latest</span><br></pre></td></tr></table></figure><p>当我们不再需要这个服务了，可以使用docker service rm命令来删除服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker service rm hello-world</span><br><span class="line">hello-world</span><br></pre></td></tr></table></figure><p>此时 hello-world 这个服务已经成功地从集群中删除。</p><p>想要了解更多的<code>docker service</code>命令的相关操作，可以参考<a href="https://docs.docker.com/engine/swarm/swarm-tutorial/deploy-service/" target="_blank" rel="noopener">这里</a>。</p><p>生产环境中，我们推荐使用 docker-compose 模板文件来部署服务，这样服务的管理会更加方便并且可追踪，而且可以同时创建和管理多个服务，更加适合生产环境中依赖关系较复杂的部署模式。</p><h4 id="（2）通过-docker-stack-命令创建服务"><a href="#（2）通过-docker-stack-命令创建服务" class="headerlink" title="（2）通过 docker stack 命令创建服务"></a>（2）通过 docker stack 命令创建服务</h4><p>我们在创建了 docker-compose 的模板文件，成功的使用该模板文件创建并启动了 MySQL 服务和 WordPress 两个服务。这里我们将 docker-compose 模板文件略微改造一下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'3'</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">   <span class="attr">mysql:</span></span><br><span class="line">     <span class="attr">image:</span> <span class="string">mysql:5.7</span></span><br><span class="line">     <span class="attr">volumes:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">mysql_data:/var/lib/mysql</span></span><br><span class="line">     <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">     <span class="attr">environment:</span></span><br><span class="line">       <span class="attr">MYSQL_ROOT_PASSWORD:</span> <span class="string">root</span></span><br><span class="line">       <span class="attr">MYSQL_DATABASE:</span> <span class="string">mywordpress</span></span><br><span class="line">       <span class="attr">MYSQL_USER:</span> <span class="string">mywordpress</span></span><br><span class="line">       <span class="attr">MYSQL_PASSWORD:</span> <span class="string">mywordpress</span></span><br><span class="line"></span><br><span class="line">   <span class="attr">wordpress:</span></span><br><span class="line">     <span class="attr">depends_on:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">mysql</span></span><br><span class="line">     <span class="attr">image:</span> <span class="string">wordpress:php7.4</span></span><br><span class="line">     <span class="attr">deploy:</span></span><br><span class="line">       <span class="attr">mode:</span> <span class="string">replicated</span></span><br><span class="line">       <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">     <span class="attr">ports:</span></span><br><span class="line">       <span class="bullet">-</span> <span class="string">"8080:80"</span></span><br><span class="line">     <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">     <span class="attr">environment:</span></span><br><span class="line">       <span class="attr">WORDPRESS_DB_HOST:</span> <span class="string">mysql:3306</span></span><br><span class="line">       <span class="attr">WORDPRESS_DB_USER:</span> <span class="string">mywordpress</span></span><br><span class="line">       <span class="attr">WORDPRESS_DB_PASSWORD:</span> <span class="string">mywordpress</span></span><br><span class="line">       <span class="attr">WORDPRESS_DB_NAME:</span> <span class="string">mywordpress</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">    <span class="attr">mysql_data:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><p>我在服务模板文件中添加了 deploy 指令，并且指定使用副本服务（replicated）的方式启动两个 WordPress 实例。</p><p>准备好启动 WordPress 服务的配置后，我们在 /tmp 目下新建 docker-compose.yml 文件，并且写入以上的内容，然后我们使用以下命令启动服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker stack deploy -c docker-compose.yml wordpress</span><br><span class="line">Ignoring unsupported options: restart</span><br><span class="line"></span><br><span class="line">Creating network wordpress_default</span><br><span class="line">Creating service wordpress_mysql</span><br><span class="line">Creating service wordpress_wordpress</span><br></pre></td></tr></table></figure><p>执行完以上命令后，我们成功启动了两个服务：</p><ul><li>MySQL 服务，默认启动了一个副本。</li><li>WordPress 服务，根据我们 docker-compose 模板的定义启动了两个副本。</li></ul><p>下面我们用docker service ls命令查看一下当前启动的服务。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker service ls</span><br><span class="line">ID                  NAME                  MODE                REPLICAS            IMAGE               PORTS</span><br><span class="line">v8i0pzb4e3tc        wordpress_mysql       replicated          1/1                 mysql:5.7</span><br><span class="line">96m8xfyeqzr5        wordpress_wordpress   replicated          2/2                 wordpress:php7.4    *:8080-&gt;80/tcp</span><br></pre></td></tr></table></figure><p>可以看到，Swarm 已经为我们成功启动了一个 MySQL 服务，并且启动了两个 WordPress 实例。WordPress 实例通过 8080 端口暴露在了主机上，我们通过访问集群中的任意节点的 IP 加 8080 端口即可访问到 WordPress 服务。例如，我们访问<a href="http://192.168.31.101:8080即可成功访问到我们搭建的">http://192.168.31.101:8080即可成功访问到我们搭建的</a> WordPress 服务。</p><blockquote><p>Docker Swarm 是一个用来定义复杂应用的集群编排工具，可以帮我们把多台主机组成一个 Swarm 集群，并且帮助我们管理和调度复杂的容器服务。由于 Swarm 已经被内置于 Docker 中，因此 Swarm 的安装和使用也变得非常简单，只要你有 Docker 的使用经验，就可以很快地将你的应用迁移到 Swarm 集群中。</p></blockquote><h2 id="如何使-Docker-和-Kubernetes-结合发挥容器的最大价值？"><a href="#如何使-Docker-和-Kubernetes-结合发挥容器的最大价值？" class="headerlink" title="如何使 Docker 和 Kubernetes 结合发挥容器的最大价值？"></a>如何使 Docker 和 Kubernetes 结合发挥容器的最大价值？</h2><p>Docker 虽然在容器领域有着不可撼动的地位，然而在容器的编排领域，却有着另外一个事实标准，那就是 Kubernetes。</p><h3 id="Kubernetes-的前生今世"><a href="#Kubernetes-的前生今世" class="headerlink" title="Kubernetes 的前生今世"></a>Kubernetes 的前生今世</h3><p>说起 Kubernetes，这一切还得从云计算这个词说起，云计算这个概念是 2006 年由 Google 提起的，近些年被提及的频率也越来越高。云计算从起初的概念演变为现在的 AWS、阿里云等实实在在的云产品（主要是虚拟机和相关的网络、存储服务），可见已经变得非常成熟和稳定。</p><p>正当大家以为云计算领域已经变成了以虚拟机为代表的云平台时，Docker 在 2013 年横空出世，Docker 提出了镜像、仓库等核心概念，规范了服务的交付标准，使得复杂服务的落地变得更加简单，之后 Docker 又定义了 OCI 标准，可以说在容器领域 Docker 已经成了事实的标准。</p><p>然而 Docker 诞生只是帮助我们定义了开发和交付标准，如果想要在生产环境中大批量的使用容器，还离不开的容器的编排技术。于是，在 2014 年 6 月 7 日，Kubernetes（Kubernetes 简称为 K8S，8 代表 ubernete 8个字母） 的第一个 commit（提交）拉开了容器编排标准定义的序幕。</p><p>Kubernetes 是舵手的意思，我们把 Docker 比喻成一个个集装箱，而 Kubernetes 正是运输这些集装箱的舵手。早期的 Kubernetes 主要参考 Google 内部的 Borg 系统，Kubernetes 刚刚诞生时，提出了 Pod、Sidecar 等概念，这些都是 Google 内部多年实战和沉淀所积累的精华。经过将近一年的沉淀和积累，Kubernetes 于 2015 年 7 月 21 日对外发布了第一个正式版本 v1.0，正式走入了大众的视线。</p><p>很荣幸，我也是在 2015 年下半年正式开始了 Kubernetes 和 Docker 的研发之路。时至今日，Kubernetes 经过 6 年的沉淀，已经成为了事实的编排技术标准。</p><p>接下来，我们就看来看看，究竟是什么样的架构使得 Kubernetes 在容器编排领域成为了王者？</p><h3 id="Kubernetes-架构"><a href="#Kubernetes-架构" class="headerlink" title="Kubernetes 架构"></a>Kubernetes 架构</h3><p>Kubernetes 采用声明式 API 来工作，所有组件的运行过程都是异步的，整个工作过程大致为用户声明想要的状态，然后 Kubernetes 各个组件相互配合并且努力达到用户想要的状态。</p><p>Kubernetes 采用典型的主从架构，分为 Master 和 Node 两个角色。</p><ul><li>Mater 是 Kubernetes 集群的控制节点，负责整个集群的管理和控制功能。</li><li>Node 为工作节点，负责业务容器的生命周期管理。</li></ul><p>整体架构如下图：</p><p><img src="/images/docker/docker-03/2.jpg" alt="Kubernetes 架构图"></p><h4 id="Master-节点"><a href="#Master-节点" class="headerlink" title="Master 节点"></a>Master 节点</h4><p>Master 节点负责对集群中所有容器的调度，各种资源对象的控制，以及响应集群的所有请求。Master 节点包含三个重要的组件： kube-apiserver、kube-scheduler、kube-controller-manager。下面我对这三个组件逐一介绍。</p><ul><li><strong>kube-apiserver</strong></li></ul><p>kube-apiserver 主要负责提供 Kubernetes 的 API 服务，所有的组件都需要与 kube-apiserver 交互获取或者更新资源信息，它是 Kubernetes Master 中最前端组件。</p><p>kube-apiserver 的所有数据都存储在 <a href="https://etcd.io/" target="_blank" rel="noopener">etcd</a> 中，etcd 是一种采用 Go 语言编写的高可用 Key-Value 数据库，由 CoreOS 开发。etcd 虽然不是 Kubernetes 的组件，但是它在 Kubernetes 中却扮演着至关重要的角色，它是 Kubernetes 的数据大脑。可以说 etcd 的稳定性直接关系着 Kubernetes 集群的稳定性，因此生产环境中 etcd 一定要部署多个实例以确保集群的高可用。</p><ul><li><strong>kube-scheduler</strong></li></ul><p>kube-scheduler 用于监听未被调度的 Pod，然后根据一定调度策略将 Pod 调度到合适的 Node 节点上运行。</p><ul><li><strong>kube-controller-manager</strong></li></ul><p>kube-controller-manager 负责维护整个集群的状态和资源的管理。例如多个副本数量的保证，Pod 的滚动更新等。每种资源的控制器都是一个独立协程。kube-controller-manager 实际上是一系列资源控制器的总称。</p><blockquote><p>为了保证 Kubernetes 集群的高可用，Master 组件需要部署在多个节点上，由于 Kubernetes 所有数据都存在于 etcd 中，Etcd 是基于 Raft 协议实现，因此生产环境中 Master 通常建议至少三个节点（如果你想要更高的可用性，可以使用 5 个或者 7 个节点）。</p></blockquote><h4 id="Node-节点"><a href="#Node-节点" class="headerlink" title="Node 节点"></a>Node 节点</h4><p>Node 节点是 Kubernetes 的工作节点，负责运行业务容器。Node 节点主要包含两个组件 ：kubelet 和 kube-proxy。</p><ul><li><strong>kubelet</strong></li></ul><p>Kubelet 是在每个工作节点运行的代理，它负责管理容器的生命周期。Kubelet 通过监听分配到自己运行的主机上的 Pod 对象，确保这些 Pod 处于运行状态，并且负责定期检查 Pod 的运行状态，将 Pod 的运行状态更新到 Pod 对象中。</p><ul><li><strong>kube-proxy</strong></li></ul><p>Kube-proxy 是在每个工作节点的网络插件，它实现了 Kubernetes 的 <a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="noopener">Service</a> 的概念。Kube-proxy 通过维护集群上的网络规则，实现集群内部可以通过负载均衡的方式访问到后端的容器。</p><p>Kubernetes 的成功不仅得益于其优秀的架构设计，更加重要的是 Kubernetes 提出了很多核心的概念，这些核心概念构成了容器编排的主要模型。</p><h3 id="Kubernetes-核心概念"><a href="#Kubernetes-核心概念" class="headerlink" title="Kubernetes 核心概念"></a>Kubernetes 核心概念</h3><p>Kubernetes 这些概念是 Google 多年的技术沉淀和积累，理解 Kubernetes 的核心概念有助于我们更好的理解 Kubernetes 的设计理念。</p><h4 id="（1）集群"><a href="#（1）集群" class="headerlink" title="（1）集群"></a>（1）集群</h4><p>集群是一组被 Kubernetes 统一管理和调度的节点，被 Kubernetes 纳管的节点可以是物理机或者虚拟机。集群其中一部分节点作为 Master 节点，负责集群状态的管理和协调，另一部分作为 Node 节点，负责执行具体的任务，实现用户服务的启停等功能。</p><h4 id="（2）标签（Label）"><a href="#（2）标签（Label）" class="headerlink" title="（2）标签（Label）"></a>（2）标签（Label）</h4><p>Label 是一组键值对，每一个资源对象都会拥有此字段。Kubernetes 中使用 Label 对资源进行标记，然后根据 Label 对资源进行分类和筛选。</p><h4 id="（3）命名空间（Namespace）"><a href="#（3）命名空间（Namespace）" class="headerlink" title="（3）命名空间（Namespace）"></a>（3）命名空间（Namespace）</h4><p>Kubernetes 中通过命名空间来实现资源的虚拟化隔离，将一组相关联的资源放到同一个命名空间内，避免不同租户的资源发生命名冲突，从逻辑上实现了多租户的资源隔离。</p><h4 id="（4）容器组（Pod）"><a href="#（4）容器组（Pod）" class="headerlink" title="（4）容器组（Pod）"></a>（4）容器组（Pod）</h4><p>Pod 是 Kubernetes 中的最小调度单位，它由一个或多个容器组成，一个 Pod 内的容器共享相同的网络命名空间和存储卷。Pod 是真正的业务进程的载体，在 Pod 运行前，Kubernetes 会先启动一个 Pause 容器开辟一个网络命名空间，完成网络和存储相关资源的初始化，然后再运行业务容器。</p><h4 id="（5）部署（Deployment）"><a href="#（5）部署（Deployment）" class="headerlink" title="（5）部署（Deployment）"></a>（5）部署（Deployment）</h4><p>Deployment 是一组 Pod 的抽象，通过 Deployment 控制器保障用户指定数量的容器副本正常运行，并且实现了滚动更新等高级功能，当我们需要更新业务版本时，Deployment 会按照我们指定策略自动的杀死旧版本的 Pod 并且启动新版本的 Pod。</p><h4 id="（6）状态副本集（StatefulSet）"><a href="#（6）状态副本集（StatefulSet）" class="headerlink" title="（6）状态副本集（StatefulSet）"></a>（6）状态副本集（StatefulSet）</h4><p>StatefulSet 和 Deployment 类似，也是一组 Pod 的抽象，但是 StatefulSet 主要用于有状态应用的管理，StatefulSet 生成的 Pod 名称是固定且有序的，确保每个 Pod 独一无二的身份标识。</p><h4 id="（7）守护进程集（DaemonSet）"><a href="#（7）守护进程集（DaemonSet）" class="headerlink" title="（7）守护进程集（DaemonSet）"></a>（7）守护进程集（DaemonSet）</h4><p>DaemonSet 确保每个 Node 节点上运行一个 Pod，当我们集群有新加入的 Node 节点时，Kubernetes 会自动帮助我们在新的节点上运行一个 Pod。一般用于日志采集，节点监控等场景。</p><h4 id="（8）任务（Job）"><a href="#（8）任务（Job）" class="headerlink" title="（8）任务（Job）"></a>（8）任务（Job）</h4><p>Job 可以帮助我们创建一个 Pod 并且保证 Pod 的正常退出，如果 Pod 运行过程中出现了错误，Job 控制器可以帮助我们创建新的 Pod，直到 Pod 执行成功或者达到指定重试次数。</p><h4 id="（9）服务（Service）"><a href="#（9）服务（Service）" class="headerlink" title="（9）服务（Service）"></a>（9）服务（Service）</h4><p>Service 是一组 Pod 访问配置的抽象。由于 Pod 的地址是动态变化的，我们不能直接通过 Pod 的 IP 去访问某个服务，Service 通过在主机上配置一定的网络规则，帮助我们实现通过一个固定的地址访问一组 Pod。</p><h4 id="（10）配置集（ConfigMap）"><a href="#（10）配置集（ConfigMap）" class="headerlink" title="（10）配置集（ConfigMap）"></a>（10）配置集（ConfigMap）</h4><p>ConfigMap 用于存放我们业务的配置信息，使用 Key-Value 的方式存放于 Kubernetes 中，使用 ConfigMap 可以帮助我们将配置数据和应用程序代码分开。</p><h4 id="（11）加密字典（Secret）"><a href="#（11）加密字典（Secret）" class="headerlink" title="（11）加密字典（Secret）"></a>（11）加密字典（Secret）</h4><p>Secret 用于存放我们业务的敏感配置信息，类似于 ConfigMap，使用 Key-Value 的方式存在于 Kubernetes 中，主要用于存放密码和证书等敏感信息。</p><p>了解完 Kubernetes 的架构和核心概念，你是不是已经迫不及待地想要体验下了。下面就让我们动手安装一个 Kubernetes 集群，来体验下 Kubernetes 的强大之处吧。</p><h3 id="安装-Kubernetes"><a href="#安装-Kubernetes" class="headerlink" title="安装 Kubernetes"></a>安装 Kubernetes</h3><p>Kubernetes 目前已经支持在多种环境下安装，我们可以在公有云，私有云，甚至裸金属中安装 Kubernetes。下面，我们通过 minikube 来演示一下如何快速安装和启动一个 Kubernetes 集群，minikube 是官方提供的一个快速搭建本地 Kubernetes 集群的工具，主要用于本地开发和调试。</p><p>下面，我以 Linux 平台为例，演示一下如何使用 minikube 安装一个 Kubernetes 集群。</p><blockquote><p>如果你想要在其他平台使用 minikube 安装 Kubernetes，请参考官网<a href="https://minikube.sigs.k8s.io/docs/start/" target="_blank" rel="noopener">安装教程</a>。<br>在使用 minikube 安装 Kubernetes 之前，请确保我们的机器已经正确安装并且启动 Docker。</p></blockquote><p>第一步，安装 minikube 和 kubectl。首先执行以下命令安装 minikube。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl -LO https://github.com/kubernetes/minikube/releases/download/v1.13.1/minikube-linux-amd64</span><br><span class="line">$ sudo install minikube-linux-amd64 /usr/<span class="built_in">local</span>/bin/minikube</span><br></pre></td></tr></table></figure><p>Kubectl 是 Kubernetes 官方的命令行工具，可以实现对 Kubernetes 集群的管理和控制。</p><p>我们使用以下命令来安装 kubectl：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ curl -LO https://dl.k8s.io/v1.19.2/kubernetes-client-linux-amd64.tar.gz</span><br><span class="line">$ tar -xvf kubernetes-client-linux-amd64.tar.gz</span><br><span class="line">kubernetes/</span><br><span class="line">kubernetes/client/</span><br><span class="line">kubernetes/client/bin/</span><br><span class="line">kubernetes/client/bin/kubectl</span><br><span class="line">$ sudo install kubernetes/client/bin/kubectl /usr/<span class="built_in">local</span>/bin/kubectl</span><br></pre></td></tr></table></figure><p>第二步，安装 Kubernetes 集群。</p><p>执行以下命令使用 minikube 安装 Kubernetes 集群：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ minikube start</span><br></pre></td></tr></table></figure><p>执行完上述命令后，minikube 会自动帮助我们创建并启动一个 Kubernetes 集群。当命令行输出 Done 时，代表集群已经部署完成。</p><p>第三步，检查集群状态。集群安装成功后，我们可以使用以下命令检查 Kubernetes 集群是否成功启动。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl cluster-info</span><br><span class="line">Kubernetes master is running at https://172.17.0.3:8443</span><br><span class="line">KubeDNS is running at https://172.17.0.3:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span><br><span class="line"></span><br><span class="line">To further debug and diagnose cluster problems, use <span class="string">'kubectl cluster-info dump'</span>.</span><br></pre></td></tr></table></figure><p>执行kubectl cluster-info命令后，输出 “Kubernetes master is running” 表示我们的集群已经成功运行。</p><blockquote><p>172.17.0.3 为演示环境机器的 IP 地址，这个 IP 会根据你的实际 IP 地址而变化。</p></blockquote><h3 id="创建第一个应用"><a href="#创建第一个应用" class="headerlink" title="创建第一个应用"></a>创建第一个应用</h3><p>集群搭建好后，下面我们来试着使用 Kubernetes 来创建我们的第一个应用。</p><p>这里我们使用 Deployment 来定义应用的部署信息，使用 Service 暴露我们的应用到集群外部，从而使得我们的应用可以从外部访问到。</p><p>第一步，创建 deployment.yaml 文件，并且定义启动的副本数（replicas）为 3。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">hello-world</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">hello-world</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">wilhelmguo/nginx-hello:v1</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>第二步，发布部署文件到 Kubernetes 集群中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f deployment.yaml</span><br></pre></td></tr></table></figure><p>部署发布完成后，我们可以使用 kubectl 来查看一下 Pod 是否被成功启动。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pod -o wide</span><br><span class="line">NAME                           READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES</span><br><span class="line">hello-world-57968f9979-xbmzt   1/1     Running   0          3m19s   172.18.0.7   minikube   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hello-world-57968f9979-xq5w4   1/1     Running   0          3m18s   172.18.0.5   minikube   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hello-world-57968f9979-zwvgg   1/1     Running   0          4m14s   172.18.0.6   minikube   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p>这里可以看到 Kubernetes 帮助我们创建了 3 个 Pod 实例。</p><p>第三步，创建 service.yaml 文件，帮助我们将服务暴露出去，内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello-world</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">hello-world</span></span><br></pre></td></tr></table></figure><p>然后执行如下命令在 Kubernetes 中创建 Service：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f service.yaml</span><br></pre></td></tr></table></figure><p>服务创建完成后，Kubernetes 会随机帮助我们分配一个外部访问端口，可以通过以下命令查看服务信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl  get service -o wide</span><br><span class="line">NAME          TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span><br><span class="line">hello-world   NodePort    10.101.83.18   &lt;none&gt;        80:32391/TCP   12s   app=hello-world</span><br><span class="line">kubernetes    ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP        40m   &lt;none&gt;</span><br></pre></td></tr></table></figure><p>由于我们的集群使用 minikube 安装，要想集群中的服务可以通过外部访问，还需要执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ minikube service hello-world</span><br></pre></td></tr></table></figure><p>可以看到 minikube 将我们的服务暴露在了 32391 端口上，我们通过 http://{YOUR-IP}:32391 可以访问到我们启动的服务。</p><p>总结下，我们首先使用 Deployment 创建了三个 nginx-hello 的实例，然后使用 Service 的方式随机负载到后端的三个实例，并将服务通过 NodePort 的方式暴露在主机上，使得我们可以直接使用主机的端口访问到容器中的服务。</p><blockquote><p>Kubernetes 从诞生到现在已经经历了 6 个年头，起初由于它的超前理念被世人误认为设计过度复杂，使得 Kubernetes 的入门门槛非常高。然而 6 年后的今天， Kubernetes 已经拥有了非常完善的社区和工具集，它可以帮助我们一键搭建 Kubernetes 集群，并且围绕 Kubernetes 构建的各种应用也是越来越丰富。</p></blockquote><blockquote><p>Kubernetes 的目标一直很明确，那就是对标 Borg，可以支撑数亿容器的运行。目前来看，要达到这个目标，Kubernetes 还有很长的路要走，但是当我们谈及云原生，谈及容器云时都必然会提到 Kubernetes，显然它已经成为容器编排的标准和标杆，目前大多数公有云也有支持 Kubernetes。容器的未来一定是美好的，而使用 Kubernetes 来调度容器则更是未来云计算的一个重要风向标。</p></blockquote><h2 id="多阶段构建：Docker-下如何实现镜像多阶级构建？"><a href="#多阶段构建：Docker-下如何实现镜像多阶级构建？" class="headerlink" title="多阶段构建：Docker 下如何实现镜像多阶级构建？"></a>多阶段构建：Docker 下如何实现镜像多阶级构建？</h2><p>我们知道 Docker 镜像是分层的，并且每一层镜像都会额外占用存储空间，一个 Docker 镜像层数越多，这个镜像占用的存储空间则会越多。镜像构建最重要的一个原则就是要保持镜像体积尽可能小，要实现这个目标通常可以从两个方面入手：</p><ul><li>基础镜像体积应该尽量小；</li><li>尽量减少 Dockerfile 的行数，因为 Dockerfile 的每一条指令都会生成一个镜像层。</li></ul><p>在 Docker 的早期版本中，对于编译型语言（例如 C、Java、Go）的镜像构建，我们只能将应用的编译和运行环境的准备，全部都放到一个 Dockerfile 中，这就导致我们构建出来的镜像体积很大，从而增加了镜像的存储和分发成本，这显然与我们的镜像构建原则不符。</p><p>为了减小镜像体积，我们需要借助一个额外的脚本，将镜像的编译过程和运行过程分开。</p><ul><li>编译阶段：负责将我们的代码编译成可执行对象。</li><li>运行时构建阶段：准备应用程序运行的依赖环境，然后将编译后的可执行对象拷贝到镜像中。</li></ul><p>我以 Go 语言开发的一个 HTTP 服务为例，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">   <span class="string">"fmt"</span></span><br><span class="line">   <span class="string">"net/http"</span></span><br><span class="line">)</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hello</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line">   fmt.Fprintf(w, <span class="string">"hello world!\n"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">   http.HandleFunc(<span class="string">"/"</span>, hello)</span><br><span class="line">   http.ListenAndServe(<span class="string">":8080"</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我将这个 Go 服务构建成镜像分为两个阶段：代码的编译阶段和镜像构建阶段。</p><p>我们构建镜像时，镜像中需要包含 Go 语言编译环境，应用的编译阶段我们可以使用 Dockerfile.build 文件来构建镜像。Dockerfile.build 的内容如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.13</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/wilhelmguo/multi-stage-demo/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -o http-server .</span></span><br></pre></td></tr></table></figure><p>Dockerfile.build 可以帮助我们把代码编译成可以执行的二进制文件，我们使用以下 Dockerfile 构建一个运行环境：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine:latest  </span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> http-server .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./http-server"</span>]</span></span><br></pre></td></tr></table></figure><p>然后，我们将应用的编译和运行环境的准备步骤，都放到一个 build.sh 脚本文件中，内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">echo</span> Building http-server:build</span><br><span class="line">docker build -t http-server:build . -f Dockerfile.build</span><br><span class="line">docker create --name builder http-server:build  </span><br><span class="line">docker cp builder:/go/src/github.com/wilhelmguo/multi-stage-demo/http-server ./http-server  </span><br><span class="line">docker rm -f builder</span><br><span class="line"><span class="built_in">echo</span> Building http-server:latest</span><br><span class="line">docker build -t http-server:latest .</span><br><span class="line">rm ./http-server</span><br></pre></td></tr></table></figure><p>下面，我带你来逐步分析下这个脚本。</p><p>第一步，声明 shell 文件，然后输出开始构建信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="built_in">echo</span> Building http-server:build</span><br></pre></td></tr></table></figure><p>第二步，使用 Dockerfile.build 文件来构建一个临时镜像 http-server:build。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t http-server:build . -f Dockerfile.build</span><br></pre></td></tr></table></figure><p>第三步，使用 http-server:build 镜像创建一个名称为 builder 的容器，该容器包含编译后的 http-server 二进制文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker create --name builder http-server:build</span><br></pre></td></tr></table></figure><p>第四步，使用docker cp命令从 builder 容器中拷贝 http-server 文件到当前构建目录下，并且删除名称为 builder 的临时容器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker cp builder:/go/src/github.com/wilhelmguo/multi-stage-demo/http-server ./http-server  </span><br><span class="line">docker rm -f builder</span><br></pre></td></tr></table></figure><p>第五步，输出开始构建镜像信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> Building http-server:latest</span><br></pre></td></tr></table></figure><p>第六步，构建运行时镜像，然后删除临时文件 http-server。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t http-server:latest .</span><br><span class="line">rm ./http-server</span><br></pre></td></tr></table></figure><p>这里总结一下，我们是使用 Dockerfile.build 文件来编译应用程序，使用 Dockerfile 文件来构建应用的运行环境。然后我们通过创建一个临时容器，把编译后的 http-server 文件拷贝到当前构建目录中，然后再把这个文件拷贝到运行环境的镜像中，最后指定容器的启动命令为 http-server。</p><p>使用这种方式虽然可以实现分离镜像的编译和运行环境，但是我们需要额外引入一个 build.sh 脚本文件，而且构建过程中，还需要创建临时容器 builder 拷贝编译后的 http-server 文件，这使得整个构建过程比较复杂，并且整个构建过程也不够透明。</p><p>为了解决这种问题， Docker 在 17.05 推出了多阶段构建（multistage-build）的解决方案。</p><h3 id="使用多阶段构建"><a href="#使用多阶段构建" class="headerlink" title="使用多阶段构建"></a>使用多阶段构建</h3><p>Docker 允许我们在 Dockerfile 中使用多个 FROM 语句，而每个 FROM 语句都可以使用不同基础镜像。最终生成的镜像，是以最后一条 FROM 为准，所以我们可以在一个 Dockerfile 中声明多个 FROM，然后选择性地将一个阶段生成的文件拷贝到另外一个阶段中，从而实现最终的镜像只保留我们需要的环境和文件。多阶段构建的主要使用场景是<strong>分离编译环境和运行环境。</strong></p><p>接下来，我们使用多阶段构建的特性，将上述未使用多阶段构建的过程精简成如下 Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.13</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/wilhelmguo/multi-stage-demo/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -o http-server .</span></span><br><span class="line"><span class="keyword">FROM</span> alpine:latest  </span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=0 /go/src/github.com/wilhelmguo/multi-stage-demo/http-server .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./http-server"</span>]</span></span><br></pre></td></tr></table></figure><p>然后，我们将这个 Dockerfile 拆解成两步进行分析。</p><p>第一步，编译代码。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.13</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/wilhelmguo/multi-stage-demo/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -o http-server .</span></span><br></pre></td></tr></table></figure><p>将代码拷贝到 golang:1.13 镜像（已经安装好了 go）中，并且使用go build命令编译代码生成 http-server 文件。</p><p>第二步，构建运行时镜像。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> alpine:latest  </span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=0 /go/src/github.com/wilhelmguo/multi-stage-demo/http-server .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./http-server"</span>]</span></span><br></pre></td></tr></table></figure><p>使用第二个 FROM 命令表示镜像构建的第二阶段，使用 COPY 指令拷贝编译后的文件到 alpine 镜像中，–from=0 表示从第一阶段构建结果中拷贝文件到当前构建阶段。</p><p>最后，我们只需要使用以下命令，即可实现整个镜像的构建：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t http-server:latest .</span><br></pre></td></tr></table></figure><p>构建出来的镜像与未使用多阶段构建之前构建的镜像大小一致，为了验证这一结论，我们分别使用这两种方式来构建镜像，最后对比一下镜像构建的结果。</p><h3 id="镜像构建对比"><a href="#镜像构建对比" class="headerlink" title="镜像构建对比"></a>镜像构建对比</h3><p>使用多阶段构建前后的代码我都已经放在了<a href="https://github.com/wilhelmguo/multi-stage-demo" target="_blank" rel="noopener">Github</a>，你只需要克隆代码到本地即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir /go/src/github.com/wilhelmguo</span><br><span class="line">$ <span class="built_in">cd</span> /go/src/github.com/wilhelmguo</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/wilhelmguo/multi-stage-demo.git</span><br></pre></td></tr></table></figure><p>代码克隆完成后，我们首先切换到without-multi-stage分支：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> without-multi-stage</span><br><span class="line">$ git checkout without-multi-stage</span><br></pre></td></tr></table></figure><p>这个分支是未使用多阶段构建技术构建镜像的代码，我们可以通过执行 build.sh 文件构建镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">$  chmod +x build.sh &amp;&amp; ./build.sh</span><br><span class="line">Building http-server:build</span><br><span class="line">Sending build context to Docker daemon  96.26kB</span><br><span class="line">Step 1/4 : FROM golang:1.13</span><br><span class="line">1.13: Pulling from library/golang</span><br><span class="line">d6ff36c9ec48: Pull complete </span><br><span class="line">c958d65b3090: Pull complete </span><br><span class="line">edaf0a6b092f: Pull complete </span><br><span class="line">80931cf68816: Pull complete </span><br><span class="line">813643441356: Pull complete </span><br><span class="line">799f41bb59c9: Pull complete </span><br><span class="line">16b5038bccc8: Pull complete </span><br><span class="line">Digest: sha256:8ebb6d5a48deef738381b56b1d4cd33d99a5d608e0d03c5fe8dfa3f68d41a1f8</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> golang:1.13</span><br><span class="line"> ---&gt; d6f3656320fe</span><br><span class="line">Step 2/4 : WORKDIR /go/src/github.com/wilhelmguo/multi-stage-demo/</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> fa3da5ffb0c0</span><br><span class="line">Removing intermediate container fa3da5ffb0c0</span><br><span class="line"> ---&gt; 97245cbb773f</span><br><span class="line">Step 3/4 : COPY main.go .</span><br><span class="line"> ---&gt; a021d2f2a5bb</span><br><span class="line">Step 4/4 : RUN CGO_ENABLED=0 GOOS=linux go build -o http-server .</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> b5c36bb67b9c</span><br><span class="line">Removing intermediate container b5c36bb67b9c</span><br><span class="line"> ---&gt; 76c0c88a5cf7</span><br><span class="line">Successfully built 76c0c88a5cf7</span><br><span class="line">Successfully tagged http-server:build</span><br><span class="line">4b0387b270bc4a4da570e1667fe6f9baac765f6b80c68f32007494c6255d9e5b</span><br><span class="line">builder</span><br><span class="line">Building http-server:latest</span><br><span class="line">Sending build context to Docker daemon  7.496MB</span><br><span class="line">Step 1/4 : FROM alpine:latest</span><br><span class="line">latest: Pulling from library/alpine</span><br><span class="line">df20fa9351a1: Already exists </span><br><span class="line">Digest: sha256:185518070891758909c9f839cf4ca393ee977ac378609f700f60a771a2dfe321</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> alpine:latest</span><br><span class="line"> ---&gt; a24bb4013296</span><br><span class="line">Step 2/4 : WORKDIR /root/</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 0b25ffe603b8</span><br><span class="line">Removing intermediate container 0b25ffe603b8</span><br><span class="line"> ---&gt; 80da40d3a0b4</span><br><span class="line">Step 3/4 : COPY http-server .</span><br><span class="line"> ---&gt; 3f2300210b7b</span><br><span class="line">Step 4/4 : CMD [<span class="string">"./http-server"</span>]</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 045cea651dde</span><br><span class="line">Removing intermediate container 045cea651dde</span><br><span class="line"> ---&gt; 5c73883177e7</span><br><span class="line">Successfully built 5c73883177e7</span><br><span class="line">Successfully tagged http-server:latest</span><br></pre></td></tr></table></figure><p>经过一段时间的等待，我们的镜像就构建完成了。</p><p>镜像构建完成后，我们使用docker image ls命令查看一下刚才构建的镜像大小：</p><p>可以看到，http-server:latest 镜像只有 13M，而我们的编译镜像 http-server:build 则为 819M，虽然我们编写了很复杂的脚本 build.sh，但是这个脚本确实帮助我们将镜像体积减小了很多。</p><p>下面，我们将代码切换到多阶段构建分支：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git checkout with-multi-stage</span><br><span class="line">Switched to branch <span class="string">'with-multi-stage'</span></span><br></pre></td></tr></table></figure><p>为了避免镜像名称重复，我们将多阶段构建的镜像命名为 http-server-with-multi-stage:latest ，并且禁用缓存，避免缓存干扰构建结果，构建命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ docker build --no-cache -t http-server-with-multi-stage:latest .</span><br><span class="line">Sending build context to Docker daemon  96.77kB</span><br><span class="line">Step 1/8 : FROM golang:1.13</span><br><span class="line"> ---&gt; d6f3656320fe</span><br><span class="line">Step 2/8 : WORKDIR /go/src/github.com/wilhelmguo/multi-stage-demo/</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 640da7a92a62</span><br><span class="line">Removing intermediate container 640da7a92a62</span><br><span class="line"> ---&gt; 9c27b4606da0</span><br><span class="line">Step 3/8 : COPY main.go .</span><br><span class="line"> ---&gt; bd9ce4af24cb</span><br><span class="line">Step 4/8 : RUN CGO_ENABLED=0 GOOS=linux go build -o http-server .</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 6b441b4cc6b7</span><br><span class="line">Removing intermediate container 6b441b4cc6b7</span><br><span class="line"> ---&gt; 759acbf6c9a6</span><br><span class="line">Step 5/8 : FROM alpine:latest</span><br><span class="line"> ---&gt; a24bb4013296</span><br><span class="line">Step 6/8 : WORKDIR /root/</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> c2aa2168acd8</span><br><span class="line">Removing intermediate container c2aa2168acd8</span><br><span class="line"> ---&gt; f026884acda6</span><br><span class="line">Step 7/8 : COPY --from=0 /go/src/github.com/wilhelmguo/multi-stage-demo/http-server .</span><br><span class="line"> ---&gt; 667503e6bc14</span><br><span class="line">Step 8/8 : CMD [<span class="string">"./http-server"</span>]</span><br><span class="line"> ---&gt; Running <span class="keyword">in</span> 15c4cc359144</span><br><span class="line">Removing intermediate container 15c4cc359144</span><br><span class="line"> ---&gt; b73cc4d99088</span><br><span class="line">Successfully built b73cc4d99088</span><br><span class="line">Successfully tagged http-server-with-multi-stage:latest</span><br></pre></td></tr></table></figure><p>镜像构建完成后，我们同样使用docker image ls命令查看一下镜像构建结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker image ls http-server-with-multi-stage:latest</span><br><span class="line">REPOSITORY                     TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">http-server-with-multi-stage   latest              b73cc4d99088        2 minutes ago       13MB</span><br></pre></td></tr></table></figure><p>可以看到，使用多阶段构建的镜像大小与上一步构建的镜像大小一致，都为 13M。但是使用多阶段构建后，却大大减少了我们的构建步骤，使得构建过程更加清晰可读。</p><h3 id="多阶段构建的其他使用方式"><a href="#多阶段构建的其他使用方式" class="headerlink" title="多阶段构建的其他使用方式"></a>多阶段构建的其他使用方式</h3><p>多阶段构建除了我们上面讲解的使用方式，还有更多其他的使用方式，这些使用方式，可以使得多阶段构建实现更多的功能。</p><h4 id="为构建阶段命名"><a href="#为构建阶段命名" class="headerlink" title="为构建阶段命名"></a>为构建阶段命名</h4><p>默认情况下，每一个构建阶段都没有被命名，你可以通过 FROM 指令出现的顺序来引用这些构建阶段，构建阶段的序号是从 0 开始的。然而，为了提高 Dockerfile 的可读性，我们需要为某些构建阶段起一个名称，这样即便后面我们对 Dockerfile 中的内容进程重新排序或者添加了新的构建阶段，其他构建过程中的 COPY 指令也不需要修改。</p><p>上面的 Dockerfile 我们可以优化成如下内容：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.13</span> AS builder</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/wilhelmguo/multi-stage-demo/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -o http-server .</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine:latest  </span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /go/src/github.com/wilhelmguo/multi-stage-demo/http-server .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./http-server"</span>]</span></span><br></pre></td></tr></table></figure><p>我们在第一个构建阶段，使用 AS 指令将这个阶段命名为 builder。然后在第二个构建阶段使用 –from=builder 指令，即可从第一个构建阶段中拷贝文件，使得 Dockerfile 更加清晰可读。</p><h4 id="停止在特定的构建阶段"><a href="#停止在特定的构建阶段" class="headerlink" title="停止在特定的构建阶段"></a>停止在特定的构建阶段</h4><p>有时候，我们的构建阶段非常复杂，我们想在代码编译阶段进行调试，但是多阶段构建默认构建 Dockerfile 的所有阶段，为了减少每次调试的构建时间，我们可以使用 target 参数来指定构建停止的阶段。</p><p>例如，我只想在编译阶段调试 Dockerfile 文件，可以使用如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build --target builder -t http-server:latest .</span><br></pre></td></tr></table></figure><p>在执行docker build命令时添加 target 参数，可以将构建阶段停止在指定阶段，从而方便我们调试代码编译过程。</p><h4 id="使用现有镜像作为构建阶段"><a href="#使用现有镜像作为构建阶段" class="headerlink" title="使用现有镜像作为构建阶段"></a>使用现有镜像作为构建阶段</h4><p>使用多阶段构建时，不仅可以从 Dockerfile 中已经定义的阶段中拷贝文件，还可以使用<code>COPY --from</code>指令从一个指定的镜像中拷贝文件，指定的镜像可以是本地已经存在的镜像，也可以是远程镜像仓库上的镜像。</p><p>例如，当我们想要拷贝 nginx 官方镜像的配置文件到我们自己的镜像中时，可以在 Dockerfile 中使用以下指令：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=nginx:latest /etc/nginx/nginx.conf /etc/<span class="built_in">local</span>/nginx.conf</span></span><br></pre></td></tr></table></figure><p>从现有镜像中拷贝文件还有一些其他的使用场景。例如，有些工具没有我们使用的操作系统的安装源，或者安装源太老，需要我们自己下载源码并编译这些工具，但是这些工具可能依赖的编译环境非常复杂，而网上又有别人已经编译好的镜像。这时我们就可以使用COPY –from指令从编译好的镜像中将工具拷贝到我们自己的镜像中，很方便地使用这些工具了。</p><blockquote><p>多阶段构建可以让我们通过一个 Dockerfile 很方便地构建出体积更小的镜像，并且我们只需要编写 Dockerfile 文件即可，无须借助外部脚本文件。这使得镜像构建过程更加简单透明，但要提醒一点：使用多阶段构建的唯一限制条件是我们使用的 Docker 版本必须高于 17.05 。</p></blockquote><h2 id="DevOps：容器化后如何通过-DevOps-提高协作效能？"><a href="#DevOps：容器化后如何通过-DevOps-提高协作效能？" class="headerlink" title="DevOps：容器化后如何通过 DevOps 提高协作效能？"></a>DevOps：容器化后如何通过 DevOps 提高协作效能？</h2><h3 id="DevOps-的前生今世"><a href="#DevOps-的前生今世" class="headerlink" title="DevOps 的前生今世"></a>DevOps 的前生今世</h3><p>1964 年，世界上的第一台计算机诞生，那时的计算机主要用于军事领域。计算机的运行离不开程序，那时负责编程的人员被称之为“程序员”。由于那时的程序比较简单，很多工作可以一个人完成，所以早期的计算软件交付流程是这样的：设计—开发—自测—发布—部署—维护。如图所示：</p><p><img src="/images/docker/docker-03/3.jpg" alt="3"></p><p>然而，随着计算机的发展和普及，越来越多的人接触到了计算机，这时的计算机也开始逐渐应用于商业领域，市场上出现了越来越多的办公、游戏等“软件”，也有越来越多的人开始从事软件开发这个行业，而这些软件开发者也有了更加专业的称呼“软件开发工程师”。</p><p>后来，又随着计算机软件规模的增大，软件也越来越复杂，这时一个人已经无法完成一个软件完整的生命周期管理。一个软件的开发需要各个团队的分工配合，同时职能划分也需要更加细化，整个软件管理流程中除了软件工程师外又增加了测试工程师和运维工程师。</p><p>分工之后软件开发流程如下：研发工程师做代码设计和开发，测试工程师做专业的测试工作，运维工程师负责将软件部署并负责维护软件。如图所示：</p><p><img src="/images/docker/docker-03/4.jpg" alt="4"></p><p>这种软件开发模式被称为瀑布模型，这种模式将软件生命周期划分为制定计划、需求分析、软件设计、程序编写、软件测试和运行维护等六个基本活动，并且规定了它们自上而下、相互衔接的固定次序，如瀑布流水一样，逐级的下降。</p><p><img src="/images/docker/docker-03/5.jpg" alt="5"></p><p>瀑布模型的模式十分理想化，它假定用户需求十分明确，开发时间十分充足，且项目是单向迭代的。但随着互联网的出现，软件迭代速度越来越快，软件开发越来越“敏捷”，这时候大名鼎鼎的“敏捷开发”出现了，敏捷开发把大的时间点变成细小的时间点，快速迭代开发，软件更新速度也越来越快。</p><p>敏捷开发对传统的开发、测试、运维模式提出了新的挑战，要求更快的开发速度和更高的软件部署频率。而运维工程师信奉的则是稳定性压倒一切，不希望软件频繁变更而引发新的问题。于是乎，敏捷开发和运维工程师之间的矛盾便诞生了。</p><p>敏捷开发使得开发和运维工程师之间的矛盾变得越来越深，为了解决这个问题，DevOps 诞生了。DevOps 是研发工程师（Development）和运维工程师（Operations）的组合。下面是维基百科对 DevOps 的定义：</p><blockquote><p>DevOps（Development 和 Operations 的组合词）是一种重视“软件开发人员（Dev）”和“IT 运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。</p></blockquote><p>DevOps 的整体目标是<strong>促进开发和运维人员之间的配合，并且通过自动化的手段缩短软件的整个交付周期，提高软件的可靠性。</strong></p><h3 id="微服务、容器与-DevOps"><a href="#微服务、容器与-DevOps" class="headerlink" title="微服务、容器与 DevOps"></a>微服务、容器与 DevOps</h3><p>软件开发早期，业务模型简单，很多功能都放在一个服务中，这时的服务称之为单体服务，然而随着业务功能越来越复杂，我们发现这种单体服务功能过于复杂，容易牵一发而动全身，导致开发维护成本很高，软件迭代成本也越来越高。</p><p>这时，软件开发者开始将单体服务拆分为多个小型服务，每一个小型服务独立负责一项任务，各个小型服务之间通过某种方式（RPC 或者 HTTP）相互调用，然后将不同的服务可以分发给不同的业务团队来开发，各个业务团队可以选择适合自己的编程语言来进行开发。</p><p>如果想要微服务实现更快的迭代和更加可靠的稳定性，一定是离不开一个一体化的 DevOps 平台，DevOps 的目标是构建一个稳定可靠的软件生命周期管理环境。所以它不仅可以帮助我们节省很多研发、测试和运维成本，还可以极大地提高我们的软件迭代速度，可以说微服务要想顺利实施，离不开 DevOps 的思想作为指导。</p><p>在 Docker 技术出现之前，人们通常更加关注如何做好 CI（Continuous Integration，持续集成）/CD（Continuous Delivery持续交付）以及 IAAS（基础设施即服务），这时我们称之为 DevOps 1.0 时代。</p><p>随着 Docker 技术的诞生，我们开始迎来了 DevOps 2.0 时代，DevOps 所有的这些需求都与 Docker 所提供的能力极其匹配。首先 Docker 足够轻量，可以帮助我们的微服务实现快速迭代。其次 Docker 可以很方便地帮助我们构建任何语言的运行环境，帮助我们顺利地使用多种语言来开发的我们的服务，最后 Docker 可以帮助我们更好地隔离开发环境和生产环境。</p><p><strong>可以说 Docker 几乎满足了微服务的所有需求，Docker 为 DevOps 提供了很好的基础支撑。</strong></p><p>这时的研发和运维都开始关注软件统一交付的格式和软件生命周期的管理，<strong>而不像之前一样研发只关注“打包前”，而运维只关注“打包后”的模式</strong>，DevOps 无论是研发环境还是生产环境都开始围绕 Docker 进行构建。</p><p><img src="/images/docker/docker-03/6.jpg" alt="6"></p><p>综上所述，微服务、Docker 与 DevOps 三者之间的关系，如上图所示。</p><ol><li>云平台作为底层基础，采用 Docker 技术将服务做容器化部署，并且使用资源管理和调度平台（例如 Kubernetes 或 Swarm）来自动化地管理容器。</li><li>DevOps 平台在云基础平台之上，通过流程自动化以及工具自动化的手段，为可持续集成和交付提供能力支持。</li><li>有了云平台和 DevOps 的支撑，微服务才能够发挥更大的作用，使得我们的业务更加成熟和稳定。</li></ol><h3 id="容器如何助力-DevOps"><a href="#容器如何助力-DevOps" class="headerlink" title="容器如何助力 DevOps"></a>容器如何助力 DevOps</h3><p>Docker 可以在 DevOps 各个阶段发挥重要作用，例如 Docker 可以帮助我们在开发阶段提供统一的开发环境，在持续集成阶段帮助我们快速构建应用，在部署阶段帮助我们快速发布或更新生产环境的应用。</p><p>下面我们来详细认识一下 Docker 在整个 DevOps 阶段究竟发挥了哪些作用。</p><h4 id="开发流程"><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h4><p>开发人员可以在本地或者开发机上快速安装一个 Docker 环境，然后使用 Docker 可以快速启动和部署一个复杂的开发环境。相比传统的配置开发环境的方式，不仅大大提升了开发环境部署的效率，同时也保证了不同开发人员的环境一致。</p><h4 id="集成流程"><a href="#集成流程" class="headerlink" title="集成流程"></a>集成流程</h4><p>通过编写 Dockerfile 可以将我们的业务容器化，然后将我们的 Dockerfile 提交到代码仓库中，在做持续集成的过程中基于已有的 Dockerfile 来构建应用镜像，可以极大提升持续集成的构建速度。</p><p>这主要是因为 Docker 镜像使用了写时复制（Copy On Write）和联合文件系统（Union FileSystem）的机制。Docker 镜像分层存储，相同层仅会保存一份，不同镜像的相同层可以复用，比如 Golang 容器在一次构建停止后，镜像已经存在于构建机上了，当我们开始新一轮的测试时，可以直接复用已有的镜像层，大大提升了构建速度。</p><h4 id="部署流程"><a href="#部署流程" class="headerlink" title="部署流程"></a>部署流程</h4><p>镜像仓库的存在使得 Docker 镜像分发变得十分简单，当我们的镜像构建完成后，无论在哪里只需要执行 docker pull 命令就可以快速地将镜像拉取到本地并且启动我们的应用，这使得应用的创建或更新更快、更高效。</p><p>另外，Docker 结合 Kubernetes 或者其他容器管理平台，可以轻松地实现蓝绿发布等流程，当我们升级应用观察到流量异常时，可以快速回滚到稳定版本。</p><h3 id="DevOps-工具介绍"><a href="#DevOps-工具介绍" class="headerlink" title="DevOps 工具介绍"></a>DevOps 工具介绍</h3><p>工欲善其事，必先利其器，要想顺利落地 DevOps，工具的选择十分重要，下面我们来看下除了Docker 外还有哪些工具可以帮助我们顺利地构建 DevOps 平台。</p><h4 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h4><p><a href="https://git-scm.com/" target="_blank" rel="noopener">Git</a> 是一种分布式的版本控制工具， 是目前使用最广泛的 DevOps 工具之一。Git 相比于其他版本控制工具，它可以<strong>实现离线代码提交</strong>，它允许我们提交代码时未连接到 Git 服务器，等到网络恢复再将我们的代码提交到远程服务器。</p><p>Git 非常容易上手，并且占用空间很小，相比于传统的版本控制工具（例如：Subversion、CVS 等）性能非常优秀，它可以帮助我们快速地创建分支，使得团队多人协作开发更加方便。</p><p>目前全球最大的在线 Git 代码托管服务是 GitHub，GitHub 提供了代码在线托管服务，可以帮助我们快速地将 DevOps 工作流集成起来。除了 GitHub 外，还有很多在线代码托管服务，例如 GitLab、Bitbucket 等。</p><h4 id="Jenkins"><a href="#Jenkins" class="headerlink" title="Jenkins"></a>Jenkins</h4><p><a href="https://www.jenkins.io/" target="_blank" rel="noopener">Jenkins</a> 是开源的 CI/CD 构建工具，Jenkins 采用插件化的方式来扩展它的功能，它拥有非常丰富的插件，这些插件可以帮助我们实现构建、部署、自动化等流程。它还拥有强大的生态系统，这些生态系统可以很方便地与 Docker 和 Kubernetes 集成。Jenkins 几乎可以和所有的 DevOps 工具进行集成。</p><h4 id="Ansible"><a href="#Ansible" class="headerlink" title="Ansible"></a>Ansible</h4><p><a href="https://www.ansible.com/" target="_blank" rel="noopener">Ansible</a> 是一个配置管理工具。Ansible 可以帮助我们自动完成一些重复的 IT 配置管理，应用程序部署等任务，还可以帮助我们放弃编写繁杂的 shell 脚本，仅仅做一些 YAML 的配置，即可实现任务下发和管理工作。并且 Ansible 的每一行命令都是幂等的，它允许我们多次重复执行相同的脚本并且得到的结果都是一致的。</p><h4 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h4><p><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a> 是当前最流行的容器编排工具之一，Docker 帮助我们解决了容器打包和镜像分发的问题，而 Kubernetes 则帮助我们解决了大批量容器管理和调度的问题，它可以打通从研发到上线的整个流程，使得 DevOps 落地更加简单方便。</p><blockquote><p>DevOps 虽然已经被提及很多年，但是一直没有很好的落地，直到 2013 年 Docker 的诞生，才使得 DevOps 这个理念又重新火了起来，因为 Docker 为我们解决了应用的构建、分发和隔离的问题，才使得 DevOps 落地变得更加简单。</p></blockquote><blockquote><p>DevOps 提倡小规模和增量的服务发布方式，并且 DevOps 还指导我们尽量避免开发大单体（把所有的功能都集成到一个服务中）应用，这一切，都与 Docker 所能提供的能力十分匹配。因此，Docker 是非常重要的 DevOps 工具。</p></blockquote><h2 id="CI-CD：容器化后如何实现持续集成与交付？（上）"><a href="#CI-CD：容器化后如何实现持续集成与交付？（上）" class="headerlink" title="CI/CD：容器化后如何实现持续集成与交付？（上）"></a>CI/CD：容器化后如何实现持续集成与交付？（上）</h2><p>具体来说，CI/CD 是一种通过在应用开发阶段，引入自动化的手段来频繁地构建应用，并且向客户交付应用的方法。它的核心理念是持续开发、持续部署以及持续交付，它还可以让自动化持续交付贯穿于整个应用生命周期，使得开发和运维统一参与协同支持。</p><h3 id="什么是-CI-CD"><a href="#什么是-CI-CD" class="headerlink" title="什么是 CI/CD"></a>什么是 CI/CD</h3><h4 id="CI-持续集成（Continuous-Integration）"><a href="#CI-持续集成（Continuous-Integration）" class="headerlink" title="CI 持续集成（Continuous Integration）"></a>CI 持续集成（Continuous Integration）</h4><p>随着软件功能越来越复杂，一个大型项目要想在规定时间内顺利完成，就需要多位开发人员协同开发。但是，如果我们每个人都负责开发自己的代码，然后集中在某一天将代码合并在一起（称为“合并日”）。你会发现，代码可能会有很多冲突和编译问题，而这个处理过程十分烦琐、耗时，并且需要每一位工程师确认代码是否被覆盖，代码是否完整。这种情况显然不是我们想要看到的，这时持续集成（CI）就可以很好地帮助我们解决这个问题。</p><p>CI 持续集成要求开发人员频繁地（甚至是每天）将代码提交到共享分支中。一旦开发人员的代码被合并，将会自动触发构建流程来构建应用，并通过触发自动化测试（单元测试或者集成测试）来验证这些代码的提交，确保这些更改没有对应用造成影响。如果发现提交的代码在测试过程中或者构建过程中有问题，则会马上通知研发人员确认，修改代码并重新提交。通过将以往的定期合并代码的方式，改变为频繁提交代码并且自动构建和测试的方式，可以帮助我们<strong>及早地发现问题和解决冲突，减少代码出错。</strong></p><p>传统 CI 流程的实现十分复杂，无法做到标准化交付，而当我们的应用容器化后，应用构建的结果就是 Docker 镜像。代码检查完毕没有缺陷后合并入主分支。此时启动构建流程，构建系统会自动将我们的应用打包成 Docker 镜像，并且推送到镜像仓库。</p><h4 id="CD-持续交付（Continuous-Delivery）"><a href="#CD-持续交付（Continuous-Delivery）" class="headerlink" title="CD 持续交付（Continuous Delivery）"></a>CD 持续交付（Continuous Delivery）</h4><p>当我们每次完成代码的测试和构建后，我们需要将编译后的镜像快速发布到测试环境，这时我们的持续交付就登场了。持续交付要求我们实现自动化准备测试环境、自动化测试应用、自动化监控代码质量，并且自动化交付生产环境镜像。</p><p>在以前，测试环境的构建是非常耗时的，并且很难保证测试环境和研发环境的一致性。但现在，借助于容器技术，我们可以很方便地构建出一个测试环境，并且可以保证开发和测试环境的一致性，这样不仅可以提高测试效率，还可以提高敏捷性。</p><p>容器化后的应用交付过程是这样的，我们将测试的环境交由 QA 来维护，当我们确定好本次上线要发布的功能列表时，我们将不同开发人员开发的 feature 分支的代码合并到 release 分支。然后由 QA 来将构建镜像部署到测试环境，结合自动测试和人工测试、自动检测和人工记录，形成完整的测试报告，并且把测试过程中遇到的问题交由开发人员修改，开发修改无误后再次构建测试环境进行测试。测试没有问题后，自动交付生产环境的镜像到镜像仓库。</p><h4 id="CD-持续部署（Continuous-Deployment）"><a href="#CD-持续部署（Continuous-Deployment）" class="headerlink" title="CD 持续部署（Continuous Deployment）"></a>CD 持续部署（Continuous Deployment）</h4><p>CD 不仅有持续交付的含义，还代表持续部署。经测试无误打包完生产环境的镜像后，我们需要把镜像部署到生产环境，持续部署是最后阶段，它作为持续交付的延伸，可以自动将生产环境的镜像发布到生产环境中。</p><p>部署业务首先需要我们有一个资源池，实现资源自动化供给，而且有的应用还希望有自动伸缩的能力，根据外部流量自动调整容器的副本数，而这一切在容器云中都将变得十分简单。</p><p>我们可以想象，如果有客户提出了反馈，我们通过持续部署在几分钟内，就能在更改完代码的情况下，将新的应用版本发布到生产环境中（假设通过了自动化测试），这时我们就可以实现快速迭代，持续接收和整合用户的反馈，将用户体验做到极致。</p><p>讲了这么多概念，也许你会感觉比较枯燥乏味。下面我们就动动手，利用一些工具搭建一个 DevOps 环境。</p><p>搭建 DevOps 环境的工具非常多，这里我选择的工具为 Jenkins、Docker 和 GitLab。Jenkins 和 Docker 都已经介绍过了，这里我再介绍一下 Gitlab。</p><p>Gitlab 是由 Gitlab Inc. 开发的一款基于 Git 的代码托管平台，它的功能和 GitHub 类似，可以帮助我们存储代码。除此之外，GitLab 还具有在线编辑 wiki、issue 跟踪等功能，另外最新版本的 GitLab 还集成了 CI/CD 功能，不过这里我们仅仅使用 GitLab 的代码存储功能， CI/CD 还是交给我们的老牌持续集成工具 Jenkins 来做。</p><h3 id="Docker-Jenkins-GitLab-搭建-CI-CD-系统"><a href="#Docker-Jenkins-GitLab-搭建-CI-CD-系统" class="headerlink" title="Docker+Jenkins+GitLab 搭建 CI/CD 系统"></a>Docker+Jenkins+GitLab 搭建 CI/CD 系统</h3><p>软件安装环境如下。</p><ul><li>操作系统：CentOS 7</li><li>Jenkins：tls 长期维护版</li><li>Docker：18.06</li><li>GitLab：13.3.8-ce.0</li></ul><h4 id="第一步：安装-Docker"><a href="#第一步：安装-Docker" class="headerlink" title="第一步：安装 Docker"></a>第一步：安装 Docker</h4><p>Docker 环境准备好后，我们就可以利用 Docker 来部署 GitLab 和 Jenkins 了。</p><h4 id="第二步：安装-GitLab"><a href="#第二步：安装-GitLab" class="headerlink" title="第二步：安装 GitLab"></a>第二步：安装 GitLab</h4><p>GitLab 官方提供了 GitLab 的 Docker 镜像，因此我们只需要执行以下命令就可以快速启动一个 GitLab 服务了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d \</span><br><span class="line">--hostname localhost \</span><br><span class="line">-p 8080:80 -p 2222:22 \</span><br><span class="line">--name gitlab \</span><br><span class="line">--restart always \</span><br><span class="line">--volume /tmp/gitlab/config:/etc/gitlab \</span><br><span class="line">--volume /tmp/gitlab/logs:/var/<span class="built_in">log</span>/gitlab \</span><br><span class="line">--volume /tmp/gitlab/data:/var/opt/gitlab \</span><br><span class="line">gitlab/gitlab-ce:13.3.8-ce.0</span><br></pre></td></tr></table></figure><p>这个启动过程可能需要几分钟的时间。当服务启动后我们就可以通过 <a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a> 访问到我们的 GitLab 服务了。</p><p>第一次登陆，GitLab 会要求我们设置管理员密码，我们输入管理员密码后点击确认即可，之后 GitLab 会自动跳转到登录页面。</p><p>然后输入默认管理员用户名：<a href="mailto:admin@example.com">admin@example.com</a>，密码为我们上一步设置的密码。点击登录即可登录到系统中，至此，GitLab 已经安装成功。</p><h4 id="第三步：安装-Jenkins"><a href="#第三步：安装-Jenkins" class="headerlink" title="第三步：安装 Jenkins"></a>第三步：安装 Jenkins</h4><p>Jenkins 官方提供了 Jenkins 的 Docker 镜像，我们使用 Jenkins 镜像就可以一键启动一个 Jenkins 服务。命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker run -d --name=jenkins \</span></span><br><span class="line">-p 8888:8080 \</span><br><span class="line">-u root \</span><br><span class="line">--restart always \</span><br><span class="line">-v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">-v /usr/bin/docker:/usr/bin/docker \</span><br><span class="line">-v /tmp/jenkins_home:/var/jenkins_home \</span><br><span class="line">jenkins/jenkins:lts</span><br></pre></td></tr></table></figure><blockquote><p>这里，我将 docker.sock 和 docker 二进制挂载到了 Jenkins 容器中，是为了让 Jenkins 可以直接调用 docker 命令来构建应用镜像。</p></blockquote><p>Jenkins 的默认密码会在容器启动后打印在容器的日志中，我们可以通过以下命令找到 Jenkins 的默认密码，星号之间的类似于一串 UUID 的随机串就是我们的密码。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">$ docker logs -f jenkins</span><br><span class="line">unning from: /usr/share/jenkins/jenkins.war</span><br><span class="line">webroot: EnvVars.masterEnvVars.get(<span class="string">"JENKINS_HOME"</span>)</span><br><span class="line">2020-10-31 16:13:06.472+0000 [id=1]INFOorg.eclipse.jetty.util.log.Log<span class="comment">#initialized: Logging initialized @292ms to org.eclipse.jetty.util.log.JavaUtilLog</span></span><br><span class="line">2020-10-31 16:13:06.581+0000 [id=1]INFOwinstone.Logger<span class="comment">#logInternal: Beginning extraction from war file</span></span><br><span class="line">2020-10-31 16:13:08.369+0000 [id=1]WARNINGo.e.j.s.handler.ContextHandler<span class="comment">#setContextPath: Empty contextPath</span></span><br><span class="line">... 省略部分启动日志</span><br><span class="line">Jenkins initial setup is required. An admin user has been created and a password generated.</span><br><span class="line">Please use the following password to proceed to installation:</span><br><span class="line">*************************************************************</span><br><span class="line">*************************************************************</span><br><span class="line">*************************************************************</span><br><span class="line"></span><br><span class="line">Jenkins initial setup is required. An admin user has been created and a password generated.</span><br><span class="line">Please use the following password to proceed to installation:</span><br><span class="line"></span><br><span class="line">fb3499944e4845bba9d4b7d9eb4e3932</span><br><span class="line"></span><br><span class="line">This may also be found at: /var/jenkins_home/secrets/initialAdminPassword</span><br><span class="line">*************************************************************</span><br><span class="line">*************************************************************</span><br><span class="line">*************************************************************</span><br><span class="line">This may also be found at: /var/jenkins_home/secrets/initialAdminPassword</span><br><span class="line">2020-10-31 16:17:07.577+0000 [id=28]INFOjenkins.InitReactorRunner<span class="variable">$1</span><span class="comment">#onAttained: Completed initialization</span></span><br><span class="line">2020-10-31 16:17:07.589+0000 [id=21]INFOhudson.WebAppMain<span class="variable">$3</span><span class="comment">#run: Jenkins is fully up and running</span></span><br></pre></td></tr></table></figure><p>之后，我们通过访问 <a href="http://localhost:8888" target="_blank" rel="noopener">http://localhost:8888</a> 就可以访问到 Jenkins 服务了。</p><p>然后在系统管理 -&gt; 插件管理 -&gt; 可选插件处，搜索 GitLab 和 Docker ，分别安装相关插件即可，以便我们的 Jenkins 服务和 GitLab 以及 Docker 可以更好地交互。</p><blockquote><p>Docker 的出现解决了 CI/CD 流程中的各种问题，Docker 交付的镜像不仅包含应用程序，也包含了应用程序的运行环境，这很好地解决了开发和线上环境不一致问题。同时 Docker 的出现也极大地提升了 CI/CD 的构建效率，我们仅仅需要编写一个 Dockerfile 并将 Dockerfile 提交到我们的代码仓库即可快速构建出我们的应用，最后，当我们构建好 Docker 镜像后 Docker 可以帮助我们快速发布及更新应用。</p></blockquote><h2 id="CI-CD：容器化后如何实现持续集成与交付？（下）"><a href="#CI-CD：容器化后如何实现持续集成与交付？（下）" class="headerlink" title="CI/CD：容器化后如何实现持续集成与交付？（下）"></a>CI/CD：容器化后如何实现持续集成与交付？（下）</h2><p>构建和部署一个应用的流程可以分为五部分。</p><ol><li>我们首先需要配置 GitLab SSH 访问公钥，使得我们可以直接通过 SSH 拉取或推送代码到 GitLab。</li><li>接着将代码通过 SSH 上传到 GitLab。</li><li>再在 Jenkins 创建构建任务，使得 Jenkins 可以成功拉取 GitLab 的代码并进行构建。</li><li>然后配置代码变更自动构建流程，使得代码变更可以触发自动构建 Docker 镜像。</li><li>最后配置自动部署流程，镜像构建完成后自动将镜像发布到测试或生产环境。</li></ol><p>接下来我们逐一操作。</p><h3 id="1-配置-GitLab-SSH-访问公钥"><a href="#1-配置-GitLab-SSH-访问公钥" class="headerlink" title="1. 配置 GitLab SSH 访问公钥"></a>1. 配置 GitLab SSH 访问公钥</h3><p>为了能够让 Jenkins 顺利从 GitLab 拉取代码，我们需要先生成 ssh 密钥。我们可以使用 ssh-keygen 命令来生成 2048 位的 ras 密钥。在 Linux 上执行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ ssh-keygen -o -t rsa -b 2048 -C <span class="string">"email@example.com"</span></span><br><span class="line"><span class="comment"># 输入上面命令后系统会提示我们密钥保存的位置等信息，只需要按回车即可。</span></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/home/centos/.ssh/id_rsa):</span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase):</span><br><span class="line">Enter same passphrase again:</span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /home/centos/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /home/centos/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:A+d0NQQrjxV2h+zR3BQIJxT23puXoLi1RiTKJm16+rg email@example.com</span><br><span class="line">The key<span class="string">'s randomart image is:</span></span><br><span class="line"><span class="string">+---[RSA 2048]----+</span></span><br><span class="line"><span class="string">|          =XB=o+o|</span></span><br><span class="line"><span class="string">|         ..=B+o .|</span></span><br><span class="line"><span class="string">|      . + +. o   |</span></span><br><span class="line"><span class="string">|       = B .o .  |</span></span><br><span class="line"><span class="string">|      o S +  o . |</span></span><br><span class="line"><span class="string">|     . * .... . +|</span></span><br><span class="line"><span class="string">|      =  ..o   +.|</span></span><br><span class="line"><span class="string">|     ...  o..   .|</span></span><br><span class="line"><span class="string">|     E=. ...     |</span></span><br><span class="line"><span class="string">+----[SHA256]-----+</span></span><br></pre></td></tr></table></figure><p>执行完上述命令后 ，$HOME/.ssh/ 目录下会自动生成两个文件：id_rsa.pub 文件为公钥文件，id_rsa 文件为私钥文件。我们可以通过 cat 命令来查看公钥文件内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat <span class="variable">$HOME</span>/.ssh/id_rsa.pub</span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDljSlDNHnUr4ursYISKXK5j2mWTYnt100mvYeJCLpr6tpeSarGyr7FnTc6sLM721plU2xq0bqlFEU5/0SSvFdLTht7bcfm/Hf31EdAuIqZuy/guP06ijpidfX6lVDxLWx/sO3Wbj3t7xgj4sfCFTiv+OOFP0NxKr5wy+emojm6KIaXkhjbPeJDgph5bvluFnKAtesMUkdhceAdN9grE3nkBOnwWw6G4dCtbrKt2o9wSyzgkDwPjj2qjFhcE9571/61/Nr8v9iqSHvcb/d7WZ0Qq7a2LYds6hQkpBg2RCDDJA16fFVs8Q5eNCpDQwGG3IbhHMUwvpKDf0OYrS9iftc5 email@example.com</span><br></pre></td></tr></table></figure><p>然后将公钥文件拷贝到 GitLab 的个人设置 -&gt; SSH Keys 中，点击添加按钮，将我们的公钥添加到 GitLab 中。</p><h3 id="2-上传服务代码到-GitLab"><a href="#2-上传服务代码到-GitLab" class="headerlink" title="2. 上传服务代码到 GitLab"></a>2. 上传服务代码到 GitLab</h3><p>这里，我使用 Golang 编写了一个 HTTP 服务，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">    <span class="string">"fmt"</span></span><br><span class="line">    <span class="string">"net/http"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">hello</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    fmt.Fprintf(w, <span class="string">"hello\n"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">headers</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> name, headers := <span class="keyword">range</span> req.Header &#123;</span><br><span class="line">        <span class="keyword">for</span> _, h := <span class="keyword">range</span> headers &#123;</span><br><span class="line">            fmt.Fprintf(w, <span class="string">"%v: %v\n"</span>, name, h)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    http.HandleFunc(<span class="string">"/hello"</span>, hello)</span><br><span class="line">    http.HandleFunc(<span class="string">"/headers"</span>, headers)</span><br><span class="line"></span><br><span class="line">    http.ListenAndServe(<span class="string">":8090"</span>, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后编写一个 Dockerfile，利用多阶段构建将我们的 Go 编译，并将编译后的二进制文件拷贝到 scratch（scratch 是一个空镜像，用于构建其他镜像，体积非常小）的基础镜像中。Dockerfile 的内容如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> golang:<span class="number">1.14</span> as builder</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /go/src/github.com/wilhelmguo/devops-demo/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> main.go .</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> CGO_ENABLED=0 GOOS=linux go build -o /tmp/http-server .</span></span><br><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /root/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> --from=builder /tmp/http-server .</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"./http-server"</span>]</span></span><br></pre></td></tr></table></figure><p>编写完 Go HTTP 文件和 Dockerfile 文件后，代码目录内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ls -lh</span><br><span class="line">total 24</span><br><span class="line">-rw-r--r--  1 root  root   243B Nov  3 22:03 Dockerfile</span><br><span class="line">-rw-r--r--  1 root  root    26B Nov  3 22:06 README.md</span><br><span class="line">-rw-r--r--  1 root  root   441B Nov  3 22:03 main.go</span><br></pre></td></tr></table></figure><p>然后，我们在 GitLab 上创建一个 hello 项目，并将代码上传。</p><ol start="3"><li>创建 Jenkins 任务</li></ol><p>在 Jenkins 中添加一个自由风格的任务。</p><p>点击确定，然后到源码管理选择 Git，填写 GitLab 项目的 URL。此时 Jenkins 会提示没有访问 GitLab 的相关权限，我们需要点击添加按钮将私钥添加到 Jenkins 中用以鉴权。</p><blockquote><p>由于部署 GitLab 的宿主机 ssh 默认端口为 22，为了避免与宿主机的 ssh 端口冲突，我们的 GitLab ssh 端口配置为 2222，因此 Jenkins 连接 GitLab 的 URL 中需要包含端口号 2222， 配置格式为 ssh://git@172.20.1.6:2222/root/hello.git。</p></blockquote><p>选择添加的密钥类型为 “SSH Username with private key”，Username 设置为 jenkins，然后将私钥粘贴到 Private Key 输入框中，点击添加即可。</p><p>添加完成后，认证名称选择 jenkins 后，红色报错提示就会消失。这证明此时 Jenkins 和 GitLab 已经认证成功，可以成功从 GitLab 拉取代码了。</p><p>下面我们使用 shell 脚本来构建我们的应用镜像，在构建中增加一个 Shell 类型的构建步骤，并且填入以下信息，将 USER 替换为目标镜像仓库的用户名，将 PASSWORD 替换为镜像仓库的密码。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第一步，登录镜像仓库</span></span><br><span class="line">$ docker login -u &#123;USER&#125; -p  &#123;PASSWORD&#125;</span><br><span class="line"><span class="comment"># 第二步，使用 docker build 命令构建镜像</span></span><br><span class="line">$ docker build -t lagoudocker/devops-demo . </span><br><span class="line"><span class="comment"># 第三步, 使用 docker push 命令推送镜像</span></span><br><span class="line">$ docker push lagoudocker/devops-demo</span><br></pre></td></tr></table></figure><p>完成后点击保存，此时任务已经成功添加到 Jenkins 中。回到任务首页，点击构建按钮即可开始构建。第一次构建需要下载依赖的基础镜像，这个过程可能比较慢。构建过程中，我们也可以点击控制台查看构建输出的内容：</p><h3 id="4-配置自动构建"><a href="#4-配置自动构建" class="headerlink" title="4. 配置自动构建"></a>4. 配置自动构建</h3><p>点击上一步创建的任务，点击配置进入任务配置界面，到构建触发器下勾选 GitLab 相关的选项，点击 Generate 按钮生成一个 GitLab 回调 Jenkins 的 token。记录下 Jenkins 的回调地址和生成的 token 信息。</p><p>在 GitLab 项目设置中，选择 Webhooks，将 Jenkins 的回调地址和 token 信息添加到 Webhooks 的配置中，点击添加即可。</p><p>为了实现根据 git 的 tag 自动构建相应版本的镜像，我们需要修改 Jenkins 构建步骤中的 shell 脚本为以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要推送的镜像名称</span></span><br><span class="line">IMAGE_NAME=<span class="string">"lagoudocker/devops-demo"</span> </span><br><span class="line"><span class="comment"># 获取当前构建的版本号</span></span><br><span class="line">GIT_VERSION=`git describe --always --tag`</span><br><span class="line"><span class="comment"># 生成完整的镜像 URL 变量，用于构建和推送镜像</span></span><br><span class="line">REPOSITORY=docker.io/<span class="variable">$&#123;IMAGE_NAME&#125;</span>:<span class="variable">$&#123;GIT_VERSION&#125;</span> </span><br><span class="line"><span class="comment"># 构建Docker镜像 </span></span><br><span class="line">docker build -t <span class="variable">$REPOSITORY</span> -f Dockerfile . </span><br><span class="line"><span class="comment"># 登录镜像仓库，username 跟 password 为目标镜像仓库的用户名和密码</span></span><br><span class="line">docker login --username=xxxxx --password=xxxxxx docker.io</span><br><span class="line"><span class="comment"># 推送 Docker 镜像到目标镜像仓库</span></span><br><span class="line">docker push <span class="variable">$REPOSITORY</span></span><br></pre></td></tr></table></figure><p>好了，到此我们已经完成了 GitLab -&gt; Jenkins -&gt; Docker 镜像仓库的自动构建和推送。当我们推送代码到 GitLab 中时，会自动触发 Webhooks，然后 GitLab 会根据配置的 Webhooks 调用 Jenkins 开始构建镜像，镜像构建完成后自动将镜像上传到我们的镜像仓库。</p><h3 id="5-配置自动部署"><a href="#5-配置自动部署" class="headerlink" title="5. 配置自动部署"></a>5. 配置自动部署</h3><p>镜像构建完成后，我们还需要将镜像发布到测试或生产环境中将镜像运行起来。发布到环境的过程可以设置为自动发布，每当我们推送代码到 master 中时，即开始自动构建镜像，并将构建后的镜像发布到测试环境中。</p><p>在镜像构建过程中，实际上 Jenkins 是通过执行我们编写的 shell 脚本完成的，要想实现镜像构建完成后自动在远程服务器上运行最新的镜像，我们需要借助一个 Jenkins 插件 Publish Over SSH，这个插件可以帮助我们自动登录远程服务器，并执行一段脚本将我们的服务启动。</p><p>下面我们来实际操作下这个插件。</p><p>第一步，在 Jenkins 中安装 Publish Over SSH 插件。 在 Jenkins 系统管理，插件管理中，搜索 Publish Over SSH，然后点击安装并重启 Jenkins 服务。</p><p>第二步，配置 Publish Over SSH 插件。 插件安装完成后，在 Jenkins 系统管理的系统设置下，找到 Publish Over SSH 功能模块，添加远程服务器节点，这里我使用密码验证的方式添加一台服务器。配置好后，我们可以使用测试按钮测试服务器是否可以正常连接，显示Success 代表服务器可以正常连接，测试连接成功后，点击保存按钮保存配置。</p><p>第三步，修改之前 shell 任务中脚本， 添加部署相关的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 需要推送的镜像名称</span></span><br><span class="line">IMAGE_NAME=<span class="string">"lagoudocker/devops-demo"</span> </span><br><span class="line"><span class="comment"># 获取当前构建的版本号</span></span><br><span class="line">GIT_VERSION=`git describe --always --tag`</span><br><span class="line"><span class="comment"># 生成完整的镜像 URL 变量，用于构建和推送镜像</span></span><br><span class="line">REPOSITORY=docker.io/<span class="variable">$&#123;IMAGE_NAME&#125;</span>:<span class="variable">$&#123;GIT_VERSION&#125;</span> </span><br><span class="line"><span class="comment"># 构建Docker镜像 </span></span><br><span class="line">docker build -t <span class="variable">$REPOSITORY</span> -f Dockerfile . </span><br><span class="line"><span class="comment"># 登录镜像仓库，username 跟 password 为目标镜像仓库的用户名和密码</span></span><br><span class="line">docker login --username=&#123;USER&#125; --password=&#123;PASSWORD&#125; docker.io</span><br><span class="line"><span class="comment"># 推送 Docker 镜像到目标镜像仓库</span></span><br><span class="line">docker push <span class="variable">$REPOSITORY</span> </span><br><span class="line">mkdir -p ./shell &amp;&amp; <span class="built_in">echo</span> \ </span><br><span class="line"><span class="string">"docker login --username=&#123;USER&#125; --password=&#123;PASSWORD&#125; \n"</span>\ </span><br><span class="line"><span class="string">"docker pull <span class="variable">$REPOSITORY</span>\n"</span>\ </span><br><span class="line"><span class="string">"docker kill hello \n"</span>\ </span><br><span class="line"><span class="string">"docker run --rm --name=hello -p 8090:8090 -d <span class="variable">$REPOSITORY</span>"</span> &gt;&gt; ./shell/release</span><br></pre></td></tr></table></figure><p>我们在 docker push 命令后，增加一个输出 shell 脚本到 release 文件的命令，这个脚本会发送到远端的服务器上并执行，通过执行这个脚本文件可以在远端服务器上，拉取最新镜像并且重新启动容器。</p><p>第四步，配置远程执行。在 Jenkins 的 hello 项目中，点击配置，在执行步骤中点击添加Send files or execute commands over SSH的步骤，选择之前添加的服务器，并且按照以下内容填写相关信息。</p><ul><li>Source file 就是我们要传递的 shell 脚本信息，这里填写我们上面生成的 shell 脚本文件即可。</li><li>Remove prefix 是需要过滤的目录，这里我们填写 shell。</li><li>Remote directory 为远程执行脚本的目录。</li></ul><p>最后点击保存，保存我们的配置即可。配置完成后，我们就完成了推送代码到 GitLab，Jenkins 自动构建镜像，之后推送镜像到镜像仓库，最后自动在远程服务器上拉取并重新部署容器。</p><blockquote><p>如果你是生产环境中使用的 Kubernetes 管理服务，可以在 Jenkins 中安装 Kubernetes 的插件，然后构建完成后直接发布镜像到 Kubernetes 集群中。</p></blockquote><blockquote><p>DevOps 是一个非常棒的指导思想，而 CI/CD 是整个 DevOps 流程中最重要的部分，目前 CI/CD 的市场已经非常成熟，CI/CD 的工具链也非常完善，因此，无论是小团队还是大团队，都有必要去学习和掌握 CI/CD，以便帮助我们改善团队的效能，一切可以自动化的流程，都应该尽量避免人工参与。</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《由浅入深吃透 Docker》</li><li>《狂神说Docker》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://www.docker-cn.com" target="_blank" rel="noopener">https://www.docker-cn.com</a></li><li><a href="https://docs.docker.com/compose/compose-file/compose-file-v3/" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/compose-file-v3/</a></li><li><a href="https://docs.docker.com/compose/reference/" target="_blank" rel="noopener">https://docs.docker.com/compose/reference/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker Compose 、Docker Swarm 、Kubernetes。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://blog.lichao.xin/categories/Docker/"/>
    
    
      <category term="docker" scheme="https://blog.lichao.xin/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>重学 Docker 之 底层实现原理及关键技术</title>
    <link href="https://blog.lichao.xin/back-end/docker/docker-02/"/>
    <id>https://blog.lichao.xin/back-end/docker/docker-02/</id>
    <published>2021-03-21T10:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.383Z</updated>
    
    <content type="html"><![CDATA[<p>资源隔离（Namespace）、资源限制（Cgroups）、数据驱动（Overlay2）。</p><a id="more"></a><h2 id="资源隔离：为什么构建容器需要-Namespace-？"><a href="#资源隔离：为什么构建容器需要-Namespace-？" class="headerlink" title="资源隔离：为什么构建容器需要 Namespace ？"></a>资源隔离：为什么构建容器需要 Namespace ？</h2><h3 id="什么是-Namespace？"><a href="#什么是-Namespace？" class="headerlink" title="什么是 Namespace？"></a>什么是 Namespace？</h3><p>下面是 Namespace 的维基百科定义：</p><blockquote><p>Namespace 是 Linux 内核的一项功能，该功能对内核资源进行分区，以使一组进程看到一组资源，而另一组进程看到另一组资源。Namespace 的工作方式通过为一组资源和进程设置相同的 Namespace 而起作用，但是这些 Namespace 引用了不同的资源。资源可能存在于多个 Namespace 中。这些资源可以是进程 ID、主机名、用户 ID、文件名、与网络访问相关的名称和进程间通信。</p></blockquote><p>简单来说，Namespace 是 Linux 内核的一个特性，该特性可以实现在同一主机系统中，对进程 ID、主机名、用户 ID、文件名、网络和进程间通信等资源的隔离。Docker 利用 Linux 内核的 Namespace 特性，实现了每个容器的资源相互隔离，从而保证容器内部只能访问到自己 Namespace 的资源。</p><p>最新的 Linux 5.6 内核中提供了 8 种类型的 Namespace：</p><table><thead><tr><th>Namespace 名称</th><th>作用</th><th>内核版本</th></tr></thead><tbody><tr><td>Mount（mnt）</td><td>隔离挂载点</td><td>2.4.19</td></tr><tr><td>Process ID (pid)</td><td>隔离进程 ID</td><td>2.6.24</td></tr><tr><td>Network (net)</td><td>隔离网络设备，端口号等</td><td>2.6.29</td></tr><tr><td>Interprocess Communication (ipc)</td><td>隔离 System V IPC 和 POSIX message queues</td><td>2.6.19</td></tr><tr><td>UTS Namespace(uts)</td><td>隔离主机名和域名</td><td>2.6.19</td></tr><tr><td>User Namespace (user)</td><td>隔离用户和用户组</td><td>3.8</td></tr><tr><td>Control group (cgroup) Namespace</td><td>隔离 Cgroups 根目录</td><td>4.6</td></tr><tr><td>Time Namespace</td><td>隔离系统时间</td><td>5.6</td></tr></tbody></table><p>虽然 Linux 内核提供了8种 Namespace，但是最新版本的 Docker 只使用了其中的前6 种，分别为Mount Namespace、PID Namespace、Net Namespace、IPC Namespace、UTS Namespace、User Namespace。</p><p>下面，我们详细了解下 Docker 使用的 6 种 Namespace的作用分别是什么。</p><h3 id="各种-Namespace-的作用？"><a href="#各种-Namespace-的作用？" class="headerlink" title="各种 Namespace 的作用？"></a>各种 Namespace 的作用？</h3><h4 id="（1）Mount-Namespace"><a href="#（1）Mount-Namespace" class="headerlink" title="（1）Mount Namespace"></a>（1）Mount Namespace</h4><p>Mount Namespace 是 Linux 内核实现的第一个 Namespace，从内核的 2.4.19 版本开始加入。它可以用来隔离不同的进程或进程组看到的挂载点。通俗地说，就是可以实现在不同的进程中看到不同的挂载目录。使用 Mount Namespace 可以实现容器内只能看到自己的挂载信息，在容器内的挂载操作不会影响主机的挂载目录。</p><p>下面我们通过一个实例来演示下 Mount Namespace。在演示之前，我们先来认识一个命令行工具 unshare。unshare 是 util-linux 工具包中的一个工具，CentOS 7 系统默认已经集成了该工具，<strong>使用 unshare 命令可以实现创建并访问不同类型的 Namespace</strong>。</p><p>首先我们使用以下命令创建一个 bash 进程并且新建一个 Mount Namespace：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo unshare --mount --fork /bin/bash</span><br><span class="line">[root@centos7 centos]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>执行完上述命令后，这时我们已经在主机上创建了一个新的 Mount Namespace，并且当前命令行窗口加入了新创建的 Mount Namespace。下面我通过一个例子来验证下，在独立的 Mount Namespace 内创建挂载目录是不影响主机的挂载目录的。</p><p>首先在 /tmp 目录下创建一个目录。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># mkdir /tmp/tmpfs</span></span><br></pre></td></tr></table></figure><p>创建好目录后使用 mount 命令挂载一个 tmpfs 类型的目录。命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># mount -t tmpfs -o size=20m tmpfs /tmp/tmpfs</span></span><br></pre></td></tr></table></figure><p>然后使用 df 命令查看一下已经挂载的目录信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/vda1       500G  1.4G  499G   1% /</span><br><span class="line">devtmpfs         16G     0   16G   0% /dev</span><br><span class="line">tmpfs            16G     0   16G   0% /dev/shm</span><br><span class="line">tmpfs            16G     0   16G   0% /sys/fs/cgroup</span><br><span class="line">tmpfs            16G   57M   16G   1% /run</span><br><span class="line">tmpfs           3.2G     0  3.2G   0% /run/user/1000</span><br><span class="line">tmpfs            20M     0   20M   0% /tmp/tmpfs</span><br></pre></td></tr></table></figure><p>可以看到 /tmp/tmpfs 目录已经被正确挂载。为了验证主机上并没有挂载此目录，我们新打开一个命令行窗口，同样执行 df 命令查看主机的挂载信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[centos@centos7 ~]$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs         16G     0   16G   0% /dev</span><br><span class="line">tmpfs            16G     0   16G   0% /dev/shm</span><br><span class="line">tmpfs            16G   57M   16G   1% /run</span><br><span class="line">tmpfs            16G     0   16G   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1       500G  1.4G  499G   1% /</span><br><span class="line">tmpfs           3.2G     0  3.2G   0% /run/user/1000</span><br></pre></td></tr></table></figure><p>通过上面输出可以看到主机上并没有挂载 /tmp/tmpfs，可见我们独立的 Mount Namespace 中执行 mount 操作并不会影响主机。</p><p>为了进一步验证我们的想法，我们继续在当前命令行窗口查看一下当前进程的 Namespace 信息，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># ls -l /proc/self/ns/</span></span><br><span class="line">total 0</span><br><span class="line">lrwxrwxrwx. 1 root root 0 Sep  4 08:20 ipc -&gt; ipc:[4026531839]</span><br><span class="line">lrwxrwxrwx. 1 root root 0 Sep  4 08:20 mnt -&gt; mnt:[4026532239]</span><br><span class="line">lrwxrwxrwx. 1 root root 0 Sep  4 08:20 net -&gt; net:[4026531956]</span><br><span class="line">lrwxrwxrwx. 1 root root 0 Sep  4 08:20 pid -&gt; pid:[4026531836]</span><br><span class="line">lrwxrwxrwx. 1 root root 0 Sep  4 08:20 user -&gt; user:[4026531837]</span><br><span class="line">lrwxrwxrwx. 1 root root 0 Sep  4 08:20 uts -&gt; uts:[4026531838]</span><br></pre></td></tr></table></figure><p>通过对比两次命令的输出结果，我们可以看到，除了 Mount Namespace 的 ID 值不一样外，其他Namespace 的 ID 值均一致。</p><p>通过以上结果我们可以得出结论，<strong>使用 unshare 命令可以新建 Mount Namespace，并且在新建的 Mount Namespace 内 mount 是和外部完全隔离的。</strong></p><h4 id="（2）PID-Namespace"><a href="#（2）PID-Namespace" class="headerlink" title="（2）PID Namespace"></a>（2）PID Namespace</h4><p>PID Namespace 的作用是用来隔离进程。在不同的 PID Namespace 中，进程可以拥有相同的 PID 号，利用 PID Namespace 可以实现每个容器的主进程为 1 号进程，而容器内的进程在主机上却拥有不同的PID。例如一个进程在主机上 PID 为 122，使用 PID Namespace 可以实现该进程在容器内看到的 PID 为 1。</p><p>下面我们通过一个实例来演示下 PID Namespace的作用。首先我们使用以下命令创建一个 bash 进程，并且新建一个 PID Namespace：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo unshare --pid --fork --mount-proc /bin/bash</span><br><span class="line">[root@centos7 centos]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>执行完上述命令后，我们在主机上创建了一个新的 PID Namespace，并且当前命令行窗口加入了新创建的 PID Namespace。在当前的命令行窗口使用 ps aux 命令查看一下进程信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># ps aux</span></span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.0 115544  2004 pts/0    S    10:57   0:00 bash</span><br><span class="line">root        10  0.0  0.0 155444  1764 pts/0    R+   10:59   0:00 ps aux</span><br></pre></td></tr></table></figure><p>通过上述命令输出结果可以看到当前 Namespace 下 bash 为 1 号进程，而且我们也看不到主机上的其他进程信息。</p><h4 id="（3）UTS-Namespace"><a href="#（3）UTS-Namespace" class="headerlink" title="（3）UTS Namespace"></a>（3）UTS Namespace</h4><p>UTS Namespace 主要是用来隔离主机名的，它允许每个 UTS Namespace 拥有一个独立的主机名。例如我们的主机名称为 docker，使用 UTS Namespace 可以实现在容器内的主机名称为 lagoudocker 或者其他任意自定义主机名。</p><p>同样我们通过一个实例来验证下 UTS Namespace 的作用，首先我们使用 unshare 命令来创建一个 UTS Namespace：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo unshare --uts --fork /bin/bash</span><br><span class="line">[root@centos7 centos]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>创建好 UTS Namespace 后，当前命令行窗口已经处于一个独立的 UTS Namespace 中，下面我们使用 hostname 命令（hostname 可以用来查看主机名称）设置一下主机名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">root@centos7 centos]<span class="comment"># hostname -b lagoudocker</span></span><br></pre></td></tr></table></figure><p>然后再查看一下主机名：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># hostname</span></span><br><span class="line">lagoudocker</span><br></pre></td></tr></table></figure><p>通过上面命令的输出，我们可以看到当前UTS Namespace 内的主机名已经被修改为 lagoudocker。然后我们新打开一个命令行窗口，使用相同的命令查看一下主机的 hostname：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[centos@centos7 ~]$ hostname</span><br><span class="line">centos7</span><br></pre></td></tr></table></figure><p>可以看到主机的名称仍然为 centos7，并没有被修改。由此，可以验证 UTS Namespace 可以用来隔离主机名。</p><h4 id="（4）IPC-Namespace"><a href="#（4）IPC-Namespace" class="headerlink" title="（4）IPC Namespace"></a>（4）IPC Namespace</h4><p>IPC Namespace 主要是用来隔离进程间通信的。例如 PID Namespace 和 IPC Namespace 一起使用可以实现同一 IPC Namespace 内的进程彼此可以通信，不同 IPC Namespace 的进程却不能通信。</p><p>同样我们通过一个实例来验证下IPC Namespace的作用，首先我们使用 unshare 命令来创建一个 IPC Namespace：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo unshare --ipc --fork /bin/bash</span><br><span class="line">[root@centos7 centos]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>下面我们需要借助两个命令来实现对 IPC Namespace 的验证。</p><ul><li>ipcs -q 命令：用来查看系统间通信队列列表。</li><li>ipcmk -Q 命令：用来创建系统间通信队列。</li></ul><p>我们首先使用 ipcs -q 命令查看一下当前 IPC Namespace 下的系统通信队列列表：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[centos@centos7 ~]$ ipcs -q</span><br><span class="line"></span><br><span class="line">------ Message Queues --------</span><br><span class="line">key        msqid      owner      perms      used-bytes   messages</span><br></pre></td></tr></table></figure><p>由上可以看到当前无任何系统通信队列，然后我们使用 ipcmk -Q 命令创建一个系统通信队列：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># ipcmk -Q</span></span><br><span class="line">Message queue id: 0</span><br></pre></td></tr></table></figure><p>再次使用 ipcs -q 命令查看当前 IPC Namespace 下的系统通信队列列表：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># ipcs -q</span></span><br><span class="line"></span><br><span class="line">------ Message Queues --------</span><br><span class="line">key        msqid      owner      perms      used-bytes   messages</span><br><span class="line">0x73682a32 0          root       644        0            0</span><br></pre></td></tr></table></figure><p>可以看到我们已经成功创建了一个系统通信队列。然后我们新打开一个命令行窗口，使用ipcs -q 命令查看一下主机的系统通信队列：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[centos@centos7 ~]$ ipcs -q</span><br><span class="line"></span><br><span class="line">------ Message Queues --------</span><br><span class="line">key        msqid      owner      perms      used-bytes   messages</span><br></pre></td></tr></table></figure><p>通过上面的实验，可以发现，在单独的 IPC Namespace 内创建的系统通信队列在主机上无法看到。即 IPC Namespace 实现了系统通信队列的隔离。</p><h4 id="（5）User-Namespace"><a href="#（5）User-Namespace" class="headerlink" title="（5）User Namespace"></a>（5）User Namespace</h4><p>User Namespace 主要是用来隔离用户和用户组的。一个比较典型的应用场景就是在主机上以非 root 用户运行的进程可以在一个单独的 User Namespace 中映射成 root 用户。使用 User Namespace 可以实现进程在容器内拥有 root 权限，而在主机上却只是普通用户。</p><p>User Namesapce 的创建是可以不使用 root 权限的。下面我们以普通用户的身份创建一个 User Namespace，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[centos@centos7 ~]$ unshare --user -r /bin/bash</span><br><span class="line">[root@centos7 ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><blockquote><p>CentOS7 默认允许创建的 User Namespace 为 0，如果执行上述命令失败（ unshare 命令返回的错误为 unshare: unshare failed: Invalid argument ），需要使用以下命令修改系统允许创建的 User Namespace 数量，命令为：echo 65535 &gt; /proc/sys/user/max_user_namespaces，然后再次尝试创建 User Namespace。</p></blockquote><p>然后执行 id 命令查看一下当前的用户信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 ~]<span class="comment"># id</span></span><br><span class="line">uid=0(root) gid=0(root) groups=0(root),65534(nfsnobody) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023</span><br></pre></td></tr></table></figure><p>通过上面的输出可以看到我们在新的 User Namespace 内已经是 root 用户了。下面我们使用只有主机 root 用户才可以执行的 reboot 命令来验证一下，在当前命令行窗口执行 reboot 命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 ~]<span class="comment"># reboot</span></span><br><span class="line">Failed to open /dev/initctl: Permission denied</span><br><span class="line">Failed to talk to init daemon.</span><br></pre></td></tr></table></figure><p>可以看到，我们在新创建的 User Namespace 内虽然是 root 用户，但是并没有权限执行 reboot 命令。这说明在隔离的 User Namespace 中，并不能获取到主机的 root 权限，也就是说 User Namespace 实现了用户和用户组的隔离。</p><h4 id="（6）Net-Namespace"><a href="#（6）Net-Namespace" class="headerlink" title="（6）Net Namespace"></a>（6）Net Namespace</h4><p>Net Namespace 是用来隔离网络设备、IP 地址和端口等信息的。Net Namespace 可以让每个进程拥有自己独立的 IP 地址，端口和网卡信息。例如主机 IP 地址为 172.16.4.1 ，容器内可以设置独立的 IP 地址为 192.168.1.1。</p><p>同样用实例验证，我们首先使用 ip a 命令查看一下主机上的网络信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 02:11:b0:14:01:0c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.20.1.11/24 brd 172.20.1.255 scope global dynamic eth0</span><br><span class="line">       valid_lft 86063337sec preferred_lft 86063337sec</span><br><span class="line">    inet6 fe80::11:b0ff:fe14:10c/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default</span><br><span class="line">    link/ether 02:42:82:8d:a0:df brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1/16 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:82ff:fe8d:a0df/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>然后我们使用以下命令创建一个 Net Namespace：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo unshare --net --fork /bin/bash</span><br><span class="line">[root@centos7 centos]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>同样的我们使用 ip a 命令查看一下网络信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@centos7 centos]<span class="comment"># ip a</span></span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br></pre></td></tr></table></figure><p>可以看到，宿主机上有 lo、eth0、docker0 等网络设备，而我们新建的 Net Namespace 内则与主机上的网络设备不同。</p><h3 id="为什么-Docker-需要-Namespace？"><a href="#为什么-Docker-需要-Namespace？" class="headerlink" title="为什么 Docker 需要 Namespace？"></a>为什么 Docker 需要 Namespace？</h3><p>Linux 内核从 2002 年 2.4.19 版本开始加入了 Mount Namespace，而直到内核 3.8 版本加入了 User Namespace 才为容器提供了足够的支持功能。</p><p>当 Docker 新建一个容器时， 它会创建这六种 Namespace，然后将容器中的进程加入这些 Namespace 之中，使得 Docker 容器中的进程只能看到当前 Namespace 中的系统资源。</p><p>正是由于 Docker 使用了 Linux 的这些 Namespace 技术，才实现了 Docker 容器的隔离，可以说没有 Namespace，就没有 Docker 容器。</p><h2 id="资源限制：如何通过-Cgroups-机制实现资源限制？"><a href="#资源限制：如何通过-Cgroups-机制实现资源限制？" class="headerlink" title="资源限制：如何通过 Cgroups 机制实现资源限制？"></a>资源限制：如何通过 Cgroups 机制实现资源限制？</h2><p>我们知道使用不同的 Namespace，可以实现容器中的进程看不到别的容器的资源，但是有一个问题你是否注意到？容器内的进程仍然可以任意地使用主机的 CPU 、内存等资源，如果某一个容器使用的主机资源过多，可能导致主机的资源竞争，进而影响业务。那如果我们想限制一个容器资源的使用（如 CPU、内存等）应该如何做呢？</p><p>这里就需要用到 Linux 内核的另一个核心技术cgroups。</p><h3 id="cgroups"><a href="#cgroups" class="headerlink" title="cgroups"></a>cgroups</h3><p>cgroups（全称：control groups）是 Linux 内核的一个功能，它可以实现限制进程或者进程组的资源（如 CPU、内存、磁盘 IO 等）。</p><blockquote><p>在 2006 年，Google 的工程师（ Rohit Seth 和 Paul Menage 为主要发起人） 发起了这个项目，起初项目名称并不是cgroups，而被称为进程容器（process containers）。在 2007 年cgroups代码计划合入Linux 内核，但是当时在 Linux 内核中，容器（container）这个词被广泛使用，并且拥有不同的含义。为了避免命名混乱和歧义，进程容器被重名为cgroups，并在 2008 年成功合入 Linux 2.6.24 版本中。cgroups目前已经成为 systemd、Docker、Linux Containers（LXC） 等技术的基础。</p></blockquote><h4 id="cgroups-功能及核心概念"><a href="#cgroups-功能及核心概念" class="headerlink" title="cgroups 功能及核心概念"></a>cgroups 功能及核心概念</h4><p>cgroups 主要提供了如下功能。</p><ul><li>资源限制： 限制资源的使用量，例如我们可以通过限制某个业务的内存上限，从而保护主机其他业务的安全运行。</li><li>优先级控制：不同的组可以有不同的资源（ CPU 、磁盘 IO 等）使用优先级。</li><li>审计：计算控制组的资源使用情况。</li><li>控制：控制进程的挂起或恢复。</li></ul><p>了解了 cgroups 可以为我们提供什么功能，下面我来看下 cgroups 是如何实现这些功能的。</p><p>cgroups功能的实现依赖于三个核心概念：子系统、控制组、层级树。</p><ul><li>子系统（subsystem）：是一个内核的组件，一个子系统代表一类资源调度控制器。例如内存子系统可以限制内存的使用量，CPU 子系统可以限制 CPU 的使用时间。</li><li>控制组（cgroup）：表示一组进程和一组带有参数的子系统的关联关系。例如，一个进程使用了 CPU 子系统来限制 CPU 的使用时间，则这个进程和 CPU 子系统的关联关系称为控制组。</li><li>层级树（hierarchy）：是由一系列的控制组按照树状结构排列组成的。这种排列方式可以使得控制组拥有父子关系，子控制组默认拥有父控制组的属性，也就是子控制组会继承于父控制组。比如，系统中定义了一个控制组 c1，限制了 CPU 可以使用 1 核，然后另外一个控制组 c2 想实现既限制 CPU 使用 1 核，同时限制内存使用 2G，那么 c2 就可以直接继承 c1，无须重复定义 CPU 限制。</li></ul><p>cgroups 的三个核心概念中，子系统是最核心的概念，因为子系统是真正实现某类资源的限制的基础。</p><h3 id="cgroups-子系统实例"><a href="#cgroups-子系统实例" class="headerlink" title="cgroups 子系统实例"></a>cgroups 子系统实例</h3><p>下面我通过一个实例演示一下在 Linux 上默认都启动了哪些子系统。</p><p>我们先通过 mount 命令查看一下当前系统已经挂载的cgroups信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mount -t cgroup</span><br><span class="line">cgroup on /sys/fs/cgroup/systemd <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)</span><br><span class="line">cgroup on /sys/fs/cgroup/net_cls,net_prio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,net_prio,net_cls)</span><br><span class="line">cgroup on /sys/fs/cgroup/blkio <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,blkio)</span><br><span class="line">cgroup on /sys/fs/cgroup/pids <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,pids)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpu,cpuacct <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpuacct,cpu)</span><br><span class="line">cgroup on /sys/fs/cgroup/perf_event <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,perf_event)</span><br><span class="line">cgroup on /sys/fs/cgroup/freezer <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,freezer)</span><br><span class="line">cgroup on /sys/fs/cgroup/devices <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,devices)</span><br><span class="line">cgroup on /sys/fs/cgroup/memory <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,memory)</span><br><span class="line">cgroup on /sys/fs/cgroup/cpuset <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpuset)</span><br><span class="line">cgroup on /sys/fs/cgroup/hugetlb <span class="built_in">type</span> cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,hugetlb)</span><br></pre></td></tr></table></figure><blockquote><p>操作系统版本为 CentOS7.8，内核为 3.10.0-1127.el7.x86_64 版本，不同内核版本cgroups子系统和使用方式可能略有差异。</p></blockquote><p>通过输出，可以看到当前系统已经挂载了我们常用的cgroups子系统，例如 cpu、memory、pids 等我们常用的cgroups子系统。这些子系统中，cpu 和 memory 子系统是容器环境中使用最多的子系统，下面我对这两个子系统做详细介绍。</p><h4 id="cpu-子系统"><a href="#cpu-子系统" class="headerlink" title="cpu 子系统"></a>cpu 子系统</h4><p>我首先以 cpu 子系统为例，演示一下cgroups如何限制进程的 cpu 使用时间。由于cgroups的操作很多需要用到 root 权限，我们在执行命令前要确保已经切换到了 root 用户，以下命令的执行默认都是使用 root 用户。</p><p><strong>第一步：在 cpu 子系统下创建 cgroup</strong></p><p>cgroups的创建很简单，只需要在相应的子系统下创建目录即可。下面我们到 cpu 子系统下创建测试文件夹：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir /sys/fs/cgroup/cpu/mydocker</span></span><br></pre></td></tr></table></figure><p>执行完上述命令后，我们查看一下我们新创建的目录下发生了什么？</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ls -l /sys/fs/cgroup/cpu/mydocker</span></span><br><span class="line">total 0</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 cgroup.clone_children</span><br><span class="line">--w--w--w-. 1 root root 0 Sep  5 09:19 cgroup.event_control</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 cgroup.procs</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 cpu.cfs_period_us</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 cpu.cfs_quota_us</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 cpu.rt_period_us</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 cpu.rt_runtime_us</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 cpu.shares</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 09:19 cpu.stat</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 09:19 cpuacct.stat</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 cpuacct.usage</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 09:19 cpuacct.usage_percpu</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 notify_on_release</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 09:19 tasks</span><br></pre></td></tr></table></figure><p>由上可以看到我们新建的目录下被自动创建了很多文件，其中 cpu.cfs_quota_us 文件代表在某一个阶段限制的 CPU 时间总量，单位为微秒。例如，我们想限制某个进程最多使用 1 核 CPU，就在这个文件里写入 100000（100000 代表限制 1 个核） ，tasks 文件中写入进程的 ID 即可（如果要限制多个进程 ID，在 tasks 文件中用换行符分隔即可）。</p><p>此时，我们所需要的 cgroup 就创建好了。对，就是这么简单。</p><p>第二步：创建进程，加入 cgroup</p><p>这里为了方便演示，我先把当前运行的 shell 进程加入 cgroup，然后在当前 shell 运行 cpu 耗时任务（这里利用到了继承，子进程会继承父进程的 cgroup）。</p><p>使用以下命令将 shell 进程加入 cgroup 中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /sys/fs/cgroup/cpu/mydocker</span></span><br><span class="line"><span class="comment"># echo $$ &gt; tasks</span></span><br></pre></td></tr></table></figure><p>查看一下 tasks 文件内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cat tasks</span></span><br><span class="line">3485</span><br><span class="line">3543</span><br></pre></td></tr></table></figure><p>其中第一个进程 ID 为当前 shell 的主进程，也就是说，当前 shell 主进程为 3485。</p><p><strong>第三步：执行 CPU 耗时任务，验证 cgroup 是否可以限制 cpu 使用时间</strong></p><p>下面，我们使用以下命令制造一个死循环，来提升 cpu 使用率：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># while true;do echo;done;</span></span><br></pre></td></tr></table></figure><p>执行完上述命令后，我们新打开一个 shell 窗口，使用 top -p 命令查看当前 cpu 使用率，-p 参数后面跟进程 ID，我这里是 3485。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ top -p 3485</span><br><span class="line">top - 09:51:35 up 3 days, 22:00,  4 users,  load average: 1.59, 0.58, 0.27</span><br><span class="line">Tasks:   1 total,   0 running,   1 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s):  9.7 us,  2.8 sy,  0.0 ni, 87.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem : 32779616 total, 31009780 free,   495988 used,  1273848 buff/cache</span><br><span class="line">KiB Swap:        0 total,        0 free,        0 used. 31852336 avail Mem</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">3485 root      20   0  116336   2852   1688 S  99.7  0.0   2:10.71 bash</span><br></pre></td></tr></table></figure><p>通过上面输出可以看到 3485 这个进程被限制到了只能使用 100 % 的 cpu，也就是 1 个核。说明我们使用 cgroup 来限制 cpu 使用时间已经生效。此时，执行 while 循环的命令行窗口可以使用 Ctrl+c 退出循环。</p><p>为了进一步证实 cgroup 限制 cpu 的准确性，我们修改 cpu 限制时间为 0.5 核，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /sys/fs/cgroup/cpu/mydocker</span></span><br><span class="line"><span class="comment"># echo 50000 &gt; cpu.cfs_quota_us</span></span><br></pre></td></tr></table></figure><p>同样使用上面的命令来制造死循环：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># while true;do echo;done;</span></span><br></pre></td></tr></table></figure><p>保持当前窗口，新打开一个 shell 窗口，使用 top -p 参数查看 cpu 使用率：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ top -p 3485</span><br><span class="line">top - 10:05:25 up 3 days, 22:14,  3 users,  load average: 1.02, 0.43, 0.40</span><br><span class="line">Tasks:   1 total,   1 running,   0 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s):  5.0 us,  1.3 sy,  0.0 ni, 93.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem : 32779616 total, 31055676 free,   450224 used,  1273716 buff/cache</span><br><span class="line">KiB Swap:        0 total,        0 free,        0 used. 31898216 avail Mem</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line"> 3485 root      20   0  115544   2116   1664 R  50.0  0.0   0:23.39 bash</span><br></pre></td></tr></table></figure><p>通过上面输出可以看到，此时 cpu 使用率已经被限制到了 50%，即 0.5 个核。</p><p>验证完 cgroup 限制 cpu，我们使用相似的方法来验证 cgroup 对内存的限制。</p><h4 id="memroy-子系统"><a href="#memroy-子系统" class="headerlink" title="memroy 子系统"></a>memroy 子系统</h4><p><strong>第一步：在 memory 子系统下创建 cgroup</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mkdir /sys/fs/cgroup/memory/mydocker</span></span><br></pre></td></tr></table></figure><p>同样，我们查看一下新创建的目录下发生了什么？</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">total 0</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 cgroup.clone_children</span><br><span class="line">--w--w--w-. 1 root root 0 Sep  5 10:18 cgroup.event_control</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 cgroup.procs</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.failcnt</span><br><span class="line">--w-------. 1 root root 0 Sep  5 10:18 memory.force_empty</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.failcnt</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.limit_in_bytes</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.max_usage_in_bytes</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.slabinfo</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.tcp.failcnt</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.tcp.limit_in_bytes</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.tcp.max_usage_in_bytes</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.tcp.usage_in_bytes</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 10:18 memory.kmem.usage_in_bytes</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.limit_in_bytes</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.max_usage_in_bytes</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.memsw.failcnt</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.memsw.limit_in_bytes</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.memsw.max_usage_in_bytes</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 10:18 memory.memsw.usage_in_bytes</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.move_charge_at_immigrate</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 10:18 memory.numa_stat</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.oom_control</span><br><span class="line">----------. 1 root root 0 Sep  5 10:18 memory.pressure_level</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.soft_limit_in_bytes</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 10:18 memory.stat</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.swappiness</span><br><span class="line">-r--r--r--. 1 root root 0 Sep  5 10:18 memory.usage_in_bytes</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 memory.use_hierarchy</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 notify_on_release</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  5 10:18 tasks</span><br></pre></td></tr></table></figure><p>其中 memory.limit_in_bytes 文件代表内存使用总量，单位为 byte。</p><p>例如，这里我希望对内存使用限制为 1G，则向 memory.limit_in_bytes 文件写入 1073741824，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /sys/fs/cgroup/memory/mydocker</span></span><br><span class="line"><span class="comment"># echo 1073741824 &gt; memory.limit_in_bytes</span></span><br></pre></td></tr></table></figure><p><strong>第二步：创建进程，加入 cgroup</strong></p><p>同样把当前 shell 进程 ID 写入 tasks 文件内：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /sys/fs/cgroup/memory/mydocker</span></span><br><span class="line"><span class="comment"># echo $$ &gt; tasks</span></span><br></pre></td></tr></table></figure><p><strong>第三步，执行内存测试工具，申请内存</strong></p><p>这里我们需要借助一下工具 memtester Memtester 是一个内存压测工具，下面介绍一下如何安装它。</p><p><strong>第一步, 安装 gcc</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install -y gcc</span><br></pre></td></tr></table></figure><p><strong>第二步，下载安装包</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /tmp$ wget http://pyropus.ca/software/memtester/old-versions/memtester-4.2.2.tar.gz</span><br></pre></td></tr></table></figure><p><strong>第三步，编译安装</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar zxvf memtester-4.2.2.tar.gz$ <span class="built_in">cd</span> memtester-4.2.2$ make &amp;&amp; make install$ sudo cp memtester /bin/memtester</span><br></pre></td></tr></table></figure><p>安装好 memtester 后，我们执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># memtester 1500M 1</span></span><br><span class="line">memtester version 4.2.2 (64-bit)</span><br><span class="line">Copyright (C) 2010 Charles Cazabon.</span><br><span class="line">Licensed under the GNU General Public License version 2 (only).</span><br><span class="line"></span><br><span class="line">pagesize is 4096</span><br><span class="line">pagesizemask is 0xfffffffffffff000</span><br><span class="line">want 1500MB (1572864000 bytes)</span><br><span class="line">got  1500MB (1572864000 bytes), trying mlock ...Killed</span><br></pre></td></tr></table></figure><p>该命令会申请 1500 M 内存，并且做内存测试。由于上面我们对当前 shell 进程内存限制为 1 G，当 memtester 使用的内存达到 1G 时，cgroup 便将 memtester 杀死。</p><p>上面最后一行的输出结果表示 memtester 想要 1500 M 内存，但是由于 cgroup 限制，达到了内存使用上限，被杀死了，与我们的预期一致。</p><p>我们可以使用以下命令，降低一下内存申请，将内存申请调整为 500M：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># memtester 500M 1</span></span><br><span class="line">memtester version 4.2.2 (64-bit)</span><br><span class="line">Copyright (C) 2010 Charles Cazabon.</span><br><span class="line">Licensed under the GNU General Public License version 2 (only).</span><br><span class="line"></span><br><span class="line">pagesize is 4096</span><br><span class="line">pagesizemask is 0xfffffffffffff000</span><br><span class="line">want 500MB (524288000 bytes)</span><br><span class="line">got  500MB (524288000 bytes), trying mlock ...locked.</span><br><span class="line">Loop 1/1:</span><br><span class="line">  Stuck Address       : ok</span><br><span class="line">  Random Value        : ok</span><br><span class="line">  Compare XOR         : ok</span><br><span class="line">  Compare SUB         : ok</span><br><span class="line">  Compare MUL         : ok</span><br><span class="line">  Compare DIV         : ok</span><br><span class="line">  Compare OR          : ok</span><br><span class="line">  Compare AND         : ok</span><br><span class="line">  Sequential Increment: ok</span><br><span class="line">  Solid Bits          : ok</span><br><span class="line">  Block Sequential    : ok</span><br><span class="line">  Checkerboard        : ok</span><br><span class="line">  Bit Spread          : ok</span><br><span class="line">  Bit Flip            : ok</span><br><span class="line">  Walking Ones        : ok</span><br><span class="line">  Walking Zeroes      : ok</span><br><span class="line">  8-bit Writes        : ok</span><br><span class="line">  16-bit Writes       : ok</span><br><span class="line"></span><br><span class="line">Done.</span><br></pre></td></tr></table></figure><p>这里可以看到，此时 memtester 已经成功申请到 500M 内存并且正常完成了内存测试。</p><p>到此，我们讲解了cgroups的 cpu 和 memroy 子系统，如果你想了解更多的cgroups的知识和使用，可以参考 <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/resource_management_guide/chap-introduction_to_control_groups" target="_blank" rel="noopener">Red Hat 官网</a>。</p><h4 id="删除-cgroups"><a href="#删除-cgroups" class="headerlink" title="删除 cgroups"></a>删除 cgroups</h4><p>上面创建的cgroups如果不想使用了，直接删除创建的文件夹即可。</p><p>例如我想删除内存下的 mydocker 目录，使用以下命令即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rmdir /sys/fs/cgroup/memory/mydocker/</span></span><br></pre></td></tr></table></figure><p>学习了cgroups的使用方式，下面我带你了解一下 Docker 是如何使用cgroups的。</p><h4 id="Docker-是如何使用cgroups的？"><a href="#Docker-是如何使用cgroups的？" class="headerlink" title="Docker 是如何使用cgroups的？"></a>Docker 是如何使用cgroups的？</h4><p>首先，我们使用以下命令创建一个 nginx 容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it -m=1g nginx</span><br></pre></td></tr></table></figure><p>上述命令创建并启动了一个 nginx 容器，并且限制内存为 1G。然后我们进入cgroups内存子系统的目录，使用 ls 命令查看一下该目录下的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ls -l /sys/fs/cgroup/memory</span></span><br><span class="line">total 0</span><br><span class="line">-rw-r--r--.  1 root root 0 Sep  1 11:50 cgroup.clone_children</span><br><span class="line">--w--w--w-.  1 root root 0 Sep  1 11:50 cgroup.event_control</span><br><span class="line">-rw-r--r--.  1 root root 0 Sep  1 11:50 cgroup.procs</span><br><span class="line">-r--r--r--.  1 root root 0 Sep  1 11:50 cgroup.sane_behavior</span><br><span class="line">drwxr-xr-x.  3 root root 0 Sep  5 10:50 docker</span><br><span class="line">... 省略部分输出</span><br></pre></td></tr></table></figure><p>通过上面输出可以看到，该目录下有一个 docker 目录，该目录正是 Docker 在内存子系统下创建的。我们进入到 docker 目录下查看一下相关内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /sys/fs/cgroup/memory/docker</span></span><br><span class="line"><span class="comment"># ls -l</span></span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x. 2 root root 0 Sep  5 10:49 cb5c5391177b44ad87636bf3840ecdda83529e51b76a6406d6742f56a2535d5e</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  4 10:40 cgroup.clone_children</span><br><span class="line">--w--w--w-. 1 root root 0 Sep  4 10:40 cgroup.event_control</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  4 10:40 cgroup.procs</span><br><span class="line">... 省略部分输出</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  4 10:40 tasks</span><br></pre></td></tr></table></figure><p>可以看到 docker 的目录下有一个一串随机 ID 的目录，该目录即为我们上面创建的 nginx 容器的 ID。然后我们进入该目录，查看一下该容器的 memory.limit_in_bytes 文件的内容。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd cb5c5391177b44ad87636bf3840ecdda83529e51b76a6406d6742f56a2535d5e</span></span><br><span class="line"><span class="comment"># cat memory.limit_in_bytes</span></span><br><span class="line">1073741824</span><br></pre></td></tr></table></figure><p>可以看到内存限制值正好为 1G。</p><p>事实上，Docker 创建容器时，Docker 会根据启动容器的参数，在对应的 cgroups 子系统下创建以容器 ID 为名称的目录, 然后根据容器启动时设置的资源限制参数, 修改对应的 cgroups 子系统资源限制文件, 从而达到资源限制的效果。</p><h2 id="组件组成：剖析-Docker-组件作用及其底层工作原理"><a href="#组件组成：剖析-Docker-组件作用及其底层工作原理" class="headerlink" title="组件组成：剖析 Docker 组件作用及其底层工作原理"></a>组件组成：剖析 Docker 组件作用及其底层工作原理</h2><h3 id="Docker-的组件构成"><a href="#Docker-的组件构成" class="headerlink" title="Docker 的组件构成"></a>Docker 的组件构成</h3><p>Docker 整体架构采用 C/S（客户端 / 服务器）模式，主要由客户端和服务端两大部分组成。客户端负责发送操作指令，服务端负责接收和处理指令。客户端和服务端通信有多种方式，即可以在同一台机器上通过<code>UNIX</code>套接字通信，也可以通过网络连接远程通信。</p><p><img src="/images/docker/docker-01/5.jpg" alt="Docker 整体架构图"></p><p>从整体架构可知，Docker 组件大体分为 Docker 相关组件，containerd 相关组件和容器运行时相关组件。</p><h3 id="Docker-组件剖析"><a href="#Docker-组件剖析" class="headerlink" title="Docker 组件剖析"></a>Docker 组件剖析</h3><p>Docker 到底有哪些组件呢？我们可以在 Docker 安装路径下执行 ls 命令，这样可以看到以下与 Docker 有关的组件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-rwxr-xr-x 1 root root 27941976 Dec 12  2019 containerd</span><br><span class="line">-rwxr-xr-x 1 root root  4964704 Dec 12  2019 containerd-shim</span><br><span class="line">-rwxr-xr-x 1 root root 15678392 Dec 12  2019 ctr</span><br><span class="line">-rwxr-xr-x 1 root root 50683148 Dec 12  2019 docker</span><br><span class="line">-rwxr-xr-x 1 root root   764144 Dec 12  2019 docker-init</span><br><span class="line">-rwxr-xr-x 1 root root  2837280 Dec 12  2019 docker-proxy</span><br><span class="line">-rwxr-xr-x 1 root root 54320560 Dec 12  2019 dockerd</span><br><span class="line">-rwxr-xr-x 1 root root  7522464 Dec 12  2019 runc</span><br></pre></td></tr></table></figure><p>这些组件根据工作职责可以分为以下三大类。</p><ul><li>Docker 相关的组件：docker、dockerd、docker-init 和 docker-proxy</li><li>containerd 相关的组件：containerd、containerd-shim 和 ctr</li><li>容器运行时相关的组件：runc</li></ul><h3 id="Docker-相关的组件"><a href="#Docker-相关的组件" class="headerlink" title="Docker 相关的组件"></a>Docker 相关的组件</h3><p><strong>（1）docker</strong></p><p>docker 是 Docker 客户端的一个完整实现，它是一个二进制文件，对用户可见的操作形式为 docker 命令，通过 docker 命令可以完成所有的 Docker 客户端与服务端的通信（还可以通过 REST API、SDK 等多种形式与 Docker 服务端通信）。</p><p>Docker 客户端与服务端的交互过程是：docker 组件向服务端发送请求后，服务端根据请求执行具体的动作并将结果返回给 docker，docker 解析服务端的返回结果，并将结果通过命令行标准输出展示给用户。这样一次完整的客户端服务端请求就完成了。</p><p><strong>（2）dockerd</strong></p><p>dockerd 是 Docker 服务端的后台常驻进程，用来接收客户端发送的请求，执行具体的处理任务，处理完成后将结果返回给客户端。</p><p>Docker 客户端可以通过多种方式向 dockerd 发送请求，我们常用的 Docker 客户端与 dockerd 的交互方式有三种。</p><ul><li>通过 UNIX 套接字与服务端通信：配置格式为unix://socket_path，默认 dockerd 生成的 socket 文件路径为 /var/run/docker.sock，该文件只有 root 用户或者 docker 用户组的用户才可以访问，这就是为什么 Docker 刚安装完成后只有 root 用户才能使用 docker 命令的原因。</li><li>通过 TCP 与服务端通信：配置格式为tcp://host:port，通过这种方式可以实现客户端远程连接服务端，但是在方便的同时也带有安全隐患，因此在生产环境中如果你要使用 TCP 的方式与 Docker 服务端通信，推荐使用 TLS 认证，可以通过设置 Docker 的 TLS 相关参数，来保证数据传输的安全。</li><li>通过文件描述符的方式与服务端通信：配置格式为：fd://这种格式一般用于 systemd 管理的系统中。</li></ul><p>Docker 客户端和服务端的通信形式必须保持一致，否则将无法通信，只有当 dockerd 监听了 UNIX 套接字客户端才可以使用 UNIX 套接字的方式与服务端通信，UNIX 套接字也是 Docker 默认的通信方式，如果你想要通过远程的方式访问 dockerd，可以在 dockerd 启动的时候添加 -H 参数指定监听的 HOST 和 PORT。</p><p><strong>（3）docker-init</strong></p><p>如果你熟悉 Linux 系统，你应该知道在 Linux 系统中，1 号进程是 init 进程，是所有进程的父进程。主机上的进程出现问题时，init 进程可以帮我们回收这些问题进程。同样的，在容器内部，当我们自己的业务进程没有回收子进程的能力时，在执行 docker run 启动容器时可以添加 –init 参数，此时 Docker 会使用 docker-init 作为1号进程，帮你管理容器内子进程，例如回收僵尸进程等。</p><p>下面我们通过启动一个 busybox 容器来演示下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it busybox sh</span><br><span class="line">/ <span class="comment"># ps aux</span></span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 sh</span><br><span class="line">    6 root      0:00 ps aux</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>可以看到容器启动时如果没有添加 –init 参数，1 号进程就是 sh 进程。</p><p>我们使用 Crtl + D 退出当前容器，重新启动一个新的容器并添加 –init 参数，然后看下进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --init busybox sh</span><br><span class="line">/ <span class="comment"># ps aux</span></span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 /sbin/docker-init -- sh</span><br><span class="line">    6 root      0:00 sh</span><br><span class="line">    7 root      0:00 ps aux</span><br></pre></td></tr></table></figure><p>可以看到此时容器内的 1 号进程已经变为 /sbin/docker-init，而不再是 sh 了。</p><p><strong>（4）docker-proxy</strong></p><p>docker-proxy 主要是用来做端口映射的。当我们使用 docker run 命令启动容器时，如果使用了 -p 参数，docker-proxy 组件就会把容器内相应的端口映射到主机上来，底层是依赖于 iptables 实现的。</p><p>下面我们通过一个实例演示下。</p><p>使用以下命令启动一个 nginx 容器并把容器的 80 端口映射到主机的 8080 端口。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name=nginx -d -p 8080:80 nginx</span><br></pre></td></tr></table></figure><p>然后通过以下命令查看一下启动的容器 IP：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect --format <span class="string">'&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;'</span> nginx</span><br><span class="line">172.17.0.2</span><br></pre></td></tr></table></figure><p>可以看到，我们启动的 nginx 容器 IP 为 172.17.0.2。</p><p>此时，我们使用 ps 命令查看一下主机上是否有 docker-proxy 进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ps aux |grep docker-proxy</span><br><span class="line">root      9100  0.0  0.0 290772  9160 ?        Sl   07:48   0:00 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8080 -container-ip 172.17.0.2 -container-port 80</span><br><span class="line">root      9192  0.0  0.0 112784   992 pts/0    S+   07:51   0:00 grep --color=auto docker-proxy</span><br></pre></td></tr></table></figure><p>可以看到当我们启动一个容器时需要端口映射时， Docker 为我们创建了一个 docker-proxy 进程，并且通过参数把我们的容器 IP 和端口传递给 docker-proxy 进程，然后 docker-proxy 通过 iptables 实现了 nat 转发。</p><p>我们通过以下命令查看一下主机上 iptables nat 表的规则：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$  sudo iptables -L -nv -t nat</span><br><span class="line">Chain PREROUTING (policy ACCEPT 35 packets, 2214 bytes)</span><br><span class="line"> pkts bytes target     prot opt <span class="keyword">in</span>     out     <span class="built_in">source</span>               destination</span><br><span class="line">  398 21882 DOCKER     all  --  *      *       0.0.0.0/0            0.0.0.0/0            ADDRTYPE match dst-type LOCAL</span><br><span class="line"></span><br><span class="line">Chain INPUT (policy ACCEPT 35 packets, 2214 bytes)</span><br><span class="line"> pkts bytes target     prot opt <span class="keyword">in</span>     out     <span class="built_in">source</span>               destination</span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT 1 packets, 76 bytes)</span><br><span class="line"> pkts bytes target     prot opt <span class="keyword">in</span>     out     <span class="built_in">source</span>               destination</span><br><span class="line">    0     0 DOCKER     all  --  *      *       0.0.0.0/0           !127.0.0.0/8          ADDRTYPE match dst-type LOCAL</span><br><span class="line"></span><br><span class="line">Chain POSTROUTING (policy ACCEPT 1 packets, 76 bytes)</span><br><span class="line"> pkts bytes target     prot opt <span class="keyword">in</span>     out     <span class="built_in">source</span>               destination</span><br><span class="line">    0     0 MASQUERADE  all  --  *      !docker0  172.17.0.0/16        0.0.0.0/0</span><br><span class="line">    0     0 MASQUERADE  tcp  --  *      *       172.17.0.2           172.17.0.2           tcp dpt:80</span><br><span class="line"></span><br><span class="line">Chain DOCKER (2 references)</span><br><span class="line"> pkts bytes target     prot opt <span class="keyword">in</span>     out     <span class="built_in">source</span>               destination</span><br><span class="line">    0     0 RETURN     all  --  docker0 *       0.0.0.0/0            0.0.0.0/0</span><br><span class="line">    0     0 DNAT       tcp  --  !docker0 *       0.0.0.0/0            0.0.0.0/0            tcp dpt:8080 to:172.17.0.2:80</span><br></pre></td></tr></table></figure><p>通过最后一行规则我们可以得知，当我们访问主机的 8080 端口时，iptables 会把流量转发到 172.17.0.2 的 80 端口，从而实现了我们从主机上可以直接访问到容器内的业务。</p><p>我们通过 curl 命令访问一下 nginx 容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ curl http://localhost:8080</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">    body &#123;</span><br><span class="line">        width: 35em;</span><br><span class="line">        margin: 0 auto;</span><br><span class="line">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span><br><span class="line">&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span><br><span class="line">working. Further configuration is required.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;For online documentation and support please refer to</span><br><span class="line">&lt;a href=<span class="string">"http://nginx.org/"</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span><br><span class="line">Commercial support is available at</span><br><span class="line">&lt;a href=<span class="string">"http://nginx.com/"</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p&gt;&lt;em&gt;Thank you <span class="keyword">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><p>通过上面的输出可以得知我们已经成功访问到了 nginx 容器。</p><p>总体来说，docker 是官方实现的标准客户端，dockerd 是 Docker 服务端的入口，负责接收客户端发送的指令并返回相应结果，而 docker-init 在业务主进程没有进程回收功能时则十分有用，docker-proxy 组件则是实现 Docker 网络访问的重要组件。</p><p>了解完 docker 相关的组件，下面我来介绍下 containerd 相关的组件。</p><h3 id="containerd-相关的组件"><a href="#containerd-相关的组件" class="headerlink" title="containerd 相关的组件"></a>containerd 相关的组件</h3><p><strong>（1）containerd</strong></p><p><a href="https://github.com/containerd/containerd" target="_blank" rel="noopener">containerd</a> 组件是从 Docker 1.11 版本正式从 dockerd 中剥离出来的，它的诞生完全遵循 OCI 标准，是容器标准化后的产物。containerd 完全遵循了 OCI 标准，并且是完全社区化运营的，因此被容器界广泛采用。</p><p>containerd 不仅负责容器生命周期的管理，同时还负责一些其他的功能：</p><ul><li>镜像的管理，例如容器运行前从镜像仓库拉取镜像到本地；</li><li>接收 dockerd 的请求，通过适当的参数调用 runc 启动容器；</li><li>管理存储相关资源；</li><li>管理网络相关资源。</li></ul><p>containerd 包含一个后台常驻进程，默认的 socket 路径为 /run/containerd/containerd.sock，dockerd 通过 UNIX 套接字向 containerd 发送请求，containerd 接收到请求后负责执行相关的动作并把执行结果返回给 dockerd。</p><p>如果你不想使用 dockerd，也可以直接使用 containerd 来管理容器，由于 containerd 更加简单和轻量，生产环境中越来越多的人开始直接使用 containerd 来管理容器。</p><p><strong>（2）containerd-shim</strong></p><p>containerd-shim 的意思是垫片，类似于拧螺丝时夹在螺丝和螺母之间的垫片。containerd-shim 的主要作用是将 containerd 和真正的容器进程解耦，使用 containerd-shim 作为容器进程的父进程，从而实现重启 containerd 不影响已经启动的容器进程。</p><p><strong>（3）ctr</strong></p><p>ctr 实际上是 containerd-ctr，它是 containerd 的客户端，主要用来开发和调试，在没有 dockerd 的环境中，ctr 可以充当 docker 客户端的部分角色，直接向 containerd 守护进程发送操作容器的请求。</p><p>了解完 containerd 相关的组件，我们来了解一下容器的真正运行时 runc。</p><h3 id="容器运行时组件runc"><a href="#容器运行时组件runc" class="headerlink" title="容器运行时组件runc"></a>容器运行时组件runc</h3><p>runc 是一个标准的 OCI 容器运行时的实现，它是一个命令行工具，可以直接用来创建和运行容器。</p><p>下面我们通过一个实例来演示一下 runc 的神奇之处。</p><p>第一步，准备容器运行时文件：进入 /home/centos 目录下，创建 runc 文件夹，并导入 busybox 镜像文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/centos</span><br><span class="line"><span class="comment">## 创建 runc 运行根目录</span></span><br><span class="line">$ mkdir runc</span><br><span class="line"><span class="comment">## 导入 rootfs 镜像文件</span></span><br><span class="line">$ mkdir rootfs &amp;&amp; docker <span class="built_in">export</span> $(docker create busybox) | tar -C rootfs -xvf -</span><br></pre></td></tr></table></figure><p>第二步，生成 runc config 文件。我们可以使用 runc spec 命令根据文件系统生成对应的 config.json 文件。命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ runc spec</span><br></pre></td></tr></table></figure><p>此时会在当前目录下生成 config.json 文件，我们可以使用 cat 命令查看一下 config.json 的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br></pre></td><td class="code"><pre><span class="line">$ cat config.json</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"ociVersion"</span>: <span class="string">"1.0.1-dev"</span>,</span><br><span class="line"><span class="string">"process"</span>: &#123;</span><br><span class="line"><span class="string">"terminal"</span>: <span class="literal">true</span>,</span><br><span class="line"><span class="string">"user"</span>: &#123;</span><br><span class="line"><span class="string">"uid"</span>: 0,</span><br><span class="line"><span class="string">"gid"</span>: 0</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"args"</span>: [</span><br><span class="line"><span class="string">"sh"</span></span><br><span class="line">],</span><br><span class="line"><span class="string">"env"</span>: [</span><br><span class="line"><span class="string">"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"</span>,</span><br><span class="line"><span class="string">"TERM=xterm"</span></span><br><span class="line">],</span><br><span class="line"><span class="string">"cwd"</span>: <span class="string">"/"</span>,</span><br><span class="line"><span class="string">"capabilities"</span>: &#123;</span><br><span class="line"><span class="string">"bounding"</span>: [</span><br><span class="line"><span class="string">"CAP_AUDIT_WRITE"</span>,</span><br><span class="line"><span class="string">"CAP_KILL"</span>,</span><br><span class="line"><span class="string">"CAP_NET_BIND_SERVICE"</span></span><br><span class="line">],</span><br><span class="line"><span class="string">"effective"</span>: [</span><br><span class="line"><span class="string">"CAP_AUDIT_WRITE"</span>,</span><br><span class="line"><span class="string">"CAP_KILL"</span>,</span><br><span class="line"><span class="string">"CAP_NET_BIND_SERVICE"</span></span><br><span class="line">],</span><br><span class="line"><span class="string">"inheritable"</span>: [</span><br><span class="line"><span class="string">"CAP_AUDIT_WRITE"</span>,</span><br><span class="line"><span class="string">"CAP_KILL"</span>,</span><br><span class="line"><span class="string">"CAP_NET_BIND_SERVICE"</span></span><br><span class="line">],</span><br><span class="line"><span class="string">"permitted"</span>: [</span><br><span class="line"><span class="string">"CAP_AUDIT_WRITE"</span>,</span><br><span class="line"><span class="string">"CAP_KILL"</span>,</span><br><span class="line"><span class="string">"CAP_NET_BIND_SERVICE"</span></span><br><span class="line">],</span><br><span class="line"><span class="string">"ambient"</span>: [</span><br><span class="line"><span class="string">"CAP_AUDIT_WRITE"</span>,</span><br><span class="line"><span class="string">"CAP_KILL"</span>,</span><br><span class="line"><span class="string">"CAP_NET_BIND_SERVICE"</span></span><br><span class="line">]</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"rlimits"</span>: [</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"RLIMIT_NOFILE"</span>,</span><br><span class="line"><span class="string">"hard"</span>: 1024,</span><br><span class="line"><span class="string">"soft"</span>: 1024</span><br><span class="line">&#125;</span><br><span class="line">],</span><br><span class="line"><span class="string">"noNewPrivileges"</span>: <span class="literal">true</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"root"</span>: &#123;</span><br><span class="line"><span class="string">"path"</span>: <span class="string">"rootfs"</span>,</span><br><span class="line"><span class="string">"readonly"</span>: <span class="literal">true</span></span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"hostname"</span>: <span class="string">"runc"</span>,</span><br><span class="line"><span class="string">"mounts"</span>: [</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"destination"</span>: <span class="string">"/proc"</span>,</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"proc"</span>,</span><br><span class="line"><span class="string">"source"</span>: <span class="string">"proc"</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"destination"</span>: <span class="string">"/dev"</span>,</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"tmpfs"</span>,</span><br><span class="line"><span class="string">"source"</span>: <span class="string">"tmpfs"</span>,</span><br><span class="line"><span class="string">"options"</span>: [</span><br><span class="line"><span class="string">"nosuid"</span>,</span><br><span class="line"><span class="string">"strictatime"</span>,</span><br><span class="line"><span class="string">"mode=755"</span>,</span><br><span class="line"><span class="string">"size=65536k"</span></span><br><span class="line">]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"destination"</span>: <span class="string">"/dev/pts"</span>,</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"devpts"</span>,</span><br><span class="line"><span class="string">"source"</span>: <span class="string">"devpts"</span>,</span><br><span class="line"><span class="string">"options"</span>: [</span><br><span class="line"><span class="string">"nosuid"</span>,</span><br><span class="line"><span class="string">"noexec"</span>,</span><br><span class="line"><span class="string">"newinstance"</span>,</span><br><span class="line"><span class="string">"ptmxmode=0666"</span>,</span><br><span class="line"><span class="string">"mode=0620"</span>,</span><br><span class="line"><span class="string">"gid=5"</span></span><br><span class="line">]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"destination"</span>: <span class="string">"/dev/shm"</span>,</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"tmpfs"</span>,</span><br><span class="line"><span class="string">"source"</span>: <span class="string">"shm"</span>,</span><br><span class="line"><span class="string">"options"</span>: [</span><br><span class="line"><span class="string">"nosuid"</span>,</span><br><span class="line"><span class="string">"noexec"</span>,</span><br><span class="line"><span class="string">"nodev"</span>,</span><br><span class="line"><span class="string">"mode=1777"</span>,</span><br><span class="line"><span class="string">"size=65536k"</span></span><br><span class="line">]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"destination"</span>: <span class="string">"/dev/mqueue"</span>,</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"mqueue"</span>,</span><br><span class="line"><span class="string">"source"</span>: <span class="string">"mqueue"</span>,</span><br><span class="line"><span class="string">"options"</span>: [</span><br><span class="line"><span class="string">"nosuid"</span>,</span><br><span class="line"><span class="string">"noexec"</span>,</span><br><span class="line"><span class="string">"nodev"</span></span><br><span class="line">]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"destination"</span>: <span class="string">"/sys"</span>,</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"sysfs"</span>,</span><br><span class="line"><span class="string">"source"</span>: <span class="string">"sysfs"</span>,</span><br><span class="line"><span class="string">"options"</span>: [</span><br><span class="line"><span class="string">"nosuid"</span>,</span><br><span class="line"><span class="string">"noexec"</span>,</span><br><span class="line"><span class="string">"nodev"</span>,</span><br><span class="line"><span class="string">"ro"</span></span><br><span class="line">]</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"destination"</span>: <span class="string">"/sys/fs/cgroup"</span>,</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"cgroup"</span>,</span><br><span class="line"><span class="string">"source"</span>: <span class="string">"cgroup"</span>,</span><br><span class="line"><span class="string">"options"</span>: [</span><br><span class="line"><span class="string">"nosuid"</span>,</span><br><span class="line"><span class="string">"noexec"</span>,</span><br><span class="line"><span class="string">"nodev"</span>,</span><br><span class="line"><span class="string">"relatime"</span>,</span><br><span class="line"><span class="string">"ro"</span></span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line">],</span><br><span class="line"><span class="string">"linux"</span>: &#123;</span><br><span class="line"><span class="string">"resources"</span>: &#123;</span><br><span class="line"><span class="string">"devices"</span>: [</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"allow"</span>: <span class="literal">false</span>,</span><br><span class="line"><span class="string">"access"</span>: <span class="string">"rwm"</span></span><br><span class="line">&#125;</span><br><span class="line">]</span><br><span class="line">&#125;,</span><br><span class="line"><span class="string">"namespaces"</span>: [</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"pid"</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"network"</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"ipc"</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"uts"</span></span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"type"</span>: <span class="string">"mount"</span></span><br><span class="line">&#125;</span><br><span class="line">],</span><br><span class="line"><span class="string">"maskedPaths"</span>: [</span><br><span class="line"><span class="string">"/proc/acpi"</span>,</span><br><span class="line"><span class="string">"/proc/asound"</span>,</span><br><span class="line"><span class="string">"/proc/kcore"</span>,</span><br><span class="line"><span class="string">"/proc/keys"</span>,</span><br><span class="line"><span class="string">"/proc/latency_stats"</span>,</span><br><span class="line"><span class="string">"/proc/timer_list"</span>,</span><br><span class="line"><span class="string">"/proc/timer_stats"</span>,</span><br><span class="line"><span class="string">"/proc/sched_debug"</span>,</span><br><span class="line"><span class="string">"/sys/firmware"</span>,</span><br><span class="line"><span class="string">"/proc/scsi"</span></span><br><span class="line">],</span><br><span class="line"><span class="string">"readonlyPaths"</span>: [</span><br><span class="line"><span class="string">"/proc/bus"</span>,</span><br><span class="line"><span class="string">"/proc/fs"</span>,</span><br><span class="line"><span class="string">"/proc/irq"</span>,</span><br><span class="line"><span class="string">"/proc/sys"</span>,</span><br><span class="line"><span class="string">"/proc/sysrq-trigger"</span></span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>config.json 文件定义了 runc 启动容器时的一些配置，如根目录的路径，文件挂载路径等配置。</p><p>第三步，使用 runc 启动容器。我们可以使用 runc run 命令直接启动 busybox 容器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ runc run busybox</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>此时，我们已经创建并启动了一个 busybox 容器。</p><p>我们新打开一个命令行窗口，可以使用 run list 命令看到刚才启动的容器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /home/centos/runc/</span><br><span class="line">$ runc list</span><br><span class="line">D          PID         STATUS      BUNDLE              CREATED                          OWNER</span><br><span class="line">busybox     9778        running     /home/centos/runc   2020-09-06T09:25:32.441957273Z   root</span><br></pre></td></tr></table></figure><p>通过上面的输出，我们可以看到，当前已经有一个 busybox 容器处于运行状态。</p><p>总体来说，Docker 的组件虽然很多，但每个组件都有自己清晰的工作职责，Docker 相关的组件负责发送和接受 Docker 请求，contianerd 相关的组件负责管理容器的生命周期，而 runc 负责真正意义上创建和启动容器。这些组件相互配合，才使得 Docker 顺利完成了容器的管理工作。</p><h2 id="网络模型：剖析-Docker-网络实现及-Libnetwork-底层原理"><a href="#网络模型：剖析-Docker-网络实现及-Libnetwork-底层原理" class="headerlink" title="网络模型：剖析 Docker 网络实现及 Libnetwork 底层原理"></a>网络模型：剖析 Docker 网络实现及 Libnetwork 底层原理</h2><h3 id="容器网络发展史"><a href="#容器网络发展史" class="headerlink" title="容器网络发展史"></a>容器网络发展史</h3><p>提起 Docker 网络，我们不得不从容器战争说起。Docker 从 2013 年诞生，到后来逐渐成为了容器的代名词，然而 Docker 的野心也不止于此，它还想在更多的领域独占鳌头，比如制定容器的网络和存储标准。</p><p>于是 Docker 从 1.7 版本开始，便把网络和存储从 Docker 中正式以插件的形式剥离开来，并且分别为其定义了标准，Docker 定义的网络模型标准称之为 CNM (Container Network Model) 。</p><blockquote><p>Docker 推出 CNM 的同时，CoreOS 推出了 CNI（Container Network Interfac）。起初，以 Kubernetes 为代表的容器编排阵营考虑过使用 CNM 作为容器的网络标准，但是后来由于很多技术和非技术原因（如果你对详细原因感兴趣，可以参考<a href="https://kubernetes.io/blog/2016/01/why-kubernetes-doesnt-use-libnetwork/" target="_blank" rel="noopener">这篇博客</a>），Kubernetes 决定支持 CoreOS 推出的容器网络标准 CNI。</p></blockquote><p>从此，容器的网络标准便分为两大阵营，一个是以 Docker 公司为代表的 CNM，另一个便是以 Google、Kubernetes、CoreOS 为代表的 CNI 网络标准。</p><h3 id="CNM"><a href="#CNM" class="headerlink" title="CNM"></a>CNM</h3><p>CNM (Container Network Model) 是 Docker 发布的容器网络标准，意在规范和指定容器网络发展标准，CNM 抽象了容器的网络接口 ，使得只要满足 CNM 接口的网络方案都可以接入到 Docker 容器网络，更好地满足了用户网络模型多样化的需求。</p><p>CNM 只是定义了网络标准，对于底层的具体实现并不太关心，这样便解耦了容器和网络，使得容器的网络模型更加灵活。</p><p>CNM 定义的网络标准包含三个重要元素。</p><ul><li><strong>沙箱（Sandbox）</strong>：沙箱代表了一系列网络堆栈的配置，其中包含路由信息、网络接口等网络资源的管理，沙箱的实现通常是 Linux 的 Net Namespace，但也可以通过其他技术来实现，比如 <a href="https://zh.wikipedia.org/wiki/FreeBSD_jail" target="_blank" rel="noopener">FreeBSD jail</a> 等。</li><li><strong>接入点（Endpoint）</strong>：接入点将沙箱连接到网络中，代表容器的网络接口，接入点的实现通常是 Linux 的 veth 设备对。</li><li><strong>网络（Network</strong>）：网络是一组可以互相通信的接入点，它将多接入点组成一个子网，并且多个接入点之间可以相互通信。</li></ul><p>CNM 的三个要素基本抽象了所有网络模型，使得网络模型的开发更加规范。</p><p>为了更好地构建容器网络标准，Docker 团队把网络功能从 Docker 中剥离出来，成为独立的项目 libnetwork，它通过插件的形式为 Docker 提供网络功能。Libnetwork 是开源的，使用 Golang 编写，它完全遵循 CNM 网络规范，是 CNM 的官方实现。Libnetwork 的工作流程也是完全围绕 CNM 的三个要素进行的，下面我们来详细了解一下 Libnetwork 是如何围绕 CNM 的三要素工作的。</p><h3 id="Libnetwork-的工作流程"><a href="#Libnetwork-的工作流程" class="headerlink" title="Libnetwork 的工作流程"></a>Libnetwork 的工作流程</h3><p>Libnetwork 是 Docker 启动容器时，用来为 Docker 容器提供网络接入功能的插件，它可以让 Docker 容器顺利接入网络，实现主机和容器网络的互通。下面，我们来详细了解一下 Libnetwork 是如何为 Docker 容器提供网络的。</p><p>第一步：Docker 通过调用 libnetwork.New 函数来创建 NetworkController 实例。NetworkController 是一个接口类型，提供了各种接口，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">type</span> NetworkController interface &#123;</span><br><span class="line">   // 创建一个新的网络。 options 参数用于指定特性类型的网络选项。</span><br><span class="line">   NewNetwork(networkType, name string, id string, options ...NetworkOption) (Network, error)</span><br><span class="line">   // ... 此次省略部分接口</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第二步：通过调用 NewNetwork 函数创建指定名称和类型的 Network，其中 Network 也是接口类型，代码如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">type</span> Network interface &#123;</span><br><span class="line">   // 为该网络创建一个具有唯一指定名称的接入点（Endpoint）</span><br><span class="line">   CreateEndpoint(name string, options ...EndpointOption) (Endpoint, error)</span><br><span class="line"></span><br><span class="line">   // 删除网络</span><br><span class="line">   Delete() error</span><br><span class="line">// ... 此次省略部分接口</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第三步：通过调用 CreateEndpoint 来创建接入点（Endpoint）。在 CreateEndpoint 函数中为容器分配了 IP 和网卡接口。其中 Endpoint 也是接口类型，代码如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// Endpoint 表示网络和沙箱之间的逻辑连接。</span><br><span class="line"><span class="built_in">type</span> Endpoint interface &#123;</span><br><span class="line">   // 将沙箱连接到接入点，并将为接入点分配的网络资源填充到沙箱中。</span><br><span class="line">   // the network resources allocated <span class="keyword">for</span> the endpoint.</span><br><span class="line">   Join(sandbox Sandbox, options ...EndpointOption) error</span><br><span class="line">   // 删除接入点</span><br><span class="line">   Delete(force bool) error</span><br><span class="line">   // ... 此次省略部分接口</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第四步：调用 NewSandbox 来创建容器沙箱，主要是初始化 Namespace 相关的资源。</p><p>第五步：调用 Endpoint 的 Join 函数将沙箱和网络接入点关联起来，此时容器就加入了 Docker 网络并具备了网络访问能力。</p><p>Libnetwork 基于以上工作流程可以构建出多种网络模式，以满足我们的在不同场景下的需求，下面我们来详细了解一下 Libnetwork 提供的常见的四种网络模式。</p><h3 id="Libnetwork-常见网络模式"><a href="#Libnetwork-常见网络模式" class="headerlink" title="Libnetwork 常见网络模式"></a>Libnetwork 常见网络模式</h3><p>Libnetwork 比较典型的网络模式主要有四种，这四种网络模式基本满足了我们单机容器的所有场景。</p><ol><li>null 空网络模式：可以帮助我们构建一个没有网络接入的容器环境，以保障数据安全。</li><li>bridge 桥接模式：可以打通容器与容器间网络通信的需求。</li><li>host 主机网络模式：可以让容器内的进程共享主机网络，从而监听或修改主机网络。</li><li>container 网络模式：可以将两个容器放在同一个网络命名空间内，让两个业务通过 localhost 即可实现访问。</li></ol><p>下面我们对 libnetwork 的四种网络模式逐一讲解：</p><h4 id="（1）null-空网络模式"><a href="#（1）null-空网络模式" class="headerlink" title="（1）null 空网络模式"></a>（1）null 空网络模式</h4><p>有时候，我们需要处理一些保密数据，出于安全考虑，我们需要一个隔离的网络环境执行一些纯计算任务。这时候 null 网络模式就派上用场了，这时候我们的容器就像一个没有联网的电脑，处于一个相对较安全的环境，确保我们的数据不被他人从网络窃取。</p><p>使用 Docker 创建 null 空网络模式的容器时，容器拥有自己独立的 Net Namespace，但是此时的容器并没有任何网络配置。在这种模式下，Docker 除了为容器创建了 Net Namespace 外，没有创建任何网卡接口、IP 地址、路由等网络配置。我们可以一起来验证下。</p><p>我们使用 <code>docker run</code> 命令启动时，添加 –net=none 参数启动一个空网络模式的容器，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --net=none -it busybox</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>容器启动后，我们使用 ifconfig 命令查看一下容器内网络配置信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># ifconfig</span></span><br><span class="line">lo        Link encap:Local Loopback</span><br><span class="line">          inet addr:127.0.0.1  Mask:255.0.0.0</span><br><span class="line">          UP LOOPBACK RUNNING  MTU:65536  Metric:1</span><br><span class="line">          RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000</span><br><span class="line">          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p>可以看到容器内除了 Net Namespace 自带的 lo 网卡并没有创建任何虚拟网卡，然后我们再使用 <code>route -n</code> 命令查看一下容器内的路由信息:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br></pre></td></tr></table></figure><p>可以看到，容器内也并没有配置任何路由信息。</p><h4 id="（2）bridge-桥接模式"><a href="#（2）bridge-桥接模式" class="headerlink" title="（2）bridge 桥接模式"></a>（2）bridge 桥接模式</h4><p>Docker 的 bridge 网络是启动容器时默认的网络模式，使用 bridge 网络可以实现容器与容器的互通，可以从一个容器直接通过容器 IP 访问到另外一个容器。同时使用 bridge 网络可以实现主机与容器的互通，我们在容器内启动的业务，可以从主机直接请求。</p><p>在介绍 Docker 的 bridge 桥接模式前，我们需要先了解一下 Linux 的 veth 和 bridge 相关的技术，因为 Docker 的 bridge 模式正是由这两种技术实现的。</p><ul><li>Linux veth</li></ul><p>veth 是 Linux 中的虚拟设备接口，veth 都是成对出现的，它在容器中，通常充当一个桥梁。veth 可以用来连接虚拟网络设备，例如 veth 可以用来连通两个 Net Namespace，从而使得两个 Net Namespace 之间可以互相访问。</p><ul><li>Linux bridge</li></ul><p>Linux bridge 是一个虚拟设备，是用来连接网络的设备，相当于物理网络环境中的交换机。Linux bridge 可以用来转发两个 Net Namespace 内的流量。</p><ul><li>veth 与 bridge 的关系</li></ul><p><img src="/images/docker/docker-02/3.jpg" alt="3"></p><p>通过上图，我们可以看到，bridge 就像一台交换机，而 veth 就像一根网线，通过交换机和网线可以把两个不同 Net Namespace 的容器连通，使得它们可以互相通信。</p><p>Docker 的 bridge 模式也是这种原理。Docker 启动时，libnetwork 会在主机上创建 docker0 网桥，docker0 网桥就相当于图中的交换机，而 Docker 创建出的 brige 模式的容器则都会连接 docker0 上，从而实现网络互通。</p><p><strong>bridge 桥接模式是 Docker 的默认网络模式，当我们创建容器时不指定任何网络模式，Docker 启动容器默认的网络模式为 bridge。</strong></p><h4 id="（3）host-主机网络模式"><a href="#（3）host-主机网络模式" class="headerlink" title="（3）host 主机网络模式"></a>（3）host 主机网络模式</h4><p>容器内的网络并不是希望永远跟主机是隔离的，有些基础业务需要创建或更新主机的网络配置，我们的程序必须以主机网络模式运行才能够修改主机网络，这时候就需要用到 Docker 的 host 主机网络模式。</p><p>使用 host 主机网络模式时：</p><ul><li>libnetwork 不会为容器创建新的网络配置和 Net Namespace。</li><li>Docker 容器中的进程直接共享主机的网络配置，可以直接使用主机的网络信息，此时，在容器内监听的端口，也将直接占用到主机的端口。</li><li>除了网络共享主机的网络外，其他的包括进程、文件系统、主机名等都是与主机隔离的。</li></ul><p>host 主机网络模式通常适用于想要使用主机网络，但又不想把运行环境直接安装到主机上的场景中。例如我想在主机上运行一个 busybox 服务，但又不想直接把 busybox 安装到主机上污染主机环境，此时我可以使用以下命令启动一个主机网络模式的 busybox 镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --net=host busybox</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>然后我们使用ip a 命令查看一下容器内的网络环境：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># ip a</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER\_UP&gt; mtu 65536 qdisc noqueue qlen 1000</span><br><span class="line">link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">inet 127.0.0.1/8 scope host lo</span><br><span class="line">valid\_lft forever preferred\_lft forever</span><br><span class="line">inet6 ::1/128 scope host</span><br><span class="line">valid\_lft forever preferred\_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER\_UP&gt; mtu 1500 qdisc pfifo\_fast qlen 1000</span><br><span class="line">link/ether 02:11:b0:14:01:0c brd ff:ff:ff:ff:ff:ff</span><br><span class="line">inet 172.20.1.11/24 brd 172.20.1.255 scope global dynamic eth0</span><br><span class="line">valid\_lft 85785286sec preferred\_lft 85785286sec</span><br><span class="line">inet6 fe80::11:b0ff:fe14:10c/64 scope link</span><br><span class="line">valid\_lft forever preferred\_lft forever</span><br><span class="line">3: docker0: \&lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue</span><br><span class="line">link/ether 02:42:82:8d:a0:df brd ff:ff:ff:ff:ff:ff</span><br><span class="line">inet 172.17.0.1/16 scope global docker0</span><br><span class="line">valid\_lft forever preferred\_lft forever</span><br><span class="line">inet6 fe80::42:82ff:fe8d:a0df/64 scope link</span><br><span class="line">valid\_lft forever preferred\_lft forever</span><br></pre></td></tr></table></figure><p>可以看到容器内的网络环境与主机完全一致。</p><h4 id="（4）container-网络模式"><a href="#（4）container-网络模式" class="headerlink" title="（4）container 网络模式"></a>（4）container 网络模式</h4><p>container 网络模式允许一个容器共享另一个容器的网络命名空间。当两个容器需要共享网络，但其他资源仍然需要隔离时就可以使用 container 网络模式，例如我们开发了一个 http 服务，但又想使用 nginx 的一些特性，让 nginx 代理外部的请求然后转发给自己的业务，这时我们使用 container 网络模式将自己开发的服务和 nginx 服务部署到同一个网络命名空间中。</p><p>下面我举例说明。首先我们使用以下命令启动一个 busybox1 容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name=busybox1 busybox sleep 3600</span><br></pre></td></tr></table></figure><p>然后我们使用 docker exec 命令进入到 centos 容器中查看一下网络配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it busybox1 sh</span><br><span class="line">/ <span class="comment"># ifconfig</span></span><br><span class="line">eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02</span><br><span class="line">inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0</span><br><span class="line">UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1</span><br><span class="line">RX packets:11 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">collisions:0 txqueuelen:0</span><br><span class="line">RX bytes:906 (906.0 B) TX bytes:0 (0.0 B)</span><br><span class="line"></span><br><span class="line">lo Link encap:Local Loopback</span><br><span class="line">inet addr:127.0.0.1 Mask:255.0.0.0</span><br><span class="line">UP LOOPBACK RUNNING MTU:65536 Metric:1</span><br><span class="line">RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">collisions:0 txqueuelen:1000</span><br><span class="line">RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p>可以看到 busybox1 的 IP 地址为 172.17.0.2。</p><p>然后我们新打开一个命令行窗口，再启动一个 busybox2 容器，通过 container 网络模式连接到 busybox1 的网络，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --net=container:busybox1 --name=busybox2 busybox sh</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>在 busybox2 容器内同样使用 ifconfig 命令查看一下容器内的网络配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># ifconfig</span></span><br><span class="line">eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02</span><br><span class="line">inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0</span><br><span class="line">UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1</span><br><span class="line">RX packets:14 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">collisions:0 txqueuelen:0</span><br><span class="line">RX bytes:1116 (1.0 KiB) TX bytes:0 (0.0 B)</span><br><span class="line"></span><br><span class="line">lo Link encap:Local Loopback</span><br><span class="line">inet addr:127.0.0.1 Mask:255.0.0.0</span><br><span class="line">UP LOOPBACK RUNNING MTU:65536 Metric:1</span><br><span class="line">RX packets:0 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">TX packets:0 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">collisions:0 txqueuelen:1000</span><br><span class="line">RX bytes:0 (0.0 B) TX bytes:0 (0.0 B)</span><br></pre></td></tr></table></figure><p>可以看到 busybox2 容器的网络 IP 也为 172.17.0.2，与 busybox1 的网络一致。</p><!-- 虽然最后k8s的CNI成为了容器网络标准，但是libnetwork的容器网络模式使得pod中容器共享网络环境成为可能 --><h3 id="理解-Docker0"><a href="#理解-Docker0" class="headerlink" title="理解 Docker0"></a>理解 Docker0</h3><p>查看本地ip</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ip addr</span><br><span class="line">lo 127.0.0.1 <span class="comment"># 本机回环地址 </span></span><br><span class="line">eth0 172.17.90.138 <span class="comment"># 阿里云的私有IP </span></span><br><span class="line">docker0 172.18.0.1 <span class="comment"># docker网桥</span></span><br></pre></td></tr></table></figure><p>我们开发了很多微服务项目，那些微服务项目都要连接数据库，需要指定数据库的url地址，通过ip。但是我们用Docker管理的话，假设数据库出问题了，我们重新启动运行一个，这个时候数据库的地址就会发生变化，docker会给每个容器都分配一个ip，且容器和容器之间是可以互相访问的。</p><p>我们可以测试下容器之间能不能ping通过：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动tomcat01 </span></span><br><span class="line">$ docker run -d -P --name tomcat01 tomcat </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看tomcat01的ip地址，docker会给每个容器都分配一个ip！ </span></span><br><span class="line">$ docker <span class="built_in">exec</span> -it tomcat01 ip addr </span><br><span class="line"></span><br><span class="line"><span class="comment"># 思考，我们的linux服务器是否可以ping通容器内的tomcat ？ </span></span><br><span class="line">$ ping 172.18.0.2</span><br></pre></td></tr></table></figure><p><strong>原理</strong></p><p>1、每一个安装了Docker的linux主机都有一个docker0的虚拟网卡。这是个桥接网卡，使用了veth-pair<br>技术！</p><p>2、每启动一个容器，linux主机就会多了一个虚拟网卡。</p><p>Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(docker0)，Docker启动一个容器时会根据 Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。</p><p><img src="/images/docker/docker-02/5.jpg" alt="5"></p><p>Docker容器网络就很好的利用了Linux虚拟网络技术，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫veth pair）；</p><p>Docker中的网络接口默认都是虚拟的接口。虚拟接口的优势就是转发效率极高（因为Linux是在内核中进行数据的复制来实现虚拟接口之间的数据转发，无需通过外部的网络设备交换），对于本地系统和容器系统来说，虚拟接口跟一个正常的以太网卡相比并没有区别，只是他的速度快很多。</p><h2 id="数据存储：剖析-Docker-卷与持久化数据存储的底层原理"><a href="#数据存储：剖析-Docker-卷与持久化数据存储的底层原理" class="headerlink" title="数据存储：剖析 Docker 卷与持久化数据存储的底层原理"></a>数据存储：剖析 Docker 卷与持久化数据存储的底层原理</h2><h3 id="为什么容器需要持久化存储"><a href="#为什么容器需要持久化存储" class="headerlink" title="为什么容器需要持久化存储"></a>为什么容器需要持久化存储</h3><p>容器按照业务类型，总体可以分为两类：</p><ul><li>无状态的（数据不需要被持久化）</li><li>有状态的（数据需要被持久化）</li></ul><p>显然，容器更擅长无状态应用。因为未持久化数据的容器根目录的生命周期与容器的生命周期一样，容器文件系统的本质是在镜像层上面创建的读写层，运行中的容器对任何文件的修改都存在于该读写层，当容器被删除时，容器中的读写层也会随之消失。</p><p>虽然容器希望所有的业务都尽量保持无状态，这样容器就可以开箱即用，并且可以任意调度，但实际业务总是有各种需要数据持久化的场景，比如 MySQL、Kafka 等有状态的业务。因此为了解决有状态业务的需求，Docker 提出了卷（Volume）的概念。</p><p>什么是卷？卷的本质是文件或者目录，它可以绕过默认的联合文件系统，直接以文件或目录的形式存在于宿主机上。卷的概念不仅解决了数据持久化的问题，还解决了容器间共享数据的问题。使用卷可以将容器内的目录或文件持久化，当容器重启后保证数据不丢失，例如我们可以使用卷将 MySQL 的目录持久化，实现容器重启数据库数据不丢失。</p><p>Docker 提供了卷（Volume）的功能，使用<code>docker volume</code>命令可以实现对卷的创建、查看和删除等操作。下面我们来详细了解一下这些命令。</p><h3 id="Docker-卷的操作"><a href="#Docker-卷的操作" class="headerlink" title="Docker 卷的操作"></a>Docker 卷的操作</h3><h4 id="创建数据卷"><a href="#创建数据卷" class="headerlink" title="创建数据卷"></a>创建数据卷</h4><p>使用<code>docker volume create</code>命令可以创建一个数据卷。</p><p>我们使用以下命令创建一个名为 myvolume 的数据卷：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume create myvolume</span><br></pre></td></tr></table></figure><p>在这里要说明下，默认情况下 ，Docker 创建的数据卷为 local 模式，仅能提供本主机的容器访问。如果想要实现远程访问，需要借助网络存储来实现。Docker 的 local 存储模式并未提供配额管理，因此在生产环境中需要手动维护磁盘存储空间。</p><p>除了使用docker volume create的方式创建卷，我们还可以在 Docker 启动时使用 -v 的方式指定容器内需要被持久化的路径，Docker 会自动为我们创建卷，并且绑定到容器中，使用命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name=nginx-volume -v /usr/share/nginx/html nginx</span><br></pre></td></tr></table></figure><p>使用以上命令，我们启动了一个 nginx 容器，-v参数使得 Docker 自动生成一个卷并且绑定到容器的 /usr/share/nginx/html 目录中。</p><p>我们可以使用docker volume ls命令来查看下主机上的卷：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume ls</span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line"><span class="built_in">local</span>               eaa8a223eb61a2091bf5cd5247c1b28ac287450a086d6eee9632d9d1b9f69171</span><br></pre></td></tr></table></figure><p>可以看到，Docker 自动为我们创建了一个名称为随机 ID 的卷。</p><h4 id="查看数据卷"><a href="#查看数据卷" class="headerlink" title="查看数据卷"></a>查看数据卷</h4><p>已经创建的数据卷可以使用 docker volume ls 命令查看。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume ls</span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line"><span class="built_in">local</span>               myvolume</span><br></pre></td></tr></table></figure><p>通过输出可以看到 myvolume 卷已经创建成功。</p><p>如果想要查看某个数据卷的详细信息，可以使用docker volume inspect命令。例如，我想查看 myvolume 的详细信息，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume inspect myvolume</span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">"CreatedAt"</span>: <span class="string">"2020-09-08T09:10:50Z"</span>,</span><br><span class="line">        <span class="string">"Driver"</span>: <span class="string">"local"</span>,</span><br><span class="line">        <span class="string">"Labels"</span>: &#123;&#125;,</span><br><span class="line">        <span class="string">"Mountpoint"</span>: <span class="string">"/var/lib/docker/volumes/myvolume/_data"</span>,</span><br><span class="line">        <span class="string">"Name"</span>: <span class="string">"myvolume"</span>,</span><br><span class="line">        <span class="string">"Options"</span>: &#123;&#125;,</span><br><span class="line">        <span class="string">"Scope"</span>: <span class="string">"local"</span></span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>通过<code>docker volume inspect</code>命令可以看到卷的创建日期、命令、挂载路径信息。</p><h4 id="使用数据卷"><a href="#使用数据卷" class="headerlink" title="使用数据卷"></a>使用数据卷</h4><p>使用docker volume创建的卷在容器启动时，添加 –mount 参数指定卷的名称即可使用。</p><p>这里我们使用上一步创建的卷来启动一个 nginx 容器，并将 /usr/share/nginx/html 目录与卷关联，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name=nginx --mount <span class="built_in">source</span>=myvolume,target=/usr/share/nginx/html nginx</span><br></pre></td></tr></table></figure><p>使用 Docker 的卷可以实现指定目录的文件持久化，下面我们进入容器中并且修改 index.html 文件内容，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it  nginx bash</span><br><span class="line"><span class="comment">## 使用以下内容直接替换 /usr/share/nginx/html/index.html 文件 </span></span><br><span class="line">root@719d3c32e211:/<span class="comment"># cat &lt;&lt;EOF &gt;/usr/share/nginx/html/index.html</span></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Hello, Docker Volume!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">    body &#123;</span><br><span class="line">        width: 35em;</span><br><span class="line">        margin: 0 auto;</span><br><span class="line">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Hello, Docker Volume!&lt;/h1&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>此时我们使用docker rm命令将运行中的 nginx 容器彻底删除。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker rm -f nginx</span><br></pre></td></tr></table></figure><p>旧的 nginx 容器删除后，我们再使用docker run命令启动一个新的容器，并且挂载 myvolume 卷，命令如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d --name=nginx --mount <span class="built_in">source</span>=myvolume,target=/usr/share/nginx/html nginx</span><br></pre></td></tr></table></figure><p>新容器启动后，我们进入容器查看一下 index.html 文件内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it nginx bash</span><br><span class="line">root@7ffac645f431:/<span class="comment"># cat /usr/share/nginx/html/index.html</span></span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;title&gt;Hello, Docker Volume!&lt;/title&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">    body &#123;</span><br><span class="line">        width: 35em;</span><br><span class="line">        margin: 0 auto;</span><br><span class="line">        font-family: Tahoma, Verdana, Arial, sans-serif;</span><br><span class="line">    &#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;Hello, Docker Volume!&lt;/h1&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure><p>可以看到，此时 index.html 文件内容依旧为我们之前写入的内容。可见，使用 Docker 卷后我们的数据并没有随着容器的删除而消失。</p><h4 id="删除数据卷"><a href="#删除数据卷" class="headerlink" title="删除数据卷"></a>删除数据卷</h4><p>容器的删除并不会自动删除已经创建的数据卷，因此不再使用的数据卷需要我们手动删除，删除的命令为 docker volume rm 。例如，我们想要删除上面创建 myvolume 数据卷，可以使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume rm myvolume</span><br></pre></td></tr></table></figure><p>这里需要注意，正在被使用中的数据卷无法删除，如果你想要删除正在使用中的数据卷，需要先删除所有关联的容器。</p><p>有时候，两个容器之间会有共享数据的需求，很典型的一个场景就是容器内产生的日志需要一个专门的日志采集程序去采集日志内容，例如我需要使用 Filebeat (一种日志采集工具)采集 nginx 容器内的日志，我就需要使用卷来共享一个日志目录，从而使得 Filebeat 和 nginx 容器都可以访问到这个目录，这时就需要用到容器之间共享数据卷的方式。</p><h4 id="容器与容器之间数据共享"><a href="#容器与容器之间数据共享" class="headerlink" title="容器与容器之间数据共享"></a>容器与容器之间数据共享</h4><p>那如何实现容器与容器之间数据共享呢？下面我举例说明。</p><p>首先使用docker volume create命令创建一个共享日志的数据卷。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume create <span class="built_in">log</span>-vol</span><br></pre></td></tr></table></figure><p>启动一个生产日志的容器（下面用 producer 窗口来表示）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --mount <span class="built_in">source</span>=<span class="built_in">log</span>-vol,target=/tmp/<span class="built_in">log</span> --name=<span class="built_in">log</span>-producer -it busybox</span><br></pre></td></tr></table></figure><p>然后新打开一个命令行窗口，启动一个消费者容器（下面用 consumer 窗口来表示）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --name consumer --volumes-from <span class="built_in">log</span>-producer  busybox</span><br></pre></td></tr></table></figure><p>使用volumes-from参数可以在启动新的容器时来挂载已经存在的容器的卷，volumes-from参数后面跟已经启动的容器名称。</p><p>下面我们切换到 producer 窗口，使用以下命令创建一个 mylog.log 文件并写入 “Hello，My log.” 的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># cat &lt;&lt;EOF &gt;/tmp/log/mylog.log</span></span><br><span class="line">Hello, My <span class="built_in">log</span>.</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><p>然后我们切换到 consumer 窗口，查看一下相关内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># cat /tmp/log/mylog.log</span></span><br><span class="line">Hello, My <span class="built_in">log</span>.</span><br></pre></td></tr></table></figure><p>可以看到我们从 producer 容器写入的文件内容会自动出现在 consumer 容器中，证明我们成功实现了两个容器间的数据共享。</p><p>总结一下，我们首先使用 docker volume create 命令创建了 log-vol 卷来作为共享目录，log-producer 容器向该卷写入数据，consumer 容器从该卷读取数据。这就像主机上的两个进程，一个向主机目录写数据，一个从主机目录读数据，利用主机的目录，实现了容器之间的数据共享。</p><h4 id="主机与容器之间数据共享"><a href="#主机与容器之间数据共享" class="headerlink" title="主机与容器之间数据共享"></a>主机与容器之间数据共享</h4><p>Docker 卷的目录默认在 /var/lib/docker 下，当我们想把主机的其他目录映射到容器内时，就需要用到主机与容器之间数据共享的方式了，例如我想把 MySQL 容器中的 /var/lib/mysql 目录映射到主机的 /var/lib/mysql 目录中，我们就可以使用主机与容器之间数据共享的方式来实现。</p><p>要实现主机与容器之间数据共享，其实很简单，只需要我们在启动容器的时候添加-v参数即可, 使用格式为：<code>-v HOST_PATH:CONTIANAER_PATH</code>。</p><p>例如，我想挂载主机的 /data 目录到容器中的 /usr/local/data 中，可以使用以下命令来启动容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -v /data:/usr/<span class="built_in">local</span>/data -it busybox</span><br></pre></td></tr></table></figure><p>容器启动后，便可以在容器内的 /usr/local/data 访问到主机 /data 目录的内容了，并且容器重启后，/data 目录下的数据也不会丢失。</p><h3 id="Docker-卷的实现原理"><a href="#Docker-卷的实现原理" class="headerlink" title="Docker 卷的实现原理"></a>Docker 卷的实现原理</h3><p>在了解 Docker 卷的原理之前，我们先来回顾一下镜像和容器的文件系统原理。</p><blockquote><p><strong>镜像和容器的文件系统原理：</strong> 镜像是由多层文件系统组成的，当我们想要启动一个容器时，Docker 会在镜像上层创建一个可读写层，容器中的文件都工作在这个读写层中，当容器删除时，与容器相关的工作文件将全部丢失。</p></blockquote><p>Docker 容器的文件系统不是一个真正的文件系统，而是通过联合文件系统实现的一个伪文件系统，而 Docker 卷则是直接利用主机的某个文件或者目录，它可以绕过联合文件系统，直接挂载主机上的文件或目录到容器中，这就是它的工作原理。</p><p>下面，我们通过一个实例来说明卷的工作原理。首先，我们创建一个名称为 volume-data 的卷：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume create volume-data</span><br></pre></td></tr></table></figure><p>我们使用 ls 命令查看一下 /var/lib/docker/volumes 目录下的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /var/lib/docker/volumes</span><br><span class="line">drwxr-xr-x. 3 root root    19 Sep  8 10:59 volume-data</span><br></pre></td></tr></table></figure><p>然后再看下 volume-data 目录下有什么内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /var/lib/docker/volumes/volume-data</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x. 2 root root 6 Sep  8 10:59 _data</span><br></pre></td></tr></table></figure><p>可以看到我们创建的卷出现在了 /var/lib/docker/volumes 目录下，并且 volume-data 目录下还创建了一个 _data 目录。</p><p>实际上，在我们创建 Docker 卷时，Docker 会把卷的数据全部放在 /var/lib/docker/volumes 目录下，并且在每个对应的卷的目录下创建一个 _data 目录，然后把 _data 目录绑定到容器中。因此我们在容器中挂载卷的目录下操作文件，实际上是在操作主机上的 _data 目录。为了证实我的说法，我们来实际演示下。</p><p>首先，我们启动一个容器，并且绑定 volume-data 卷到容器内的 /data 目录下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$  docker run -it --mount <span class="built_in">source</span>=volume-data,target=/data busybox</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>我们进入到容器的 /data 目录，创建一个 data.log 文件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># cd data/</span></span><br><span class="line">/data <span class="comment"># touch data.log</span></span><br></pre></td></tr></table></figure><p>然后我们新打开一个命令行窗口，查看一下主机上的文件内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$  sudo ls -l /var/lib/docker/volumes/volume-data/_data</span><br><span class="line">total 0</span><br><span class="line">-rw-r--r--. 1 root root 0 Sep  8 11:15 data.log</span><br></pre></td></tr></table></figure><p>可以看到主机上的 _data 目录下也出现了 data.log 文件。这说明，在容器内操作卷挂载的目录就是直接操作主机上的 _data 目录，符合我上面的说法。</p><p>综上，Docker 卷的实现原理是在主机的 /var/lib/docker/volumes 目录下，根据卷的名称创建相应的目录，然后在每个卷的目录下创建 _data 目录，在容器启动时如果使用 –mount 参数，Docker 会把主机上的目录直接映射到容器的指定目录下，实现数据持久化。</p><h2 id="文件存储驱动：AUFS-文件系统原理及生产环境的最佳配置"><a href="#文件存储驱动：AUFS-文件系统原理及生产环境的最佳配置" class="headerlink" title="文件存储驱动：AUFS 文件系统原理及生产环境的最佳配置"></a>文件存储驱动：AUFS 文件系统原理及生产环境的最佳配置</h2><h3 id="什么是联合文件系统"><a href="#什么是联合文件系统" class="headerlink" title="什么是联合文件系统"></a>什么是联合文件系统</h3><p>联合文件系统（Union File System，Unionfs）是一种分层的轻量级文件系统，它可以把多个目录内容联合挂载到同一目录下，从而形成一个单一的文件系统，这种特性可以让使用者像是使用一个目录一样使用联合文件系统。</p><p>那联合文件系统对于 Docker 是一个怎样的存在呢？它可以说是 Docker 镜像和容器的基础，因为它可以使 Docker 可以把镜像做成分层的结构，从而使得镜像的每一层可以被共享。例如两个业务镜像都是基于 CentOS 7 镜像构建的，那么这两个业务镜像在物理机上只需要存储一次 CentOS 7 这个基础镜像即可，从而节省大量存储空间。</p><p>说到这儿，你有没有发现，联合文件系统只是一个概念，真正实现联合文件系统才是关键，那如何实现呢？其实实现方案有很多，Docker 中最常用的联合文件系统有三种：AUFS、Devicemapper 和 OverlayFS。</p><p>今天我主要讲解 Docker 中最常用的联合文件系统里的 AUFS，为什么呢？因为 AUFS 是 Docker 最早使用的文件系统驱动，多用于 Ubuntu 和 Debian 系统中。在 Docker 早期，OverlayFS 和 Devicemapper 相对不够成熟，AUFS 是最早也是最稳定的文件系统驱动。</p><p>接下来，我们就看看如何配置 Docker 的 AUFS 模式。</p><h3 id="如何配置-Docker-的-AUFS-模式"><a href="#如何配置-Docker-的-AUFS-模式" class="headerlink" title="如何配置 Docker 的 AUFS 模式"></a>如何配置 Docker 的 AUFS 模式</h3><p>AUFS 目前并未被合并到 Linux 内核主线，因此只有 Ubuntu 和 Debian 等少数操作系统支持 AUFS。你可以使用以下命令查看你的系统是否支持 AUFS：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ grep aufs /proc/filesystems</span><br><span class="line">nodev   aufs</span><br></pre></td></tr></table></figure><p>执行以上命令后，如果输出结果包含aufs，则代表当前操作系统支持 AUFS。AUFS 推荐在 Ubuntu 或 Debian 操作系统下使用，如果你想要在 CentOS 等操作系统下使用 AUFS，需要单独安装 AUFS 模块（生产环境不推荐在 CentOS 下使用 AUFS，如果你想在 CentOS 下安装 AUFS 用于研究和测试，可以参考这个<a href="https://github.com/bnied/kernel-ml-aufs" target="_blank" rel="noopener">链接</a>），安装完成后使用上述命令输出结果中有aufs即可。</p><p>当确认完操作系统支持 AUFS 后，你就可以配置 Docker 的启动参数了。</p><p>先在 /etc/docker 下新建 daemon.json 文件，并写入以下内容：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"storage-driver"</span>: <span class="string">"aufs"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后使用以下命令重启 Docker：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl restart docker</span><br></pre></td></tr></table></figure><p>Docker 重启以后使用docker info命令即可查看配置是否生效：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker info</span><br><span class="line">Client:</span><br><span class="line"> Debug Mode: <span class="literal">false</span></span><br><span class="line">Server:</span><br><span class="line"> Containers: 0</span><br><span class="line">  Running: 0</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 0</span><br><span class="line"> Images: 1</span><br><span class="line"> Server Version: 19.03.12</span><br><span class="line"> Storage Driver: aufs</span><br><span class="line">  Root Dir: /var/lib/docker/aufs</span><br><span class="line">  Backing Filesystem: extfs</span><br><span class="line">  Dirs: 1</span><br><span class="line">  Dirperm1 Supported: <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>可以看到 Storage Driver 已经变为 aufs，证明配置已经生效，配置生效后就可以使用 AUFS 为 Docker 提供联合文件系统了。</p><p>配置好 Docker 的 AUFS 联合文件系统后，你一定很好奇 AUFS 到底是如何工作的呢？下面我带你详细学习一下 AUFS 的工作原理。</p><h3 id="AUFS-工作原理"><a href="#AUFS-工作原理" class="headerlink" title="AUFS 工作原理"></a>AUFS 工作原理</h3><h4 id="AUFS-是如何存储文件的？"><a href="#AUFS-是如何存储文件的？" class="headerlink" title="AUFS 是如何存储文件的？"></a>AUFS 是如何存储文件的？</h4><p>AUFS 是联合文件系统，意味着它在主机上使用多层目录存储，每一个目录在 AUFS 中都叫作分支，而在 Docker 中则称之为层（layer），但最终呈现给用户的则是一个普通单层的文件系统，我们把多层以单一层的方式呈现出来的过程叫作联合挂载。</p><p><img src="/images/docker/docker-02/7.jpg" alt="7"></p><p>如图 所示，每一个镜像层和容器层都是 /var/lib/docker 下的一个子目录，镜像层和容器层都在 aufs/diff 目录下，每一层的目录名称是镜像或容器的 ID 值，联合挂载点在 aufs/mnt 目录下，mnt 目录是真正的容器工作目录。</p><p>下面我们针对 aufs 文件夹下的各目录结构，在创建容器前后的变化做详细讲述。</p><p>当一个镜像未生成容器时，AUFS 的存储结构如下。</p><ul><li>diff 文件夹：存储镜像内容，每一层都存储在以镜像层 ID 命名的子文件夹中。</li><li>layers 文件夹：存储镜像层关系的元数据，在 diif 文件夹下的每个镜像层在这里都会有一个文件，文件的内容为该层镜像的父级镜像的 ID。</li><li>mnt 文件夹：联合挂载点目录，未生成容器时，该目录为空。</li></ul><p>当一个镜像已经生成容器时，AUFS 存储结构会发生如下变化。</p><ul><li>diff 文件夹：当容器运行时，会在 diff 目录下生成容器层。</li><li>layers 文件夹：增加容器层相关的元数据。</li><li>mnt 文件夹：容器的联合挂载点，这和容器中看到的文件内容一致。</li></ul><p>以上便是 AUFS 的工作原理，那你知道容器的在工作过程中是如何使用 AUFS 的吗？</p><h4 id="AUFS-是如何工作的？"><a href="#AUFS-是如何工作的？" class="headerlink" title="AUFS 是如何工作的？"></a>AUFS 是如何工作的？</h4><p>AUFS 的工作过程中对文件的操作分为读取文件和修改文件。下面我们分别来看下 AUFS 对于不同的文件操作是如何工作的。</p><h5 id="1-读取文件"><a href="#1-读取文件" class="headerlink" title="1. 读取文件"></a>1. 读取文件</h5><p>当我们在容器中读取文件时，可能会有以下场景。</p><ul><li>文件在容器层中存在时：当文件存在于容器层时，直接从容器层读取。</li><li>当文件在容器层中不存在时：当容器运行时需要读取某个文件，如果容器层中不存在时，则从镜像层查找该文件，然后读取文件内容。</li><li>文件既存在于镜像层，又存在于容器层：当我们读取的文件既存在于镜像层，又存在于容器层时，将会从容器层读取该文件。</li></ul><h5 id="2-修改文件或目录"><a href="#2-修改文件或目录" class="headerlink" title="2. 修改文件或目录"></a>2. 修改文件或目录</h5><p>AUFS 对文件的修改采用的是写时复制的工作机制，这种工作机制可以最大程度节省存储空间。</p><p>具体的文件操作机制如下。</p><ul><li>第一次修改文件：当我们第一次在容器中修改某个文件时，AUFS 会触发写时复制操作，AUFS 首先从镜像层复制文件到容器层，然后再执行对应的修改操作。</li></ul><blockquote><p>AUFS 写时复制的操作将会复制整个文件，如果文件过大，将会大大降低文件系统的性能，因此当我们有大量文件需要被修改时，AUFS 可能会出现明显的延迟。好在，写时复制操作只在第一次修改文件时触发，对日常使用没有太大影响。</p></blockquote><ul><li>删除文件或目录：当文件或目录被删除时，AUFS 并不会真正从镜像中删除它，因为镜像层是只读的，AUFS 会创建一个特殊的文件或文件夹，这种特殊的文件或文件夹会阻止容器的访问。</li></ul><p>下面我们通过一个实例来演示一下 AUFS 。</p><h3 id="AUFS-演示"><a href="#AUFS-演示" class="headerlink" title="AUFS 演示"></a>AUFS 演示</h3><h4 id="准备演示目录和文件"><a href="#准备演示目录和文件" class="headerlink" title="准备演示目录和文件"></a>准备演示目录和文件</h4><p>首先我们在 /tmp 目录下创建 aufs 目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /tmp</span><br><span class="line">/tmp$ mkdir aufs</span><br></pre></td></tr></table></figure><p>准备挂载点目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tmp$ <span class="built_in">cd</span> aufs</span><br><span class="line">/tmp/aufs$ mkdir mnt</span><br></pre></td></tr></table></figure><p>接下来准备容器层内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 创建镜像层目录</span></span><br><span class="line">/tmp/aufs$ mkdir container1</span><br><span class="line"><span class="comment">## 在镜像层目录下准备一个文件</span></span><br><span class="line">/tmp/aufs$ <span class="built_in">echo</span> Hello, Container layer! &gt; container1/container1.txt</span><br></pre></td></tr></table></figure><p>最后准备镜像层内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 创建两个镜像层目录</span></span><br><span class="line">/tmp/aufs$ mkdir image1 &amp;&amp; mkdir image2</span><br><span class="line"><span class="comment">## 分别写入数据</span></span><br><span class="line">/tmp/aufs$ <span class="built_in">echo</span> Hello, Image layer1! &gt; image1/image1.txt</span><br><span class="line">/tmp/aufs$ <span class="built_in">echo</span> Hello, Image layer2! &gt; image2/image2.txt</span><br></pre></td></tr></table></figure><p>准备好的目录和文件结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/tmp/aufs$ tree .</span><br><span class="line">.</span><br><span class="line">|-- container1</span><br><span class="line">|   `-- container1.txt</span><br><span class="line">|-- image1</span><br><span class="line">|   `-- image1.txt</span><br><span class="line">|-- image2</span><br><span class="line">|   `-- image2.txt</span><br><span class="line">`-- mnt</span><br><span class="line">4 directories, 3 files</span><br></pre></td></tr></table></figure><h3 id="创建-AUFS-联合文件系统"><a href="#创建-AUFS-联合文件系统" class="headerlink" title="创建 AUFS 联合文件系统"></a>创建 AUFS 联合文件系统</h3><p>使用 mount 命令可以创建 AUFS 类型的文件系统，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/tmp/aufs$ sudo mount -t aufs -o <span class="built_in">dirs</span>=./container1:./image2:./image1  none ./mnt</span><br></pre></td></tr></table></figure><p>mount 命令创建 AUFS 类型文件系统时，这里要注意，dirs 参数第一个冒号默认为读写权限，后面的目录均为只读权限，与 Docker 容器使用 AUFS 的模式一致。</p><p>执行完上述命令后，mnt 变成了 AUFS 的联合挂载目录，我们可以使用 mount 命令查看一下已经创建的 AUFS 文件系统：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tmp/aufs$ mount -t aufs</span><br><span class="line">none on /tmp/aufs/mnt <span class="built_in">type</span> aufs (rw,relatime,si=4174b83d649ffb7c)</span><br></pre></td></tr></table></figure><p>我们每创建一个 AUFS 文件系统，AUFS 都会为我们生成一个 ID，这个 ID 在 /sys/fs/aufs/ 会创建对应的目录，在这个 ID 的目录下可以查看文件挂载的权限。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tmp/aufs$ cat /sys/fs/aufs/si_4174b83d649ffb7c/*</span><br><span class="line">/tmp/aufs/container1=rw</span><br><span class="line">/tmp/aufs/image2=ro</span><br><span class="line">/tmp/aufs/image1=ro</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td></tr></table></figure><p>可以看到 container1 目录的权限为 rw（代表可读写），image1 和 image2 的权限为 ro（代表只读）。</p><p>为了验证 mnt 目录下可以看到 container1、image1 和 image2 目录下的所有内容，我们使用 ls 命令查看一下 mnt 目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/tmp/aufs$ ls -l mnt/</span><br><span class="line">total 12</span><br><span class="line">-rw-rw-r-- 1 ubuntu ubuntu 24 Sep  9 16:55 container1.txt</span><br><span class="line">-rw-rw-r-- 1 ubuntu ubuntu 21 Sep  9 16:59 image1.txt</span><br><span class="line">-rw-rw-r-- 1 ubuntu ubuntu 21 Sep  9 16:59 image2.txt</span><br></pre></td></tr></table></figure><p>可以看到 mnt 目录下已经出现了我们准备的所有镜像层和容器层的文件。下面让我们来验证一下 AUFS 的写时复制。</p><h3 id="验证-AUFS-的写时复制"><a href="#验证-AUFS-的写时复制" class="headerlink" title="验证 AUFS 的写时复制"></a>验证 AUFS 的写时复制</h3><p>AUFS 的写时复制是指在容器中，只有需要修改某个文件时，才会把文件从镜像层复制到容器层，下面我们通过修改联合挂载目录 mnt 下的内容来验证下这个过程。</p><p>我们使用以下命令修改 mnt 目录下的 image1.txt 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/tmp/aufs$ <span class="built_in">echo</span> Hello, Image layer1 changed! &gt; mnt/image1.txt</span><br></pre></td></tr></table></figure><p>然后我们查看下 image1/image1.txt 文件内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tmp/aufs$ cat image1/image1.txt</span><br><span class="line">Hello, Image layer1!</span><br></pre></td></tr></table></figure><p>发现“镜像层”的 image1.txt 文件并未被修改。</p><p>然后我们查看一下”容器层”对应的 image1.txt 文件内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/tmp/aufs$ ls -l container1/</span><br><span class="line">total 8</span><br><span class="line">-rw-rw-r-- 1 ubuntu ubuntu 24 Sep  9 16:55 container1.txt</span><br><span class="line">-rw-rw-r-- 1 ubuntu ubuntu 29 Sep  9 17:21 image1.txt</span><br><span class="line"><span class="comment">## 查看文件内容</span></span><br><span class="line">/tmp/aufs$ cat container1/image1.txt</span><br><span class="line">Hello, Image layer1 changed!</span><br></pre></td></tr></table></figure><p>发现 AUFS 在“容器层”自动创建了 image1.txt 文件，并且内容为我们刚才写入的内容。</p><p>至此，我们完成了 AUFS 写时复制的验证。我们在第一次修改镜像内某个文件时，AUFS 会复制这个文件到容器层，然后在容器层对该文件进行修改操作，这就是 AUFS 最典型的特性写时复制。</p><h2 id="文件存储驱动：Devicemapper-文件系统原理及生产环境的最佳配置"><a href="#文件存储驱动：Devicemapper-文件系统原理及生产环境的最佳配置" class="headerlink" title="文件存储驱动：Devicemapper 文件系统原理及生产环境的最佳配置"></a>文件存储驱动：Devicemapper 文件系统原理及生产环境的最佳配置</h2><h3 id="什么是-Devicemapper-？"><a href="#什么是-Devicemapper-？" class="headerlink" title="什么是 Devicemapper ？"></a>什么是 Devicemapper ？</h3><p>Devicemapper 是 Linux 内核提供的框架，从 Linux 内核 2.6.9 版本开始引入，Devicemapper 与 AUFS 不同，AUFS 是一种文件系统，而<strong>Devicemapper 是一种映射块设备的技术框架。</strong></p><p>Devicemapper 提供了一种将物理块设备映射到虚拟块设备的机制，目前 Linux 下比较流行的 LVM （Logical Volume Manager 是 Linux 下对磁盘分区进行管理的一种机制）和软件磁盘阵列（将多个较小的磁盘整合成为一个较大的磁盘设备用于扩大磁盘存储和提供数据可用性）都是基于 Devicemapper 机制实现的。</p><p>那么 Devicemapper 究竟是如何实现的呢？下面我们首先来了解一下它的关键技术。</p><h3 id="Devicemapper-的关键技术"><a href="#Devicemapper-的关键技术" class="headerlink" title="Devicemapper 的关键技术"></a>Devicemapper 的关键技术</h3><p>Devicemapper 将主要的工作部分分为用户空间和内核空间。</p><ul><li>用户空间负责配置具体的设备映射策略与相关的内核空间控制逻辑，例如逻辑设备 dm-a 如何与物理设备 sda 相关联，怎么建立逻辑设备和物理设备的映射关系等。</li><li>内核空间则负责用户空间配置的关联关系实现，例如当 IO 请求到达虚拟设备 dm-a 时，内核空间负责接管 IO 请求，然后处理和过滤这些 IO 请求并转发到具体的物理设备 sda 上。</li></ul><p>这个架构类似于 C/S （客户端/服务区）架构的工作模式，客户端负责具体的规则定义和配置下发，服务端根据客户端配置的规则来执行具体的处理任务。</p><p>Devicemapper 的工作机制主要围绕三个核心概念。</p><ul><li>映射设备（mapped device）：即对外提供的逻辑设备，它是由 Devicemapper 模拟的一个虚拟设备，并不是真正存在于宿主机上的物理设备。</li><li>目标设备（target device）：目标设备是映射设备对应的物理设备或者物理设备的某一个逻辑分段，是真正存在于物理机上的设备。</li><li>映射表（map table）：映射表记录了映射设备到目标设备的映射关系，它记录了映射设备在目标设备的起始地址、范围和目标设备的类型等变量。</li></ul><p><img src="/images/docker/docker-02/8.jpg" alt="Devicemapper 核心概念关系图"></p><p>Devicemapper 三个核心概念之间的关系如图，<strong>映射设备通过映射表关联到具体的物理目标设备。事实上，映射设备不仅可以通过映射表关联到物理目标设备，也可以关联到虚拟目标设备，然后虚拟目标设备再通过映射表关联到物理目标设备。</strong></p><p>Devicemapper 在内核中通过很多模块化的映射驱动（target driver）插件实现了对真正 IO 请求的拦截、过滤和转发工作，比如 Raid、软件加密、瘦供给（Thin Provisioning）等。其中瘦供给模块是 Docker 使用 Devicemapper 技术框架中非常重要的模块，下面我们来详细了解下瘦供给（Thin Provisioning）。</p><h4 id="瘦供给（Thin-Provisioning）"><a href="#瘦供给（Thin-Provisioning）" class="headerlink" title="瘦供给（Thin Provisioning）"></a>瘦供给（Thin Provisioning）</h4><p>瘦供给的意思是动态分配，这跟传统的固定分配不一样。传统的固定分配是无论我们用多少都一次性分配一个较大的空间，这样可能导致空间浪费。而瘦供给是我们需要多少磁盘空间，存储驱动就帮我们分配多少磁盘空间。</p><p>这种分配机制就好比我们一群人围着一个大锅吃饭，负责分配食物的人每次都给你一点分量，当你感觉食物不够时再去申请食物，而当你吃饱了就不需要再去申请食物了，从而避免了食物的浪费，节约的食物可以分配给更多需要的人。</p><p>那么，你知道 Docker 是如何使用瘦供给来做到像 AUFS 那样分层存储文件的吗？答案就是： Docker 使用了瘦供给的快照（snapshot）技术。</p><p>什么是快照（snapshot）技术？这是全球网络存储工业协会 SNIA（StorageNetworking Industry Association）对快照（Snapshot）的定义：</p><blockquote><p>关于指定数据集合的一个完全可用拷贝，该拷贝包括相应数据在某个时间点（拷贝开始的时间点）的映像。快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品。</p></blockquote><p>简单来说，<strong>快照是数据在某一个时间点的存储状态。快照的主要作用是对数据进行备份，当存储设备发生故障时，可以使用已经备份的快照将数据恢复到某一个时间点，而 Docker 中的数据分层存储也是基于快照实现的。</strong></p><p>以上便是实现 Devicemapper 的关键技术，那 Docker 究竟是如何使用 Devicemapper 实现存储数据和镜像分层共享的呢？</p><h3 id="Devicemapper-是如何数据存储的？"><a href="#Devicemapper-是如何数据存储的？" class="headerlink" title="Devicemapper 是如何数据存储的？"></a>Devicemapper 是如何数据存储的？</h3><p>当 Docker 使用 Devicemapper 作为文件存储驱动时，<strong>Docker 将镜像和容器的文件存储在瘦供给池（thinpool）中，并将这些内容挂载在 /var/lib/docker/devicemapper/ 目录下。</strong></p><p>这些目录储存 Docker 的容器和镜像相关数据，目录的数据内容和功能说明如下。</p><ul><li>devicemapper 目录（/var/lib/docker/devicemapper/devicemapper/）：存储镜像和容器实际内容，该目录由一个或多个块设备构成。</li><li>metadata 目录（/var/lib/docker/devicemapper/metadata/）： 包含 Devicemapper 本身配置的元数据信息, 以 json 的形式配置，这些元数据记录了镜像层和容器层之间的关联信息。</li><li>mnt 目录（ /var/lib/docker/devicemapper/mnt/）：是容器的联合挂载点目录，未生成容器时，该目录为空，而容器存在时，该目录下的内容跟容器中一致。</li></ul><h3 id="Devicemapper-如何实现镜像分层与共享？"><a href="#Devicemapper-如何实现镜像分层与共享？" class="headerlink" title="Devicemapper 如何实现镜像分层与共享？"></a>Devicemapper 如何实现镜像分层与共享？</h3><p>Devicemapper 使用专用的块设备实现镜像的存储，并且像 AUFS 一样使用了写时复制的技术来保障最大程度节省存储空间，所以 Devicemapper 的镜像分层也是依赖快照来是实现的。</p><p>Devicemapper 的每一镜像层都是其下一层的快照，最底层的镜像层是我们的瘦供给池，通过这种方式实现镜像分层有以下优点。</p><ul><li>相同的镜像层，仅在磁盘上存储一次。例如，我有 10 个运行中的 busybox 容器，底层都使用了 busybox 镜像，那么 busybox 镜像只需要在磁盘上存储一次即可。</li><li>快照是写时复制策略的实现，也就是说，当我们需要对文件进行修改时，文件才会被复制到读写层。</li><li>相比对文件系统加锁的机制，Devicemapper 工作在块级别，因此可以实现同时修改和读写层中的多个块设备，比文件系统效率更高。</li></ul><p>当我们需要读取数据时，如果数据存在底层快照中，则向底层快照查询数据并读取。当我们需要写数据时，则向瘦供给池动态申请存储空间生成读写层，然后把数据复制到读写层进行修改。Devicemapper 默认每次申请的大小是 64K 或者 64K 的倍数，因此每次新生成的读写层的大小都是 64K 或者 64K 的倍数。</p><p>以下是一个运行中的 Ubuntu 容器示意图。</p><p><img src="/images/docker/docker-02/9.jpg" alt="Devicemapper 存储模型"></p><p>这个 Ubuntu 镜像一共有四层，每一层镜像都是下一层的快照，镜像的最底层是基础设备的快照。当容器运行时，容器是基于镜像的快照。综上，Devicemapper 实现镜像分层的根本原理就是快照。</p><p>接下来，我们看下如何配置 Docker 的 Devicemapper 模式。</p><h3 id="如何在-Docker-中配置-Devicemapper"><a href="#如何在-Docker-中配置-Devicemapper" class="headerlink" title="如何在 Docker 中配置 Devicemapper"></a>如何在 Docker 中配置 Devicemapper</h3><p>Docker 的 Devicemapper 模式有两种：第一种是 loop-lvm 模式，该模式主要用来开发和测试使用；第二种是 direct-lvm 模式，该模式推荐在生产环境中使用。</p><p>下面我们逐一配置，首先来看下如何配置 loop-lvm 模式。</p><h4 id="配置-loop-lvm-模式"><a href="#配置-loop-lvm-模式" class="headerlink" title="配置 loop-lvm 模式"></a>配置 loop-lvm 模式</h4><ol><li>使用以下命令停止已经运行的 Docker：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl stop docker</span><br></pre></td></tr></table></figure><ol start="2"><li>编辑 /etc/docker/daemon.json 文件，如果该文件不存在，则创建该文件，并添加以下配置：</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"storage-driver"</span>: <span class="string">"devicemapper"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="3"><li>启动 Docker：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure><ol start="4"><li>验证 Docker 的文件驱动模式：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ docker info</span><br><span class="line">Client:</span><br><span class="line"> Debug Mode: <span class="literal">false</span></span><br><span class="line">Server:</span><br><span class="line"> Containers: 1</span><br><span class="line">  Running: 0</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 1</span><br><span class="line"> Images: 1</span><br><span class="line"> Server Version: 19.03.12</span><br><span class="line"> Storage Driver: devicemapper</span><br><span class="line">  Pool Name: docker-253:1-423624832-pool</span><br><span class="line">  Pool Blocksize: 65.54kB</span><br><span class="line">  Base Device Size: 10.74GB</span><br><span class="line">  Backing Filesystem: xfs</span><br><span class="line">  Udev Sync Supported: <span class="literal">true</span></span><br><span class="line">  Data file: /dev/loop0</span><br><span class="line">  Metadata file: /dev/loop1</span><br><span class="line">  Data loop file: /var/lib/docker/devicemapper/devicemapper/data</span><br><span class="line">  Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata</span><br><span class="line">  Data Space Used: 22.61MB</span><br><span class="line">  Data Space Total: 107.4GB</span><br><span class="line">  Data Space Available: 107.4GB</span><br><span class="line">  Metadata Space Used: 17.37MB</span><br><span class="line">  Metadata Space Total: 2.147GB</span><br><span class="line">  Metadata Space Available: 2.13GB</span><br><span class="line">  Thin Pool Minimum Free Space: 10.74GB</span><br><span class="line">  Deferred Removal Enabled: <span class="literal">true</span></span><br><span class="line">  Deferred Deletion Enabled: <span class="literal">true</span></span><br><span class="line">  Deferred Deleted Device Count: 0</span><br><span class="line">  Library Version: 1.02.164-RHEL7 (2019-08-27)</span><br><span class="line">... 省略部分输出</span><br></pre></td></tr></table></figure><p>可以看到 Storage Driver 为 devicemapper，这表示 Docker 已经被配置为 Devicemapper 模式。</p><p>但是这里输出的 Data file 为 /dev/loop0，这表示我们目前在使用的模式为 loop-lvm。但是由于 loop-lvm 性能比较差，因此不推荐在生产环境中使用 loop-lvm 模式。下面我们看下生产环境中应该如何配置 Devicemapper 的 direct-lvm 模式。</p><h4 id="配置-direct-lvm-模式"><a href="#配置-direct-lvm-模式" class="headerlink" title="配置 direct-lvm 模式"></a>配置 direct-lvm 模式</h4><ol><li>使用以下命令停止已经运行的 Docker：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl stop docker</span><br></pre></td></tr></table></figure><ol start="2"><li>编辑 /etc/docker/daemon.json 文件，如果该文件不存在，则创建该文件，并添加以下配置：</li></ol><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"storage-driver"</span>: <span class="string">"devicemapper"</span>,</span><br><span class="line">  <span class="attr">"storage-opts"</span>: [</span><br><span class="line">    <span class="string">"dm.directlvm_device=/dev/xdf"</span>,</span><br><span class="line">    <span class="string">"dm.thinp_percent=95"</span>,</span><br><span class="line">    <span class="string">"dm.thinp_metapercent=1"</span>,</span><br><span class="line">    <span class="string">"dm.thinp_autoextend_threshold=80"</span>,</span><br><span class="line">    <span class="string">"dm.thinp_autoextend_percent=20"</span>,</span><br><span class="line">    <span class="string">"dm.directlvm_device_force=false"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 directlvm_device 指定需要用作 Docker 存储的磁盘路径，Docker 会动态为我们创建对应的存储池。例如这里我想把 /dev/xdf 设备作为我的 Docker 存储盘，directlvm_device 则配置为 /dev/xdf。</p><ol start="3"><li>启动 Docker：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure><ol start="4"><li>验证 Docker 的文件驱动模式：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ docker info</span><br><span class="line">Client:</span><br><span class="line"> Debug Mode: <span class="literal">false</span></span><br><span class="line">Server:</span><br><span class="line"> Containers: 1</span><br><span class="line">  Running: 0</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 1</span><br><span class="line"> Images: 1</span><br><span class="line"> Server Version: 19.03.12</span><br><span class="line"> Storage Driver: devicemapper</span><br><span class="line">  Pool Name: docker-thinpool</span><br><span class="line">  Pool Blocksize: 65.54kB</span><br><span class="line">  Base Device Size: 10.74GB</span><br><span class="line">  Backing Filesystem: xfs</span><br><span class="line">  Udev Sync Supported: <span class="literal">true</span></span><br><span class="line">  Data file:</span><br><span class="line">  Metadata file:</span><br><span class="line">  Data loop file: /var/lib/docker/devicemapper/devicemapper/data</span><br><span class="line">  Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata</span><br><span class="line">  Data Space Used: 22.61MB</span><br><span class="line">  Data Space Total: 107.4GB</span><br><span class="line">  Data Space Available: 107.4GB</span><br><span class="line">  Metadata Space Used: 17.37MB</span><br><span class="line">  Metadata Space Total: 2.147GB</span><br><span class="line">  Metadata Space Available: 2.13GB</span><br><span class="line">  Thin Pool Minimum Free Space: 10.74GB</span><br><span class="line">  Deferred Removal Enabled: <span class="literal">true</span></span><br><span class="line">  Deferred Deletion Enabled: <span class="literal">true</span></span><br><span class="line">  Deferred Deleted Device Count: 0</span><br><span class="line">  Library Version: 1.02.164-RHEL7 (2019-08-27)</span><br><span class="line">... 省略部分输出</span><br></pre></td></tr></table></figure><p>当我们看到 Storage Driver 为 devicemapper，并且 Pool Name 为 docker-thinpool 时，这表示 Devicemapper 的 direct-lvm 模式已经配置成功。</p><blockquote><p>Devicemapper 使用块设备来存储文件，运行速度会比直接操作文件系统更快，因此很长一段时间内在 Red Hat 或 CentOS 系统中，Devicemapper 一直作为 Docker 默认的联合文件系统驱动，为 Docker 在 Red Hat 或 CentOS 稳定运行提供强有力的保障。</p></blockquote><h2 id="文件存储驱动：OverlayFS-文件系统原理及生产环境的最佳配置"><a href="#文件存储驱动：OverlayFS-文件系统原理及生产环境的最佳配置" class="headerlink" title="文件存储驱动：OverlayFS 文件系统原理及生产环境的最佳配置"></a>文件存储驱动：OverlayFS 文件系统原理及生产环境的最佳配置</h2><p>OverlayFS 的发展分为两个阶段。2014 年，OverlayFS 第一个版本被合并到 Linux 内核 3.18 版本中，此时的 OverlayFS 在 Docker 中被称为<code>overlay</code>文件驱动。由于第一版的<code>overlay</code>文件系统存在很多弊端（例如运行一段时间后Docker 会报 “too many links problem” 的错误）， Linux 内核在 4.0 版本对<code>overlay</code>做了很多必要的改进，此时的 OverlayFS 被称之为<code>overlay2</code>。</p><p>因此，在 Docker 中 OverlayFS 文件驱动被分为了两种，一种是早期的<code>overlay</code>，不推荐在生产环境中使用，另一种是更新和更稳定的<code>overlay2</code>，推荐在生产环境中使用。下面的内容我们主要围绕<code>overlay2</code>展开。</p><h3 id="使用-overlay2-的先决条件"><a href="#使用-overlay2-的先决条件" class="headerlink" title="使用 overlay2 的先决条件"></a>使用 overlay2 的先决条件</h3><p><code>overlay2</code>虽然很好，但是它的使用是有一定条件限制的。</p><ul><li>要想使用<code>overlay2</code>，Docker 版本必须高于 17.06.02。</li><li>如果你的操作系统是 RHEL 或 CentOS，Linux 内核版本必须使用 3.10.0-514 或者更高版本，其他 Linux 发行版的内核版本必须高于 4.0（例如 Ubuntu 或 Debian），你可以使用<code>uname -a</code>查看当前系统的内核版本。</li><li><code>overlay2</code>最好搭配 xfs 文件系统使用，并且使用 xfs 作为底层文件系统时，d_type必须开启，可以使用以下命令验证 d_type 是否开启：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ xfs_info /var/lib/docker | grep ftype</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=1</span><br></pre></td></tr></table></figure><p>当输出结果中有 ftype=1 时，表示 d_type 已经开启。如果你的输出结果为 ftype=0，则需要重新格式化磁盘目录，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkfs.xfs -f -n ftype=1 /path/to/disk</span><br></pre></td></tr></table></figure><p>另外，在生产环境中，推荐挂载 /var/lib/docker 目录到单独的磁盘或者磁盘分区，这样可以避免该目录写满影响主机的文件写入，并且把挂载信息写入到 /etc/fstab，防止机器重启后挂载信息丢失。</p><p>挂载配置中推荐开启 pquota，这样可以防止某个容器写文件溢出导致整个容器目录空间被占满。写入到 /etc/fstab 中的内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$UUID</span> /var/lib/docker xfs defaults,pquota 0 0</span><br></pre></td></tr></table></figure><p>其中 UUID 为 /var/lib/docker 所在磁盘或者分区的 UUID 或者磁盘路径。</p><p>如果你的操作系统无法满足上面的任何一个条件，那我推荐你使用 AUFS 或者 Devicemapper 作为你的 Docker 文件系统驱动。</p><blockquote><p>通常情况下，overlay2 会比 AUFS 和 Devicemapper 性能更好，而且更加稳定，因为 overlay2 在 inode 优化上更加高效。因此在生产环境中推荐使用 overlay2 作为 Docker 的文件驱动。</p></blockquote><p>下面我通过实例来教你如何初始化 /var/lib/docker 目录，为后面配置 Docker 的overlay2文件驱动做准备。</p><h4 id="准备-var-lib-docker-目录"><a href="#准备-var-lib-docker-目录" class="headerlink" title="准备 /var/lib/docker 目录"></a>准备 /var/lib/docker 目录</h4><ol><li>使用 lsblk（Linux 查看磁盘和块设备信息命令）命令查看本机磁盘信息：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ lsblk</span><br><span class="line">NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">vda    253:0    0  500G  0 disk</span><br><span class="line">`-vda1 253:1    0  500G  0 part /</span><br><span class="line">vdb    253:16   0  500G  0 disk</span><br><span class="line">`-vdb1 253:17   0    8G  0 part</span><br></pre></td></tr></table></figure><p>可以看到，我的机器有两块磁盘，一块是 vda，一块是 vdb。其中 vda 已经被用来挂载系统根目录，这里我想把 /var/lib/docker 挂载到 vdb1 分区上。</p><ol start="2"><li>使用 mkfs 命令格式化磁盘 vdb1：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkfs.xfs -f -n ftype=1 /dev/vdb1</span><br></pre></td></tr></table></figure><ol start="3"><li>将挂载信息写入到 /etc/fstab，保证机器重启挂载目录不丢失：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="built_in">echo</span> <span class="string">"/dev/vdb1 /var/lib/docker xfs defaults,pquota 0 0"</span> &gt;&gt; /etc/fstab</span><br></pre></td></tr></table></figure><ol start="4"><li>使用 mount 命令使得挂载目录生效：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mount -a</span><br></pre></td></tr></table></figure><ol start="5"><li>查看挂载信息：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ lsblk</span><br><span class="line">NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">vda    253:0    0  500G  0 disk</span><br><span class="line">`-vda1 253:1    0  500G  0 part /</span><br><span class="line">vdb    253:16   0  500G  0 disk</span><br><span class="line">`-vdb1 253:17   0    8G  0 part /var/lib/docker</span><br></pre></td></tr></table></figure><p>可以看到此时 /var/lib/docker 目录已经被挂载到了 vdb1 这个磁盘分区上。我们使用 xfs_info 命令验证下 d_type 是否已经成功开启：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ xfs_info /var/lib/docker | grep ftype</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0 ftype=1</span><br></pre></td></tr></table></figure><p>可以看到输出结果为 ftype=1，证明 d_type 已经被成功开启。</p><p>准备好 /var/lib/docker 目录后，我们就可以配置 Docker 的文件驱动为 overlay2，并且启动 Docker 了。</p><h3 id="如何在-Docker-中配置-overlay2？"><a href="#如何在-Docker-中配置-overlay2？" class="headerlink" title="如何在 Docker 中配置 overlay2？"></a>如何在 Docker 中配置 overlay2？</h3><p>当你的系统满足上面的条件后，就可以配置你的 Docker 存储驱动为 overlay2 了，具体配置步骤如下。</p><ol><li>停止已经运行的 Docker：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl stop docker</span><br></pre></td></tr></table></figure><ol start="2"><li>备份 /var/lib/docker 目录：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cp -au /var/lib/docker /var/lib/docker.back</span><br></pre></td></tr></table></figure><ol start="3"><li>在 /etc/docker 目录下创建 daemon.json 文件，如果该文件已经存在，则修改配置为以下内容：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span>,</span><br><span class="line">  <span class="string">"storage-opts"</span>: [</span><br><span class="line">    <span class="string">"overlay2.size=20G"</span>,</span><br><span class="line">    <span class="string">"overlay2.override_kernel_check=true"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 storage-driver 参数指定使用 overlay2 文件驱动，overlay2.size 参数表示限制每个容器根目录大小为 20G。限制每个容器的磁盘空间大小是通过 xfs 的 pquota 特性实现，overlay2.size 可以根据不同的生产环境来设置这个值的大小。我推荐你在生产环境中开启此参数，防止某个容器写入文件过大，导致整个 Docker 目录空间溢出。</p><ol start="4"><li>启动 Docker：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure><ol start="5"><li>检查配置是否生效：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ docker info</span><br><span class="line">Client:</span><br><span class="line"> Debug Mode: <span class="literal">false</span></span><br><span class="line">Server:</span><br><span class="line"> Containers: 1</span><br><span class="line">  Running: 0</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 1</span><br><span class="line"> Images: 1</span><br><span class="line"> Server Version: 19.03.12</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: xfs</span><br><span class="line">  Supports d_type: <span class="literal">true</span></span><br><span class="line">  Native Overlay Diff: <span class="literal">true</span></span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: cgroupfs</span><br><span class="line"> ... 省略部分无用输出</span><br></pre></td></tr></table></figure><p>可以看到 Storage Driver 已经变为 overlay2，并且 d_type 也是 true。至此，你的 Docker 已经配置完成。下面我们看下 overlay2 是如何工作的。</p><h3 id="overlay2-工作原理"><a href="#overlay2-工作原理" class="headerlink" title="overlay2 工作原理"></a>overlay2 工作原理</h3><h4 id="overlay2-是如何存储文件的？"><a href="#overlay2-是如何存储文件的？" class="headerlink" title="overlay2 是如何存储文件的？"></a>overlay2 是如何存储文件的？</h4><p>overlay2 和 AUFS 类似，它将所有目录称之为层（layer），overlay2 的目录是镜像和容器分层的基础，而把这些层统一展现到同一的目录下的过程称为联合挂载（union mount）。overlay2 把目录的下一层叫作<code>lowerdir</code>，上一层叫作<code>upperdir</code>，联合挂载后的结果叫作<code>merged</code>。</p><blockquote><p>overlay2 文件系统最多支持 128 个层数叠加，也就是说你的 Dockerfile 最多只能写 128 行，不过这在日常使用中足够了。</p></blockquote><p>下面我们通过拉取一个 Ubuntu 操作系统的镜像来看下 overlay2 是如何存放镜像文件的。</p><p>首先，我们通过以下命令拉取 Ubuntu 镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull ubuntu:16.04</span><br><span class="line">16.04: Pulling from library/ubuntu</span><br><span class="line">8e097b52bfb8: Pull complete</span><br><span class="line">a613a9b4553c: Pull complete</span><br><span class="line">acc000f01536: Pull complete</span><br><span class="line">73eef93b7466: Pull complete</span><br><span class="line">Digest: sha256:3dd44f7ca10f07f86add9d0dc611998a1641f501833692a2651c96defe8db940</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> ubuntu:16.04</span><br><span class="line">docker.io/library/ubuntu:16.04</span><br></pre></td></tr></table></figure><p>可以看到镜像一共被分为四层拉取，拉取完镜像后我们查看一下 overlay2 的目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /var/lib/docker/overlay2/</span><br><span class="line">total 0</span><br><span class="line">drwx------. 3 root root      47 Sep 13 08:16 01946de89606800dac8530e3480b32be9d7c66b493a1cdf558df52d7a1476d4a</span><br><span class="line">drwx------. 4 root root      55 Sep 13 08:16 0849daa41598a333101f6a411755907d182a7fcef780c7f048f15d335b774deb</span><br><span class="line">drwx------. 4 root root      72 Sep 13 08:16 94222a2fa3b2405cb00459285dd0d0ba7e6936d9b693ed18fbb0d08b93dc272f</span><br><span class="line">drwx------. 4 root root      72 Sep 13 08:16 9d392cf38f245d37699bdd7672daaaa76a7d702083694fa8be380087bda5e396</span><br><span class="line">brw-------. 1 root root 253, 17 Sep 13 08:14 backingFsBlockDev</span><br><span class="line">drwx------. 2 root root     142 Sep 13 08:16 l</span><br></pre></td></tr></table></figure><p>可以看到 overlay2 目录下出现了四个镜像层目录和一个l目录，我们首先来查看一下l目录的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /var/lib/docker/overlay2/l</span><br><span class="line">total 0</span><br><span class="line">lrwxrwxrwx. 1 root root 72 Sep 13 08:16 FWGSYEA56RNMS53EUCKEQIKVLQ -&gt; ../9d392cf38f245d37699bdd7672daaaa76a7d702083694fa8be380087bda5e396/diff</span><br><span class="line">lrwxrwxrwx. 1 root root 72 Sep 13 08:16 RNN2FM3YISKADNAZFRONVNWTIS -&gt; ../0849daa41598a333101f6a411755907d182a7fcef780c7f048f15d335b774deb/diff</span><br><span class="line">lrwxrwxrwx. 1 root root 72 Sep 13 08:16 SHAQ5GYA3UZLJJVEGXEZM34KEE -&gt; ../01946de89606800dac8530e3480b32be9d7c66b493a1cdf558df52d7a1476d4a/diff</span><br><span class="line">lrwxrwxrwx. 1 root root 72 Sep 13 08:16 VQSNH735KNX4YK2TCMBAJRFTGT -&gt; ../94222a2fa3b2405cb00459285dd0d0ba7e6936d9b693ed18fbb0d08b93dc272f/diff</span><br></pre></td></tr></table></figure><p>可以看到l目录是一堆软连接，把一些较短的随机串软连到镜像层的 diff 文件夹下，这样做是为了避免达到mount命令参数的长度限制。</p><p>下面我们查看任意一个镜像层下的文件内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /var/lib/docker/overlay2/0849daa41598a333101f6a411755907d182a7fcef780c7f048f15d335b774deb/</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x. 3 root root 17 Sep 13 08:16 diff</span><br><span class="line">-rw-r--r--. 1 root root 26 Sep 13 08:16 link</span><br><span class="line">-rw-r--r--. 1 root root 86 Sep 13 08:16 lower</span><br><span class="line">drwx------. 2 root root  6 Sep 13 08:16 work</span><br></pre></td></tr></table></figure><p>镜像层的 link 文件内容为该镜像层的短 ID，diff 文件夹为该镜像层的改动内容，lower 文件为该层的所有父层镜像的短 ID。</p><p>我们可以通过docker image inspect命令来查看某个镜像的层级关系，例如我想查看刚刚下载的 Ubuntu 镜像之间的层级关系，可以使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ docker image inspect ubuntu:16.04</span><br><span class="line">...省略部分输出</span><br><span class="line"><span class="string">"GraphDriver"</span>: &#123;</span><br><span class="line">            <span class="string">"Data"</span>: &#123;</span><br><span class="line">                <span class="string">"LowerDir"</span>: <span class="string">"/var/lib/docker/overlay2/9d392cf38f245d37699bdd7672daaaa76a7d702083694fa8be380087bda5e396/diff:/var/lib/docker/overlay2/94222a2fa3b2405cb00459285dd0d0ba7e6936d9b693ed18fbb0d08b93dc272f/diff:/var/lib/docker/overlay2/01946de89606800dac8530e3480b32be9d7c66b493a1cdf558df52d7a1476d4a/diff"</span>,</span><br><span class="line">                <span class="string">"MergedDir"</span>: <span class="string">"/var/lib/docker/overlay2/0849daa41598a333101f6a411755907d182a7fcef780c7f048f15d335b774deb/merged"</span>,</span><br><span class="line">                <span class="string">"UpperDir"</span>: <span class="string">"/var/lib/docker/overlay2/0849daa41598a333101f6a411755907d182a7fcef780c7f048f15d335b774deb/diff"</span>,</span><br><span class="line">                <span class="string">"WorkDir"</span>: <span class="string">"/var/lib/docker/overlay2/0849daa41598a333101f6a411755907d182a7fcef780c7f048f15d335b774deb/work"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">"Name"</span>: <span class="string">"overlay2"</span></span><br><span class="line">        &#125;,</span><br><span class="line">...省略部分输出</span><br></pre></td></tr></table></figure><p>其中 MergedDir 代表当前镜像层在 overlay2 存储下的目录，LowerDir 代表当前镜像的父层关系，使用冒号分隔，冒号最后代表该镜像的最底层。</p><p>下面我们将镜像运行起来成为容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name=ubuntu -d ubuntu:16.04 sleep 3600</span><br></pre></td></tr></table></figure><p>我们使用docker inspect命令来查看一下容器的工作目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect ubuntu</span><br><span class="line">...省略部分输出</span><br><span class="line"> <span class="string">"GraphDriver"</span>: &#123;</span><br><span class="line">            <span class="string">"Data"</span>: &#123;</span><br><span class="line">                <span class="string">"LowerDir"</span>: <span class="string">"/var/lib/docker/overlay2/4753c2aa5bdb20c97cddd6978ee3b1d07ef149e3cc2bbdbd4d11da60685fe9b2-init/diff:/var/lib/docker/overlay2/0849daa41598a333101f6a411755907d182a7fcef780c7f048f15d335b774deb/diff:/var/lib/docker/overlay2/9d392cf38f245d37699bdd7672daaaa76a7d702083694fa8be380087bda5e396/diff:/var/lib/docker/overlay2/94222a2fa3b2405cb00459285dd0d0ba7e6936d9b693ed18fbb0d08b93dc272f/diff:/var/lib/docker/overlay2/01946de89606800dac8530e3480b32be9d7c66b493a1cdf558df52d7a1476d4a/diff"</span>,</span><br><span class="line">                <span class="string">"MergedDir"</span>: <span class="string">"/var/lib/docker/overlay2/4753c2aa5bdb20c97cddd6978ee3b1d07ef149e3cc2bbdbd4d11da60685fe9b2/merged"</span>,</span><br><span class="line">                <span class="string">"UpperDir"</span>: <span class="string">"/var/lib/docker/overlay2/4753c2aa5bdb20c97cddd6978ee3b1d07ef149e3cc2bbdbd4d11da60685fe9b2/diff"</span>,</span><br><span class="line">                <span class="string">"WorkDir"</span>: <span class="string">"/var/lib/docker/overlay2/4753c2aa5bdb20c97cddd6978ee3b1d07ef149e3cc2bbdbd4d11da60685fe9b2/work"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">"Name"</span>: <span class="string">"overlay2"</span></span><br><span class="line">        &#125;,</span><br><span class="line">...省略部分输出</span><br></pre></td></tr></table></figure><p>MergedDir 后面的内容即为容器层的工作目录，LowerDir 为容器所依赖的镜像层目录。 然后我们查看下 overlay2 目录下的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /var/lib/docker/overlay2/</span><br><span class="line">total 0</span><br><span class="line">drwx------. 3 root root      47 Sep 13 08:16 01946de89606800dac8530e3480b32be9d7c66b493a1cdf558df52d7a1476d4a</span><br><span class="line">drwx------. 4 root root      72 Sep 13 08:47 0849daa41598a333101f6a411755907d182a7fcef780c7f048f15d335b774deb</span><br><span class="line">drwx------. 5 root root      69 Sep 13 08:47 4753c2aa5bdb20c97cddd6978ee3b1d07ef149e3cc2bbdbd4d11da60685fe9b2</span><br><span class="line">drwx------. 4 root root      72 Sep 13 08:47 4753c2aa5bdb20c97cddd6978ee3b1d07ef149e3cc2bbdbd4d11da60685fe9b2-init</span><br><span class="line">drwx------. 4 root root      72 Sep 13 08:16 94222a2fa3b2405cb00459285dd0d0ba7e6936d9b693ed18fbb0d08b93dc272f</span><br><span class="line">drwx------. 4 root root      72 Sep 13 08:16 9d392cf38f245d37699bdd7672daaaa76a7d702083694fa8be380087bda5e396</span><br><span class="line">brw-------. 1 root root 253, 17 Sep 13 08:14 backingFsBlockDev</span><br><span class="line">drwx------. 2 root root     210 Sep 13 08:47 l</span><br></pre></td></tr></table></figure><p>可以看到 overlay2 目录下增加了容器层相关的目录，我们再来查看一下容器层下的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /var/lib/docker/overlay2/4753c2aa5bdb20c97cddd6978ee3b1d07ef149e3cc2bbdbd4d11da60685fe9b2</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x. 2 root root   6 Sep 13 08:47 diff</span><br><span class="line">-rw-r--r--. 1 root root  26 Sep 13 08:47 link</span><br><span class="line">-rw-r--r--. 1 root root 144 Sep 13 08:47 lower</span><br><span class="line">drwxr-xr-x. 1 root root   6 Sep 13 08:47 merged</span><br><span class="line">drwx------. 3 root root  18 Sep 13 08:47 work</span><br></pre></td></tr></table></figure><p>link 和 lower 文件与镜像层的功能一致，link 文件内容为该容器层的短 ID，lower 文件为该层的所有父层镜像的短 ID 。diff 目录为容器的读写层，容器内修改的文件都会在 diff 中出现，merged 目录为分层文件联合挂载后的结果，也是容器内的工作目录。</p><p>总体来说，overlay2 是这样储存文件的：overlay2将镜像层和容器层都放在单独的目录，并且有唯一 ID，每一层仅存储发生变化的文件，最终使用联合挂载技术将容器层和镜像层的所有文件统一挂载到容器中，使得容器中看到完整的系统文件。</p><h4 id="overlay2-如何读取、修改文件？"><a href="#overlay2-如何读取、修改文件？" class="headerlink" title="overlay2 如何读取、修改文件？"></a>overlay2 如何读取、修改文件？</h4><p>overlay2 的工作过程中对文件的操作分为读取文件和修改文件。</p><p><strong>读取文件</strong></p><p>容器内进程读取文件分为以下三种情况。</p><ul><li>文件在容器层中存在：当文件存在于容器层并且不存在于镜像层时，直接从容器层读取文件；</li><li>当文件在容器层中不存在：当容器中的进程需要读取某个文件时，如果容器层中不存在该文件，则从镜像层查找该文件，然后读取文件内容；</li><li>文件既存在于镜像层，又存在于容器层：当我们读取的文件既存在于镜像层，又存在于容器层时，将会从容器层读取该文件。</li></ul><p><strong>修改文件或目录</strong></p><p>overlay2 对文件的修改采用的是写时复制的工作机制，这种工作机制可以最大程度节省存储空间。具体的文件操作机制如下。</p><ul><li>第一次修改文件：当我们第一次在容器中修改某个文件时，overlay2 会触发写时复制操作，overlay2 首先从镜像层复制文件到容器层，然后在容器层执行对应的文件修改操作。</li></ul><blockquote><p>overlay2 写时复制的操作将会复制整个文件，如果文件过大，将会大大降低文件系统的性能，因此当我们有大量文件需要被修改时，overlay2 可能会出现明显的延迟。好在，写时复制操作只在第一次修改文件时触发，对日常使用没有太大影响。</p></blockquote><ul><li>删除文件或目录：当文件或目录被删除时，overlay2 并不会真正从镜像中删除它，因为镜像层是只读的，overlay2 会创建一个特殊的文件或目录，这种特殊的文件或目录会阻止容器的访问。</li></ul><blockquote><p>overlay2 目前已经是 Docker 官方推荐的文件系统了，也是目前安装 Docker 时默认的文件系统，因为 overlay2 在生产环境中不仅有着较高的性能，它的稳定性也极其突出。但是 overlay2 的使用还是有一些限制条件的，例如要求 Docker 版本必须高于 17.06.02，内核版本必须高于 4.0 等。因此，在生产环境中，如果你的环境满足使用 overlay2 的条件，请尽量使用 overlay2 作为 Docker 的联合文件系统。</p></blockquote><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《由浅入深吃透 Docker》</li><li>《狂神说Docker》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://www.docker-cn.com" target="_blank" rel="noopener">https://www.docker-cn.com</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;资源隔离（Namespace）、资源限制（Cgroups）、数据驱动（Overlay2）。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://blog.lichao.xin/categories/Docker/"/>
    
    
      <category term="docker" scheme="https://blog.lichao.xin/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>重学 Docker 之 容器入门</title>
    <link href="https://blog.lichao.xin/back-end/docker/docker-01/"/>
    <id>https://blog.lichao.xin/back-end/docker/docker-01/</id>
    <published>2021-03-13T13:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>Docker 概述、核心概念、组成、安装、基本操作。</p><a id="more"></a><h2 id="Docker-概述"><a href="#Docker-概述" class="headerlink" title="Docker 概述"></a>Docker 概述</h2><h3 id="Docker-为什么出现？"><a href="#Docker-为什么出现？" class="headerlink" title="Docker 为什么出现？"></a>Docker 为什么出现？</h3><p>一款产品从开发到上线，从操作系统，到运行环境，再到应用配置。作为开发+运维之间的协作我们需要关心很多东西，这也是很多互联网公司都不得不面对的问题，特别是各种版本的迭代之后，不同版本环境的兼容，对运维人员是极大的考验！</p><p>环境配置如此麻烦，换一台机器，就要重来一次，费力费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。解决开发人员说的“在我的机器上可正常工作”的问题。</p><p>之前在服务器配置一个应用的运行环境，要安装各种软件，就拿一个基本的工程项目的环境来说吧，Java/Tomcat/MySQL/JDBC驱动包等。安装和配置这些东西有多麻烦就不说了，它还不能跨平台。假如我们是在 Windows 上安装的这些环境，到了 Linux 又得重新装。况且就算不跨操作系统，换另一台同样操作系统的服务器，要移植应用也是非常麻烦的。</p><p>传统上认为，软件编码开发/测试结束后，所产出的成果即是程序或是能够编译执行的二进制字节码文件等（Java为例）。而为了让这些程序可以顺利执行，开发团队也得准备完整的部署文件，让维运团队得以部署应用程式，<strong>开发需要清楚的告诉运维部署团队，用的全部配置文件+所有软件环境。不过，即便如此，仍然常常发生部署失败的状况。</strong></p><p>Docker之所以发展如此迅速，也是因为它对此给出了一个标准化的解决方案。</p><p>Docker镜像的设计，<strong>使得Docker得以打破过去「程序即应用」的观念。通过Docker镜像 ( images ) 将应用程序所需要的系统环境，由下而上打包，达到应用程序跨平台间的无缝接轨运作。</strong></p><p>Docker的思想来自于集装箱，集装箱解决了什么问题？在一艘大船上，可以把货物规整的摆放起来。并且各种各样的货物被集装箱标准化了，集装箱和集装箱之间不会互相影响。那么我就不需要专门运送水果的船和专门运送化学品的船了。只要这些货物在集装箱里封装的好好的，那我就可以用一艘大船把他们都运走。</p><p>docker 就是类似的理念。</p><h3 id="Docker-历史"><a href="#Docker-历史" class="headerlink" title="Docker 历史"></a>Docker 历史</h3><p>2010年，几个搞IT的年轻人，在美国旧金山成立了一家名叫“dotCloud”的公司。这家公司主要提供基于PaaS的云计算技术服务。具体来说，是和LXC有关的容器技术。后来，dotCloud公司将自己的容器技术进行了简化和标准化，并命名为——<strong>Docker</strong>。</p><p>Docker技术诞生之后，并没有引起行业的关注。而dotCloud公司，作为一家小型创业企业，在激烈的竞争之下，也步履维艰。正当他们快要坚持不下去的时候，脑子里蹦出了“开源”的想法。</p><p>什么是“开源”？开源，就是开放源代码。也就是将原来内部保密的程序源代码开放给所有人，然后让大家一起参与进来，贡献代码和意见。有的软件是一开始就开源的。也有的软件，是混不下去，创造者又不想放弃，所以选择开源。自己养不活，就吃“百家饭”嘛。</p><p>2013年3月，dotCloud公司的创始人之一，Docker之父，28岁的<strong>Solomon Hykes</strong>正式决定，将Docker项目开源。不开则已，一开惊人。越来越多的IT工程师发现了Docker的优点，然后蜂拥而至，加入Docker开源社区。 Docker的人气迅速攀升，速度之快，令人瞠目结舌。</p><p>开源当月，Docker 0.1 版本发布。此后的每一个月，Docker都会发布一个版本。到2014年6月9日，Docker 1.0 版本正式发布。</p><p>此时的Docker，已经成为行业里人气最火爆的开源技术，没有之一。甚至像Google、微软、Amazon、VMware这样的巨头，都对它青睐有加，表示将全力支持。</p><p>Docker和容器技术为什么会这么火爆？说白了，就是因为它“轻”。在容器技术之前，业界的网红是<strong>虚拟机</strong>。虚拟机技术的代表，是<strong>VMWare</strong>和<strong>OpenStack</strong>。相信很多人都用过虚拟机。虚拟机，就是在你的操作系统里面，装一个软件，然后通过这个软件，再模拟一台甚至多台“子电脑”出来。</p><p>在“子电脑”里，你可以和正常电脑一样运行程序，例如开QQ。如果你愿意，你可以变出好几个“子电脑”，里面都开上QQ。“子电脑”和“子电脑”之间，是<strong>相互隔离</strong>的，互不影响。</p><p>虚拟机属于虚拟化技术。而Docker这样的容器技术，也是虚拟化技术，属于<strong>轻量级的虚拟化</strong>。虚拟机虽然可以隔离出很多“子电脑”，但占用空间更大，启动更慢，虚拟机软件可能还要花钱（例如VMWare）。而容器技术恰好没有这些缺点。它不需要虚拟出整个操作系统，只需要虚拟一个小规模的环境（类似“沙箱”）。它启动时间很快，几秒钟就能完成。而且，它对资源的利用率很高（一台主机可以同时运行几千个Docker容器）。此外，它占的空间很小，虚拟机一般要几GB到几十GB的空间，而容器只需要MB级甚至KB级。</p><p>正因为如此，容器技术受到了热烈的欢迎和追捧，发展迅速。</p><h3 id="Docker-理念"><a href="#Docker-理念" class="headerlink" title="Docker 理念"></a>Docker 理念</h3><p>Docker是基于Go语言实现的云开源项目。</p><p>Docker的主要目标是“Build，Ship and Run Any App , Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”。</p><p>Linux 容器技术的出现就解决了这样一个问题，而 Docker 就是在它的基础上发展过来的。将应用运行在 Docker 容器上面，而 Docker 容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作。</p><h3 id="Docker-能干嘛"><a href="#Docker-能干嘛" class="headerlink" title="Docker 能干嘛"></a>Docker 能干嘛</h3><p><strong>之前的虚拟机技术</strong></p><p>虚拟机（virtual machine）就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统，比如在Windows 系统里面运行Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序，操作系统和硬件三者之间的逻辑不变。</p><p><img src="/images/docker/docker-01/1.jpg" alt="1"></p><p>虚拟机的缺点：</p><ul><li>资源占用多</li><li>冗余步骤多</li><li>启动慢</li></ul><p><strong>容器虚拟化技术</strong></p><p>由于前面虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。</p><p>Linux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。有了容器，就可以将软件运行所需的所有资源打包到一个隔离的容器中。容器与虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行。</p><p><img src="/images/docker/docker-01/2.jpg" alt="2"></p><p>比较了 Docker 和传统虚拟化方式的不同之处：</p><ul><li>传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；</li><li>而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。</li><li>每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。</li></ul><h4 id="开发-运维（DevOps）"><a href="#开发-运维（DevOps）" class="headerlink" title="开发/运维（DevOps）"></a>开发/运维（DevOps）</h4><p><strong>更快速的应用交付和部署：</strong></p><p>传统的应用开发完成后，需要提供一堆安装程序和配置说明文档，安装部署后需根据配置文档进行繁杂的配置才能正常运行。Docker化之后只需要交付少量容器镜像文件，在正式生产环境加载镜像并运行即可，应用安装配置在镜像里已经内置好，大大节省部署配置和测试验证时间。</p><p><strong>更便捷的升级和扩缩容：</strong></p><p>随着微服务架构和Docker的发展，大量的应用会通过微服务方式架构，应用的开发构建将变成搭乐高积木一样，每个Docker容器将变成一块“积木”，应用的升级将变得非常容易。当现有的容器不足以支撑业务处理时，可通过镜像运行新的容器进行快速扩容，使应用系统的扩容从原先的天级变成分钟级甚至秒级。</p><p><strong>更简单的系统运维：</strong></p><p>应用容器化运行后，生产环境运行的应用可与开发、测试环境的应用高度一致，容器会将应用程序相关的环境和状态完全封装起来，不会因为底层基础架构和操作系统的不一致性给应用带来影响，产生新的BUG。当出现程序异常时，也可以通过测试环境的相同容器进行快速定位和修复。</p><p><strong>更高效的计算资源利用：</strong></p><p>Docker是内核级虚拟化，其不像传统的虚拟化技术一样需要额外的Hypervisor [管理程序] 支持，所以在 一台物理机上可以运行很多个容器实例，可大大提升物理服务器的CPU和内存的利用率。</p><h2 id="Docker-安装"><a href="#Docker-安装" class="headerlink" title="Docker 安装"></a>Docker 安装</h2><p>Docker 是跨平台的解决方案，它支持在当前主流的各大平台安装，包括 Ubuntu、RHEL、CentOS、Debian 等 Linux 发行版，同时也可以在 OSX 、Microsoft Windows 等非 Linux 平台下安装使用。</p><p>因为 Linux 是 Docker 的原生支持平台，所以推荐你在 Linux 上使用 Docker。由于生产环境中我们使用 CentOS 较多，下面主要针对在 CentOS 平台下安装和使用 Docker 展开介绍。</p><h3 id="操作系统要求"><a href="#操作系统要求" class="headerlink" title="操作系统要求"></a>操作系统要求</h3><p>要安装 Docker，我们需要 CentOS 7 及以上的发行版本。建议使用overlay2存储驱动程序。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 打印当前系统相关信息（内核版本号、硬件架构、主机名称和操作系统类型）</span></span><br><span class="line">uname -r </span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看系统版本</span></span><br><span class="line">cat /etc/os-release</span><br></pre></td></tr></table></figure><h3 id="卸载已有-Docker"><a href="#卸载已有-Docker" class="headerlink" title="卸载已有 Docker"></a>卸载已有 Docker</h3><p>如果你已经安装过旧版的 Docker，可以先执行以下命令卸载旧版 Docker。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure><h3 id="安装-Docker"><a href="#安装-Docker" class="headerlink" title="安装 Docker"></a>安装 Docker</h3><p>首次安装 Docker 之前，需要添加 Docker 安装源。添加之后，我们就可以从已经配置好的源，安装和更新 Docker。添加 Docker 安装源的命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install -y yum-utils</span></span><br><span class="line"></span><br><span class="line">sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用国内的镜像</span></span><br><span class="line">sudo yum-config-manager \</span><br><span class="line">  --add-repo \</span><br><span class="line">  http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更新yum软件包索引</span></span><br><span class="line">yum makecache fast</span><br></pre></td></tr></table></figure><p>正常情况下，直接安装最新版本的 Docker 即可，因为最新版本的 Docker 有着更好的稳定性和安全性。你可以使用以下命令安装最新版本的 Docker。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure><p>如果你想要安装指定版本的 Docker，可以使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo yum list docker-ce --showduplicates | sort -r</span><br><span class="line">docker-ce.x86_64            18.06.1.ce-3.el7                   docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.0.ce-3.el7                   docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.03.1.ce-1.el7.centos            docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.03.0.ce-1.el7.centos            docker-ce-stable</span><br><span class="line">docker-ce.x86_64            17.12.1.ce-1.el7.centos            docker-ce-stable</span><br><span class="line">docker-ce.x86_64            17.12.0.ce-1.el7.centos            docker-ce-stable</span><br><span class="line">docker-ce.x86_64            17.09.1.ce-1.el7.centos            docker-ce-stable</span><br></pre></td></tr></table></figure><p>然后选取想要的版本执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io</span><br></pre></td></tr></table></figure><p>安装完成后，使用以下命令启动 Docker。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看版本</span></span><br><span class="line">docker version</span><br></pre></td></tr></table></figure><p>这里有一个国际惯例，安装完成后，我们需要使用以下命令启动一个 hello world 的容器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo docker run hello-world</span><br><span class="line">Unable to find image <span class="string">'hello-world:latest'</span> locally</span><br><span class="line">latest: Pulling from library/hello-world</span><br><span class="line">0e03bdcc26d7: Pull complete</span><br><span class="line">Digest: sha256:7f0a9f93b4aa3022c3a4c147a449bf11e0941a1fd0bf4a8e6c9408b2600777c5</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> hello-world:latest</span><br><span class="line">Hello from Docker!</span><br></pre></td></tr></table></figure><p>运行上述命令，Docker 首先会检查本地是否有<code>hello-world</code>这个镜像，如果发现本地没有这个镜像，Docker 就会去 Docker Hub 官方仓库下载此镜像，然后运行它。最后我们看到该镜像输出 “Hello from Docker!” 并退出。</p><p><strong>docker run</strong> 干了什么？</p><p><img src="/images/docker/docker-01/7.jpg" alt="7"></p><blockquote><p>安装完成后默认 docker 命令只能以 root 用户执行，如果想允许普通用户执行 docker 命令，需要执行以下命令 sudo groupadd docker &amp;&amp; sudo gpasswd -a ${USER} docker &amp;&amp; sudo systemctl restart docker ，执行完命令后，退出当前命令行窗口并打开新的窗口即可。</p></blockquote><p>安装完 Docker，先不着急使用，先来了解下容器的技术原理，这样才能知其所以然。</p><h2 id="容器技术原理"><a href="#容器技术原理" class="headerlink" title="容器技术原理"></a>容器技术原理</h2><p>提起容器就不得不说 chroot，因为 chroot 是最早的容器雏形。chroot 意味着切换根目录，有了 chroot 就意味着我们可以把任何目录更改为当前进程的根目录，这与容器非常相似，下面我们通过一个实例了解下 chroot。</p><h3 id="chroot"><a href="#chroot" class="headerlink" title="chroot"></a>chroot</h3><p>什么是 chroot 呢？下面是 chroot 维基百科定义：</p><p>chroot 是在 Unix 和 Linux 系统的一个操作，针对正在运作的软件行程和它的子进程，改变它外显的根目录。一个运行在这个环境下，经由 chroot 设置根目录的程序，它不能够对这个指定根目录之外的文件进行访问动作，不能读取，也不能更改它的内容。</p><p>通俗地说 ，chroot 就是可以改变某进程的根目录，使这个程序不能访问目录之外的其他目录，这个跟我们在一个容器中是很相似的。下面我们通过一个实例来演示下 chroot。</p><p>首先我们在当前目录下创建一个 rootfs 目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir rootfs</span><br></pre></td></tr></table></figure><p>这里为了方便演示，我使用现成的 busybox 镜像来创建一个系统，镜像的概念和组成后面会详细讲解，如果你没有 Docker 基础可以把下面的操作命令理解成在 rootfs 下创建了一些目录和放置了一些二进制文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> rootfs </span><br><span class="line">docker <span class="built_in">export</span> $(docker create busybox) -o busybox.tar</span><br><span class="line">tar -xf busybox.tar</span><br></pre></td></tr></table></figure><p>执行完上面的命令后，在 rootfs 目录下，我们会得到一些目录和文件。下面我们使用 ls 命令查看一下 rootfs 目录下的内容。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls</span><br><span class="line">bin  busybox.tar  dev  etc  home  proc  root  sys  tmp  usr  var</span><br></pre></td></tr></table></figure><p>可以看到我们在 rootfs 目录下初始化了一些目录，下面让我们通过一条命令来见证 chroot 的神奇之处。使用以下命令，可以启动一个 sh 进程，并且把 /home/centos/rootfs 作为 sh 进程的根目录。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ chroot /home/centos/rootfs /bin/sh</span><br></pre></td></tr></table></figure><p>此时，我们的命令行窗口已经处于上述命令启动的 sh 进程中。在当前 sh 命令行窗口下，我们使用 ls 命令查看一下当前进程，看是否真的与主机上的其他目录隔离开了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># /bin/ls /</span></span><br><span class="line">bin  busybox.tar  dev  etc  home  proc  root  sys  tmp  usr  var</span><br></pre></td></tr></table></figure><p>这里可以看到当前进程的根目录已经变成了主机上的 /home/centos/rootfs 目录。这样就实现了当前进程与主机的隔离。到此为止，一个目录隔离的容器就完成了。<br>但是，此时还不能称之为一个容器，为什么呢？你可以在上一步（使用 chroot 启动命令行窗口）执行以下命令，查看如下路由信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">/etc <span class="comment"># /bin/ip route</span></span><br><span class="line">default via 172.20.1.1 dev eth0</span><br><span class="line">172.17.0.0/16 dev docker0 scope link  src 172.17.0.1</span><br><span class="line">172.20.1.0/24 dev eth0 scope link  src 172.20.1.3</span><br></pre></td></tr></table></figure><p>执行 ip route 命令后，你可以看到网络信息并没有隔离，实际上进程等信息此时也并未隔离。要想实现一个完整的容器，我们还需要 Linux 的其他三项技术： Namespace、Cgroups 和联合文件系统。</p><p>Docker 是利用 Linux 的 Namespace 、Cgroups 和联合文件系统三大机制来保证实现的， 所以它的原理是使用 Namespace 做主机名、网络、PID 等资源的隔离，使用 Cgroups 对进程或者进程组做资源（例如：CPU、内存等）的限制，联合文件系统用于镜像构建和容器运行环境。</p><h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><p>Namespace 是 Linux 内核的一项功能，该功能对内核资源进行隔离，使得容器中的进程都可以在单独的命名空间中运行，并且只可以访问当前容器命名空间的资源。Namespace 可以隔离进程 ID、主机名、用户 ID、文件名、网络访问和进程间通信等相关资源。</p><p>Docker 主要用到以下五种命名空间。</p><ul><li>pid namespace：用于隔离进程 ID。</li><li>net namespace：隔离网络接口，在虚拟的 net namespace 内用户可以拥有自己独立的 IP、路由、端口等。</li><li>mnt namespace：文件系统挂载点隔离。</li><li>ipc namespace：信号量,消息队列和共享内存的隔离。</li><li>uts namespace：主机名和域名的隔离。</li></ul><h3 id="Cgroups"><a href="#Cgroups" class="headerlink" title="Cgroups"></a>Cgroups</h3><p>Cgroups 是一种 Linux 内核功能，可以限制和隔离进程的资源使用情况（CPU、内存、磁盘 I/O、网络等）。在容器的实现中，Cgroups 通常用来限制容器的 CPU 和内存等资源的使用。</p><h3 id="联合文件系统"><a href="#联合文件系统" class="headerlink" title="联合文件系统"></a>联合文件系统</h3><p>联合文件系统，又叫 UnionFS，是一种通过创建文件层进程操作的文件系统，因此，联合文件系统非常轻快。Docker 使用联合文件系统为容器提供构建层，使得容器可以实现写时复制以及镜像的分层构建和存储。常用的联合文件系统有 AUFS、Overlay 和 Devicemapper 等。</p><p>容器技术从 1979 年 chroot 的首次问世便已崭露头角，但是到了 2013 年，Dokcer 的横空出世才使得容器技术迅速发展，可见 Docker 对于容器技术的推动力和影响力。</p><blockquote><p>另外， Docker 还提供了工具和平台来管理容器的生命周期：</p><ol><li>使用容器开发应用程序及其支持组件。</li><li>容器成为分发和测试你的应用程序的单元。</li><li>可以将应用程序作为容器或协调服务部署到生产环境中。无论您的生产环境是本地数据中心，云提供商还是两者的混合，其工作原理都相同。</li></ol></blockquote><h2 id="Docker-的核心概念和一些重要的组件"><a href="#Docker-的核心概念和一些重要的组件" class="headerlink" title="Docker 的核心概念和一些重要的组件"></a>Docker 的核心概念和一些重要的组件</h2><h3 id="镜像-image"><a href="#镜像-image" class="headerlink" title="镜像(image)"></a>镜像(image)</h3><p>镜像是什么呢？通俗地讲，它是一个只读的文件和文件夹组合。它包含了容器运行时所需要的所有基础文件和配置信息，是容器启动的基础。所以你想启动一个容器，那首先必须要有一个镜像。镜像是 Docker 容器启动的先决条件。</p><p>如果你想要使用一个镜像，你可以用这两种方式：</p><p>自己创建镜像。通常情况下，一个镜像是基于一个基础镜像构建的，你可以在基础镜像上添加一些用户自定义的内容。例如你可以基于centos镜像制作你自己的业务镜像，首先安装nginx服务，然后部署你的应用程序，最后做一些自定义配置，这样一个业务镜像就做好了。</p><p>从功能镜像仓库拉取别人制作好的镜像。一些常用的软件或者系统都会有官方已经制作好的镜像，例如nginx、ubuntu、centos、mysql等，你可以到 Docker Hub 搜索并下载它们。</p><blockquote><p>Docker 镜像（Image）就是一个只读的模板。镜像可以用来创建 Docker 容器，一个镜像可以创建很 多容器。 就好似 Java 中的 类和对象，类就是镜像，容器就是对象！</p></blockquote><h3 id="容器-container"><a href="#容器-container" class="headerlink" title="容器(container)"></a>容器(container)</h3><p>容器是什么呢？容器是 Docker 的另一个核心概念。通俗地讲，容器是镜像的运行实体。镜像是静态的只读文件，而容器带有运行时需要的可写文件层，并且容器中的进程属于运行状态。即容器运行着真正的应用进程。容器有初建、运行、停止、暂停和删除五种状态。</p><p>虽然容器的本质是主机上运行的一个进程，但是容器有自己独立的命名空间隔离和资源限制。也就是说，在容器内部，无法看到主机上的进程、环境变量、网络等信息，这是容器与直接运行在主机上进程的本质区别。</p><blockquote><p>Docker 利用容器（Container）独立运行的一个或一组应用。容器是用镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的，保证安全的平台。可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。容器的定义和镜像几乎一模一样，也是一堆层的统一视角，唯一区别在于容器的最上面那一层是可读可写的。</p></blockquote><h3 id="仓库-repository"><a href="#仓库-repository" class="headerlink" title="仓库(repository)"></a>仓库(repository)</h3><p>Docker 的镜像仓库类似于代码仓库，用来存储和分发 Docker 镜像。镜像仓库分为公共镜像仓库和私有镜像仓库。</p><p>目前，[Docker Hub(<a href="https://hub.docker.com" target="_blank" rel="noopener">https://hub.docker.com</a>) 是 Docker 官方的公开镜像仓库，它不仅有很多应用或者操作系统的官方镜像，还有很多组织或者个人开发的镜像供我们免费存放、下载、研究和使用。除了公开镜像仓库，你也可以构建自己的私有镜像仓库。</p><p>仓库(Repository)和仓库注册服务器（Registry）是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。仓库分为公开仓库（Public）和私有仓库（Private）两种形式。</p><h3 id="镜像、容器、仓库，三者之间的联系"><a href="#镜像、容器、仓库，三者之间的联系" class="headerlink" title="镜像、容器、仓库，三者之间的联系"></a>镜像、容器、仓库，三者之间的联系</h3><p><img src="/images/docker/docker-01/4.jpg" alt="4"></p><p>从图可以看到，镜像是容器的基石，容器是由镜像创建的。一个镜像可以创建多个容器，容器是镜像运行的实体。仓库就非常好理解了，就是用来存放和分发镜像的。</p><h3 id="Docker-的核心架构"><a href="#Docker-的核心架构" class="headerlink" title="Docker 的核心架构"></a>Docker 的核心架构</h3><p>容器技术随着 Docker 的出现变得炙手可热，所有公司都在积极拥抱容器技术。此时市场上除了有 Docker 容器，还有很多其他的容器技术，比如 CoreOS 的 rkt、lxc 等。容器技术百花齐放是好事，但也出现了很多问题。比如容器技术的标准到底是什么？容器标准应该由谁来制定？</p><p>也许你可能会说，Docker 已经成为了事实标准，把 Docker 作为容器技术的标准不就好了？事实并没有想象的那么简单。因为那时候不仅有容器标准之争，编排技术之争也十分激烈。当时的编排技术有三大主力，分别是 Docker Swarm、Kubernetes 和 Mesos 。Swarm 毋庸置疑，肯定愿意把 Docker 作为唯一的容器运行时，但是 Kubernetes 和 Mesos 就不同意了，因为它们不希望调度的形式过度单一。</p><p>在这样的背景下，最终爆发了容器大战，OCI也正是在这样的背景下应运而生。</p><p><code>OCI</code>全称为开放容器标准（Open Container Initiative），它是一个轻量级、开放的治理结构。OCI组织在 Linux 基金会的大力支持下，于 2015 年 6 月份正式注册成立。基金会旨在为用户围绕工业化容器的格式和镜像运行时，制定一个开放的容器标准。目前主要有两个标准文档：容器运行时标准 （runtime spec）和容器镜像标准（image spec）。</p><p>正是由于容器的战争，才导致 Docker 不得不在战争中改变一些技术架构。最终形成了下图所示的技术架构。</p><p><img src="/images/docker/docker-01/5.jpg" alt="5"></p><p>我们可以看到，Docker 整体架构采用 C/S（客户端 / 服务器）模式，主要由客户端和服务端两大部分组成。客户端负责发送操作指令，服务端负责接收和处理指令。客户端和服务端通信有多种方式，既可以在同一台机器上通过UNIX套接字通信，也可以通过网络连接远程通信。</p><h3 id="Docker-客户端"><a href="#Docker-客户端" class="headerlink" title="Docker 客户端"></a>Docker 客户端</h3><p>Docker 客户端其实是一种泛称。其中 docker 命令是 Docker 用户与 Docker 服务端交互的主要方式。除了使用 docker 命令的方式，还可以使用直接请求 REST API 的方式与 Docker 服务端交互，甚至还可以使用各种语言的 SDK 与 Docker 服务端交互。目前社区维护着 Go、Java、Python、PHP 等数十种语言的 SDK，足以满足你的日常需求。</p><h3 id="Docker-服务端"><a href="#Docker-服务端" class="headerlink" title="Docker 服务端"></a>Docker 服务端</h3><p>Docker 服务端是 Docker 所有后台服务的统称。其中 dockerd 是一个非常重要的后台管理进程，它负责响应和处理来自 Docker 客户端的请求，然后将客户端的请求转化为 Docker 的具体操作。例如镜像、容器、网络和挂载卷等具体对象的操作和管理。</p><p>Docker 从诞生到现在，服务端经历了多次架构重构。起初，服务端的组件是全部集成在 docker 二进制里。但是从 1.11 版本开始， dockerd 已经成了独立的二进制，此时的容器也不是直接由 dockerd 来启动了，而是集成了 containerd、runC 等多个组件。</p><p>虽然 Docker 的架构在不停重构，但是各个模块的基本功能和定位并没有变化。它和一般的 C/S 架构系统一样，Docker 服务端模块负责和 Docker 客户端交互，并管理 Docker 的容器、镜像、网络等资源。</p><h3 id="Docker-重要组件"><a href="#Docker-重要组件" class="headerlink" title="Docker 重要组件"></a>Docker 重要组件</h3><p>下面，我以 Docker 的 18.09.2 版本为例，看下 Docker 都有哪些工具和组件。在 Docker 安装路径下执行 ls 命令可以看到以下与 docker 有关的二进制文件。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-rwxr-xr-x 1 root root 27941976 Dec 12  2019 containerd</span><br><span class="line">-rwxr-xr-x 1 root root  4964704 Dec 12  2019 containerd-shim</span><br><span class="line">-rwxr-xr-x 1 root root 15678392 Dec 12  2019 ctr</span><br><span class="line">-rwxr-xr-x 1 root root 50683148 Dec 12  2019 docker</span><br><span class="line">-rwxr-xr-x 1 root root   764144 Dec 12  2019 docker-init</span><br><span class="line">-rwxr-xr-x 1 root root  2837280 Dec 12  2019 docker-proxy</span><br><span class="line">-rwxr-xr-x 1 root root 54320560 Dec 12  2019 dockerd</span><br><span class="line">-rwxr-xr-x 1 root root  7522464 Dec 12  2019 runc</span><br></pre></td></tr></table></figure><p>可以看到，Docker 目前已经有了非常多的组件和工具。这里先介绍一下 Docker 的两个至关重要的组件：<code>runC</code>和<code>containerd</code>。</p><ul><li><p><code>runC</code>是 Docker 官方按照 OCI 容器运行时标准的一个实现。通俗地讲，runC 是一个用来运行容器的轻量级工具，是真正用来运行容器的。</p></li><li><p><code>containerd</code>是 Docker 服务端的一个核心组件，它是从<code>dockerd</code>中剥离出来的 ，它的诞生完全遵循 OCI 标准，是容器标准化后的产物。<code>containerd</code>通过 containerd-shim 启动并管理 runC，可以说<code>containerd</code>真正管理了容器的生命周期。</p></li></ul><p><img src="/images/docker/docker-01/6.jpg" alt="Docker 服务端组件调用关系图"></p><p>通过上图，可以看到，<code>dockerd</code>通过 gRPC 与<code>containerd</code>通信，由于<code>dockerd</code>与真正的容器运行时，<code>runC</code>中间有了<code>containerd</code>这一 OCI 标准层，使得<code>dockerd</code>可以确保接口向下兼容。</p><blockquote><p><a href="https://grpc.io/" target="_blank" rel="noopener">gRPC</a> 是一种远程服务调用。想了解更多信息可以参考<a href="https://grpc.io/" target="_blank" rel="noopener">https://grpc.io</a><br>containerd-shim 的意思是垫片，类似于拧螺丝时夹在螺丝和螺母之间的垫片。containerd-shim 的主要作用是将 containerd 和真正的容器进程解耦，使用 containerd-shim 作为容器进程的父进程，从而实现重启 dockerd 不影响已经启动的容器进程。</p></blockquote><p>了解了 dockerd、containerd 和 runC 之间的关系，下面可以通过启动一个 Docker 容器，来验证它们进程之间的关系。</p><h3 id="Docker-各组件之间的关系"><a href="#Docker-各组件之间的关系" class="headerlink" title="Docker 各组件之间的关系"></a>Docker 各组件之间的关系</h3><p>首先通过以下命令来启动一个 busybox 容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d busybox sleep 3600</span><br></pre></td></tr></table></figure><p>容器启动后，通过以下命令查看一下 dockerd 的 PID：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ps aux |grep dockerd</span><br><span class="line">root      4147  0.3  0.2 1447892 83236 ?       Ssl  Jul09 245:59 /usr/bin/dockerd</span><br></pre></td></tr></table></figure><p>通过上面的输出结果可以得知 dockerd 的 PID 为 4147。为了验证图 3 中 Docker 各组件之间的调用关系，下面使用 pstree 命令查看一下进程父子关系：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo pstree -l -a -A 4147</span><br><span class="line">dockerd</span><br><span class="line">  |-containerd --config /var/run/docker/containerd/containerd.toml --<span class="built_in">log</span>-level info</span><br><span class="line">  |   |-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/d14d20507073e5743e607efd616571c834f1a914f903db6279b8de4b5ba3a45a -address /var/run/docker/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc</span><br><span class="line">  |   |   |-sleep 3600</span><br></pre></td></tr></table></figure><p>事实上，dockerd 启动的时候， containerd 就随之启动了，dockerd 与 containerd 一直存在。当执行 docker run 命令（通过 busybox 镜像创建并启动容器）时，containerd 会创建 containerd-shim 充当 “垫片”进程，然后启动容器的真正进程 sleep 3600 。这个过程和架构图是完全一致的。</p><blockquote><p>docker 19.03.12 版本的 dockerd 和containerd 组件已经不是父子关系，可以使用以下命令查看，sudo ps aux | grep containerd , 然后使用 pstree 查看 containerd 的 PID</p></blockquote><h2 id="为什么Docker比较-VM-快"><a href="#为什么Docker比较-VM-快" class="headerlink" title="为什么Docker比较 VM 快"></a>为什么Docker比较 VM 快</h2><ol><li><p>docker有着比虚拟机更少的抽象层。由亍docker不需要Hypervisor实现硬件资源虚拟化,运行在<br>docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在<br>效率上有明显优势。</p></li><li><p>docker利用的是宿主机的内核,而不需要Guest OS。因此,当新建一个容器时,docker不需要和虚拟机<br>一样重新加载一个操作系统内核。仍而避免引寻、加载操作系统内核返个比较费时费资源的过程,当新建<br>一个虚拟机时,虚拟机软件需要加载Guest OS,返个新建过程是分钟级别的。而docker由于直接利用宿主<br>机的操作系统,则省略了返个过程,因此新建一个docker容器只需要几秒钟。</p></li></ol><p><img src="/images/docker/docker-01/8.jpg" alt="8"></p><h2 id="Docker-镜像"><a href="#Docker-镜像" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h2><h3 id="镜像是什么？"><a href="#镜像是什么？" class="headerlink" title="镜像是什么？"></a>镜像是什么？</h3><p>镜像是一个只读的 Docker 容器模板，包含启动容器所需要的所有文件系统结构和内容。简单来讲，镜像是一个特殊的文件系统，它提供了容器运行时所需的程序、软件库、资源、配置等静态数据。即镜像不包含任何动态数据，镜像内容在构建后不会被改变。</p><h3 id="镜像操作"><a href="#镜像操作" class="headerlink" title="镜像操作"></a>镜像操作</h3><p><img src="/images/docker/docker-01/10.jpg" alt="镜像操作"></p><p>从图中可知，镜像的操作可分为：</p><ul><li>拉取镜像，使用docker pull命令拉取远程仓库的镜像到本地 ；</li><li>重命名镜像，使用docker tag命令“重命名”镜像 ；</li><li>查看镜像，使用docker image ls或docker images命令查看本地已经存在的镜像 ；</li><li>删除镜像，使用docker rmi命令删除无用镜像 ；</li><li>构建镜像，构建镜像有两种方式。第一种方式是使用docker build命令基于 Dockerfile 构建镜像，也是我比较推荐的镜像构建方式；第二种方式是使用docker commit命令基于已经运行的容器提交为镜像。</li></ul><h4 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h4><p>Docker 镜像的拉取使用 <code>docker pull</code> 命令， 命令格式一般为 <code>docker pull [Registry]/[Repository]/[Image]:[Tag]</code>。</p><ul><li>Registry 为注册服务器，Docker 默认会从 docker.io 拉取镜像，如果你有自己的镜像仓库，可以把 Registry 替换为自己的注册服务器。</li><li>Repository 为镜像仓库，通常把一组相关联的镜像归为一个镜像仓库，library为 Docker 默认的镜像仓库。</li><li>Image 为镜像名称。</li><li>Tag 为镜像的标签，如果你不指定拉取镜像的标签，默认为latest。</li></ul><p>例如，我们需要获取一个 busybox 镜像，可以执行以下命令：</p><blockquote><p>busybox 是一个集成了数百个 Linux 命令（例如 curl、grep、mount、telnet 等）的精简工具箱，只有几兆大小，被誉为 Linux 系统的瑞士军刀。我经常会使用 busybox 做调试来查找生产环境中遇到的问题。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull busybox</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/busybox</span><br><span class="line">61c5ed1cbdf8: Pull complete</span><br><span class="line">Digest: sha256:4f47c01fa91355af2865ac10fef5bf6ec9c7f42ad2321377c21e844427972977</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> busybox:latest</span><br><span class="line">docker.io/library/busybox:latest</span><br></pre></td></tr></table></figure><p>实际上执行 <code>docker pull busybox</code> 命令，都是先从本地搜索，如果本地搜索不到busybox镜像则从 Docker Hub 下载镜像。</p><h4 id="查看镜像"><a href="#查看镜像" class="headerlink" title="查看镜像"></a>查看镜像</h4><p>Docker 镜像查看使用docker images或者docker image ls命令。</p><p>下面我们使用docker images命令列出本地所有的镜像。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">nginx               latest              4bb46517cac3        9 days ago          133MB</span><br><span class="line">nginx               1.15                53f3fd8007f7        15 months ago       109MB</span><br><span class="line">busybox             latest              018c9d7b792b        3 weeks ago         1.22MB</span><br></pre></td></tr></table></figure><p>如果我们想要查询指定的镜像，可以使用docker image ls命令来查询。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker image ls busybox</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">busybox             latest              018c9d7b792b        3 weeks ago         1.22MB</span><br></pre></td></tr></table></figure><p>当然你也可以使用docker images命令列出所有镜像，然后使用grep命令进行过滤。使用方法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker images |grep busybox</span><br><span class="line">busybox             latest              018c9d7b792b        3 weeks ago         1.22MB</span><br></pre></td></tr></table></figure><h4 id="“重命名”镜像"><a href="#“重命名”镜像" class="headerlink" title="“重命名”镜像"></a>“重命名”镜像</h4><p>如果你想要自定义镜像名称或者推送镜像到其他镜像仓库，你可以使用docker tag命令将镜像重命名。docker tag的命令格式为 <code>docker tag [SOURCE_IMAGE][:TAG] [TARGET_IMAGE][:TAG]</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker tag busybox:latest mybusybox:latest</span><br></pre></td></tr></table></figure><p>执行完docker tag命令后，可以使用查询镜像命令查看一下镜像列表：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">busybox             latest              018c9d7b792b        3 weeks ago         1.22MB</span><br><span class="line">mybusybox           latest              018c9d7b792b        3 weeks ago         1.22MB</span><br></pre></td></tr></table></figure><p>可以看到，镜像列表中多了一个<code>mybusybox</code>的镜像。但细心的同学可能已经发现，busybox和mybusybox这两个镜像的 IMAGE ID 是完全一样的。为什么呢？实际上它们指向了同一个镜像文件，只是别名不同而已。</p><h4 id="删除镜像"><a href="#删除镜像" class="headerlink" title="删除镜像"></a>删除镜像</h4><p>你可以使用<code>docker rmi</code>或者<code>docker image rm</code>命令删除镜像。</p><p>举例：你可以使用以下命令删除mybusybox镜像。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker rmi mybusybox</span><br><span class="line">Untagged: mybusybox:latest</span><br></pre></td></tr></table></figure><h4 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h4><p>构建镜像主要有两种方式：</p><ol><li><p>使用docker commit命令从运行中的容器提交为镜像；</p></li><li><p>使用docker build命令从 Dockerfile 构建镜像。</p></li></ol><p>首先介绍下如何从运行中的容器提交为镜像。我依旧使用 busybox 镜像举例，使用以下命令创建一个名为 busybox 的容器并进入 busybox 容器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --rm --name=busybox -it busybox sh</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>执行完上面的命令后，当前窗口会启动一个 busybox 容器并且进入容器中。在容器中，执行以下命令创建一个文件并写入内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/ <span class="comment"># touch hello.txt &amp;&amp; echo "I love Docker. " &gt; hello.txt</span></span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>此时在容器的根目录下，已经创建了一个 hello.txt 文件，并写入了 “I love Docker. “。下面，我们新打开另一个命令行窗口，运行以下命令提交镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker commit busybox busybox:hello</span><br><span class="line">sha256:cbc6406aaef080d1dd3087d4ea1e6c6c9915ee0ee0f5dd9e0a90b03e2215e81c</span><br></pre></td></tr></table></figure><p>然后使用上面讲到的docker image ls命令查看镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker image ls busybox</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">busybox             hello               cbc6406aaef0        2 minutes ago       1.22MB</span><br><span class="line">busybox             latest              018c9d7b792b        4 weeks ago         1.22MB</span><br></pre></td></tr></table></figure><p>此时我们可以看到主机上新生成了 busybox:hello 这个镜像。</p><p>第二种方式是最重要也是最常用的镜像构建方式：Dockerfile。Dockerfile 是一个包含了用户所有构建命令的文本。通过<code>docker build</code>命令可以从 Dockerfile 生成镜像。</p><p>使用 Dockerfile 构建镜像具有以下特性：</p><ul><li>Dockerfile 的每一行命令都会生成一个独立的镜像层，并且拥有唯一的 ID；</li><li>Dockerfile 的命令是完全透明的，通过查看 Dockerfile 的内容，就可以知道镜像是如何一步步构建的；</li><li>Dockerfile 是纯文本的，方便跟随代码一起存放在代码仓库并做版本管理。</li></ul><p><strong>Dockerfile 常用的指令：</strong></p><table><thead><tr><th>Dockerfile 指令</th><th>指令简介</th></tr></thead><tbody><tr><td>FROM</td><td>Dockerfile 除了注释第一行必须是 FROM ，FROM 后面跟镜像名称，代表我们要基于哪个基础镜像构建我们的容器。</td></tr><tr><td>RUN</td><td>RUN 后面跟一个具体的命令，类似于 Linux 命令行执行命令。</td></tr><tr><td>ADD</td><td>拷贝本机文件或者远程文件到镜像内</td></tr><tr><td>COPY</td><td>拷贝本机文件到镜像内</td></tr><tr><td>USER</td><td>指定容器启动的用户</td></tr><tr><td>ENTRYPOINT</td><td>容器的启动命令</td></tr><tr><td>CMD</td><td>CMD 为 ENTRYPOINT 指令提供默认参数，也可以单独使用 CMD 指定容器启动参数</td></tr><tr><td>ENV</td><td>指定容器运行时的环境变量，格式为 key=value</td></tr><tr><td>ARG</td><td>定义外部变量，构建镜像时可以使用 build-arg = 的格式传递参数用于构建</td></tr><tr><td>EXPOSE</td><td>指定容器监听的端口，格式为 [port]/tcp 或者 [port]/udp</td></tr><tr><td>WORKDIR</td><td>为 Dockerfile 中跟在其后的所有 RUN、CMD、ENTRYPOINT、COPY 和 ADD 命令设置工作目录。</td></tr></tbody></table><p>看了这么多指令，感觉有点懵？别担心，我通过一个实例让你来熟悉它们。这是一个 Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">7</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> nginx.repo /etc/yum.repos.d/nginx.repo</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y nginx</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">80</span></span><br><span class="line"><span class="keyword">ENV</span> HOST=mynginx</span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">"nginx"</span>,<span class="string">"-g"</span>,<span class="string">"daemon off;"</span>]</span></span><br></pre></td></tr></table></figure><p>nginx.repo：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">name&#x3D;nginx repo</span><br><span class="line">baseurl&#x3D;http:&#x2F;&#x2F;nginx.org&#x2F;packages&#x2F;centos&#x2F;$releasever&#x2F;$basearch&#x2F;</span><br><span class="line">gpgcheck&#x3D;0</span><br><span class="line">enabled&#x3D;1</span><br></pre></td></tr></table></figure><p>好，我来逐行分析一下上述的 Dockerfile。</p><ul><li>第一行表示我要基于 centos:7 这个镜像来构建自定义镜像。这里需要注意，每个 Dockerfile 的第一行除了注释都必须以 FROM 开头。</li><li>第二行表示拷贝本地文件 nginx.repo 文件到容器内的 /etc/yum.repos.d 目录下。这里拷贝 nginx.repo 文件是为了添加 nginx 的安装源。</li><li>第三行表示在容器内运行<code>yum install -y nginx</code>命令，安装 nginx 服务到容器内，执行完第三行命令，容器内的 nginx 已经安装完成。</li><li>第四行声明容器内业务（nginx）使用 80 端口对外提供服务。</li><li>第五行定义容器启动时的环境变量 HOST=mynginx，容器启动后可以获取到环境变量 HOST 的值为 mynginx。</li><li>第六行定义容器的启动命令，命令格式为 json 数组。这里设置了容器的启动命令为 nginx ，并且添加了 nginx 的启动参数 -g ‘daemon off;’ ，使得 nginx 以前台的方式启动。</li></ul><p>学习了镜像的各种操作，下面我们深入了解一下镜像的实现原理。</p><h3 id="镜像的实现原理"><a href="#镜像的实现原理" class="headerlink" title="镜像的实现原理"></a>镜像的实现原理</h3><p>其实 Docker 镜像是由一系列镜像层（layer）组成的，每一层代表了镜像构建过程中的一次提交。下面以一个镜像构建的 Dockerfile 来说明镜像是如何分层的。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> busybox</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> <span class="built_in">test</span> /tmp/<span class="built_in">test</span></span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir /tmp/testdir</span></span><br></pre></td></tr></table></figure><p>上面的 Dockerfile 由三步组成：</p><p>第一行基于 busybox 创建一个镜像层；</p><p>第二行拷贝本机 test 文件到镜像内；</p><p>第三行在 /tmp 文件夹下创建一个目录 testdir。</p><p>为了验证镜像的存储结构，我们使用docker build命令在上面 Dockerfile 所在目录构建一个镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t mybusybox .</span><br></pre></td></tr></table></figure><p>这里我的 Docker 使用的是 overlay2 文件驱动，进入到<code>/var/lib/docker/overlay2</code>目录下使用tree .命令查看产生的镜像文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ tree .</span><br><span class="line"><span class="comment"># 以下为 tree . 命令输出内容</span></span><br><span class="line">|-- 3e89b959f921227acab94f5ab4524252ae0a829ff8a3687178e3aca56d605679</span><br><span class="line">|   |-- diff  <span class="comment"># 这一层为基础层，对应上述 Dockerfile 第一行，包含 busybox 镜像所有文件内容，例如 /etc,/bin,/var 等目录</span></span><br><span class="line">... 此次省略部分原始镜像文件内容</span><br><span class="line">|   `-- link </span><br><span class="line">|-- 6591d4e47eb2488e6297a0a07a2439f550cdb22845b6d2ddb1be2466ae7a9391</span><br><span class="line">|   |-- diff   <span class="comment"># 这一层对应上述 Dockerfile 第二行，拷贝 test 文件到 /tmp 文件夹下，因此 diff 文件夹下有了 /tmp/test 文件</span></span><br><span class="line">|   |   `-- tmp</span><br><span class="line">|   |       `-- <span class="built_in">test</span></span><br><span class="line">|   |-- link</span><br><span class="line">|   |-- lower</span><br><span class="line">|   `-- work</span><br><span class="line">|-- backingFsBlockDev</span><br><span class="line">|-- bec6a018080f7b808565728dee8447b9e86b3093b16ad5e6a1ac3976528a8bb1</span><br><span class="line">|   |-- diff  <span class="comment"># 这一层对应上述 Dockerfile 第三行，在 /tmp 文件夹下创建 testdir 文件夹，因此 diff 文件夹下有了 /tmp/testdir 文件夹</span></span><br><span class="line">|   |   `-- tmp</span><br><span class="line">|   |       `-- testdir</span><br><span class="line">|   |-- link</span><br><span class="line">|   |-- lower</span><br><span class="line">|   `-- work</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>通过上面的目录结构可以看到，Dockerfile 的每一行命令，都生成了一个镜像层，每一层的 diff 夹下只存放了增量数据，如图所示。</p><p><img src="/images/docker/docker-01/11.jpg" alt="镜像文件系统"></p><p>分层的结构使得 Docker 镜像非常轻量，每一层根据镜像的内容都有一个唯一的 ID 值，当不同的镜像之间有相同的镜像层时，便可以实现不同的镜像之间共享镜像层的效果。</p><p>总结一下， Docker 镜像是静态的分层管理的文件组合，镜像底层的实现依赖于联合文件系统（UnionFS）。充分掌握镜像的原理，可以帮助我们在生产实践中构建出最优的镜像，同时也可以帮助我们更好地理解容器和镜像的关系。</p><h3 id="Docker-镜像加载原理"><a href="#Docker-镜像加载原理" class="headerlink" title="Docker 镜像加载原理"></a>Docker 镜像加载原理</h3><h4 id="UnionFS-（联合文件系统）"><a href="#UnionFS-（联合文件系统）" class="headerlink" title="UnionFS （联合文件系统）"></a>UnionFS （联合文件系统）</h4><p>UnionFS（联合文件系统）：Union文件系统（UnionFS）是一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)。</p><p>Union 文件系统是 Docker 镜像的基础。镜像可以通过分层来进行继承，基于基础镜像（没有父镜像），可以制作各种具体的应用镜像。</p><p>特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件<br>系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。</p><h4 id="Docker镜像加载原理"><a href="#Docker镜像加载原理" class="headerlink" title="Docker镜像加载原理"></a>Docker镜像加载原理</h4><p>docker的镜像实际上由一层一层的文件系统组成，这种层级的文件系统UnionFS。</p><p>bootfs(boot file system)主要包含bootloader和kernel, bootloader主要是引导加载kernel, Linux刚启<br>动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs。这一层与我们典型的Linux/Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载bootfs。</p><p>rootfs (root file system) ，在bootfs之上。包含的就是典型 Linux 系统中的 /dev, /proc, /bin, /etc 等标准目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu，Centos等等。</p><p><img src="/images/docker/docker-01/12.jpg" alt="12"></p><p>平时我们安装进虚拟机的CentOS都是好几个G，为什么Docker这里才200M？</p><p>对于一个精简的OS，rootfs 可以很小，只需要包含最基本的命令，工具和程序库就可以了，因为底层直接用Host的kernel，自己只需要提供rootfs就可以了。由此可见对于不同的linux发行版, bootfs基本是一致的, rootfs会有差别, 因此不同的发行版可以公用bootfs。</p><h4 id="分层理解"><a href="#分层理解" class="headerlink" title="分层理解"></a>分层理解</h4><p>我们可以去下载一个镜像，注意观察下载的日志输出，可以看到是一层一层的在下载！</p><p>思考：为什么Docker镜像要采用这种分层的结构呢？</p><p>最大的好处，我觉得莫过于是资源共享了！比如有多个镜像都从相同的Base镜像构建而来，那么宿主机只需在磁盘上保留一份base镜像，同时内存中也只需要加载一份base镜像，这样就可以为所有的容器服务了，而且镜像的每一层都可以被共享。</p><p>查看镜像分层的方式可以通过 <code>docker image inspect</code> 命令！</p><p>理解：</p><p>所有的 Docker 镜像都起始于一个基础镜像层，当进行修改或增加新的内容时，就会在当前镜像层之上，创建新的镜像层。</p><p>举一个简单的例子，假如基于 Ubuntu Linux 16.04 创建一个新的镜像，这就是新镜像的第一层；如果在该镜像中添加 Python包，就会在基础镜像层之上创建第二个镜像层；如果继续添加一个安全补丁，就会创建第三个镜像层。该镜像当前已经包含 3 个镜像层，如下图所示（这只是一个用于演示的很简单的例子）。</p><p><img src="/images/docker/docker-01/13.jpg" alt="13"></p><p>在添加额外的镜像层的同时，镜像始终保持是当前所有镜像的组合，理解这一点非常重要。下图中举了一个简单的例子，每个镜像层包含 3 个文件，而镜像包含了来自两个镜像层的 6 个文件。</p><p><img src="/images/docker/docker-01/14.jpg" alt="14"></p><p>上图中的镜像层跟之前图中的略有区别，主要目的是便于展示文件。</p><p>下图中展示了一个稍微复杂的三层镜像，在外部看来整个镜像只有 6 个文件，这是因为最上层中的文件 7 是文件 5 的一个更新版本。</p><p><img src="/images/docker/docker-01/15.jpg" alt="15"></p><p>这种情况下，上层镜像层中的文件覆盖了底层镜像层中的文件。这样就使得文件的更新版本作为一个新镜像层添加到镜像当中。</p><p>Docker 通过存储引擎（新版本采用快照机制）的方式来实现镜像层堆栈，并保证多镜像层对外展示为统一的文件系统。</p><p>Linux 上可用的存储引擎有 AUFS、Overlay2、Device Mapper、Btrfs 以及 ZFS。顾名思义，每种存储引擎都基于 Linux 中对应的文件系统或者块设备技术，并且每种存储引擎都有其独有的性能特点。</p><p>Docker 在 Windows 上仅支持 windowsfilter 一种存储引擎，该引擎基于 NTFS 文件系统之上实现了分层和 CoW<a href="/images/docker/docker-01/1.jpg">1</a>。</p><p>下图展示了与系统显示相同的三层镜像。所有镜像层堆叠并合并，对外提供统一的视图。</p><p><img src="/images/docker/docker-01/16.jpg" alt="16"></p><blockquote><p>Docker镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部！ 这一层就是我们通常说的容器层，容器之下的都叫镜像层！</p></blockquote><h2 id="容器操作"><a href="#容器操作" class="headerlink" title="容器操作"></a>容器操作</h2><h3 id="容器（Container）是什么？"><a href="#容器（Container）是什么？" class="headerlink" title="容器（Container）是什么？"></a>容器（Container）是什么？</h3><p>容器是基于镜像创建的可运行实例，并且单独存在，一个镜像可以创建出多个容器。运行容器化环境时，实际上是在容器内部创建该文件系统的读写副本。 这将添加一个容器层，该层允许修改镜像的整个副本。如图所示。</p><p><img src="/images/docker/docker-01/17.jpg" alt="容器组成"></p><h3 id="容器的生命周期"><a href="#容器的生命周期" class="headerlink" title="容器的生命周期"></a>容器的生命周期</h3><p>容器的生命周期是容器可能处于的状态，容器的生命周期分为 5 种。</p><ul><li>created：初建状态</li><li>running：运行状态</li><li>stopped：停止状态</li><li>paused： 暂停状态</li><li>deleted：删除状态</li></ul><p>各生命周期之前的转换关系如图所示：</p><p><img src="/images/docker/docker-01/18.jpg" alt="容器的生命周期"></p><p>通过<code>docker create</code>命令生成的容器状态为初建状态，初建状态通过<code>docker start</code>命令可以转化为运行状态，运行状态的容器可以通过<code>docker stop</code>命令转化为停止状态，处于停止状态的容器可以通过<code>docker start</code>转化为运行状态，运行状态的容器也可以通过<code>docker pause</code>命令转化为暂停状态，处于暂停状态的容器可以通过<code>docker unpause</code>转化为运行状态 。处于初建状态、运行状态、停止状态、暂停状态的容器都可以直接删除。</p><h3 id="容器的操作"><a href="#容器的操作" class="headerlink" title="容器的操作"></a>容器的操作</h3><p>容器的操作可以分为五个步骤：创建并启动容器、终止容器、进入容器、删除容器、导入和导出容器。</p><h4 id="创建并启动容器"><a href="#创建并启动容器" class="headerlink" title="创建并启动容器"></a>创建并启动容器</h4><p>容器十分轻量，用户可以随时创建和删除它。我们可以使用<code>docker create</code>命令来创建容器，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ docker create -it --name=busybox busybox</span><br><span class="line">Unable to find image <span class="string">'busybox:latest'</span> locally</span><br><span class="line">latest: Pulling from library/busybox</span><br><span class="line">61c5ed1cbdf8: Pull complete</span><br><span class="line">Digest: sha256:4f47c01fa91355af2865ac10fef5bf6ec9c7f42ad2321377c21e844427972977</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> busybox:latest</span><br><span class="line">2c2e919c2d6dad1f1712c65b3b8425ea656050bd5a0b4722f8b01526d5959ec6</span><br><span class="line">$ docker ps -a| grep busybox</span><br><span class="line">2c2e919c2d6d        busybox             <span class="string">"sh"</span>                     34 seconds ago      Created                                         busybox</span><br></pre></td></tr></table></figure><p>如果使用docker create命令创建的容器处于停止状态，我们可以使用docker start命令来启动它，如下所示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker start busybox</span><br><span class="line">$ docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line">d6f3d364fad3        busybox             <span class="string">"sh"</span>                16 seconds ago      Up 8 seconds                            busybox</span><br></pre></td></tr></table></figure><p>这时候我们可以看到容器已经处于启动状态了。</p><p>容器启动有两种方式：</p><ul><li><p>使用docker start命令基于已经创建好的容器直接启动 。</p></li><li><p>使用docker run命令直接基于镜像新建一个容器并启动，相当于先执行docker create命令从镜像创建容器，然后再执行docker start命令启动容器。</p></li></ul><p>使用docker run的命令如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --name=busybox busybox</span><br></pre></td></tr></table></figure><p>当使用<code>docker run</code>创建并启动容器时，Docker 后台执行的流程为：</p><ul><li>Docker 会检查本地是否存在 busybox 镜像，如果镜像不存在则从 Docker Hub 拉取 busybox 镜像；</li><li>使用 busybox 镜像创建并启动一个容器；</li><li>分配文件系统，并且在镜像只读层外创建一个读写层；</li><li>从 Docker IP 池中分配一个 IP 给容器；</li><li>执行用户的启动命令运行镜像。</li></ul><p>上述命令中， -t 参数的作用是分配一个伪终端，-i 参数则可以终端的 STDIN 打开，同时使用 -it 参数可以让我们进入交互模式。 在交互模式下，用户可以通过所创建的终端来输入命令，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ps aux</span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 sh</span><br><span class="line">    6 root      0:00 ps aux</span><br></pre></td></tr></table></figure><p>我们可以看到容器的 1 号进程为 sh 命令，在容器内部并不能看到主机上的进程信息，因为容器内部和主机是完全隔离的。同时由于 sh 是 1 号进程，意味着如果通过 exit 退出 sh，那么容器也会退出。所以对于容器来说，<code>杀死容器中的主进程，则容器也会被杀死</code>。</p><blockquote><p>Docker容器后台运行，就必须有一个前台进程，容器运行的命令如果不是那些一直挂起的命令，就会自动退出。<br>比如，你运行了nginx服务，但是docker前台没有运行应用，这种情况下，容器启动后，会立即自杀，因为他觉得没有程序了，所以最好的情况是，将你的应用使用前台进程的方式运行启动。<br>容器本质是进程，启动需要一个不能退出的命令作为主进程。</p></blockquote><h4 id="终止容器"><a href="#终止容器" class="headerlink" title="终止容器"></a>终止容器</h4><p>容器启动后，如果我们想停止运行中的容器，可以使用docker stop命令。命令格式为 <code>docker stop [-t|--time[=10]]</code>。该命令首先会向运行中的容器发送 SIGTERM 信号，如果容器内 1 号进程接受并能够处理 SIGTERM，则等待 1 号进程处理完毕后退出，如果等待一段时间后，容器仍然没有退出，则会发送 SIGKILL 强制终止容器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker stop busybox</span><br><span class="line">busybox</span><br></pre></td></tr></table></figure><p>如果你想查看停止状态的容器信息，你可以使用 docker ps -a 命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps -a</span><br><span class="line">CONTAINERID       IMAGE      COMMAND            CREATED             STATUS     PORTS         NAMES</span><br><span class="line">28d477d3737a        busybox             <span class="string">"sh"</span>                26 minutes ago      Exited (137) About a minute ago                       busybox</span><br></pre></td></tr></table></figure><blockquote><p>处于终止状态的容器也可以通过docker start命令来重新启动。</p></blockquote><p>此外，<code>docker restart</code> 命令会将一个运行中的容器终止，并且重新启动它。</p><h4 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h4><p>处于运行状态的容器可以通过<code>docker attach</code>、<code>docker exec</code>、<code>nsenter</code>等多种方式进入容器。</p><ul><li><strong>使用docker attach命令进入容器</strong></li></ul><p>使用 docker attach ，进入我们上一步创建好的容器，如下所示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker attach busybox</span><br><span class="line">/ <span class="comment"># ps aux</span></span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 sh</span><br><span class="line">    7 root      0:00 ps aux</span><br><span class="line">/ <span class="comment">#</span></span><br></pre></td></tr></table></figure><p>注意：当我们同时使用<code>docker attach</code>命令同时在多个终端运行时，所有的终端窗口将同步显示相同内容，当某个命令行窗口的命令阻塞时，其他命令行窗口同样也无法操作。</p><p>由于<code>docker attach</code>命令不够灵活，因此我们一般不会使用<code>docker attach</code>进入容器。下面我介绍一个更加灵活的进入容器的方式<code>docker exec</code></p><ul><li><strong>使用 docker exec 命令进入容器</strong></li></ul><p>Docker 从 1.3 版本开始，提供了一个更加方便地进入容器的命令<code>docker exec</code>，我们可以通过<code>docker exec -it CONTAINER</code>的方式进入到一个已经运行中的容器，如下所示。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker <span class="built_in">exec</span> -it busybox sh</span><br><span class="line">/ <span class="comment"># ps aux</span></span><br><span class="line">PID   USER     TIME  COMMAND</span><br><span class="line">    1 root      0:00 sh</span><br><span class="line">    7 root      0:00 sh</span><br><span class="line">   12 root      0:00 ps aux</span><br></pre></td></tr></table></figure><p>我们进入容器后，可以看到容器内有两个sh进程，这是因为以exec的方式进入容器，会单独启动一个 sh 进程，每个窗口都是独立且互不干扰的，也是使用最多的一种方式。</p><h4 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h4><p>我们已经掌握了用 Docker 命令创建、启动和终止容器。那如何删除处于终止状态或者运行中的容器呢？删除容器命令的使用方式如下：<code>docker rm [OPTIONS] CONTAINER [CONTAINER...]</code>。</p><p>如果要删除一个停止状态的容器，可以使用<code>docker rm</code>命令删除。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm busybox</span><br></pre></td></tr></table></figure><p>如果要删除正在运行中的容器，必须添加 -f (或 –force) 参数， Docker 会发送 SIGKILL 信号强制终止正在运行的容器。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm -f busybox</span><br></pre></td></tr></table></figure><h4 id="导出导入容器"><a href="#导出导入容器" class="headerlink" title="导出导入容器"></a>导出导入容器</h4><ul><li><strong>导出容器</strong></li></ul><p>我们可以使用<code>docker export CONTAINER</code>命令导出一个容器到文件，不管此时该容器是否处于运行中的状态。导出容器前我们先进入容器，创建一个文件，过程如下。</p><p>首先进入容器创建文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it busybox sh</span><br><span class="line"><span class="built_in">cd</span> /tmp &amp;&amp; touch <span class="built_in">test</span></span><br></pre></td></tr></table></figure><p>然后执行导出命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">export</span> busybox &gt; busybox.tar</span><br></pre></td></tr></table></figure><p>执行以上命令后会在当前文件夹下生成 busybox.tar 文件，我们可以将该文件拷贝到其他机器上，通过导入命令实现容器的迁移。</p><ul><li><strong>导入容器</strong></li></ul><p>通过<code>docker export</code>命令导出的文件，可以使用<code>docker import</code>命令导入，执行完<code>docker import</code>后会变为本地镜像，最后再使用<code>docker run</code>命令启动该镜像，这样我们就实现了容器的迁移。</p><p>导入容器的命令格式为 <code>docker import [OPTIONS] file|URL [REPOSITORY[:TAG]]</code>。接下来我们一步步将上一步导出的镜像文件导入到其他机器的 Docker 中并启动它。</p><p>首先，使用<code>docker import</code>命令导入上一步导出的容器</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker import busybox.tar busybox:<span class="built_in">test</span></span><br></pre></td></tr></table></figure><p>此时，busybox.tar 被导入成为新的镜像，镜像名称为 busybox:test 。下面，我们使用docker run命令启动并进入容器，查看上一步创建的临时文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run -it busybox:<span class="built_in">test</span> sh</span><br><span class="line">/ <span class="comment"># ls /tmp/</span></span><br><span class="line"><span class="built_in">test</span></span><br></pre></td></tr></table></figure><p>可以看到我们之前在 /tmp 目录下创建的 test 文件也被迁移过来了。这样我们就通过docker export和docker import命令配合实现了容器的迁移。</p><h2 id="仓库访问"><a href="#仓库访问" class="headerlink" title="仓库访问"></a>仓库访问</h2><h3 id="仓库是什么？"><a href="#仓库是什么？" class="headerlink" title="仓库是什么？"></a>仓库是什么？</h3><p>仓库（Repository）是存储和分发 Docker 镜像的地方。镜像仓库类似于代码仓库，Docker Hub 的命名来自 GitHub，Github 是我们常用的代码存储和分发的地方。同样 Docker Hub 是用来提供 Docker 镜像存储和分发的地方。</p><p>有的同学可能经常分不清注册服务器（Registry）和仓库（Repository）的概念。在这里我可以解释下这两个概念的区别：注册服务器是存放仓库的实际服务器，而仓库则可以被理解为一个具体的项目或者目录；注册服务器可以包含很多个仓库，每个仓库又可以包含多个镜像。例如我的镜像地址为 docker.io/centos，docker.io 是注册服务器，centos 是仓库名。 它们之间的关系如图所示。</p><p><img src="/images/docker/docker-01/19.jpg" alt="注册服务器、仓库和镜像的关系"></p><h3 id="公共镜像仓库"><a href="#公共镜像仓库" class="headerlink" title="公共镜像仓库"></a>公共镜像仓库</h3><p>公共镜像仓库一般是 Docker 官方或者其他第三方组织（阿里云，腾讯云，网易云等）提供的，允许所有人注册和使用的镜像仓库。</p><p>Docker Hub 是全球最大的镜像市场，目前已经有超过 10w 个容器镜像，这些容器镜像主要来自软件供应商、开源组织和社区。大部分的操作系统镜像和软件镜像都可以直接在 Docker Hub 下载并使用。</p><p>我们首先访问<a href="https://hub.docker.com" target="_blank" rel="noopener">Docker Hub</a>官网，点击注册按钮进入注册账号界面。</p><p>注册完成后，我们可以点击创建仓库，新建一个仓库用于推送镜像。</p><p>在推送镜像仓库前，我们需要使用<code>docker login</code>命令先登录一下镜像服务器，因为只有已经登录的用户才可以推送镜像到仓库。</p><p>使用<code>docker login</code>命令登录镜像服务器，这时 Docker 会要求我们输入用户名和密码，输入我们刚才注册的账号和密码，看到<code>Login Succeeded</code>表示登录成功。登录成功后就可以推送镜像到自己创建的仓库了。</p><blockquote><p><code>docker login</code>命令默认会请求 Docker Hub，如果你想登录第三方镜像仓库或者自建的镜像仓库，在<code>docker login</code>后面加上注册服务器即可。例如我们想登录访问阿里云镜像服务器，则使用<code>docker login registry.cn-beijing.aliyuncs.com</code>，输入阿里云镜像服务的用户名密码即可。</p></blockquote><p>在本地镜像推送到自定义仓库前，我们需要先把镜像“重命名”一下，才能正确推送到自己创建的镜像仓库中，使用<code>docker tag</code>命令将镜像“重命名”：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker tag busybox lagoudocker/busybox</span><br></pre></td></tr></table></figure><p>镜像“重命名”后使用docker push命令就可以推送镜像到自己创建的仓库中了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker push lagoudocker/busybox</span><br><span class="line">The push refers to repository [docker.io/lagoudocker/busybox]</span><br><span class="line">514c3a3e64d4: Mounted from library/busybox</span><br><span class="line">latest: digest: sha256:400ee2ed939df769d4681023810d2e4fb9479b8401d97003c710d0e20f7c49c6 size: 527</span><br></pre></td></tr></table></figure><p>此时，busybox这个镜像就被推送到自定义的镜像仓库了。这里我们也可以新建其他的镜像仓库，然后把自己构建的镜像推送到仓库中。</p><p>有时候，出于安全或保密的需求，你可能想要搭建一个自己的镜像仓库，下面我带你一步一步构建一个私有的镜像仓库。</p><h3 id="搭建私有仓库"><a href="#搭建私有仓库" class="headerlink" title="搭建私有仓库"></a>搭建私有仓库</h3><h4 id="启动本地仓库"><a href="#启动本地仓库" class="headerlink" title="启动本地仓库"></a>启动本地仓库</h4><p>Docker 官方提供了开源的镜像仓库 <a href="https://github.com/docker/distribution" target="_blank" rel="noopener">Distribution</a>，并且镜像存放在 Docker Hub 的 <a href="https://hub.docker.com/_/registry" target="_blank" rel="noopener">Registry</a> 仓库下供我们下载。</p><p>我们可以使用以下命令启动一个本地镜像仓库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d -p 5000:5000 --name registry registry:2.7</span><br><span class="line">Unable to find image <span class="string">'registry:2.7'</span> locally</span><br><span class="line">2.7: Pulling from library/registry</span><br><span class="line">cbdbe7a5bc2a: Pull complete</span><br><span class="line">47112e65547d: Pull complete</span><br><span class="line">46bcb632e506: Pull complete</span><br><span class="line">c1cc712bcecd: Pull complete</span><br><span class="line">3db6272dcbfa: Pull complete</span><br><span class="line">Digest: sha256:8be26f81ffea54106bae012c6f349df70f4d5e7e2ec01b143c46e2c03b9e551d</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> registry:2.7</span><br><span class="line">d7e449a8a93e71c9a7d99c67470bd7e7a723eee5ae97b3f7a2a8a1cf25982cc3</span><br></pre></td></tr></table></figure><p>使用docker ps命令查看一下刚才启动的容器</p><p>此时我们就拥有了一个私有镜像仓库，访问地址为localhost，端口号为 5000。</p><h4 id="推送镜像到本地仓库"><a href="#推送镜像到本地仓库" class="headerlink" title="推送镜像到本地仓库"></a>推送镜像到本地仓库</h4><p>我们依旧使用 busybox 镜像举例。首先我们使用docker tag命令把 busybox 镜像”重命名”为<code>localhost:5000/busybox</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker tag busybox localhost:5000/busybox</span><br></pre></td></tr></table></figure><p>此时 Docker 为busybox镜像创建了一个别名localhost:5000/busybox，localhost:5000为主机名和端口，Docker 将会把镜像推送到这个地址。</p><p>使用docker push推送镜像到本地仓库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker push localhost:5000/busybox</span><br><span class="line">The push refers to repository [localhost:5000/busybox]</span><br><span class="line">514c3a3e64d4: Layer already exists</span><br><span class="line">latest: digest: sha256:400ee2ed939df769d4681023810d2e4fb9479b8401d97003c710d0e20f7c49c6 size: 527</span><br></pre></td></tr></table></figure><p>这里可以看到，我们已经可以把busybox推送到了本地镜像仓库。</p><p>此时，我们验证一下从本地镜像仓库拉取镜像。首先，我们删除本地的busybox和<code>localhost:5000/busybox</code>镜像。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker rmi busybox localhost:5000/busybox</span><br><span class="line">Untagged: busybox:latest</span><br><span class="line">Untagged: busybox@sha256:4f47c01fa91355af2865ac10fef5bf6ec9c7f42ad2321377c21e844427972977</span><br><span class="line">Untagged: localhost:5000/busybox:latest</span><br><span class="line">Untagged: localhost:5000/busybox@sha256:400ee2ed939df769d4681023810d2e4fb9479b8401d97003c710d0e20f7c49c6</span><br></pre></td></tr></table></figure><p><code>docker image ls busybox</code> 可以看到此时本地已经没有busybox这个镜像了。下面，我们从本地镜像仓库拉取busybox镜像：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker pull localhost:5000/busybox</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from busybox</span><br><span class="line">Digest: sha256:400ee2ed939df769d4681023810d2e4fb9479b8401d97003c710d0e20f7c49c6</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> localhost:5000/busybox:latest</span><br><span class="line">localhost:5000/busybox:latest</span><br></pre></td></tr></table></figure><h4 id="持久化镜像存储"><a href="#持久化镜像存储" class="headerlink" title="持久化镜像存储"></a>持久化镜像存储</h4><p>我们知道，容器是无状态的。上面私有仓库的启动方式可能会导致镜像丢失，因为我们并没有把仓库的数据信息持久化到主机磁盘上，这在生产环境中是无法接受的。下面我们使用以下命令将镜像持久化到主机目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -v /var/lib/registry/data:/var/lib/registry -d -p 5000:5000 --name registry registry:2.7</span><br></pre></td></tr></table></figure><p>我们在上面启动registry的命令中加入了<code>-v /var/lib/registry/data:/var/lib/registry</code>，-v的含义是把 Docker 容器的某个目录或文件挂载到主机上，保证容器被重建后数据不丢失。-v参数冒号前面为主机目录，冒号后面为容器内目录。</p><blockquote><p>事实上，registry 的持久化存储除了支持本地文件系统还支持很多种类型，例如 S3、Google Cloud Platform、Microsoft Azure Blob Storage Service 等多种存储类型。</p></blockquote><p>到这里我们的镜像仓库虽然可以本地访问和拉取，但是如果你在另外一台机器上是无法通过 Docker 访问到这个镜像仓库的，因为 Docker 要求非localhost访问的镜像仓库必须使用 HTTPS，这时候就需要构建外部可访问的镜像仓库。</p><h4 id="构建外部可访问的镜像仓库"><a href="#构建外部可访问的镜像仓库" class="headerlink" title="构建外部可访问的镜像仓库"></a>构建外部可访问的镜像仓库</h4><p>要构建一个支持 HTTPS 访问的安全镜像仓库，需要满足以下两个条件：</p><ul><li>拥有一个合法的域名，并且可以正确解析到镜像服务器；</li><li>从证书颁发机构（CA）获取一个证书。</li></ul><p>在准备好域名和证书后，就可以部署我们的镜像服务器了。这里我以<code>regisry.lagoudocker.io</code>这个域名为例。首先准备存放证书的目录<code>/var/lib/registry/certs</code>，然后把申请到的证书私钥和公钥分别放到该目录下。 假设我们申请到的证书文件分别为<code>regisry.lagoudocker.io.crt</code>和<code>regisry.lagoudocker.io.key</code>。</p><p>如果上一步启动的仓库容器还在运行，我们需要先停止并删除它。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker stop registry &amp;&amp; docker rm registry</span><br></pre></td></tr></table></figure><p>然后使用以下命令启动新的镜像仓库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -d \</span><br><span class="line">  --name registry \</span><br><span class="line">  -v <span class="string">"/var/lib/registry/data:/var/lib/registry \</span></span><br><span class="line"><span class="string">  -v "</span>/var/lib/registry/certs:/certs \</span><br><span class="line">  -e REGISTRY_HTTP_ADDR=0.0.0.0:443 \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/regisry.lagoudocker.io.crt \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_KEY=/certs/regisry.lagoudocker.io.key \</span><br><span class="line">  -p 443:443 \</span><br><span class="line">  registry:2.7</span><br></pre></td></tr></table></figure><p>这里，我们使用 -v 参数把镜像数据持久化在/var/lib/registry/data目录中，同时把主机上的证书文件挂载到了容器的 /certs 目录下，同时通过 -e 参数设置 HTTPS 相关的环境变量参数，最后让仓库在主机上监听 443 端口。</p><p>仓库启动后，我们就可以远程推送镜像了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker tag busybox regisry.lagoudocker.io/busybox</span><br><span class="line">$ docker push regisry.lagoudocker.io/busybox</span><br></pre></td></tr></table></figure><h4 id="私有仓库进阶"><a href="#私有仓库进阶" class="headerlink" title="私有仓库进阶"></a>私有仓库进阶</h4><p>Docker 官方开源的镜像仓库<code>Distribution</code>仅满足了镜像存储和管理的功能，用户权限管理相对较弱，并且没有管理界面。</p><p>如果你想要构建一个企业的镜像仓库，<a href="https://goharbor.io/" target="_blank" rel="noopener">Harbor</a> 是一个非常不错的解决方案。Harbor 是一个基于<code>Distribution</code>项目开发的一款企业级镜像管理软件，拥有 RBAC （基于角色的访问控制）、管理用户界面以及审计等非常完善的功能。目前已经从 CNCF 毕业，这代表它已经有了非常高的软件成熟度。</p><p>Harbor 的使命是成为 Kubernetes 信任的云原生镜像仓库。 Harbor 需要结合 Kubernetes 才能发挥其最大价值，因此，在这里我就不展开介绍 Harbor 了。如果你对 Harbor 构建企业级镜像仓库感兴趣，可以到它的官网了解更多。</p><h2 id="在生产中编写最优-Dockerfile"><a href="#在生产中编写最优-Dockerfile" class="headerlink" title="在生产中编写最优 Dockerfile"></a>在生产中编写最优 Dockerfile</h2><p>这里再强调一下，<strong>生产实践中一定优先使用 Dockerfile 的方式构建镜像。</strong> 因为使用 Dockerfile 构建镜像可以带来很多好处：</p><ul><li>易于版本化管理，Dockerfile 本身是一个文本文件，方便存放在代码仓库做版本管理，可以很方便地找到各个版本之间的变更历史；</li><li>过程可追溯，Dockerfile 的每一行指令代表一个镜像层，根据 Dockerfile 的内容即可很明确地查看镜像的完整构建过程；</li><li>屏蔽构建环境异构，使用 Dockerfile 构建镜像无须考虑构建环境，基于相同 Dockerfile 无论在哪里运行，构建结果都一致。</li></ul><p>虽然有这么多好处，但是如果你 Dockerfile 使用不当也会引发很多问题。比如镜像构建时间过长，甚至镜像构建失败；镜像层数过多，导致镜像文件过大。所以，接下来就介绍如何在生产环境中编写最优的 Dockerfile。</p><p>在介绍 Dockerfile 最佳实践前，我们再聊一下我们平时书写 Dockerfile 应该尽量遵循的原则。</p><h3 id="Dockerfile-书写原则"><a href="#Dockerfile-书写原则" class="headerlink" title="Dockerfile 书写原则"></a>Dockerfile 书写原则</h3><p>遵循以下 Dockerfile 书写原则，不仅可以使得我们的 Dockerfile 简洁明了，让协作者清楚地了解镜像的完整构建流程，还可以帮助我们减少镜像的体积，加快镜像构建的速度和分发速度。</p><h4 id="（1）单一职责"><a href="#（1）单一职责" class="headerlink" title="（1）单一职责"></a>（1）单一职责</h4><p>由于容器的本质是进程，一个容器代表一个进程，因此不同功能的应用应该尽量拆分为不同的容器，每个容器只负责单一业务进程。</p><h4 id="（2）提供注释信息"><a href="#（2）提供注释信息" class="headerlink" title="（2）提供注释信息"></a>（2）提供注释信息</h4><p>Dockerfile 也是一种代码，我们应该保持良好的代码编写习惯，晦涩难懂的代码尽量添加注释，让协作者可以一目了然地知道每一行代码的作用，并且方便扩展和使用。</p><h4 id="（3）保持容器最小化"><a href="#（3）保持容器最小化" class="headerlink" title="（3）保持容器最小化"></a>（3）保持容器最小化</h4><p>应该避免安装无用的软件包，比如在一个 nginx 镜像中，我并不需要安装 vim 、gcc 等开发编译工具。这样不仅可以加快容器构建速度，而且可以避免镜像体积过大。</p><h4 id="（4）合理选择基础镜像"><a href="#（4）合理选择基础镜像" class="headerlink" title="（4）合理选择基础镜像"></a>（4）合理选择基础镜像</h4><p>容器的核心是应用，因此只要基础镜像能够满足应用的运行环境即可。例如一个<code>Java</code>类型的应用运行时只需要<code>JRE</code>，并不需要<code>JDK</code>，因此我们的基础镜像只需要安装<code>JRE</code>环境即可。</p><h4 id="（5）使用-dockerignore-文件"><a href="#（5）使用-dockerignore-文件" class="headerlink" title="（5）使用 .dockerignore 文件"></a>（5）使用 .dockerignore 文件</h4><p>在使用<code>git</code>时，我们可以使用<code>.gitignore</code>文件忽略一些不需要做版本管理的文件。同理，使用<code>.dockerignore</code>文件允许我们在构建时，忽略一些不需要参与构建的文件，从而提升构建效率。<code>.dockerignore</code>的定义类似于<code>.gitignore</code>。</p><p><code>.dockerignore</code>的本质是文本文件，Docker 构建时可以使用换行符来解析文件定义，每一行可以忽略一些文件或者文件夹。具体使用方式如下：</p><table><thead><tr><th>规则</th><th>含义</th></tr></thead><tbody><tr><td>#</td><td># 开头的表示注释，# 后面所有内容将会被忽略</td></tr><tr><td><em>/tmp</em></td><td>匹配当前目录下任何以 tmp 开头的文件或者文件夹</td></tr><tr><td>*.md</td><td>匹配以 .md 为后缀的任意文件</td></tr><tr><td>tem?</td><td>匹配以 tem 开头并且以任意字符结尾的文件，？代表任意一个字符</td></tr><tr><td>!README.md</td><td>! 表示排除忽略。 例如 .dockerignore 定义如下：  *.md !README.md  表示除了 README.md 文件外所有以 .md 结尾的文件。</td></tr></tbody></table><h4 id="（6）尽量使用构建缓存"><a href="#（6）尽量使用构建缓存" class="headerlink" title="（6）尽量使用构建缓存"></a>（6）尽量使用构建缓存</h4><p>Docker 构建过程中，每一条 Dockerfile 指令都会提交为一个镜像层，下一条指令都是基于上一条指令构建的。如果构建时发现要构建的镜像层的父镜像层已经存在，并且下一条命令使用了相同的指令，即可命中构建缓存。</p><p>Docker 构建时判断是否需要使用缓存的规则如下：</p><ul><li>从当前构建层开始，比较所有的子镜像，检查所有的构建指令是否与当前完全一致，如果不一致，则不使用缓存；</li><li>一般情况下，只需要比较构建指令即可判断是否需要使用缓存，但是有些指令除外（例如<code>ADD</code>和<code>COPY</code>）；</li><li>对于<code>ADD</code>和<code>COPY</code>指令不仅要校验命令是否一致，还要为即将拷贝到容器的文件计算校验和（根据文件内容计算出的一个数值，如果两个文件计算的数值一致，表示两个文件内容一致 ），命令和校验和完全一致，才认为命中缓存。</li></ul><p>因此，基于 Docker 构建时的缓存特性，我们可以把不轻易改变的指令放到 Dockerfile 前面（例如安装软件包），而可能经常发生改变的指令放在 Dockerfile 末尾（例如编译应用程序）。</p><p>例如，我们想要定义一些环境变量并且安装一些软件包，可以按照如下顺序编写 Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">7</span></span><br><span class="line"><span class="comment"># 设置环境变量指令放前面</span></span><br><span class="line"><span class="keyword">ENV</span> PATH /usr/local/bin:$PATH</span><br><span class="line"><span class="comment"># 安装软件指令放前面</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y make</span></span><br><span class="line"><span class="comment"># 把业务软件的配置,版本等经常变动的步骤放最后</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>按照上面原则编写的 Dockerfile 在构建镜像时，前面步骤命中缓存的概率会增加，可以大大缩短镜像构建时间。</p><h4 id="（7）正确设置时区"><a href="#（7）正确设置时区" class="headerlink" title="（7）正确设置时区"></a>（7）正确设置时区</h4><p>我们从 Docker Hub 拉取的官方操作系统镜像大多数都是 UTC 时间（世界标准时间）。如果你想要在容器中使用中国区标准时间（东八区），请根据使用的操作系统修改相应的时区信息，下面我介绍几种常用操作系统的修改方式：</p><ul><li><strong>Ubuntu 和Debian 系统</strong></li></ul><p>Ubuntu 和Debian 系统可以向 Dockerfile 中添加以下指令：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">"Asia/Shanghai"</span> &gt;&gt; /etc/timezone</span></span><br></pre></td></tr></table></figure><ul><li><strong>CentOS系统</strong></li></ul><p>CentOS 系统则向 Dockerfile 中添加以下指令：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span></span><br></pre></td></tr></table></figure><h4 id="（8）使用国内软件源加快镜像构建速度"><a href="#（8）使用国内软件源加快镜像构建速度" class="headerlink" title="（8）使用国内软件源加快镜像构建速度"></a>（8）使用国内软件源加快镜像构建速度</h4><p>由于我们常用的官方操作系统镜像基本都是国外的，软件服务器大部分也在国外，所以我们构建镜像的时候想要安装一些软件包可能会非常慢。</p><p>这里我以 CentOS 7 为例，介绍一下如何使用 163 软件源（国内有很多大厂，例如阿里、腾讯、网易等公司都免费提供的软件加速源）加快镜像构建。</p><p>首先在容器构建目录创建文件 CentOS7-Base-163.repo，文件内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CentOS-Base.repo</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The mirror system uses the connecting IP address of the client and the</span></span><br><span class="line"><span class="comment"># update status of each mirror to pick mirrors that are updated to and</span></span><br><span class="line"><span class="comment"># geographically close to the client.  You should use this for CentOS updates</span></span><br><span class="line"><span class="comment"># unless you are manually picking other mirrors.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># If the mirrorlist= does not work for you, as a fall back you can try the </span></span><br><span class="line"><span class="comment"># remarked out baseurl= line instead.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">[base]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Base - 163.com</span><br><span class="line"><span class="comment">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=os</span></span><br><span class="line">baseurl=http://mirrors.163.com/centos/<span class="variable">$releasever</span>/os/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7</span><br><span class="line"><span class="comment">#released updates</span></span><br><span class="line">[updates]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Updates - 163.com</span><br><span class="line"><span class="comment">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=updates</span></span><br><span class="line">baseurl=http://mirrors.163.com/centos/<span class="variable">$releasever</span>/updates/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7</span><br><span class="line"><span class="comment">#additional packages that may be useful</span></span><br><span class="line">[extras]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Extras - 163.com</span><br><span class="line"><span class="comment">#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=extras</span></span><br><span class="line">baseurl=http://mirrors.163.com/centos/<span class="variable">$releasever</span>/extras/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7</span><br><span class="line"><span class="comment">#additional packages that extend functionality of existing packages</span></span><br><span class="line">[centosplus]</span><br><span class="line">name=CentOS-<span class="variable">$releasever</span> - Plus - 163.com</span><br><span class="line">baseurl=http://mirrors.163.com/centos/<span class="variable">$releasever</span>/centosplus/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=0</span><br><span class="line">gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7</span><br></pre></td></tr></table></figure><p>然后在 Dockerfile 中添加如下指令：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">COPY</span><span class="bash"> CentOS7-Base-163.repo /etc/yum.repos.d/CentOS7-Base.repo</span></span><br></pre></td></tr></table></figure><p>执行完上述步骤后，再使用yum install命令安装软件时就会默认从 163 获取软件包，这样可以大大提升构建速度。</p><h4 id="（9）最小化镜像层数"><a href="#（9）最小化镜像层数" class="headerlink" title="（9）最小化镜像层数"></a>（9）最小化镜像层数</h4><p>在构建镜像时尽可能地减少 Dockerfile 指令行数。例如我们要在 CentOS 系统中安装<code>make</code>和<code>net-tools</code>两个软件包，应该在 Dockerfile 中使用以下指令：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y make net-tools</span></span><br></pre></td></tr></table></figure><p>而不应该写成这样：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y make</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y net-tools</span></span><br></pre></td></tr></table></figure><p>了解完 Dockerfile 的书写原则后，我们再来具体了解下这些原则落实到具体的 Dockerfile 指令应该如何书写。</p><h3 id="Dockerfile-指令书写建议"><a href="#Dockerfile-指令书写建议" class="headerlink" title="Dockerfile 指令书写建议"></a>Dockerfile 指令书写建议</h3><p>下面是我们常用的一些指令，这些指令对于刚接触 Docker 的人来说会非常容易出错，下面我对这些指令的书写建议详细讲解一下。</p><h4 id="（1）RUN"><a href="#（1）RUN" class="headerlink" title="（1）RUN"></a>（1）RUN</h4><p><code>RUN</code>指令在构建时将会生成一个新的镜像层并且执行<code>RUN</code>指令后面的内容。</p><p>使用<code>RUN</code>指令时应该尽量遵循以下原则：</p><ul><li>当<code>RUN</code>指令后面跟的内容比较复杂时，建议使用反斜杠（\） 结尾并且换行；</li><li><code>RUN</code>指令后面的内容尽量按照字母顺序排序，提高可读性。</li></ul><p>例如，我想在官方的 CentOS 镜像下安装一些软件，一个建议的 Dockerfile 指令如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> centos:<span class="number">7</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> yum install -y automake \</span></span><br><span class="line"><span class="bash">                   curl \</span></span><br><span class="line"><span class="bash">                   python \</span></span><br><span class="line"><span class="bash">                   vim</span></span><br></pre></td></tr></table></figure><h4 id="（2）CMD-和-ENTRYPOINT"><a href="#（2）CMD-和-ENTRYPOINT" class="headerlink" title="（2）CMD 和 ENTRYPOINT"></a>（2）CMD 和 ENTRYPOINT</h4><p><code>CMD</code>和<code>ENTRYPOINT</code>指令都是容器运行的命令入口，这两个指令使用中有很多相似的地方，但是也有一些区别。</p><p>这两个指令的相同之处，<code>CMD</code>和<code>ENTRYPOINT</code>的基本使用格式分为两种。</p><ul><li>第一种为<code>CMD</code>/<code>ENTRYPOINT</code>[“command” , “param”]。这种格式是使用 Linux 的<code>exec</code>实现的， 一般称为<code>exec</code>模式，这种书写格式为<code>CMD</code>/<code>ENTRYPOINT</code>后面跟 json 数组，也是Docker 推荐的使用格式。</li><li>另外一种格式为<code>CMD</code>/<code>ENTRYPOINT</code>command param ，这种格式是基于 shell 实现的， 通常称为<code>shell</code>模式。当使用<code>shell</code>模式时，Docker 会以 /bin/sh -c command 的方式执行命令。</li></ul><blockquote><p>使用 exec 模式启动容器时，容器的 1 号进程就是 CMD/ENTRYPOINT 中指定的命令，而使用 shell 模式启动容器时相当于我们把启动命令放在了 shell 进程中执行，等效于执行 /bin/sh -c “task command” 命令。因此 shell 模式启动的进程在容器中实际上并不是 1 号进程。</p></blockquote><p>这两个指令的区别：</p><ul><li>Dockerfile 中如果使用了<code>ENTRYPOINT</code>指令，启动 Docker 容器时需要使用 –entrypoint 参数才能覆盖 Dockerfile 中的<code>ENTRYPOINT</code>指令 ，而使用<code>CMD</code>设置的命令则可以被<code>docker run</code>后面的参数直接覆盖。</li><li><code>ENTRYPOINT</code>指令可以结合<code>CMD</code>指令使用，也可以单独使用，而<code>CMD</code>指令只能单独使用。</li></ul><p>看到这里你也许会问，我什么时候应该使用<code>ENTRYPOINT</code>,什么时候使用<code>CMD</code>呢？</p><p>如果你希望你的镜像足够灵活，推荐使用<code>CMD</code>指令。如果你的镜像只执行单一的具体程序，并且不希望用户在执行<code>docker run</code>时覆盖默认程序，建议使用<code>ENTRYPOINT</code>。</p><p>最后再强调一下，无论使用<code>CMD</code>还是<code>ENTRYPOINT</code>，都尽量使用<code>exec</code>模式。</p><h4 id="（3）ADD-和-COPY"><a href="#（3）ADD-和-COPY" class="headerlink" title="（3）ADD 和 COPY"></a>（3）ADD 和 COPY</h4><p><code>ADD</code>和<code>COPY</code>指令功能类似，都是从外部往容器内添加文件。但是<code>COPY</code>指令只支持基本的文件和文件夹拷贝功能，<code>ADD</code>则支持更多文件来源类型，比如自动提取 tar 包，并且可以支持源文件为 URL 格式。</p><p>那么在日常应用中，我们应该使用哪个命令向容器里添加文件呢？你可能在想，既然<code>ADD</code>指令支持的功能更多，当然应该使用<code>ADD</code>指令了。然而事实恰恰相反，我更推荐你使用<code>COPY</code>指令，因为<code>COPY</code>指令更加透明，仅支持本地文件向容器拷贝，而且使用<code>COPY</code>指令可以更好地利用构建缓存，有效减小镜像体积。</p><p>当你想要使用<code>ADD</code>向容器中添加 URL 文件时，请尽量考虑使用其他方式替代。例如你想要在容器中安装 memtester（一种内存压测工具），你应该避免使用以下格式：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ADD</span><span class="bash"> http://pyropus.ca/software/memtester/old-versions/memtester-4.3.0.tar.gz /tmp/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> tar -xvf /tmp/memtester-4.3.0.tar.gz -C /tmp</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> make -C /tmp/memtester-4.3.0 &amp;&amp; make -C /tmp/memtester-4.3.0 install</span></span><br></pre></td></tr></table></figure><p>下面是推荐写法：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> wget -O /tmp/memtester-4.3.0.tar.gz http://pyropus.ca/software/memtester/old-versions/memtester-4.3.0.tar.gz \</span></span><br><span class="line"><span class="bash">&amp;&amp; tar -xvf /tmp/memtester-4.3.0.tar.gz -C /tmp \</span></span><br><span class="line"><span class="bash">&amp;&amp; make -C /tmp/memtester-4.3.0 &amp;&amp; make -C /tmp/memtester-4.3.0 install</span></span><br></pre></td></tr></table></figure><h4 id="（4）WORKDIR"><a href="#（4）WORKDIR" class="headerlink" title="（4）WORKDIR"></a>（4）WORKDIR</h4><p>为了使构建过程更加清晰明了，推荐使用 WORKDIR 来指定容器的工作路径，应该尽量避免使用 RUN cd /work/path &amp;&amp; do some work 这样的指令。</p><p>最后给出几个常用软件的官方 Dockerfile 示例链接，希望可以对你有所帮助。</p><ul><li><a href="https://github.com/docker-library/golang/blob/4d68c4dd8b51f83ce4fdce0f62484fdc1315bfa8/1.15/buster/Dockerfile" target="_blank" rel="noopener">Go</a></li><li><a href="https://github.com/nginxinc/docker-nginx/blob/9774b522d4661effea57a1fbf64c883e699ac3ec/mainline/buster/Dockerfile" target="_blank" rel="noopener">Nginx</a></li><li><a href="https://github.com/hylang/docker-hylang/blob/f9c873b7f71f466e5af5ea666ed0f8f42835c688/dockerfiles-generated/Dockerfile.python3.8-buster" target="_blank" rel="noopener">Hy</a></li></ul><h2 id="Docker-安全：基于内核的弱隔离系统如何保障安全性？"><a href="#Docker-安全：基于内核的弱隔离系统如何保障安全性？" class="headerlink" title="Docker 安全：基于内核的弱隔离系统如何保障安全性？"></a>Docker 安全：基于内核的弱隔离系统如何保障安全性？</h2><p>Docker 是基于 Linux 内核的 Namespace 技术实现资源隔离的，所有的容器都共享主机的内核。其实这与以虚拟机为代表的云计算时代还是有很多区别的，比如虚拟机有着更好的隔离性和安全性，而容器的隔离性和安全性则相对较弱。</p><p>在讨论容器的安全性之前，我们先了解下容器与虚拟机的区别，这样可以帮助我们更好地了解容器的安全隐患以及如何加固容器安全。</p><h3 id="Docker-与虚拟机区别"><a href="#Docker-与虚拟机区别" class="headerlink" title="Docker 与虚拟机区别"></a>Docker 与虚拟机区别</h3><p><img src="/images/docker/docker-01/20.jpg" alt="虚拟机和容器的比较"></p><p>从图可以看出，虚拟机是通过管理系统(Hypervisor)模拟出 CPU、内存、网络等硬件，然后在这些模拟的硬件上创建客户内核和操作系统。这样做的好处就是虚拟机有自己的内核和操作系统，并且硬件都是通过虚拟机管理系统模拟出来的，用户程序无法直接使用到主机的操作系统和硬件资源，因此虚拟机也对隔离性和安全性有着更好的保证。</p><p>而 Docker 容器则是通过 Linux 内核的 Namespace 技术实现了文件系统、进程、设备以及网络的隔离，然后再通过 Cgroups 对 CPU、 内存等资源进行限制，最终实现了容器之间相互不受影响，由于容器的隔离性仅仅依靠内核来提供，因此容器的隔离性也远弱于虚拟机。</p><p>你可能会问，既然虚拟机安全性这么好，为什么我们还要用容器呢？这是因为容器与虚拟机相比，容器的性能损耗非常小，并且镜像也非常小，而且在业务快速开发和迭代的今天，容器秒级的启动等特性也非常匹配业务快速迭代的业务场景。</p><p>既然我们要利用容器的优点，那有没有什么办法可以尽量弥补容器弱隔离的安全性缺点呢？要了解如何解决容器的安全问题，我们首先需要了解下容器目前存在的安全问题。</p><h3 id="Docker-容器的安全问题"><a href="#Docker-容器的安全问题" class="headerlink" title="Docker 容器的安全问题"></a>Docker 容器的安全问题</h3><h4 id="1-Docker-自身安全"><a href="#1-Docker-自身安全" class="headerlink" title="(1) Docker 自身安全"></a>(1) Docker 自身安全</h4><p>Docker 作为一款容器引擎，本身也会存在一些安全漏洞，CVE 目前已经记录了多项与 Docker 相关的安全漏洞，主要有权限提升、信息泄露等几类安全问题。具体 Docker 官方记录的安全问题可以参考<a href="https://docs.docker.com/engine/security/non-events/" target="_blank" rel="noopener">这里</a>。</p><blockquote><p>CVE 的维基百科定义：CVE 是公共漏洞和暴露（英语：CVE, Common Vulnerabilities and Exposures）又称常见漏洞与披露，是一个与信息安全有关的数据库，收集各种信息安全弱点及漏洞并给予编号以便于公众查阅。此数据库现由美国非营利组织 MITRE 所属的 National Cybersecurity FFRDC 所营运维护 。</p></blockquote><h4 id="2-镜像安全"><a href="#2-镜像安全" class="headerlink" title="(2) 镜像安全"></a>(2) 镜像安全</h4><p>由于 Docker 容器是基于镜像创建并启动，因此镜像的安全直接影响到容器的安全。具体影响镜像安全的总结如下。</p><ul><li>镜像软件存在安全漏洞：由于容器需要安装基础的软件包，如果软件包存在漏洞，则可能会被不法分子利用并且侵入容器，影响其他容器或主机安全。</li><li>仓库漏洞：无论是 Docker 官方的镜像仓库还是我们私有的镜像仓库，都有可能被攻击，然后篡改镜像，当我们使用镜像时，就可能成为攻击者的目标对象。</li><li>用户程序漏洞：用户自己构建的软件包可能存在漏洞或者被植入恶意脚本，这样会导致运行时提权影响其他容器或主机安全。</li></ul><h4 id="3-Linux-内核隔离性不够"><a href="#3-Linux-内核隔离性不够" class="headerlink" title="(3) Linux 内核隔离性不够"></a>(3) Linux 内核隔离性不够</h4><p>尽管目前 Namespace 已经提供了非常多的资源隔离类型，但是仍有部分关键内容没有被完全隔离，其中包括一些系统的关键性目录（如 /sys、/proc 等），这些关键性的目录可能会泄露主机上一些关键性的信息，让攻击者利用这些信息对整个主机甚至云计算中心发起攻击。</p><p>而且仅仅依靠 Namespace 的隔离是远远不够的，因为一旦内核的 Namespace 被突破，使用者就有可能直接提权获取到主机的超级权限，从而影响主机安全。</p><h4 id="4-所有容器共享主机内核"><a href="#4-所有容器共享主机内核" class="headerlink" title="(4) 所有容器共享主机内核"></a>(4) 所有容器共享主机内核</h4><p>由于同一宿主机上所有容器共享主机内核，所以攻击者可以利用一些特殊手段导致内核崩溃，进而导致主机宕机影响主机上其他服务。</p><p>既然容器有这么多安全上的问题，那么我们应该如何做才能够既享受到容器的便利性同时也可以保障容器安全呢？下面我带你来逐步了解下如何解决容器的安全问题。</p><h3 id="如何解决容器的安全问题？"><a href="#如何解决容器的安全问题？" class="headerlink" title="如何解决容器的安全问题？"></a>如何解决容器的安全问题？</h3><h4 id="1-Docker-自身安全性改进"><a href="#1-Docker-自身安全性改进" class="headerlink" title="(1) Docker 自身安全性改进"></a>(1) Docker 自身安全性改进</h4><p>事实上，Docker 从 2013 年诞生到现在，在安全性上面已经做了非常多的努力。目前 Docker 在默认配置和默认行为下是足够安全的。</p><p>Docker 自身是基于 Linux 的多种 Namespace 实现的，其中有一个很重要的 Namespace 叫作 User Namespace，User Namespace 主要是用来做容器内用户和主机的用户隔离的。在过去容器里的 root 用户就是主机上的 root 用户，如果容器受到攻击，或者容器本身含有恶意程序，在容器内就可以直接获取到主机 root 权限。Docker 从 1.10 版本开始，使用 User Namespace 做用户隔离，实现了容器中的 root 用户映射到主机上的非 root 用户，从而大大减轻了容器被突破的风险。</p><p>因此，我们尽可能地使用 Docker 最新版本就可以得到更好的安全保障。</p><h4 id="2-保障镜像安全"><a href="#2-保障镜像安全" class="headerlink" title="(2) 保障镜像安全"></a>(2) 保障镜像安全</h4><p>为保障镜像安全，我们可以在私有镜像仓库安装镜像安全扫描组件，对上传的镜像进行检查，通过与 CVE 数据库对比，一旦发现有漏洞的镜像及时通知用户或阻止非安全镜像继续构建和分发。同时为了确保我们使用的镜像足够安全，在拉取镜像时，要确保只从受信任的镜像仓库拉取，并且与镜像仓库通信一定要使用 HTTPS 协议。</p><h4 id="3-加强内核安全和管理"><a href="#3-加强内核安全和管理" class="headerlink" title="(3) 加强内核安全和管理"></a>(3) 加强内核安全和管理</h4><p>由于仅仅依赖内核的隔离可能会引发安全问题，因此我们对于内核的安全应该更加重视。可以从以下几个方面进行加强。</p><p><strong>宿主机及时升级内核漏洞</strong></p><p>宿主机内核应该尽量安装最新补丁，因为更新的内核补丁往往有着更好的安全性和稳定性。</p><p><strong>使用 Capabilities 划分权限</strong></p><p>Capabilities 是 Linux 内核的概念，Linux 将系统权限分为了多个 Capabilities，它们都可以单独地开启或关闭，Capabilities 实现了系统更细粒度的访问控制。</p><p>容器和虚拟机在权限控制上还是有一些区别的，在虚拟机内我们可以赋予用户所有的权限，例如设置 cron 定时任务、操作内核模块、配置网络等权限。而容器则需要针对每一项 Capabilities 更细粒度的去控制权限，例如：</p><ul><li>cron 定时任务可以在容器内运行，设置定时任务的权限也仅限于容器内部；</li><li>由于容器是共享主机内核的，因此在容器内部一般不允许直接操作主机内核；</li><li>容器的网络管理在容器外部，这就意味着一般情况下，我们在容器内部是不需要执行<code>ifconfig</code>、<code>route</code>等命令的 。</li></ul><p>由于容器可以按照需求逐项添加 Capabilities 权限，因此在大多数情况下，容器并不需要主机的 root 权限，Docker 默认情况下也是不开启额外特权的。</p><p>最后，在执行<code>docker run</code>命令启动容器时，如非特殊可控情况，–privileged 参数不允许设置为 true，其他特殊权限可以使用 –cap-add 参数，根据使用场景适当添加相应的权限。</p><p><strong>使用安全加固组件</strong></p><p>Linux 的 SELinux、AppArmor、GRSecurity 组件都是 Docker 官方推荐的安全加固组件。下面我对这三个组件做简单介绍。</p><ul><li>SELinux (Secure Enhanced Linux): 是 Linux 的一个内核安全模块，提供了安全访问的策略机制，通过设置 SELinux 策略可以实现某些进程允许访问某些文件。</li><li>AppArmor: 类似于 SELinux，也是一个 Linux 的内核安全模块，普通的访问控制仅能控制到用户的访问权限，而 AppArmor 可以控制到用户程序的访问权限。</li><li>GRSecurity: 是一个对内核的安全扩展，可通过智能访问控制，提供内存破坏防御，文件系统增强等多种防御形式。</li></ul><p>这三个组件可以限制一个容器对主机的内核或其他资源的访问控制。目前，容器报告的一些安全漏洞中，很多都是通过对内核进行加强访问和隔离来实现的。</p><p><strong>资源限制</strong></p><p>在生产环境中，建议每个容器都添加相应的资源限制。下面给出一些执行docker run命令启动容器时可以传递的资源限制参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--cpus                          限制 CPU 配额</span><br><span class="line">-m, --memory                    限制内存配额</span><br><span class="line">--pids-limit                    限制容器的 PID 个数</span><br></pre></td></tr></table></figure><p>例如我想要启动一个 1 核 2G 的容器，并且限制在容器内最多只能创建 1000 个 PID，启动命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --cpus=1 -m=2048m --pids-limit=1000 busybox sh</span><br></pre></td></tr></table></figure><p>推荐在生产环境中限制 CPU、内存、PID 等资源，这样即便应用程序有漏洞，也不会导致主机的资源完全耗尽，最大限度降低安全风险。</p><h4 id="4-使用安全容器"><a href="#4-使用安全容器" class="headerlink" title="(4) 使用安全容器"></a>(4) 使用安全容器</h4><p>容器有着轻便快速启动的优点，虚拟机有着安全隔离的优点，有没有一种技术可以兼顾两者的优点，做到既轻量又安全呢？</p><p>答案是有，那就是安全容器。安全容器是相较于普通容器的，安全容器与普通容器的主要区别在于，安全容器中的每个容器都运行在一个单独的微型虚拟机中，拥有独立的操作系统和内核，并且有虚拟化层的安全隔离。</p><p>安全容器目前推荐的技术方案是 <a href="https://github.com/kata-containers" target="_blank" rel="noopener">Kata Containers</a>，Kata Container 并不包含一个完整的操作系统，只有一个精简版的 Guest Kernel 运行着容器本身的应用，并且通过减少不必要的内存，尽量共享可以共享的内存来进一步减少内存的开销。另外，Kata Container 实现了 OCI 规范，可以直接使用 Docker 的镜像启动 Kata 容器，具有开销更小、秒级启动、安全隔离等许多优点。</p><h2 id="容器监控：容器监控原理及-cAdvisor-的安装与使用"><a href="#容器监控：容器监控原理及-cAdvisor-的安装与使用" class="headerlink" title="容器监控：容器监控原理及 cAdvisor 的安装与使用"></a>容器监控：容器监控原理及 cAdvisor 的安装与使用</h2><p>生产环境中监控容器的运行状况十分重要，通过监控我们可以随时掌握容器的运行状态，做到线上隐患和问题早发现，早解决。</p><p>虽然传统的物理机和虚拟机监控已经有了比较成熟的监控方案，但是容器的监控面临着更大的挑战，因为容器的行为和本质与传统的虚拟机是不一样的，总的来说，容器具有以下特性：</p><ul><li>容器是短期存活的，并且可以动态调度；</li><li>容器的本质是进程，而不是一个完整操作系统；</li><li>由于容器非常轻量，容器的创建和销毁也会比传统虚拟机更加频繁。</li></ul><p>Docker 容器的监控方案有很多，除了 Docker 自带的<code>docker stats</code>命令，还有很多开源的解决方案，例如 sysdig、cAdvisor、Prometheus 等，都是非常优秀的监控工具。</p><p>下面我们首先来看下，不借助任何外部工具，如何用 Docker 自带的<code>docker stats</code>命令实现容器的监控。</p><h3 id="使用-docker-stats-命令"><a href="#使用-docker-stats-命令" class="headerlink" title="使用 docker stats 命令"></a>使用 docker stats 命令</h3><p>使用 Docker 自带的<code>docker stats</code>命令可以很方便地看到主机上所有容器的 CPU、内存、网络 IO、磁盘 IO、PID 等资源的使用情况。下面我们可以具体操作看看。</p><p>首先在主机上使用以下命令启动一个资源限制为 1 核 2G 的 nginx 容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --cpus=1 -m=2g --name=nginx  -d nginx</span><br></pre></td></tr></table></figure><p>容器启动后，可以使用docker stats命令查看容器的资源使用状态:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker stats nginx</span><br></pre></td></tr></table></figure><p>通过docker stats命令可以看到容器的运行状态如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CONTAINER           CPU %               MEM USAGE / LIMIT   MEM %               NET I/O             BLOCK I/O           PIDS</span><br><span class="line">f742a467b6d8        0.00%               1.387 MiB / 2 GiB   0.07%               656 B / 656 B       0 B / 9.22 kB       2</span><br></pre></td></tr></table></figure><p>从容器的运行状态可以看出，<code>docker stats</code>命令确实可以获取并显示 Docker 容器运行状态。但是它的缺点也很明显，因为它只能获取本机数据，无法查看历史监控数据，没有可视化展示面板。</p><p>因此，生产环境中我们通常使用另一种容器监控解决方案 <code>cAdvisor</code>。</p><h3 id="cAdvisor"><a href="#cAdvisor" class="headerlink" title="cAdvisor"></a>cAdvisor</h3><p>cAdvisor 是谷歌开源的一款通用的容器监控解决方案。cAdvisor 不仅可以采集机器上所有运行的容器信息，还提供了基础的查询界面和 HTTP 接口，更方便与外部系统结合。所以，cAdvisor很快成了容器指标监控最常用组件，并且 Kubernetes 也集成了 cAdvisor 作为容器监控指标的默认工具。</p><h4 id="cAdvisor-的安装与使用"><a href="#cAdvisor-的安装与使用" class="headerlink" title="cAdvisor 的安装与使用"></a>cAdvisor 的安装与使用</h4><p>下面我们以 cAdvisor 0.37.0 版本为例，演示一下 cAdvisor 的安装与使用。</p><p>cAdvisor 官方提供了 Docker 镜像，我们只需要拉取镜像并且启动镜像即可。</p><blockquote><p>由于 cAdvisor 镜像存放在谷歌的 gcr.io 镜像仓库中，国内无法访问到。这里我把打好的镜像放在了 Docker Hub。你可以使用 docker pull lagoudocker/cadvisor:v0.37.0 命令从 Docker Hub 拉取。</p></blockquote><p>首先使用以下命令启动 cAdvisor：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ docker run \</span><br><span class="line">  --volume=/:/rootfs:ro \</span><br><span class="line">  --volume=/var/run:/var/run:ro \</span><br><span class="line">  --volume=/sys:/sys:ro \</span><br><span class="line">  --volume=/var/lib/docker/:/var/lib/docker:ro \</span><br><span class="line">  --volume=/dev/disk/:/dev/disk:ro \</span><br><span class="line">  --publish=8080:8080 \</span><br><span class="line">  --detach=<span class="literal">true</span> \</span><br><span class="line">  --name=cadvisor \</span><br><span class="line">  --privileged \</span><br><span class="line">  --device=/dev/kmsg \</span><br><span class="line">  lagoudocker/cadvisor:v0.37.0</span><br></pre></td></tr></table></figure><p>此时，cAdvisor 已经成功启动，我们可以通过访问 <a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a> 访问到 cAdvisor 的 Web 界面。</p><p>cAdvisor 不仅可以监控容器的资源使用情况，还可以监控主机的资源使用情况。下面我们就先看下它是如何查看主机资源使用情况的。</p><h4 id="使用-cAdvisor-查看主机监控"><a href="#使用-cAdvisor-查看主机监控" class="headerlink" title="使用 cAdvisor 查看主机监控"></a>使用 cAdvisor 查看主机监控</h4><p>访问 <a href="http://localhost:8080/containers/" target="_blank" rel="noopener">http://localhost:8080/containers/</a> 地址，在首页可以看到主机的资源使用情况，包含 CPU、内存、文件系统、网络等资源。</p><h4 id="使用-cAdvisor-查看容器监控"><a href="#使用-cAdvisor-查看容器监控" class="headerlink" title="使用 cAdvisor 查看容器监控"></a>使用 cAdvisor 查看容器监控</h4><p>如果你想要查看主机上运行的容器资源使用情况，可以访问 <a href="http://localhost:8080/docker/，这个页面会列出" target="_blank" rel="noopener">http://localhost:8080/docker/，这个页面会列出</a> Docker 的基本信息和运行的容器情况。</p><p>总体来说，使用 cAdvisor 监控容器具有以下特点：</p><ul><li>可以同时采集物理机和容器的状态；</li><li>可以展示监控历史数据。</li></ul><p>了解 Docker 的监控工具，你是否想问，这些监控数据是怎么来的呢？下面我就带你了解一下容器监控的原理。</p><h3 id="监控原理"><a href="#监控原理" class="headerlink" title="监控原理"></a>监控原理</h3><p>我们知道 Docker 是基于 Namespace、Cgroups 和联合文件系统实现的。其中 Cgroups 不仅可以用于容器资源的限制，还可以提供容器的资源使用率。无论何种监控方案的实现，底层数据都来源于 Cgroups。</p><p>Cgroups 的工作目录为<code>/sys/fs/cgroup</code>，<code>/sys/fs/cgroup</code>目录下包含了 Cgroups 的所有内容。Cgroups包含很多子系统，可以用来对不同的资源进行限制。例如对CPU、内存、PID、磁盘 IO等资源进行限制和监控。</p><p>为了更详细的了解 Cgroups 的子系统，我们通过 ls -l 命令查看<code>/sys/fs/cgroup</code>文件夹，可以看到很多目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /sys/fs/cgroup/</span><br><span class="line">total 0</span><br><span class="line">dr-xr-xr-x 5 root root  0 Jul  9 19:32 blkio</span><br><span class="line">lrwxrwxrwx 1 root root 11 Jul  9 19:32 cpu -&gt; cpu,cpuacct</span><br><span class="line">dr-xr-xr-x 5 root root  0 Jul  9 19:32 cpu,cpuacct</span><br><span class="line">lrwxrwxrwx 1 root root 11 Jul  9 19:32 cpuacct -&gt; cpu,cpuacct</span><br><span class="line">dr-xr-xr-x 3 root root  0 Jul  9 19:32 cpuset</span><br><span class="line">dr-xr-xr-x 5 root root  0 Jul  9 19:32 devices</span><br><span class="line">dr-xr-xr-x 3 root root  0 Jul  9 19:32 freezer</span><br><span class="line">dr-xr-xr-x 3 root root  0 Jul  9 19:32 hugetlb</span><br><span class="line">dr-xr-xr-x 5 root root  0 Jul  9 19:32 memory</span><br><span class="line">lrwxrwxrwx 1 root root 16 Jul  9 19:32 net_cls -&gt; net_cls,net_prio</span><br><span class="line">dr-xr-xr-x 3 root root  0 Jul  9 19:32 net_cls,net_prio</span><br><span class="line">lrwxrwxrwx 1 root root 16 Jul  9 19:32 net_prio -&gt; net_cls,net_prio</span><br><span class="line">dr-xr-xr-x 3 root root  0 Jul  9 19:32 perf_event</span><br><span class="line">dr-xr-xr-x 5 root root  0 Jul  9 19:32 pids</span><br><span class="line">dr-xr-xr-x 5 root root  0 Jul  9 19:32 systemd</span><br></pre></td></tr></table></figure><p>这些目录代表了 Cgroups 的子系统，Docker 会在每一个 Cgroups 子系统下创建 docker 文件夹。这里如果你对 Cgroups 子系统不了解的话，不要着急，后续会对 Cgroups 子系统做详细讲解，这里你只需要明白容器监控数据来源于 Cgroups 即可。</p><h4 id="监控系统是如何获取容器的内存限制的？"><a href="#监控系统是如何获取容器的内存限制的？" class="headerlink" title="监控系统是如何获取容器的内存限制的？"></a>监控系统是如何获取容器的内存限制的？</h4><p>下面我们以 memory 子系统（memory 子系统是Cgroups 众多子系统的一个，主要用来限制内存使用）为例，讲解一下监控组件是如何获取到容器的资源限制和使用状态的（即容器的内存限制）。</p><p>我们首先在主机上使用以下命令启动一个资源限制为 1 核 2G 的 nginx 容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name=nginx --cpus=1 -m=2g --name=nginx  -d nginx</span><br><span class="line"><span class="comment">## 这里输出的是容器 ID</span></span><br><span class="line">51041a74070e9260e82876974762b8c61c5ed0a51832d74fba6711175f89ede1</span><br></pre></td></tr></table></figure><blockquote><p>注意：如果你已经创建过名称为 nginx 的容器，请先使用 docker  rm -f nginx 命令删除已经存在的 nginx 容器。</p></blockquote><p>容器启动后，我们通过命令行的输出可以得到容器的 ID，同时 Docker 会在<code>/sys/fs/cgroup/memory/docker</code>目录下以容器 ID 为名称创建对应的文件夹。</p><p>下面我们查看一下<code>/sys/fs/cgroup/memory/docker</code>目录下的文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /sys/fs/cgroup/memory/docker</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x 2 root root 0 Sep  2 15:12 51041a74070e9260e82876974762b8c61c5ed0a51832d74fba6711175f89ede1</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 cgroup.clone_children</span><br><span class="line">--w--w--w- 1 root root 0 Sep  2 14:57 cgroup.event_control</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 cgroup.procs</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.failcnt</span><br><span class="line">--w------- 1 root root 0 Sep  2 14:57 memory.force_empty</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.failcnt</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.limit_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.max_usage_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.slabinfo</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.tcp.failcnt</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.tcp.limit_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.tcp.max_usage_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.tcp.usage_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 14:57 memory.kmem.usage_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.limit_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.max_usage_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.memsw.failcnt</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.memsw.limit_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.memsw.max_usage_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 14:57 memory.memsw.usage_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.move_charge_at_immigrate</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 14:57 memory.numa_stat</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.oom_control</span><br><span class="line">---------- 1 root root 0 Sep  2 14:57 memory.pressure_level</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.soft_limit_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 14:57 memory.stat</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.swappiness</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 14:57 memory.usage_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 memory.use_hierarchy</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 notify_on_release</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 14:57 tasks</span><br></pre></td></tr></table></figure><p>可以看到 Docker 已经创建了以容器 ID 为名称的目录，我们再使用 ls 命令查看一下该目录的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ls -l /sys/fs/cgroup/memory/docker/51041a74070e9260e82876974762b8c61c5ed0a51832d74fba6711175f89ede1</span><br><span class="line">total 0</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 cgroup.clone_children</span><br><span class="line">--w--w--w- 1 root root 0 Sep  2 15:13 cgroup.event_control</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:12 cgroup.procs</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:12 memory.failcnt</span><br><span class="line">--w------- 1 root root 0 Sep  2 15:21 memory.force_empty</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.kmem.failcnt</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:12 memory.kmem.limit_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.kmem.max_usage_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 15:21 memory.kmem.slabinfo</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.kmem.tcp.failcnt</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.kmem.tcp.limit_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.kmem.tcp.max_usage_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 15:21 memory.kmem.tcp.usage_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 15:21 memory.kmem.usage_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:12 memory.limit_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:12 memory.max_usage_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.memsw.failcnt</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:12 memory.memsw.limit_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.memsw.max_usage_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 15:21 memory.memsw.usage_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.move_charge_at_immigrate</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 15:21 memory.numa_stat</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:13 memory.oom_control</span><br><span class="line">---------- 1 root root 0 Sep  2 15:21 memory.pressure_level</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.soft_limit_in_bytes</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 15:21 memory.stat</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.swappiness</span><br><span class="line">-r--r--r-- 1 root root 0 Sep  2 15:12 memory.usage_in_bytes</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 memory.use_hierarchy</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 notify_on_release</span><br><span class="line">-rw-r--r-- 1 root root 0 Sep  2 15:21 tasks</span><br></pre></td></tr></table></figure><p>由上可以看到，容器 ID 的目录下有很多文件，其中 memory.limit_in_bytes 文件代表该容器内存限制大小，单位为 byte，我们使用 cat 命令（cat 命令可以查看文件内容）查看一下文件内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cat /sys/fs/cgroup/memory/docker/51041a74070e9260e82876974762b8c61c5ed0a51832d74fba6711175f89ede1/memory.limit_in_bytes</span><br><span class="line">2147483648</span><br></pre></td></tr></table></figure><p>这里可以看到memory.limit_in_bytes 的值为2147483648，转换单位后正好为 2G，符合我们启动容器时的内存限制 2G。</p><p>通过 memory 子系统的例子，我们可以知道<strong>监控组件通过读取 memory.limit_in_bytes 文件即可获取到容器内存的限制值</strong>。了解完容器的内存限制我们来了解一下容器的内存使用情况。</p><h4 id="监控系统是如何获取容器的内存使用状态的？"><a href="#监控系统是如何获取容器的内存使用状态的？" class="headerlink" title="监控系统是如何获取容器的内存使用状态的？"></a>监控系统是如何获取容器的内存使用状态的？</h4><p>内存使用情况存放在 memory.usage_in_bytes 文件里，同样我们也使用 cat 命令查看一下文件内容:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cat /sys/fs/cgroup/memory/docker/51041a74070e9260e82876974762b8c61c5ed0a51832d74fba6711175f89ede1/memory.usage_in_bytes</span><br><span class="line">4259840</span><br></pre></td></tr></table></figure><p>可以看到当前内存的使用大小为 4259840 byte，约为 4 M。了解了内存的监控，下面我们来了解下网络的监控数据来源。</p><p>网络的监控数据来源是从 /proc/{PID}/net/dev 目录下读取的，其中 PID 为容器在主机上的进程 ID。下面我们首先使用 docker inspect 命令查看一下上面启动的 nginx 容器的 PID，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect nginx |grep Pid</span><br><span class="line">            <span class="string">"Pid"</span>: 27348,</span><br><span class="line">            <span class="string">"PidMode"</span>: <span class="string">""</span>,</span><br><span class="line">            <span class="string">"PidsLimit"</span>: 0,</span><br></pre></td></tr></table></figure><p>可以看到容器的 PID 为 27348，使用 cat 命令查看一下 /proc/27348/net/dev 的内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo cat /proc/27348/net/dev</span><br><span class="line">Inter-|   Receive                                                |  Transmit</span><br><span class="line"> face |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed</span><br><span class="line">    lo:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0</span><br><span class="line">  eth0:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0</span><br></pre></td></tr></table></figure><p>/proc/27348/net/dev 文件记录了该容器里每一个网卡的流量接收和发送情况，以及错误数、丢包数等信息。可见容器的网络监控数据都是定时从这里读取并展示的。</p><p>总结一下，<strong>容器的监控原理其实就是定时读取 Linux 主机上相关的文件并展示给用户</strong>。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《由浅入深吃透 Docker》</li><li>《狂神说Docker》</li><li><a href="http://www.docker.com" target="_blank" rel="noopener">http://www.docker.com</a></li><li><a href="https://www.docker-cn.com" target="_blank" rel="noopener">https://www.docker-cn.com</a></li><li><a href="https://hub.docker.com" target="_blank" rel="noopener">https://hub.docker.com</a></li><li><a href="https://docs.docker.com/engine/install/centos/" target="_blank" rel="noopener">https://docs.docker.com/engine/install/centos/</a></li><li><a href="https://docs.docker.com/engine/reference/run/" target="_blank" rel="noopener">https://docs.docker.com/engine/reference/run/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Docker 概述、核心概念、组成、安装、基本操作。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="https://blog.lichao.xin/categories/Docker/"/>
    
    
      <category term="docker" scheme="https://blog.lichao.xin/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>MapStruct 使用详解</title>
    <link href="https://blog.lichao.xin/back-end/java/mapstruct/"/>
    <id>https://blog.lichao.xin/back-end/java/mapstruct/</id>
    <published>2021-03-07T15:10:00.000Z</published>
    <updated>2021-06-14T01:33:22.387Z</updated>
    
    <content type="html"><![CDATA[<p>MapStruct 是一个可以生成类型安全的，高性能的且无依赖的 JavaBean 映射代码的注解处理器，可以在编译期生成对应的 Mapping，既没有BeanUtils 等工具使用反射的性能问题，又免去了自己写映射代码的繁琐。</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>按照日常开发习惯，对于不同领域层使用不同JavaBean对象传输数据，避免相互影响，因此基于数据库实体对象User衍生出比如UserDto、UserVo等对象，于是在不同层之间进行数据传输时，不可避免地需要将这些对象进行互相转换操作。</p><p>常见的转换方式有：</p><ul><li>调用getter/setter方法进行属性赋值</li><li>调用BeanUtil.copyPropertie进行反射属性赋值</li></ul><p>第一种方式不必说，属性多了就需要写一大坨getter/setter代码。第二种方式比第一种方式要简便很多，但是坑巨多，比如sources与target写反，难以定位某个字段在哪里进行的赋值，同时因为用到反射，导致性能也不佳。</p><p>鉴于此，今天写一写第三种对象转换方式，本文使用的是 MapStruct 工具进行转换，MapStruct 原理也很简单，就是在代码编译阶段生成对应的赋值代码，底层原理还是调用getter/setter方法，但是这是由工具替我们完成，MapStruct在不影响性能的情况下，解决了前面两种方式弊端，很赞~</p><h2 id="Maven-依赖"><a href="#Maven-依赖" class="headerlink" title="Maven 依赖"></a>Maven 依赖</h2><p>支持 lombok 一起使用</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mapstruct.version</span>&gt;</span>1.4.2.Final<span class="tag">&lt;/<span class="name">mapstruct.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">lombok-mapstruct-binding.version</span>&gt;</span>0.2.0<span class="tag">&lt;/<span class="name">lombok-mapstruct-binding.version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">projectlombok.version</span>&gt;</span>1.18.16<span class="tag">&lt;/<span class="name">projectlombok.version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">...</span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;projectlombok.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mapstruct<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mapstruct<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;mapstruct.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">...</span><br><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span> <span class="comment">&lt;!-- depending on your project --&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span> <span class="comment">&lt;!-- depending on your project --&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">encoding</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">encoding</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">compilerArgs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">arg</span>&gt;</span>-parameters<span class="tag">&lt;/<span class="name">arg</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">compilerArgs</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!-- MapStruct 处理器 --&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">annotationProcessorPaths</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">path</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mapstruct<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mapstruct-processor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;mapstruct.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">path</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;projectlombok.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">path</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok-mapstruct-binding<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;lombok-mapstruct-binding.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">path</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">annotationProcessorPaths</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><ul><li>使用@Mapper注解，声明映射器，可以是接口，或者抽象类。</li><li>使用@Mapping注解，实现灵活的字段映射，定制映射的规则。</li></ul><h3 id="转换器的检索"><a href="#转换器的检索" class="headerlink" title="转换器的检索"></a>转换器的检索</h3><p>在声明好转换接口之后，MapStruct提供几种方式获取生成的Mapper映射器。</p><h4 id="使用Mappers工厂获取"><a href="#使用Mappers工厂获取" class="headerlink" title="使用Mappers工厂获取"></a>使用Mappers工厂获取</h4><p>可以通过提供的Mappers工厂类，获取指定的类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Assembler</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 使用工厂方法获取Mapper实例</span></span><br><span class="line">    Assembler INSTANCE = Mappers.getMapper(Assembler<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="通过依赖注入的方式获取"><a href="#通过依赖注入的方式获取" class="headerlink" title="通过依赖注入的方式获取"></a>通过依赖注入的方式获取</h4><p>MapStuct同时支持和其他框架结合，通过依赖注入的方式获取Mapper实例。目前支持spring和cdi。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Assembler</span> </span>&#123;</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成代码在：<code>项目根目录/target/generated-sources/annotations/xxx</code> 如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="简单映射"><a href="#简单映射" class="headerlink" title="简单映射"></a>简单映射</h3><h4 id="基本映射"><a href="#基本映射" class="headerlink" title="基本映射"></a>基本映射</h4><p>对于同名同属性的字段，无需特别声明指定，自动转换。</p><p>对于不同名相同属性的字段，可以使用Mapping注解指定。</p><p>实体：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>DTO：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDTO</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">6780322740093464581L</span>;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> String productName;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义映射器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Mapping</span>(source = <span class="string">"name"</span>, target = <span class="string">"productName"</span>)</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成的映射器试实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setProductName( product.getName() );  <span class="comment">// 不同字段名映射</span></span><br><span class="line">        productDTO.setProductId( product.getProductId() ); <span class="comment">// 相同映射名自动转换</span></span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="多源参数映射"><a href="#多源参数映射" class="headerlink" title="多源参数映射"></a>多源参数映射</h4><p>支持把多个参数映射成一个类型，使用@Mapping指定即可。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo6Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"productId"</span>, source = <span class="string">"product.productId"</span>)</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"desc"</span>, source = <span class="string">"detail.desc"</span>)</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDetailDTO</span><span class="params">(Product product, ProductDetail detail)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="更新对象"><a href="#更新对象" class="headerlink" title="更新对象"></a>更新对象</h4><p>映射时除了生成新的新对象外，还支持现存对象的更新：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo6Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"desc"</span>, source = <span class="string">"desc"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">updateDTO</span><span class="params">(@MappingTarget ProductDTO productDTO, ProductDetail detail)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h3><h4 id="对于基础数据类型会进行自动隐式的转换"><a href="#对于基础数据类型会进行自动隐式的转换" class="headerlink" title="对于基础数据类型会进行自动隐式的转换"></a>对于基础数据类型会进行自动隐式的转换</h4><p>如int、long、String，Integer、Long等。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> Long price;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDTO</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">6780322740093464581L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> productId;</span><br><span class="line">    <span class="keyword">private</span> String price;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义映射器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Assembler</span> </span>&#123;</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成的映射代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        <span class="keyword">if</span> ( product.getProductId() != <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="comment">//String自动转int</span></span><br><span class="line">            productDTO.setProductId( Integer.parseInt( product.getProductId() ) );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> ( product.getPrice() != <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="comment">//Long转String</span></span><br><span class="line">            productDTO.setPrice( String.valueOf( product.getPrice() ) );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="指定转换格式"><a href="#指定转换格式" class="headerlink" title="指定转换格式"></a>指定转换格式</h4><p>某些类型的转换，我们可以指定具体转换的格式。</p><p>对于基本数据类型与String之间的转换，可以使用 numberFormat 指定转换格式，使用的是java.text.DecimalFormat 实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> BigDecimal price;</span><br><span class="line">    <span class="keyword">private</span> String stock;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDTO</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">6780322740093464581L</span>;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> String price;</span><br><span class="line">    <span class="keyword">private</span> Integer stock;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>映射器定义：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo3Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"price"</span>, numberFormat = <span class="string">"#.00元"</span>)   <span class="comment">//BigDecimal转换成字符串</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"stock"</span>, numberFormat = <span class="string">"#个"</span>)      <span class="comment">//字符串转换成int</span></span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo3AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo3Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">        <span class="keyword">if</span> ( product.getPrice() != <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="comment">//BigDecimal格式化成字符串</span></span><br><span class="line">            productDTO.setPrice( createDecimalFormat( <span class="string">"#.00元"</span> ).format( product.getPrice() ) );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> ( product.getStock() != <span class="keyword">null</span> ) &#123;</span><br><span class="line">                 <span class="comment">//字符串格式化为int</span></span><br><span class="line">                productDTO.setStock( <span class="keyword">new</span> DecimalFormat( <span class="string">"#个"</span> ).parse( product.getStock() ).intValue() );</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> ( ParseException e ) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException( e );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> DecimalFormat <span class="title">createDecimalFormat</span><span class="params">( String numberFormat )</span> </span>&#123;</span><br><span class="line">        DecimalFormat df = <span class="keyword">new</span> DecimalFormat( numberFormat );</span><br><span class="line">        df.setParseBigDecimal( <span class="keyword">true</span> );</span><br><span class="line">        <span class="keyword">return</span> df;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    com.gotten.study.mapstruct.demo3.Product  product = <span class="keyword">new</span> com.gotten.study.mapstruct.demo3.Product ();</span><br><span class="line">    product.setProductId(<span class="string">"P001"</span>);</span><br><span class="line">    product.setPrice(<span class="keyword">new</span> BigDecimal(<span class="string">"100"</span>));</span><br><span class="line">    product.setStock(<span class="string">"1个"</span>);</span><br><span class="line">    com.gotten.study.mapstruct.demo3.ProductDTO productDTO = demo3Assembler.toDTO(product);</span><br><span class="line">    System.out.println(<span class="string">"productDTO:"</span> + JSON.toJSONString(productDTO));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">productDTO:&#123;<span class="string">"price"</span>:<span class="string">"100.00元"</span>,<span class="string">"productId"</span>:<span class="string">"P001"</span>,<span class="string">"stock"</span>:<span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure><p>Date和String之间的转换，可以通过dateFormat指定转换格式，使用的是SimpleDateFormat的实现。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> Date saleTime;</span><br><span class="line">    <span class="keyword">private</span> String validTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDTO</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = -<span class="number">6780322740093464581L</span>;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> String saleTime;</span><br><span class="line">    <span class="keyword">private</span> Date validTime;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义映射器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo4Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"saleTime"</span>, dateFormat = <span class="string">"yyyy-MM-dd HH:mm:ss"</span>)  <span class="comment">//Date转换成String</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"validTime"</span>, dateFormat = <span class="string">"yyyy-MM-dd HH:mm"</span>)    <span class="comment">//String转换成Date</span></span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo4AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo4Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">        <span class="keyword">if</span> ( product.getSaleTime() != <span class="keyword">null</span> ) &#123;</span><br><span class="line">            productDTO.setSaleTime( <span class="keyword">new</span> SimpleDateFormat( <span class="string">"yyyy-MM-dd HH:mm:ss"</span> ).format( product.getSaleTime() ) ); <span class="comment">//转换成String</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> ( product.getValidTime() != <span class="keyword">null</span> ) &#123;</span><br><span class="line">                productDTO.setValidTime( <span class="keyword">new</span> SimpleDateFormat( <span class="string">"yyyy-MM-dd HH:mm"</span> ).parse( product.getValidTime() ) ); <span class="comment">//转换成Date</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">catch</span> ( ParseException e ) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException( e );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="属性为复杂对象的映射"><a href="#属性为复杂对象的映射" class="headerlink" title="属性为复杂对象的映射"></a>属性为复杂对象的映射</h3><ul><li>如果是相同类型的对象引用，不会创建新的对象，直接把对象的引用从源对象赋值给目标对象。</li><li>如果类型相同，但是是集合类的引用，会创建一个新的集合，集合里面的所有引用进行拷贝。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">    productDTO.setProductId( product.getProductId() );</span><br><span class="line">    List&lt;Sku&gt; list = product.getSkuList();</span><br><span class="line">    <span class="keyword">if</span> ( list != <span class="keyword">null</span> ) &#123;</span><br><span class="line">        productDTO.setSkuList( <span class="keyword">new</span> ArrayList&lt;Sku&gt;( list ) ); <span class="comment">//创建新的集合，并对所有元素进行拷贝</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> productDTO;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对象的类型不同，会检查映射器中是否存在对应的映射方法，如果存在，直接使用，否则会尝试自动创建子映射方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> ProductDetail productDetail;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDetail</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDTO</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">2184784038009791692L</span>;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> ProductDetailDTO productDetail;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDetailDTO</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String detailId;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义映射器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo6Assembler</span> </span>&#123;</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"detailId"</span>, source = <span class="string">"id"</span>)</span><br><span class="line">    <span class="function">ProductDetailDTO <span class="title">toDetailDTO</span><span class="params">(ProductDetail detail)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo6AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo6Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">        productDTO.setProductDetail( toDetailDTO( product.getProductDetail() ) ); <span class="comment">//查找使用存在的转换方法</span></span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDetailDTO <span class="title">toDetailDTO</span><span class="params">(ProductDetail detail)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( detail == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDetailDTO productDetailDTO = <span class="keyword">new</span> ProductDetailDTO();</span><br><span class="line">        productDetailDTO.setDetailId( detail.getId() );</span><br><span class="line">        <span class="keyword">return</span> productDetailDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>多层bean之间的转换</p><p>@Mapping注解支持跨层级的属性转换，属性可以在不同层级之间切换。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> ProductDetail productDetail;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDetail</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String id;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDTO</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">2184784038009791692L</span>;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> ProductDetailDTO productDetail;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDetailDTO</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> String detailId;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义映射器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo7Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"productDetail.detailId"</span>, source = <span class="string">"productDetail.id"</span>) <span class="comment">//声明productDetail下的属性转换规则</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"productDetail.productId"</span>, source = <span class="string">"productId"</span>) <span class="comment">//跨层级的属性转换,把product层级的productId放到productDetail层级</span></span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo7AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo7Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        <span class="keyword">if</span> ( product.getProductDetail() != <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">if</span> ( productDTO.getProductDetail() == <span class="keyword">null</span> ) &#123;</span><br><span class="line">                productDTO.setProductDetail( <span class="keyword">new</span> ProductDetailDTO() );</span><br><span class="line">            &#125;</span><br><span class="line">            productDetailToProductDetailDTO( product.getProductDetail(), productDTO.getProductDetail() );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> ( productDTO.getProductDetail() == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            productDTO.setProductDetail( <span class="keyword">new</span> ProductDetailDTO() );</span><br><span class="line">        &#125;</span><br><span class="line">        productToProductDetailDTO( product, productDTO.getProductDetail() );</span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">　　<span class="comment">//detail的转换方法</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">productDetailToProductDetailDTO</span><span class="params">(ProductDetail productDetail, ProductDetailDTO mappingTarget)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( productDetail == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        mappingTarget.setDetailId( productDetail.getId() );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">　　<span class="comment">//product转成detail（更新处理）</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">productToProductDetailDTO</span><span class="params">(Product product, ProductDetailDTO mappingTarget)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        mappingTarget.setProductId( product.getProductId() );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="自定义转换器"><a href="#自定义转换器" class="headerlink" title="自定义转换器"></a>自定义转换器</h3><p>MapStruct支持自定义转换器，实现类型之间的转换自定义的规则。</p><p>一个自定义映射器可以定义多个映射方法，匹配时，是以方法的入参和出参进行匹配的。如果绑定的映射中，存在多个相同的入参和出参方法，将会报错。</p><p>如果多个入参或者出参方法存在继承关系，将会匹配最具体的那一个方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> List&lt;String&gt; images;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="meta">@AllArgsConstructor</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductDTO</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">2184784038009791692L</span>;</span><br><span class="line">    <span class="keyword">private</span> String productId;</span><br><span class="line">    <span class="keyword">private</span> String images;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义映射器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ImageFormater</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">format</span><span class="params">(List&lt;String&gt; images)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> String.join(<span class="string">","</span>, images);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>绑定转换器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>, uses = ImageFormater<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">Demo8Assembler</span> </span>&#123;</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>映射器实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo8AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo8Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> ImageFormater imageFormater;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">　　　　 <span class="comment">//调用自定义的映射器进行映射，把list转成string</span></span><br><span class="line">        productDTO.setImages( imageFormater.format( product.getImages() ) );</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用限定符限定使用转换方法"><a href="#使用限定符限定使用转换方法" class="headerlink" title="使用限定符限定使用转换方法"></a>使用限定符限定使用转换方法</h3><p>自定义转换器时，存在多个相同入参和出参的方法，MapStruct无法匹配使用哪个映射方法。这时可以使用限定符绑定每个属性转换时使用的转换方法。</p><p>限定符使用自定义注解实现。</p><p>声明限定符：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.mapstruct.Qualifier;</span><br><span class="line"><span class="comment">//映射器上的限定符</span></span><br><span class="line"><span class="meta">@Qualifier</span> <span class="comment">//标记为限定符</span></span><br><span class="line"><span class="meta">@Target</span>(ElementType.TYPE)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.CLASS)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Formators &#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//映射方法上的限定符</span></span><br><span class="line"><span class="meta">@Qualifier</span> <span class="comment">//标记为限定符</span></span><br><span class="line"><span class="meta">@Target</span>(ElementType.METHOD)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.CLASS)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> FormatImages &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//映射方法上的限定符</span></span><br><span class="line"><span class="meta">@Qualifier</span> <span class="comment">//标记为限定符</span></span><br><span class="line"><span class="meta">@Target</span>(ElementType.METHOD)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.CLASS)</span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> FormatDetails &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>绑定限定符到映射器的方法上面：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Formators</span> <span class="comment">//绑定限定符</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CusFormater</span> </span>&#123;</span><br><span class="line">    <span class="meta">@FormatImages</span> <span class="comment">//绑定限定符</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">formatImages</span><span class="params">(List&lt;String&gt; images)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> String.join(<span class="string">","</span>, images);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@FormatDetails</span> <span class="comment">//绑定限定符</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">formatDetails</span><span class="params">(List&lt;String&gt; images)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> String.join(<span class="string">","</span>, images);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>映射时，绑定限定符，定位映射方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>, uses = CusFormater<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">Demo9Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"images"</span>, qualifiedBy = FormatImages<span class="class">.<span class="keyword">class</span>) //转换指定限定符，定位具体的映射方法</span></span><br><span class="line"><span class="class">    @<span class="title">Mapping</span>(<span class="title">target</span> </span>= <span class="string">"details"</span>, qualifiedBy = FormatDetails<span class="class">.<span class="keyword">class</span>)//转换指定限定符，定位具体的映射方法</span></span><br><span class="line"><span class="class">    <span class="title">ProductDTO</span> <span class="title">toDTO</span>(<span class="title">Product</span> <span class="title">product</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo9AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo9Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> CusFormater cusFormater;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">        productDTO.setImages( cusFormater.formatImages( product.getImages() ) ); <span class="comment">//定位方法</span></span><br><span class="line">        productDTO.setDetails( cusFormater.formatDetails( product.getDetails() ) );</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>基于named注解实现（推荐）</p><p>除了使用自定义注解的方法，还可以使用@Named注解实现限定符的绑定。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Named</span>(<span class="string">"CusFormater"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CusFormater</span> </span>&#123;</span><br><span class="line">    <span class="comment">//绑定限定符</span></span><br><span class="line">    <span class="meta">@Named</span>(<span class="string">"formatImages"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">formatImages</span><span class="params">(List&lt;String&gt; images)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> String.join(<span class="string">","</span>, images);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//绑定限定符</span></span><br><span class="line">    <span class="meta">@Named</span>(<span class="string">"formatDetails"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">formatDetails</span><span class="params">(List&lt;String&gt; images)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> String.join(<span class="string">","</span>, images);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用时绑定：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>, uses = CusFormater<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">Demo10Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"images"</span>, qualifiedByName = <span class="string">"formatImages"</span>) <span class="comment">//转换指定限定符，定位具体的映射方法</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"details"</span>, qualifiedByName = <span class="string">"formatDetails"</span>)<span class="comment">//转换指定限定符，定位具体的映射方法</span></span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Map的映射"><a href="#Map的映射" class="headerlink" title="Map的映射"></a>Map的映射</h3><p>可以使用@MapMapping实现对key和value的分别映射：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo11Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@MapMapping</span>(valueDateFormat = <span class="string">"yyyy-MM-dd HH:mm:ss"</span>)</span><br><span class="line">    <span class="function">Map&lt;String, String&gt; <span class="title">toDTO</span><span class="params">(Map&lt;Long, Date&gt; map)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="枚举值之间的转换"><a href="#枚举值之间的转换" class="headerlink" title="枚举值之间的转换"></a>枚举值之间的转换</h3><p>MapStruct可以在多个枚举值之间转换，使用@ValueMapping注解。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> E1 &#123;</span><br><span class="line">    E1_1,</span><br><span class="line">    E1_2,</span><br><span class="line">    E1_3,</span><br><span class="line">    ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> E2 &#123;</span><br><span class="line">    E2_1,</span><br><span class="line">    E2_2,</span><br><span class="line">    E2_3,</span><br><span class="line">    ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo11Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@ValueMapping</span>(target = <span class="string">"E1_1"</span>, source = <span class="string">"E2_1"</span>)</span><br><span class="line">    <span class="meta">@ValueMapping</span>(target = <span class="string">"E1_2"</span>, source = <span class="string">"E2_2"</span>)</span><br><span class="line">    <span class="meta">@ValueMapping</span>(target = MappingConstants.NULL, source = <span class="string">"E2_3"</span>) <span class="comment">//转换成null</span></span><br><span class="line">    <span class="function">E1 <span class="title">toDTO</span><span class="params">(E2 e2)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo11AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo11Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> E1 <span class="title">toDTO</span><span class="params">(E2 e2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( e2 == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        E1 e1;</span><br><span class="line">        <span class="keyword">switch</span> ( e2 ) &#123;</span><br><span class="line">            <span class="keyword">case</span> E2_1: e1 = E1.E1_1;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> E2_2: e1 = E1.E1_2;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> E2_3: e1 = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>: <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException( <span class="string">"Unexpected enum constant: "</span> + e2 );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> e1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="定制Bean生成"><a href="#定制Bean生成" class="headerlink" title="定制Bean生成"></a>定制Bean生成</h3><p>使用MapStruct可以使用对象工厂来创建bean，同时也可以更新bean。</p><p>定义对象工厂：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DTOFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">createDTO</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setStock(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用对象工厂：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>, uses = DTOFactory<span class="class">.<span class="keyword">class</span>) //指定使用的对象工厂</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">Demo13Assembler</span> </span>&#123;</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo13AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo13Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> DTOFactory dTOFactory;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = dTOFactory.createDTO(); <span class="comment">//使用对象工厂创建对象</span></span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="缺省值和常量"><a href="#缺省值和常量" class="headerlink" title="缺省值和常量"></a>缺省值和常量</h3><p>MapStruct允许设置缺省值和常量，同时缺省值允许使用表达式。</p><p>注意：使用缺省值，源字段必须存在，否则缺省值不生效，否则应该使用常量。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>, imports = UUID<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">Demo15Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"productId"</span>, source = <span class="string">"productId"</span>, defaultValue = <span class="string">"0"</span>) <span class="comment">//当product的productId为null，设置为0</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"random"</span>, source = <span class="string">"random"</span>, defaultExpression = <span class="string">"java(UUID.randomUUID().toString())"</span>) <span class="comment">//缺省设置随机数</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"stock"</span>, constant = <span class="string">"0"</span>) <span class="comment">//固定设置为0</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"createTime"</span>, dateFormat = <span class="string">"yyyy-MM-dd"</span>, constant = <span class="string">"2020-05-30"</span>) <span class="comment">//固定格式化设置为2020-05-30，</span></span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="存在继承关系的结果处理"><a href="#存在继承关系的结果处理" class="headerlink" title="存在继承关系的结果处理"></a>存在继承关系的结果处理</h3><p>当返回的结果类型存在继承关系时，可以使用 @BeanMapping注解指定真实返回的结果类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo17Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@BeanMapping</span>(resultType = DogDTO<span class="class">.<span class="keyword">class</span>) //指定返回的结果类型</span></span><br><span class="line"><span class="class">    <span class="title">Animal</span> <span class="title">toDTO</span>(<span class="title">Dog</span> <span class="title">dog</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo17AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo17Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Animal <span class="title">toDTO</span><span class="params">(Dog dog)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( dog == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        DogDTO animal = <span class="keyword">new</span> DogDTO();</span><br><span class="line">        animal.setId( dog.getId() );</span><br><span class="line">        <span class="keyword">return</span> animal;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="映射关系继承"><a href="#映射关系继承" class="headerlink" title="映射关系继承"></a>映射关系继承</h3><p>MapStruct允许对映射关系进行继承，使用@InheritConfiguration标记当前方法继承其他映射方法的映射关系。会自动查找相同类型映射源、映射目标的方法进行继承，如果存在多个相同类型的方法，则需要手工指定。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo18Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"productId"</span>, source = <span class="string">"id"</span>)</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"detail"</span>, source = <span class="string">"detail1"</span>)</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"productId"</span>, source = <span class="string">"id2"</span>)</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"detail"</span>, source = <span class="string">"detail2"</span>)</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO2</span><span class="params">(Product product)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@InheritConfiguration</span>(name = <span class="string">"toDTO"</span>) <span class="comment">//对toDTO的映射关系进行继承</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"detail"</span>, source = <span class="string">"detail2"</span>) <span class="comment">//对继承的关系进行重写</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">update</span><span class="params">(@MappingTarget ProductDTO productDTO, Product product)</span></span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除了正向继承规则外，还可以进行规则逆向继承，从被继承方法的目标对象映射到源对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo18Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"productId"</span>, source = <span class="string">"id"</span>)</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"detail"</span>, source = <span class="string">"detail1"</span>)</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"productId"</span>, source = <span class="string">"id2"</span>)</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"detail"</span>, source = <span class="string">"detail2"</span>)</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO2</span><span class="params">(Product product)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@InheritInverseConfiguration</span>(name = <span class="string">"toDTO"</span>) <span class="comment">//对toDTO的映射关系进行逆继承</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"detail2"</span>, source = <span class="string">"detail"</span>) <span class="comment">//对逆向继承的关系进行重写</span></span><br><span class="line">    <span class="function">Product <span class="title">toEntity</span><span class="params">(ProductDTO dto)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="复杂映射的实现"><a href="#复杂映射的实现" class="headerlink" title="复杂映射的实现"></a>复杂映射的实现</h3><p>有时候我们除了普通映射外，还需要进行一些复杂的映射，如把多个字段计算映射成一个字段，或者借用一些工具进行映射的计算等。MapStruct提供了集中方式实现。</p><h4 id="使用java表达式进行映射"><a href="#使用java表达式进行映射" class="headerlink" title="使用java表达式进行映射"></a>使用java表达式进行映射</h4><p>对于复杂的映射，允许使用java表达式实现字段的映射。</p><p>注意要导入使用到的类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>, imports = DecimalUtils<span class="class">.<span class="keyword">class</span>) //导入<span class="title">java</span>表达式使用的类</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">Demo16Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"price"</span>, expression = <span class="string">"java(product.getPrice1() + product.getPrice2())"</span>) <span class="comment">//直接相加</span></span><br><span class="line">    <span class="meta">@Mapping</span>(target = <span class="string">"price2"</span>, expression = <span class="string">"java(DecimalUtils.add(product.getPrice1(), product.getPrice2()))"</span>) <span class="comment">//使用工具类处理</span></span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成的映射代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo16AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo16Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line">        productDTO.setPrice( product.getPrice1() + product.getPrice2() );</span><br><span class="line">        productDTO.setPrice2( DecimalUtils.add(product.getPrice1(), product.getPrice2()) );</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="使用装饰器进行映射"><a href="#使用装饰器进行映射" class="headerlink" title="使用装饰器进行映射"></a>使用装饰器进行映射</h4><p>MapStruct允许使用装饰器进行一些复杂映射，同时可以支持和Spring结合。</p><p>定义一个映射器，同时声明绑定装饰器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="meta">@DecoratedWith</span>(Demo18AssemblerDecorator<span class="class">.<span class="keyword">class</span>) //声明绑定装饰器</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">Demo18Assembler</span> </span>&#123;</span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义装饰器：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo18AssemblerDecorator</span> <span class="keyword">implements</span> <span class="title">Demo18Assembler</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="meta">@Qualifier</span>(<span class="string">"delegate"</span>) <span class="comment">//注入mapStruct生成的转换器，原始的转换器注入spring时，会使用delegate装饰符</span></span><br><span class="line">    <span class="keyword">private</span> Demo18Assembler assembler;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//可以获取spring的bean进行操作</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> StringUtils stringUtils;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//调用MapStruct进行转换</span></span><br><span class="line">        ProductDTO productDTO = assembler.toDTO(product);</span><br><span class="line">        <span class="comment">//自定义操作</span></span><br><span class="line">        stringUtils.join(product.getName(), <span class="string">"-"</span>, product.getTitle());</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成装饰器代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="meta">@Primary</span> <span class="comment">//Primary修饰，方便使用时直接使用autowired注入</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo18AssemblerImpl</span> <span class="keyword">extends</span> <span class="title">Demo18AssemblerDecorator</span> <span class="keyword">implements</span> <span class="title">Demo18Assembler</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="使用前后置处理实现复杂映射"><a href="#使用前后置处理实现复杂映射" class="headerlink" title="使用前后置处理实现复杂映射"></a>使用前后置处理实现复杂映射</h4><p>使用@BeforeMapping和@AfterMapping注解可以指定映射过程的的回调方法，进行一些前置或者后置的操作。</p><p>前置回调方法的执行时机是在映射方法开始时，后置方法是在映射完成return之前。</p><p>回调方法可以直接定义在映射器内：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(componentModel = <span class="string">"spring"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Demo19Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function">ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@BeforeMapping</span> <span class="comment">//前置执行</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> ProductDTO <span class="title">toDTOBefore</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line">        productDTO.setSales(<span class="number">9999</span>);</span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@AfterMapping</span> <span class="comment">//后置执行</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">toDTOAfter</span><span class="params">(Product product, @MappingTarget ProductDTO productDTO)</span> </span>&#123;</span><br><span class="line">        productDTO.setViewName(product.getName() + <span class="string">"-"</span> + product.getTitle());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>生成的实现代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo19AssemblerImpl</span> <span class="keyword">implements</span> <span class="title">Demo19Assembler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProductDTO <span class="title">toDTO</span><span class="params">(Product product)</span> </span>&#123;</span><br><span class="line">        ProductDTO target = toDTOBefore( product ); <span class="comment">//前置</span></span><br><span class="line">        <span class="keyword">if</span> ( target != <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> target;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ( product == <span class="keyword">null</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ProductDTO productDTO = <span class="keyword">new</span> ProductDTO();</span><br><span class="line"></span><br><span class="line">        productDTO.setProductId( product.getProductId() );</span><br><span class="line"></span><br><span class="line">        toDTOAfter( product, productDTO ); <span class="comment">//后置</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> productDTO;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>回调方法与映射的方法的匹配规则：</p><ul><li><p>映射方法和回调方法没有强绑定的关系，是依靠参数类型来匹配映射方法与回调方法的。映射方法的所有入参和出参类型，能覆盖回调方法的入参，就会调用对应的回调方法，当要注意，如果回调方法的入参是映射方法的出参类型，回调方法中需要用@MappingTarget 指定，否则不会调用。</p></li><li><p>回调方法是void或者返回映射方法的出参类型才能匹配，但要注意，如果返回的是映射方法的出参类型，如果执行时返回不为null，则映射方法直接返回回调方法执行结果，不会往后执行。</p></li></ul><blockquote><p>建议多读读官方文档，有很多高级用法，如继承组成，配置策略等。 <a href="https://mapstruct.org/documentation/stable/reference/html/#mapping-composition" target="_blank" rel="noopener">https://mapstruct.org/documentation/stable/reference/html/#mapping-composition</a></p></blockquote><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="通用配置"><a href="#通用配置" class="headerlink" title="通用配置"></a>通用配置</h3><p>因为项目中的对象转换操作基本都一样，因此抽取除了一个转换基类，不同对象如果只是简单转换可以直接继承该基类，而无需覆写基类任何方法，即只需要一个空类即可。如果子类覆写了基类的方法，则基类上的 @Mapping 会失效。</p><p>对象转换通用基类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对象转换通用基类</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;D&gt; DTO</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;E&gt; Entity</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Richard</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2021-03-03</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">BaseConvertMapper</span>&lt;<span class="title">D</span>, <span class="title">E</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DTO 转 Entity</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> dto DTO</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> Entity</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">///@Mapping(target = "createTime", dateFormat = "yyyy-MM-dd HH:mm:ss", ignore = true)</span></span><br><span class="line"><span class="function">E <span class="title">toEntity</span><span class="params">(D dto)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Entity 转 DTO</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> entity Entity</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> DTO</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@InheritInverseConfiguration</span>(name = <span class="string">"toEntity"</span>)</span><br><span class="line"><span class="function">D <span class="title">toDto</span><span class="params">(E entity)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DTO 集合转 Entity 集合</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> dtoList DTO List</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> Entity List</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@InheritConfiguration</span>(name = <span class="string">"toEntity"</span>)</span><br><span class="line"><span class="function">List&lt;E&gt; <span class="title">toEntityList</span><span class="params">(List&lt;D&gt; dtoList)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Entity 集合转 DTO 集合</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> entityList Entity List</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> DTO List</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@InheritConfiguration</span>(name = <span class="string">"toDto"</span>)</span><br><span class="line"><span class="function">List&lt;D&gt; <span class="title">toDtoList</span><span class="params">(List&lt;E&gt; entityList)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 映射同名属性，集合流形式</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> dtoStream DTO Stream</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> Entity Stream</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">List&lt;E&gt; <span class="title">toEntityStream</span><span class="params">(Stream&lt;D&gt; dtoStream)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 反向，映射同名属性，集合流形式</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> entityStream Entity Stream</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> DTO Stream</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function">List&lt;D&gt; <span class="title">toDtoStream</span><span class="params">(Stream&lt;E&gt; entityStream)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 更新属性</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> dto    DTO</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> entity Entity</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@InheritConfiguration</span>(name = <span class="string">"toEntity"</span>)</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">updateEntity</span><span class="params">(D dto, @MappingTarget E entity)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 反向，更新属性</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> entity Entity</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> dto    dto</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@InheritConfiguration</span>(name = <span class="string">"toDto"</span>)</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">updateDto</span><span class="params">(E entity, @MappingTarget D dto)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对象转换通用配置</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 对象转换通用配置</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> Richard</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@since</span> 2021-03-03</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@MapperConfig</span>(</span><br><span class="line">componentModel = <span class="string">"spring"</span>,</span><br><span class="line">builder = <span class="meta">@Builder</span>(disableBuilder = <span class="keyword">true</span>),</span><br><span class="line">unmappedTargetPolicy = ReportingPolicy.IGNORE,</span><br><span class="line">unmappedSourcePolicy = ReportingPolicy.IGNORE</span><br><span class="line"><span class="comment">//nullValueCheckStrategy = NullValueCheckStrategy.ALWAYS</span></span><br><span class="line"><span class="comment">//      disableSubMappingMethodsGeneration = true,</span></span><br><span class="line"><span class="comment">//      mappingInheritanceStrategy = MappingInheritanceStrategy.AUTO_INHERIT_FROM_CONFIG,</span></span><br><span class="line">        <span class="comment">// imports = &#123;</span></span><br><span class="line">        <span class="comment">//     Helper.class</span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">BaseConvertConfig</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>继承即可实现通用转换</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Mapper</span>(config = BaseConvertConfig<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">UserConvertMapper</span> <span class="keyword">extends</span> <span class="title">BaseConvertMapper</span>&lt;<span class="title">UserDTO</span>, <span class="title">User</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="插件工具"><a href="#插件工具" class="headerlink" title="插件工具"></a>插件工具</h3><p>mapstruct的插件可以自动检查到属性字段的更改，并且提供属性灵活的选择, idea通过插件市场下载 <code>MapStruct Support</code> 即可。</p><h3 id="下面是对MapStruct的注解做的思维导图，方便对此框架的理解"><a href="#下面是对MapStruct的注解做的思维导图，方便对此框架的理解" class="headerlink" title="下面是对MapStruct的注解做的思维导图，方便对此框架的理解"></a>下面是对MapStruct的注解做的思维导图，方便对此框架的理解</h3><p><img src="/images/java/mapstruct/1.jpg" alt="1"></p><p>重点介绍下：BeforeMapping 、 AfterMapping 、 ObjectFactory 、Context</p><ol><li>BeforeMapping、AfterMapping：表示的是转换动作之前或是之后需要执行的动作</li><li>ObjectFactory：由于我们转换到目标对象，一般执行都是目标对象的默认构造函数。此方法帮助我们生成一个对象</li><li>Context：我们在转换动作之前或是之后需要执行一系列的动作，那么数据怎么传送。context负责数据之间的共享。</li></ol><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.cnblogs.com/gotten/p/13052911.html" target="_blank" rel="noopener">https://www.cnblogs.com/gotten/p/13052911.html</a></li><li><a href="https://www.baeldung.com/java-performance-mapping-frameworks" target="_blank" rel="noopener">https://www.baeldung.com/java-performance-mapping-frameworks</a></li><li><a href="https://mapstruct.org/documentation/stable/reference/html" target="_blank" rel="noopener">https://mapstruct.org/documentation/stable/reference/html</a></li><li><a href="https://github.com/mapstruct/mapstruct/" target="_blank" rel="noopener">https://github.com/mapstruct/mapstruct/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MapStruct 是一个可以生成类型安全的，高性能的且无依赖的 JavaBean 映射代码的注解处理器，可以在编译期生成对应的 Mapping，既没有BeanUtils 等工具使用反射的性能问题，又免去了自己写映射代码的繁琐。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="https://blog.lichao.xin/categories/Java/"/>
    
    
      <category term="Spring" scheme="https://blog.lichao.xin/tags/Spring/"/>
    
      <category term="java" scheme="https://blog.lichao.xin/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Jackson 使用详解</title>
    <link href="https://blog.lichao.xin/back-end/java/jackson/"/>
    <id>https://blog.lichao.xin/back-end/java/jackson/</id>
    <published>2021-02-28T13:25:00.000Z</published>
    <updated>2021-06-14T01:33:22.387Z</updated>
    
    <content type="html"><![CDATA[<p>Jackson 是用来序列化和反序列化 json 的 Java 的开源框架。Spring MVC 的默认 json 解析器便是 Jackson。与其他 Java 的 json 的框架 Gson 等相比，Jackson 解析大的 json 文件速度比较快；Jackson 运行时占用内存比较低，性能比较好；Jackson 有灵活的 API，可以很容易进行扩展和定制。</p><a id="more"></a><h2 id="常见的JSON解析类库"><a href="#常见的JSON解析类库" class="headerlink" title="常见的JSON解析类库"></a>常见的JSON解析类库</h2><ul><li>fastjson：阿里出品的一个JSON解析类库，很快，提供了很多静态方法使用方便，但是底层实现不是很好，解析过程中使用String的substring，性能很好，但是可能会导致内存泄漏。</li><li>Gson：谷歌出品的JSON解析类库，但是性能相较于其他连个稍微差点。</li><li>Jackson：相对比较推荐的一种JSON解析类库，性能好稳定。</li></ul><blockquote><p>Spring MVC 默认采用Jackson解析Json，尽管还有一些其它同样优秀的json解析工具，例如Fast Json、GSON，但是出于最小依赖的考虑，也许Json解析第一选择就应该是Jackson。</p></blockquote><h2 id="Jackson-简介"><a href="#Jackson-简介" class="headerlink" title="Jackson 简介"></a>Jackson 简介</h2><p>Jackson 是当前用的比较广泛的，用来序列化和反序列化 json 的 Java 的开源框架。Jackson 社区相对比较活跃，更新速度也比较快， 从 Github 中的统计来看，Jackson 是最流行的 json 解析器之一 。 Spring MVC 的默认 json 解析器便是 Jackson。 Jackson 优点很多。 Jackson 所依赖的 jar 包较少 ，简单易用。与其他 Java 的 json 的框架 Gson 等相比， Jackson 解析大的 json 文件速度比较快；Jackson 运行时占用内存比较低，性能比较好；Jackson 有灵活的 API，可以很容易进行扩展和定制。</p><p>Jackson 的 1.x 版本的包名是 org.codehaus.jackson ，当升级到 2.x 版本时，包名变为 com.fasterxml.jackson。</p><p>Jackson 的核心模块由三部分组成。</p><ul><li>jackson-core，核心包，提供基于”流模式”解析的相关 API，它包括 JsonPaser 和 JsonGenerator。 Jackson 内部实现正是通过高性能的流模式 API 的 JsonGenerator 和 JsonParser 来生成和解析 json。</li><li>jackson-annotations，注解包，提供标准注解功能；</li><li>jackson-databind ，数据绑定包， 提供基于”对象绑定” 解析的相关 API （ ObjectMapper ） 和”树模型” 解析的相关 API （JsonNode）；基于”对象绑定” 解析的 API 和”树模型”解析的 API 依赖基于”流模式”解析的 API。</li></ul><p>源码地址：<a href="https://github.com/FasterXML/jackson" target="_blank" rel="noopener">FasterXML/jackson</a></p><h2 id="Maven-依赖"><a href="#Maven-依赖" class="headerlink" title="Maven 依赖"></a>Maven 依赖</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 其中Jackson Annotations依赖Jackson Core，Jackson Databind依赖Jackson Annotations。--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.fasterxml.jackson.core<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jackson-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.fasterxml.jackson.core<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jackson-annotations<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.fasterxml.jackson.core<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jackson-databind<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><p>当然了，jackson-databind 依赖 jackson-core 和 jackson-annotations，所以可以只显示地添加jackson-databind依赖，jackson-core 和 jackson-annotations 也随之添加到 Java 项目工程中。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.fasterxml.jackson.core<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jackson-databind<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="ObjectMapper"><a href="#ObjectMapper" class="headerlink" title="ObjectMapper"></a>ObjectMapper</h2><p>Jackson 最常用的 API 就是基于”对象绑定” 的 ObjectMapper：</p><ul><li>ObjectMapper可以从字符串，流或文件中解析JSON，并创建表示已解析的JSON的Java对象。 将JSON解析为Java对象也称为从JSON反序列化Java对象。</li><li>ObjectMapper也可以从Java对象创建JSON。 从Java对象生成JSON也称为将Java对象序列化为JSON。</li><li>Object映射器可以将JSON解析为自定义的类的对象，也可以解析置JSON树模型的对象。</li></ul><p>之所以称为ObjectMapper是因为它将JSON映射到Java对象（反序列化），或者将Java对象映射到JSON（序列化）。</p><h3 id="从JSON中获取Java对象"><a href="#从JSON中获取Java对象" class="headerlink" title="从JSON中获取Java对象"></a>从JSON中获取Java对象</h3><h4 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h4><p>一个简单的例子：</p><p>Car类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Car</span> </span>&#123;</span><br><span class="line"> <span class="keyword">private</span> String brand = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> doors = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getBrand</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.brand; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span>   <span class="title">setBrand</span><span class="params">(String brand)</span></span>&#123; <span class="keyword">this</span>.brand = brand;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span>  <span class="title">getDoors</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.doors; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDoors</span> <span class="params">(<span class="keyword">int</span> doors)</span> </span>&#123; <span class="keyword">this</span>.doors = doors; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将Json转换为Car类对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    Car car = objectMapper.readValue(carJson, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">"car brand = "</span> + car.getBrand());</span><br><span class="line">    System.out.println(<span class="string">"car doors = "</span> + car.getDoors());</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="ObjectMapper如何匹配JSON对象的字段和Java对象的属性"><a href="#ObjectMapper如何匹配JSON对象的字段和Java对象的属性" class="headerlink" title="ObjectMapper如何匹配JSON对象的字段和Java对象的属性"></a>ObjectMapper如何匹配JSON对象的字段和Java对象的属性</h4><p>默认情况下，Jackson通过将JSON字段的名称与Java对象中的getter和setter方法进行匹配，将JSON对象的字段映射到Java对象中的属性。 Jackson删除了getter和setter方法名称的“ get”和“ set”部分，并将其余名称的第一个字符转换为小写。</p><p>例如，名为brand的JSON字段与名为getBrand()和setBrand()的Java  getter和setter方法匹配。 名为engineNumber的JSON字段将与名为getEngineNumber()和setEngineNumber()的getter和setter匹配。</p><p>如果需要以其他方式将JSON对象字段与Java对象字段匹配，则需要使用自定义序列化器和反序列化器，或者使用一些Jackson注解。</p><h4 id="JSON字符串–-gt-Java对象"><a href="#JSON字符串–-gt-Java对象" class="headerlink" title="JSON字符串–&gt;Java对象"></a>JSON字符串–&gt;Java对象</h4><p>从JSON字符串读取Java对象非常容易。 上面已经有了一个示例——JSON字符串作为第一个参数传递给ObjectMapper的readValue()方法。 这是另一个简单的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line">Car car = objectMapper.readValue(carJson, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><h4 id="JSON-字符输入流–-gt-Java对象"><a href="#JSON-字符输入流–-gt-Java对象" class="headerlink" title="JSON 字符输入流–&gt;Java对象"></a>JSON 字符输入流–&gt;Java对象</h4><p>还可以从通过Reader实例加载的JSON中读取对象。示例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 4 &#125;"</span>;</span><br><span class="line">Reader reader = <span class="keyword">new</span> StringReader(carJson);</span><br><span class="line"></span><br><span class="line">Car car = objectMapper.readValue(reader, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><h4 id="JSON文件–-gt-Java对象"><a href="#JSON文件–-gt-Java对象" class="headerlink" title="JSON文件–&gt;Java对象"></a>JSON文件–&gt;Java对象</h4><p>从文件读取JSON当然可以通过FileReader（而不是StringReader）来完成，也可以通过File对象来完成。 这是从文件读取JSON的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">File file = <span class="keyword">new</span> File(<span class="string">"data/car.json"</span>);</span><br><span class="line"></span><br><span class="line">Car car = objectMapper.readValue(file, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><h4 id="JSON-via-URL—-gt-Java对象"><a href="#JSON-via-URL—-gt-Java对象" class="headerlink" title="JSON via URL—&gt;Java对象"></a>JSON via URL—&gt;Java对象</h4><p>可以通过URL（java.net.URL）从JSON读取对象，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">URL url = <span class="keyword">new</span> URL(<span class="string">"file:data/car.json"</span>);</span><br><span class="line"></span><br><span class="line">Car car = objectMapper.readValue(url, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><p>示例使用文件URL，也可以使用HTTP URL（类似于<a href="http://jenkov.com/some-data.json）。" target="_blank" rel="noopener">http://jenkov.com/some-data.json）。</a></p><h4 id="JSON字节输入流–-gt-Java对象"><a href="#JSON字节输入流–-gt-Java对象" class="headerlink" title="JSON字节输入流–&gt;Java对象"></a>JSON字节输入流–&gt;Java对象</h4><p>也可以使用ObjectMapper通过InputStream从JSON读取对象。 这是一个从InputStream读取JSON的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">InputStream input = <span class="keyword">new</span> FileInputStream(<span class="string">"data/car.json"</span>);</span><br><span class="line"></span><br><span class="line">Car car = objectMapper.readValue(input, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><h4 id="JSON二进制数组–-gt-Java对象"><a href="#JSON二进制数组–-gt-Java对象" class="headerlink" title="JSON二进制数组–&gt;Java对象"></a>JSON二进制数组–&gt;Java对象</h4><p>Jackson还支持从JSON字节数组读取对象。 这是从JSON字节数组读取对象的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">byte</span>[] bytes = carJson.getBytes(<span class="string">"UTF-8"</span>);</span><br><span class="line"></span><br><span class="line">Car car = objectMapper.readValue(bytes, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><h4 id="JSON数组字符串–-gt-Java对象数组"><a href="#JSON数组字符串–-gt-Java对象数组" class="headerlink" title="JSON数组字符串–&gt;Java对象数组"></a>JSON数组字符串–&gt;Java对象数组</h4><p>Jackson ObjectMapper也可以从JSON数组字符串读取对象数组。 这是从JSON数组字符串读取对象数组的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String jsonArray = <span class="string">"[&#123;\"brand\":\"ford\"&#125;, &#123;\"brand\":\"Fiat\"&#125;]"</span>;</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">Car[] cars2 = objectMapper.readValue(jsonArray, Car[]<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><p>需要将Car数组类作为第二个参数传递给readValue()方法。</p><p>读取对象数组还可以与字符串以外的其他JSON源一起使用。 例如，文件，URL，InputStream，Reader等。</p><h4 id="JSON数组字符串–-gt-List"><a href="#JSON数组字符串–-gt-List" class="headerlink" title="JSON数组字符串–&gt;List"></a>JSON数组字符串–&gt;List</h4><p>Jackson ObjectMapper还可以从JSON数组字符串读取对象的Java List。 这是从JSON数组字符串读取对象列表的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String jsonArray = <span class="string">"[&#123;\"brand\":\"ford\"&#125;, &#123;\"brand\":\"Fiat\"&#125;]"</span>;</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">List&lt;Car&gt; cars1 = objectMapper.readValue(jsonArray, <span class="keyword">new</span> TypeReference&lt;List&lt;Car&gt;&gt;()&#123;&#125;);</span><br></pre></td></tr></table></figure><h4 id="JSON字符串–-gt-Map"><a href="#JSON字符串–-gt-Map" class="headerlink" title="JSON字符串–&gt;Map"></a>JSON字符串–&gt;Map</h4><p>Jackson ObjectMapper还可以从JSON字符串读取Java Map。 如果事先不知道将要解析的确切JSON结构，这种方法是很有用的。 通常，会将JSON对象读入Java Map。 JSON对象中的每个字段都将成为Java Map中的键，值对。</p><p>这是一个使用Jackson ObjectMapper从JSON字符串读取Java Map的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String jsonObject = <span class="string">"&#123;\"brand\":\"ford\", \"doors\":5&#125;"</span>;</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">Map&lt;String, Object&gt; jsonMap = objectMapper.readValue(jsonObject,</span><br><span class="line">    <span class="keyword">new</span> TypeReference&lt;Map&lt;String,Object&gt;&gt;()&#123;&#125;);</span><br></pre></td></tr></table></figure><h4 id="忽略未知的JSON字段"><a href="#忽略未知的JSON字段" class="headerlink" title="忽略未知的JSON字段"></a>忽略未知的JSON字段</h4><p>有时候，与要从JSON读取的Java对象相比，JSON中的字段更多。 默认情况下，Jackson在这种情况下会抛出异常，报不知道XYZ字段异常，因为在Java对象中找不到该字段。</p><p>但是，有时应该允许JSON中的字段多于相应的Java对象中的字段。 例如，要从REST服务解析JSON，而该REST服务包含的数据远远超出所需的。 在这种情况下，可以使用Jackson配置忽略这些额外的字段。 以下是配置Jackson ObjectMapper忽略未知字段的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">objectMapper.configure(</span><br><span class="line">    DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, <span class="keyword">false</span>);</span><br></pre></td></tr></table></figure><h4 id="不允许基本类型为null"><a href="#不允许基本类型为null" class="headerlink" title="不允许基本类型为null"></a>不允许基本类型为null</h4><p>如果JSON字符串包含其值设置为null的字段（对于在相应的Java对象中是基本数据类型（int，long，float，double等）的字段），Jackson ObjectMapper默认会处理基本数据类型为null的情况，我们可以可以将Jackson ObjectMapper默认配置为失效，这样基本数据为null就会转换失败。 例如以下Car类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Car</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String brand = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> doors = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getBrand</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.brand; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span>   <span class="title">setBrand</span><span class="params">(String brand)</span></span>&#123; <span class="keyword">this</span>.brand = brand;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span>  <span class="title">getDoors</span><span class="params">()</span></span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.doors; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDoors</span> <span class="params">(<span class="keyword">int</span> doors)</span> </span>&#123; <span class="keyword">this</span>.doors = doors; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>doors字段是一个int类型，它是Java中的基本数据类型。</p><p>现在，假设有一个与Car对象相对应的JSON字符串，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123; <span class="string">"brand"</span>:<span class="string">"Toyota"</span>, <span class="string">"doors"</span>:<span class="keyword">null</span> &#125;</span><br></pre></td></tr></table></figure><p>请注意，doors字段值为null。 Java中的基本数据类型不能为null值。 默认情况下，Jackson ObjectMapper会忽略原始字段的空值。 但是，可以将Jackson ObjectMapper配置设置为失败。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">objectMapper.configure(DeserializationFeature.FAIL_ON_NULL_FOR_PRIMITIVES, <span class="keyword">true</span>);</span><br></pre></td></tr></table></figure><p>在FAIL_ON_NULL_FOR_PRIMITIVES配置值设置为true的情况下，尝试将空JSON字段解析为基本类型Java字段时会遇到异常。 这是一个Java Jackson ObjectMapper示例，该示例将失败，因为JSON字段包含原始Java字段的空值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">objectMapper.configure(DeserializationFeature.FAIL_ON_NULL_FOR_PRIMITIVES, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">String carJson = <span class="string">"&#123; \"brand\":\"Toyota\", \"doors\":null &#125;"</span>;</span><br><span class="line"></span><br><span class="line">Car car = objectMapper.readValue(carJson, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><blockquote><p>会报错：MismatchedInputException</p></blockquote><h4 id="自定义反序列化"><a href="#自定义反序列化" class="headerlink" title="自定义反序列化"></a>自定义反序列化</h4><p>有时，可能希望以不同于Jackson ObjectMapper缺省方式的方式将JSON字符串读入Java对象。 可以将自定义反序列化器添加到ObjectMapper，可以按需要执行反序列化。</p><p>这是在Jackson的ObjectMapper中注册和使用自定义反序列化器的方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">String json = <span class="string">"&#123; \"brand\" : \"Ford\", \"doors\" : 6 &#125;"</span>;</span><br><span class="line"></span><br><span class="line">SimpleModule <span class="keyword">module</span> =</span><br><span class="line">        <span class="keyword">new</span> SimpleModule(<span class="string">"CarDeserializer"</span>, <span class="keyword">new</span> Version(<span class="number">3</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>));</span><br><span class="line"><span class="keyword">module</span>.addDeserializer(Car<span class="class">.<span class="keyword">class</span>, <span class="title">new</span> <span class="title">CarDeserializer</span>(<span class="title">Car</span>.<span class="title">class</span>))</span>;</span><br><span class="line"></span><br><span class="line">ObjectMapper mapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">mapper.registerModule(<span class="keyword">module</span>);</span><br><span class="line"></span><br><span class="line">Car car = mapper.readValue(json, Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br></pre></td></tr></table></figure><p>自定义反序列化器CarDeserializer类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CarDeserializer</span> <span class="keyword">extends</span> <span class="title">StdDeserializer</span>&lt;<span class="title">Car</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CarDeserializer</span><span class="params">(Class&lt;?&gt; vc)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(vc);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Car <span class="title">deserialize</span><span class="params">(JsonParser parser, DeserializationContext deserializer)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Car car = <span class="keyword">new</span> Car();</span><br><span class="line">        <span class="keyword">while</span>(!parser.isClosed())&#123;</span><br><span class="line">            JsonToken jsonToken = parser.nextToken();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span>(JsonToken.FIELD_NAME.equals(jsonToken))&#123;</span><br><span class="line">                String fieldName = parser.getCurrentName();</span><br><span class="line">                System.out.println(fieldName);</span><br><span class="line"></span><br><span class="line">                jsonToken = parser.nextToken();</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>(<span class="string">"brand"</span>.equals(fieldName))&#123;</span><br><span class="line">                    car.setBrand(parser.getValueAsString());</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"doors"</span>.equals(fieldName))&#123;</span><br><span class="line">                    car.setDoors(parser.getValueAsInt());</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> car;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="将对象写入JSON"><a href="#将对象写入JSON" class="headerlink" title="将对象写入JSON"></a>将对象写入JSON</h3><h4 id="Java对象–-gt-JSON"><a href="#Java对象–-gt-JSON" class="headerlink" title="Java对象–&gt;JSON"></a>Java对象–&gt;JSON</h4><p>Jackson ObjectMapper也可以用于从对象生成JSON。 可以使用以下方法之一进行操作：</p><ul><li>writeValue()</li><li>writeValueAsString()</li><li>writeValueAsBytes()</li></ul><p>这是一个从Car对象生成JSON的示例，和上面的实例相反：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">  Car car = <span class="keyword">new</span> Car();</span><br><span class="line">  car.setBrand(<span class="string">"BMW"</span>);</span><br><span class="line">  car.setDoors(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">  objectMapper.writeValue(</span><br><span class="line">      <span class="keyword">new</span> FileOutputStream(<span class="string">"data/output-2.json"</span>), car);</span><br></pre></td></tr></table></figure><p>此示例首先创建一个ObjectMapper，然后创建一个Car实例，最后调用ObjectMapper的writeValue()方法，该方法将Car对象转换为JSON并将其写入给定的FileOutputStream。</p><p>ObjectMapper的writeValueAsString()和writeValueAsBytes()都从一个对象生成JSON，并将生成的JSON作为String或字节数组返回。 示例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">Car car = <span class="keyword">new</span> Car();</span><br><span class="line">car.setBrand(<span class="string">"宝马"</span>);</span><br><span class="line">car.setDoors(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">String json = objectMapper.writeValueAsString(car);</span><br><span class="line">System.out.println(json);</span><br></pre></td></tr></table></figure><h4 id="自定义序列化"><a href="#自定义序列化" class="headerlink" title="自定义序列化"></a>自定义序列化</h4><p>有时，想要将Java对象序列化为JSON的方式与使用Jackson的默认方式不同。例如，可能想要在JSON中使用与Java对象中不同的字段名称，或者希望完全省略某些字段。</p><p>Jackson可以在ObjectMapper上设置自定义序列化器。该序列化器已为某个类注册，然后在每次要求ObjectMapper序列化Car对象时将调用该序列化器。</p><p>这是为Car类注册自定义序列化器的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">CarSerializer carSerializer = <span class="keyword">new</span> CarSerializer(Car<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">SimpleModule <span class="keyword">module</span> =</span><br><span class="line">        <span class="keyword">new</span> SimpleModule(<span class="string">"CarSerializer"</span>, <span class="keyword">new</span> Version(<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>));</span><br><span class="line"><span class="keyword">module</span>.addSerializer(Car<span class="class">.<span class="keyword">class</span>, <span class="title">carSerializer</span>)</span>;</span><br><span class="line"></span><br><span class="line">objectMapper.registerModule(<span class="keyword">module</span>);</span><br><span class="line"></span><br><span class="line">Car car = <span class="keyword">new</span> Car();</span><br><span class="line">car.setBrand(<span class="string">"Mercedes"</span>);</span><br><span class="line">car.setDoors(<span class="number">5</span>);</span><br><span class="line"></span><br><span class="line">String carJson = objectMapper.writeValueAsString(car);</span><br></pre></td></tr></table></figure><p>自定义序列化器CarSerializer类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CarSerializer</span> <span class="keyword">extends</span> <span class="title">StdSerializer</span>&lt;<span class="title">Car</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="title">CarSerializer</span><span class="params">(Class&lt;Car&gt; t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(t);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">serialize</span><span class="params">(Car car, JsonGenerator jsonGenerator,</span></span></span><br><span class="line"><span class="function"><span class="params">                          SerializerProvider serializerProvider)</span></span></span><br><span class="line"><span class="function">            <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        jsonGenerator.writeStartObject();</span><br><span class="line">        jsonGenerator.writeStringField(<span class="string">"producer"</span>, car.getBrand());</span><br><span class="line">        jsonGenerator.writeNumberField(<span class="string">"doorCount"</span>, car.getDoors());</span><br><span class="line">        jsonGenerator.writeEndObject();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Jackson-日期转化"><a href="#Jackson-日期转化" class="headerlink" title="Jackson 日期转化"></a>Jackson 日期转化</h3><p>默认情况下，Jackson会将java.util.Date对象序列化为其long型的值，该值是自1970年1月1日以来的毫秒数。但是，Jackson还支持将日期格式化为字符串。</p><h4 id="Date–-gt-long"><a href="#Date–-gt-long" class="headerlink" title="Date–&gt;long"></a>Date–&gt;long</h4><p>默认的Jackson日期格式，该格式将Date序列化为自1970年1月1日以来的毫秒数（long类型）。</p><p>这是一个包含Date字段的Java类示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> String type = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">private</span> Date date = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Transaction</span><span class="params">()</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Transaction</span><span class="params">(String type, Date date)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.type = type;</span><br><span class="line">    <span class="keyword">this</span>.date = date;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> type;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setType</span><span class="params">(String type)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.type = type;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Date <span class="title">getDate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> date;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDate</span><span class="params">(Date date)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.date = date;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就像使用其他Java对象进行序列化一样，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Transaction transaction = <span class="keyword">new</span> Transaction(<span class="string">"transfer"</span>, <span class="keyword">new</span> Date());</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">String output = objectMapper.writeValueAsString(transaction);</span><br><span class="line"></span><br><span class="line">System.out.println(output);</span><br></pre></td></tr></table></figure><h4 id="Date–-gt-String"><a href="#Date–-gt-String" class="headerlink" title="Date–&gt;String"></a>Date–&gt;String</h4><p>日期的long序列化格式不符合人类的时间查看格式。 因此，Jackson也支持文本日期格式。 可以通过在ObjectMapper上设置SimpleDateFormat来指定要使用的确切Jackson日期格式。 这是在Jackson的ObjectMapper上设置SimpleDateFormat的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Transaction transaction = <span class="keyword">new</span> Transaction(<span class="string">"transfer"</span>, <span class="keyword">new</span> Date());</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">SimpleDateFormat dateFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>);</span><br><span class="line">objectMapper.setDateFormat(dateFormat);</span><br><span class="line"></span><br><span class="line">String output2 = objectMapper.writeValueAsString(transaction);</span><br><span class="line">System.out.println(output2);</span><br></pre></td></tr></table></figure><h3 id="Jackson-JSON-树模型"><a href="#Jackson-JSON-树模型" class="headerlink" title="Jackson JSON 树模型"></a>Jackson JSON 树模型</h3><p>Jackson具有内置的树模型，可用于表示JSON对象。 如果不知道接收到的JSON的格式，或者由于某种原因而不能（或者只是不想）创建一个类来表示它，那么就要用到Jackson的树模型。 如果需要在使用或转化JSON之前对其进行操作，也需要被用到Jackson树模型。 所有这些情况在数据流场景中都很常见。</p><p>Jackson树模型由JsonNode类表示。 您可以使用Jackson ObjectMapper将JSON解析为JsonNode树模型，就像使用您自己的类一样。</p><p>以下将展示如何使用Jackson ObjectMapper读写JsonNode实例。</p><h4 id="Jackson-Tree-Model简单例子"><a href="#Jackson-Tree-Model简单例子" class="headerlink" title="Jackson Tree Model简单例子"></a>Jackson Tree Model简单例子</h4><p>下面是一个简单的例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">    JsonNode jsonNode = objectMapper.readValue(carJson, JsonNode<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只需将JsonNode.class作为第二个参数传递给readValue()方法，而不是本教程前面的示例中使用的Car.class，就可以将JSON字符串解析为JsonNode对象而不是Car对象。 。</p><p>ObjectMapper类还具有一个特殊的readTree()方法，该方法返回JsonNode。 这是使用ObjectMapper readTree()方法将JSON解析为JsonNode的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">    JsonNode jsonNode = objectMapper.readTree(carJson);</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Jackson-JsonNode类"><a href="#Jackson-JsonNode类" class="headerlink" title="Jackson JsonNode类"></a>Jackson JsonNode类</h4><p>通过JsonNode类，可以以非常灵活和动态的方式将JSON作为Java对象导航。这里了解一些如何使用它的基础知识。</p><p>将JSON解析为JsonNode（或JsonNode实例树）后，就可以浏览JsonNode树模型。 这是一个JsonNode示例，显示了如何访问JSON字段，数组和嵌套对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">String carJson =</span><br><span class="line">        <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5,"</span> +</span><br><span class="line">        <span class="string">"  \"owners\" : [\"John\", \"Jack\", \"Jill\"],"</span> +</span><br><span class="line">        <span class="string">"  \"nestedObject\" : &#123; \"field\" : \"value\" &#125; &#125;"</span>;</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">    JsonNode jsonNode = objectMapper.readValue(carJson, JsonNode<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    JsonNode brandNode = jsonNode.get(<span class="string">"brand"</span>);</span><br><span class="line">    String brand = brandNode.asText();</span><br><span class="line">    System.out.println(<span class="string">"brand = "</span> + brand);</span><br><span class="line"></span><br><span class="line">    JsonNode doorsNode = jsonNode.get(<span class="string">"doors"</span>);</span><br><span class="line">    <span class="keyword">int</span> doors = doorsNode.asInt();</span><br><span class="line">    System.out.println(<span class="string">"doors = "</span> + doors);</span><br><span class="line"></span><br><span class="line">    JsonNode array = jsonNode.get(<span class="string">"owners"</span>);</span><br><span class="line">    JsonNode jsonNode = array.get(<span class="number">0</span>);</span><br><span class="line">    String john = jsonNode.asText();</span><br><span class="line">    System.out.println(<span class="string">"john  = "</span> + john);</span><br><span class="line"></span><br><span class="line">    JsonNode child = jsonNode.get(<span class="string">"nestedObject"</span>);</span><br><span class="line">    JsonNode childField = child.get(<span class="string">"field"</span>);</span><br><span class="line">    String field = childField.asText();</span><br><span class="line">    System.out.println(<span class="string">"field = "</span> + field);</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请注意，JSON字符串现在包含一个称为owners的数组字段和一个称为nestedObject的嵌套对象字段。</p><p>无论访问的是字段，数组还是嵌套对象，都可以使用JsonNode类的get()方法。 通过将字符串作为参数提供给get()方法，可以访问JsonNode的字段。 如果JsonNode表示数组，则需要将索引传递给get()方法。 索引指定要获取的数组元素。</p><h4 id="Java对象–-gt-JsonNode"><a href="#Java对象–-gt-JsonNode" class="headerlink" title="Java对象–&gt;JsonNode"></a>Java对象–&gt;JsonNode</h4><p>可以使用Jackson ObjectMapper将Java对象转换为JsonNode，而JsonNode是转换后的Java对象的JSON表示形式。 可以通过Jackson ObjectMapper valueToTree()方法将Java对象转换为JsonNode。 这是一个使用ObjectMapper valueToTree()方法将Java对象转换为JsonNode的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">Car car = <span class="keyword">new</span> Car();</span><br><span class="line">car.brand = <span class="string">"Cadillac"</span>;</span><br><span class="line">car.doors = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line">JsonNode carJsonNode = objectMapper.valueToTree(car);</span><br></pre></td></tr></table></figure><h4 id="JsonNode–-gt-Java对象"><a href="#JsonNode–-gt-Java对象" class="headerlink" title="JsonNode–&gt;Java对象"></a>JsonNode–&gt;Java对象</h4><p>可以使用Jackson  ObjectMapper treeToValue()方法将JsonNode转换为Java对象。 这类似于使用Jackson Jackson的ObjectMapper将JSON字符串（或其他来源）解析为Java对象。 唯一的区别是，JSON源是JsonNode。 这是一个使用Jackson ObjectMapper treeToValue()方法将JsonNode转换为Java对象的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line">JsonNode carJsonNode = objectMapper.readTree(carJson);</span><br><span class="line"></span><br><span class="line">Car car = objectMapper.treeToValue(carJsonNode);</span><br></pre></td></tr></table></figure><p>上面的示例有点“人为”，因为我们首先将JSON字符串转换为JsonNode，然后将JsonNode转换为Car对象。 显然，如果我们有对原始JSON字符串的引用，则最好将其直接转换为Car对象，而无需先将其转换为JsonNode。</p><h2 id="JsonNode"><a href="#JsonNode" class="headerlink" title="JsonNode"></a>JsonNode</h2><p>Jackson JsonNode类com.fasterxml.jackson.databind.JsonNode是Jackson的JSON树形模型（对象图模型）。 Jackson可以将JSON读取到JsonNode实例中，然后将JsonNode写入JSON。 因此，这一节将说明如何将JSON反序列化为JsonNode以及将JsonNode序列化为JSON。 此Jackson JsonNode教程还将说明如何从头开始构建JsonNode对象图，因此以后可以将它们序列化为JSON。</p><h3 id="JsonNode-vs-ObjectNode"><a href="#JsonNode-vs-ObjectNode" class="headerlink" title="JsonNode vs ObjectNode"></a>JsonNode vs ObjectNode</h3><p>Jackson JsonNode类是不可变的。 这意味着，实际上不能直接构建JsonNode实例的对象图。 而是创建JsonNode子类ObjectNode的对象图。 作为JsonNode的子类，可以在可以使用JsonNode的任何地方使用ObjectNode。</p><h3 id="JSON–-gt-JsonNode"><a href="#JSON–-gt-JsonNode" class="headerlink" title="JSON–&gt;JsonNode"></a>JSON–&gt;JsonNode</h3><p>要使用Jackson将JSON读取到JsonNode中，首先需要创建一个Jackson ObjectMapper实例。 在ObjectMapper实例上，调用readTree()并将JSON源作为参数传递。 这是将JSON反序列化为JsonNode的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">String json = <span class="string">"&#123; \"f1\" : \"v1\" &#125; "</span>;</span><br><span class="line"></span><br><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">JsonNode jsonNode = objectMapper.readTree(json);</span><br><span class="line"></span><br><span class="line">System.out.println(jsonNode.get(<span class="string">"f1"</span>).asText());</span><br></pre></td></tr></table></figure><h3 id="JsonNode–-gt-JSON"><a href="#JsonNode–-gt-JSON" class="headerlink" title="JsonNode–&gt;JSON"></a>JsonNode–&gt;JSON</h3><p>要将Jackson的JsonNode写入JSON，还需要一个Jackson ObjectMapper实例。 在ObjectMapper上，调用writeValueAsString()方法或任何适合需要的写入方法。 这是将JsonNode写入JSON的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">JsonNode jsonNode = readJsonIntoJsonNode();</span><br><span class="line"></span><br><span class="line">String json = objectMapper.writeValueAsString(jsonNode);</span><br></pre></td></tr></table></figure><h3 id="获取JsonNode字段"><a href="#获取JsonNode字段" class="headerlink" title="获取JsonNode字段"></a>获取JsonNode字段</h3><p>JsonNode可以像JSON对象一样具有字段。 假设已将以下JSON解析为JsonNode：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"field1"</span> : <span class="string">"value1"</span>,</span><br><span class="line">    <span class="attr">"field2"</span> : <span class="number">999</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此JSON对象具有两个名为field1和field2的字段。 如果有一个表示上述JSON对象的Jackson JsonNode，则可以这样获得两个字段：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JsonNode jsonNode = ... <span class="comment">//parse above JSON into a JsonNode</span></span><br><span class="line"></span><br><span class="line">JsonNode field1 = jsonNode.get(<span class="string">"field1"</span>);</span><br><span class="line">JsonNode field2 = jsonNode.get(<span class="string">"field2"</span>);</span><br></pre></td></tr></table></figure><p>请注意，即使两个字段都是String字段，get()方法也始终返回JsonNode来表示该字段。</p><h3 id="在路径中获取JsonNode字段"><a href="#在路径中获取JsonNode字段" class="headerlink" title="在路径中获取JsonNode字段"></a>在路径中获取JsonNode字段</h3><p>Jackson JsonNode有一个称为at()的特殊方法。 at()方法可以从JSON图中以给定JsonNode为根的任何位置访问JSON字段。 假设JSON结构如下所示：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"identification"</span> :  &#123;</span><br><span class="line">        <span class="attr">"name"</span> : <span class="string">"James"</span>,</span><br><span class="line">        "ssn: "ABC123552"</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果将此JSON解析为JsonNode，则可以使用at()方法访问名称字段，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JsonNode nameNode = jsonNode.at(<span class="string">"/identification/name"</span>);</span><br></pre></td></tr></table></figure><p>注意传递给at()方法的参数：字符串/ identification / name。 这是一个JSON路径表达式。 此路径表达式指定从根JsonNode到您要访问其值的字段的完整路径。 这类似于从文件系统根目录到Unix文件系统中文件的路径。</p><p>请注意，JSON路径表达式必须以斜杠字符（/字符）开头。</p><p>at()方法返回一个JsonNode，它表示请求的JSON字段。 要获取该字段的实际值，需要调用下一部分介绍的方法之一。 如果没有节点与给定的路径表达式匹配，则将返回null。</p><h3 id="转换JsonNode字段"><a href="#转换JsonNode字段" class="headerlink" title="转换JsonNode字段"></a>转换JsonNode字段</h3><p>Jackson JsonNode类包含一组可以将字段值转换为另一种数据类型的方法。 例如，将String字段值转换为long或相反。 这是将JsonNode字段转换为一些更常见的数据类型的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String f2Str = jsonNode.get(<span class="string">"f2"</span>).asText();</span><br><span class="line"><span class="keyword">double</span> f2Dbl = jsonNode.get(<span class="string">"f2"</span>).asDouble();</span><br><span class="line"><span class="keyword">int</span>    f2Int = jsonNode.get(<span class="string">"f2"</span>).asInt();</span><br><span class="line"><span class="keyword">long</span>   f2Lng = jsonNode.get(<span class="string">"f2"</span>).asLong();</span><br></pre></td></tr></table></figure><p>使用默认值转换: 如果JsonNode中的字段可以为null，则在尝试转换它时可以提供默认值。 这是使用默认值调用转换方法的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">String json = <span class="string">"&#123; \"f1\":\"Hello\", \"f2\":null &#125;"</span>;</span><br><span class="line"></span><br><span class="line">JsonNode jsonNode = objectMapper.readTree(json);</span><br><span class="line"></span><br><span class="line">String f2Value = jsonNode.get(<span class="string">"f2"</span>).asText(<span class="string">"Default"</span>);</span><br></pre></td></tr></table></figure><p>在示例的JSON字符串中可以看到，声明了f2字段，但将其设置为null。 在这种情况下，调用jsonNode.get（“ f2”）。asText（“ Default”）将返回默认值，在此示例中为字符串Default。</p><p>asDouble()，asInt()和asLong()方法还可以采用默认参数值，如果尝试从中获取值的字段为null，则将返回默认参数值。</p><p>请注意，如果该字段在JSON中未显式设置为null，但在JSON中丢失，则调用jsonNode.get（“ fieldName”）将返回Java null值，您无法在该Java值上调用asInt() ，asDouble()，asLong()或asText()。 如果尝试这样做，将会导致NullPointerException。 这是说明这种情况的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">String json = <span class="string">"&#123; \"f1\":\"Hello\" &#125;"</span>;</span><br><span class="line"></span><br><span class="line">JsonNode jsonNode = objectMapper.readTree(json);</span><br><span class="line"></span><br><span class="line">JsonNode f2FieldNode = jsonNode.get(<span class="string">"f2"</span>);</span><br></pre></td></tr></table></figure><h3 id="创建一个ObjectNode"><a href="#创建一个ObjectNode" class="headerlink" title="创建一个ObjectNode"></a>创建一个ObjectNode</h3><p>如前所述，JsonNode类是不可变的。 要创建JsonNode对象图，必须能够更改图中的JsonNode实例，例如 设置属性值和子JsonNode实例等。由于是不可变的，因此无法直接使用JsonNode来实现。</p><p>而是创建一个ObjectNode实例，该实例是JsonNode的子类。 这是一个通过Jackson ObjectMapper createObjectNode()方法创建ObjectNode的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line"></span><br><span class="line">ObjectNode objectNode = objectMapper.createObjectNode();</span><br></pre></td></tr></table></figure><h3 id="Set-ObjectNode字段"><a href="#Set-ObjectNode字段" class="headerlink" title="Set ObjectNode字段"></a>Set ObjectNode字段</h3><p>要在Jackson ObjectNode上设置字段，可以调用其set()方法，并将字段名称String和JsonNode作为参数传递。 这是在Jackson的ObjectNode上设置字段的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ObjectMapper objectMapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">ObjectNode parentNode = objectMapper.createObjectNode();</span><br><span class="line"></span><br><span class="line">JsonNode childNode = readJsonIntoJsonNode();</span><br><span class="line"></span><br><span class="line">parentNode.set(<span class="string">"child1"</span>, childNode);</span><br></pre></td></tr></table></figure><h3 id="Put-ObjectNode字段"><a href="#Put-ObjectNode字段" class="headerlink" title="Put ObjectNode字段"></a>Put ObjectNode字段</h3><p>ObjectNode类还具有一组方法，可以直接为字段put(设置)值。 这比尝试将原始值转换为JsonNode并使用set()进行设置要容易得多。 以下是使用put()方法为ObjectNode上的字段设置字符串值的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">objectNode.put(<span class="string">"field1"</span>, <span class="string">"value1"</span>);</span><br><span class="line">objectNode.put(<span class="string">"field2"</span>, <span class="number">123</span>);</span><br><span class="line">objectNode.put(<span class="string">"field3"</span>, <span class="number">999.999</span>);</span><br></pre></td></tr></table></figure><h3 id="删除字段"><a href="#删除字段" class="headerlink" title="删除字段"></a>删除字段</h3><p>ObjectNode类具有一个称为remove()的方法，该方法可用于从ObjectNode中删除字段。 这是一个通过其remove()方法从Jackson ObjectNode删除字段的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objectNode.remove(<span class="string">"fieldName"</span>);</span><br></pre></td></tr></table></figure><h3 id="循环JsonNode字段"><a href="#循环JsonNode字段" class="headerlink" title="循环JsonNode字段"></a>循环JsonNode字段</h3><p>JsonNode类具有一个名为fieldNames()的方法，该方法返回一个Iterator，可以迭代JsonNode的所有字段名称。 我们可以使用字段名称来获取字段值。 这是一个迭代Jackson JsonNode的所有字段名称和值的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;String&gt; fieldNames = jsonNode.fieldNames();</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(fieldNames.hasNext()) &#123;</span><br><span class="line">    String fieldName = fieldNames.next();</span><br><span class="line"></span><br><span class="line">    JsonNode field = jsonNode.get(fieldName);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="JsonParser"><a href="#JsonParser" class="headerlink" title="JsonParser"></a>JsonParser</h2><p>Jackson JsonParser类是一个底层一些的JSON解析器。 它类似于XML的Java StAX解析器，差别是JsonParser解析JSON而不解析XML。</p><p>Jackson JsonParser的运行层级低于Jackson ObjectMapper。 这使得JsonParser比ObjectMapper更快，但使用起来也比较麻烦。</p><h3 id="创建一个JsonParser"><a href="#创建一个JsonParser" class="headerlink" title="创建一个JsonParser"></a>创建一个JsonParser</h3><p>为了创建Jackson JsonParser，首先需要创建一个JsonFactory。 JsonFactory用于创建JsonParser实例。 JsonFactory类包含几个createParser()方法，每个方法都使用不同的JSON源作为参数。</p><p>这是创建一个JsonParser来从字符串中解析JSON的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line">JsonFactory factory = <span class="keyword">new</span> JsonFactory();</span><br><span class="line">JsonParser  parser  = factory.createParser(carJson);</span><br></pre></td></tr></table></figure><h3 id="用JsonParser转化JSON"><a href="#用JsonParser转化JSON" class="headerlink" title="用JsonParser转化JSON"></a>用JsonParser转化JSON</h3><p>一旦创建了Jackson JsonParser，就可以使用它来解析JSON。 JsonParser的工作方式是将JSON分解为一系列令牌，可以一个一个地迭代令牌。</p><p>这是一个JsonParser示例，它简单地循环遍历所有标记并将它们输出到System.out。 这是一个实际上很少用示例，只是展示了将JSON分解成的令牌，以及如何遍历令牌的基础知识。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tring carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line">JsonFactory factory = <span class="keyword">new</span> JsonFactory();</span><br><span class="line">JsonParser  parser  = factory.createParser(carJson);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(!parser.isClosed())&#123;</span><br><span class="line">    JsonToken jsonToken = parser.nextToken();</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">"jsonToken = "</span> + jsonToken);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只要JsonParser的isClosed()方法返回false，那么JSON源中仍然会有更多的令牌。</p><p>可以使用JsonParser的nextToken()获得一个JsonToken。 您可以使用此JsonToken实例检查给定的令牌。 令牌类型由JsonToken类中的一组常量表示。 这些常量是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">START_OBJECT</span><br><span class="line">END_OBJECT</span><br><span class="line">START_ARRAY</span><br><span class="line">END_ARRAY</span><br><span class="line">FIELD_NAME</span><br><span class="line">VALUE_EMBEDDED_OBJECT</span><br><span class="line">VALUE_FALSE</span><br><span class="line">VALUE_TRUE</span><br><span class="line">VALUE_NULL</span><br><span class="line">VALUE_STRING</span><br><span class="line">VALUE_NUMBER_INT</span><br><span class="line">VALUE_NUMBER_FLOAT</span><br></pre></td></tr></table></figure><p>可以使用这些常量来找出当前JsonToken是什么类型的令牌。 可以通过这些常量的equals()方法进行操作。 这是一个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">String carJson = <span class="string">"&#123; \"brand\" : \"Mercedes\", \"doors\" : 5 &#125;"</span>;</span><br><span class="line"></span><br><span class="line">JsonFactory factory = <span class="keyword">new</span> JsonFactory();</span><br><span class="line">JsonParser  parser  = factory.createParser(carJson);</span><br><span class="line"></span><br><span class="line">Car car = <span class="keyword">new</span> Car();</span><br><span class="line"><span class="keyword">while</span>(!parser.isClosed())&#123;</span><br><span class="line">    JsonToken jsonToken = parser.nextToken();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(JsonToken.FIELD_NAME.equals(jsonToken))&#123;</span><br><span class="line">        String fieldName = parser.getCurrentName();</span><br><span class="line">        System.out.println(fieldName);</span><br><span class="line"></span><br><span class="line">        jsonToken = parser.nextToken();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(<span class="string">"brand"</span>.equals(fieldName))&#123;</span><br><span class="line">            car.brand = parser.getValueAsString();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"doors"</span>.equals(fieldName))&#123;</span><br><span class="line">            car.doors = parser.getValueAsInt();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">System.out.println(<span class="string">"car.brand = "</span> + car.brand);</span><br><span class="line">System.out.println(<span class="string">"car.doors = "</span> + car.doors);</span><br></pre></td></tr></table></figure><p>如果指向的标记是字段名称，则JsonParser的getCurrentName()方法将返回当前字段名称。</p><p>如果指向的令牌是字符串字段值，则getValueAsString()返回当前令牌值作为字符串。 如果指向的令牌是整数字段值，则getValueAsInt()返回当前令牌值作为int值。 JsonParser具有更多类似的方法来获取不同类型的curren令牌值（例如boolean，short，long，float，double等）。</p><h2 id="JsonGenerator"><a href="#JsonGenerator" class="headerlink" title="JsonGenerator"></a>JsonGenerator</h2><p>Jackson JsonGenerator用于从Java对象（或代码从中生成JSON的任何数据结构）生成JSON。</p><h3 id="创建一个JsonGenerator"><a href="#创建一个JsonGenerator" class="headerlink" title="创建一个JsonGenerator"></a>创建一个JsonGenerator</h3><p>为了创建Jackson JsonGenerator，必须首先创建JsonFactory实例。 这是创建JsonFactory的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JsonFactory factory = <span class="keyword">new</span> JsonFactory();</span><br></pre></td></tr></table></figure><p>一旦创建了JsonFactory，就可以使用JsonFactory的createGenerator()方法创建JsonGenerator。 这是创建JsonGenerator的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JsonFactory factory = <span class="keyword">new</span> JsonFactory();</span><br><span class="line"></span><br><span class="line">JsonGenerator generator = factory.createGenerator(</span><br><span class="line">    <span class="keyword">new</span> File(<span class="string">"data/output.json"</span>), JsonEncoding.UTF8);</span><br></pre></td></tr></table></figure><p>createGenerator()方法的第一个参数是生成的JSON的目标。 在上面的示例中，参数是File对象。 这意味着生成的JSON将被写入给定文件。 createGenerator()方法已重载，因此还有其他版本的createGenerator()方法采用例如OutputStream等，提供了有关将生成的JSON写入何处的不同选项。</p><p>createGenerator()方法的第二个参数是生成JSON时使用的字符编码。上面的示例使用UTF-8。</p><h3 id="使用JsonGenerator生成JSON"><a href="#使用JsonGenerator生成JSON" class="headerlink" title="使用JsonGenerator生成JSON"></a>使用JsonGenerator生成JSON</h3><p>一旦创建了JsonGenerator，就可以开始生成JSON。 JsonGenerator包含一组write …()方法，可以使用这些方法来编写JSON对象的各个部分。 这是一个使用Jackson JsonGenerator生成JSON的简单示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">JsonFactory factory = <span class="keyword">new</span> JsonFactory();</span><br><span class="line"></span><br><span class="line">JsonGenerator generator = factory.createGenerator(</span><br><span class="line">    <span class="keyword">new</span> File(<span class="string">"data/output.json"</span>), JsonEncoding.UTF8);</span><br><span class="line"></span><br><span class="line">generator.writeStartObject();</span><br><span class="line">generator.writeStringField(<span class="string">"brand"</span>, <span class="string">"Mercedes"</span>);</span><br><span class="line">generator.writeNumberField(<span class="string">"doors"</span>, <span class="number">5</span>);</span><br><span class="line">generator.writeEndObject();</span><br><span class="line"></span><br><span class="line">generator.close();</span><br></pre></td></tr></table></figure><p>此示例首先调用writeStartObject()，将{写入输出。 然后，该示例调用writeStringField()，将品牌字段名称+值写入输出。 之后，将调用writeNumberField()方法，此方法会将Doors字段名称+值写入输出。 最后，调用writeEndObject()，将}写入输出。</p><p>JsonGenerator还可以使用许多其他写入方法。 这个例子只显示了其中一些。</p><h3 id="关闭JsonGenerator"><a href="#关闭JsonGenerator" class="headerlink" title="关闭JsonGenerator"></a>关闭JsonGenerator</h3><p>完成生成JSON后，应关闭JsonGenerator。 您可以通过调用其close()方法来实现。 这是关闭JsonGenerator的样子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">generator.close();</span><br></pre></td></tr></table></figure><h2 id="Jackson注解"><a href="#Jackson注解" class="headerlink" title="Jackson注解"></a>Jackson注解</h2><p>Jackson JSON工具包包含一组Java注解，可以使用这些注解来设置将JSON读入对象的方式或从对象生成什么JSON的方式。 此Jackson注解教程介绍了如何使用Jackson的注解。</p><p>下面是一些常用的注解：</p><table><thead><tr><th>注解</th><th>用法</th></tr></thead><tbody><tr><td>@JsonProperty</td><td>用于属性，把属性的名称序列化时转换为另外一个名称。示例：   @JsonProperty(“birth_ d                            ate”)   private Date birthDate;</td></tr><tr><td>@JsonFormat</td><td>用于属性或者方法，把属性的格式序列化时转换成指定的格式。示例：   @JsonFormat(timezone =                            “GMT+8”, pattern = “yyyy-MM-dd HH:mm”)   public Date                            getBirthDate()</td></tr><tr><td>@JsonPropertyOrder</td><td>用于类， 指定属性在序列化时 json 中的顺序 ， 示例：   @JsonPropertyOrder({                            “birth_Date”, “name” })   public class Person</td></tr><tr><td>@JsonCreator</td><td>用于构造方法，和 @JsonProperty 配合使用，适用有参数的构造方法。 示例：                              @JsonCreator   public Person(@JsonProperty(“name”)String                            name) {…}</td></tr><tr><td>@JsonAnySetter</td><td>用于属性或者方法，设置未反序列化的属性名和值作为键值存储到 map 中   @JsonAnySetter                              public void set(String key, Object value) {                              map.put(key, value);   }</td></tr><tr><td>@JsonAnyGetter</td><td>用于方法 ，获取所有未序列化的属性   <code>public Map&lt;String, Object&gt;                            any() { return map; }</code></td></tr></tbody></table><p>下面是一些注解的详细说明。</p><h3 id="Read-Write注解"><a href="#Read-Write注解" class="headerlink" title="Read + Write注解"></a>Read + Write注解</h3><p>Jackson包含一组注解，这些注解会影响从JSON读取Java对象以及将Java对象写入JSON。 我将这些注解称为“读+写注解”。 以下各节将更详细地介绍Jackson的读写注解。</p><h4 id="JsonIgnore"><a href="#JsonIgnore" class="headerlink" title="@JsonIgnore"></a>@JsonIgnore</h4><p>Jackson注解@JsonIgnore用于告诉Jackson忽略Java对象的某个属性（字段）。 在将JSON读取到Java对象中以及将Java对象写入JSON时，都将忽略该属性。</p><p>这是使用@JsonIgnore注解的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonIgnore;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonIgnore</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonIgnore</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>  personId = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String name = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的类中，不会从JSON读取或写入JSON属性personId。</p><h4 id="JsonIgnoreProperties"><a href="#JsonIgnoreProperties" class="headerlink" title="@JsonIgnoreProperties"></a>@JsonIgnoreProperties</h4><p>@JsonIgnoreProperties Jackson注解用于指定要忽略的类的属性列表。 @JsonIgnoreProperties注解放置在类声明上方，而不是要忽略的各个属性（字段）上方。</p><p>这是如何使用@JsonIgnoreProperties注解的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonIgnoreProperties;</span><br><span class="line"></span><br><span class="line"><span class="meta">@JsonIgnoreProperties</span>(&#123;<span class="string">"firstName"</span>, <span class="string">"lastName"</span>&#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonIgnoreProperties</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>   personId = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String  firstName = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">public</span> String  lastName  = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在此示例中，属性firstName和lastName都将被忽略，因为它们的名称在类声明上方的@JsonIgnoreProperties注解声明内列出。</p><h4 id="JsonIgnoreType"><a href="#JsonIgnoreType" class="headerlink" title="@JsonIgnoreType"></a>@JsonIgnoreType</h4><p>@JsonIgnoreType Jackson注解用于将整个类型（类）标记为在使用该类型的任何地方都将被忽略。</p><p>这是一个示例，展示如何使用@JsonIgnoreType注解：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonIgnoreType;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonIgnoreType</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonIgnoreType</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Address</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> String streetName  = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">public</span> String houseNumber = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">public</span> String zipCode     = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">public</span> String city        = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">public</span> String country     = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>    personId = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String  name = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Address address = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的示例中，所有Address实例将被忽略。</p><h3 id="JsonAutoDetect"><a href="#JsonAutoDetect" class="headerlink" title="@JsonAutoDetect"></a>@JsonAutoDetect</h3><p>Jackson注解@JsonAutoDetect用于告诉Jackson在读写对象时包括非public修饰的属性。</p><p>这是一个示例类，展示如何使用@JsonAutoDetect注解：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonAutoDetect;</span><br><span class="line"></span><br><span class="line"><span class="meta">@JsonAutoDetect</span>(fieldVisibility = JsonAutoDetect.Visibility.ANY )</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonAutoDetect</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span>  personId = <span class="number">123</span>;</span><br><span class="line">    <span class="keyword">public</span> String name     = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>JsonAutoDetect.Visibility类包含与Java中的可见性级别匹配的常量，表示ANY，DEFAULT，NON_PRIVATE，NONE，PROTECTED_AND_PRIVATE和PUBLIC_ONLY。</p><h3 id="Read注解"><a href="#Read注解" class="headerlink" title="Read注解"></a>Read注解</h3><p>Jackson包含一组注解，这些注解仅影响Jackson将JSON解析为对象的方式-意味着它们影响Jackson对JSON的读取。 我称这些为“读注解”。 以下各节介绍了Jackson的读注解。</p><h4 id="JsonSetter"><a href="#JsonSetter" class="headerlink" title="@JsonSetter"></a>@JsonSetter</h4><p>Jackson注解@JsonSetter用于告诉Jackson，当将JSON读入对象时，应将此setter方法的名称与JSON数据中的属性名称匹配。 如果Java类内部使用的属性名称与JSON文件中使用的属性名称不同，这个注解就很有用了。</p><p>以下Person类用personId名称对应JSON中名为id的字段：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span>   personId = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> String name     = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getPersonId</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.personId; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPersonId</span><span class="params">(<span class="keyword">long</span> personId)</span> </span>&#123; <span class="keyword">this</span>.personId = personId; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> name; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123; <span class="keyword">this</span>.name = name; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是在此JSON对象中，使用名称id代替personId：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"id"</span>   : <span class="number">1234</span>,</span><br><span class="line">  <span class="attr">"name"</span> : <span class="string">"John"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Jackson无法将id属性从JSON对象映射到Java类的personId字段。</p><p>@JsonSetter注解指示Jackson为给定的JSON字段使用setter方法。 在我们的示例中，我们在setPersonId()方法上方添加@JsonSetter注解。</p><p>这是添加@JsonSetter注解的实例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span>   personId = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> String name     = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getPersonId</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.personId; &#125;</span><br><span class="line">    <span class="meta">@JsonSetter</span>(<span class="string">"id"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPersonId</span><span class="params">(<span class="keyword">long</span> personId)</span> </span>&#123; <span class="keyword">this</span>.personId = personId; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> name; &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123; <span class="keyword">this</span>.name = name; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>@JsonSetter注解中指定的值是要与此setter方法匹配的JSON字段的名称。 在这种情况下，名称为id，因为这是我们要映射到setPersonId()setter方法的JSON对象中字段的名称。</p><h4 id="JsonAnySetter"><a href="#JsonAnySetter" class="headerlink" title="@JsonAnySetter"></a>@JsonAnySetter</h4><p>Jackson注解@JsonAnySetter表示Jackson为JSON对象中所有无法识别的字段调用相同的setter方法。 “无法识别”是指尚未映射到Java对象中的属性或设置方法的所有字段。</p><p>看一下这个Bag类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Bag</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Object&gt; properties = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(String fieldName, Object value)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.properties.put(fieldName, value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">get</span><span class="params">(String fieldName)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.properties.get(fieldName);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后查看此JSON对象：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"id"</span>   : <span class="number">1234</span>,</span><br><span class="line">  <span class="attr">"name"</span> : <span class="string">"John"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Jackson无法直接将此JSON对象的id和name属性映射到Bag类，因为Bag类不包含任何公共字段或setter方法。</p><p>可以通过添加@JsonAnySetter注解来告诉Jackson为所有无法识别的字段调用set()方法，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Bag</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Object&gt; properties = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonAnySetter</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">set</span><span class="params">(String fieldName, Object value)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.properties.put(fieldName, value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">get</span><span class="params">(String fieldName)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.properties.get(fieldName);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，Jackson将使用JSON对象中所有无法识别的字段的名称和值调用set()方法。</p><p>请记住，这仅对无法识别的字段有效。 例如，如果您向Bag Java类添加了公共名称属性或setName（String）方法，则JSON对象中的名称字段将改为映射到该属性/设置器。</p><h4 id="JsonCreator"><a href="#JsonCreator" class="headerlink" title="@JsonCreator"></a>@JsonCreator</h4><p>Jackson注解@JsonCreator用于告诉Jackson该Java对象具有一个构造函数（“创建者”），该构造函数可以将JSON对象的字段与Java对象的字段进行匹配。</p><p>@JsonCreator注解在无法使用@JsonSetter注解的情况下很有用。 例如，不可变对象没有任何设置方法，因此它们需要将其初始值注入到构造函数中。</p><p>以这个PersonImmutable类为例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonImmutable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span>   id   = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> String name = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PersonImmutable</span><span class="params">(<span class="keyword">long</span> id, String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>要告诉Jackson应该调用PersonImmutable的构造函数，我们必须在构造函数中添加@JsonCreator注解。 但是，仅凭这一点还不够。 我们还必须注解构造函数的参数，以告诉Jackson将JSON对象中的哪些字段传递给哪些构造函数参数。</p><p>添加了@JsonCreator和@JsonProperty注解的PersonImmutable类的示例如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonImmutable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span>   id   = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> String name = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonCreator</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">PersonImmutable</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">            @JsonProperty(<span class="string">"id"</span>)</span>  <span class="keyword">long</span> id,</span></span><br><span class="line"><span class="function">            @<span class="title">JsonProperty</span><span class="params">(<span class="string">"name"</span>)</span> String name  ) </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请注意，构造函数上方的注解以及构造函数参数之前的注解。 现在，Jackson能够从此JSON对象创建PersonImmutable：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"id"</span>   : <span class="number">1234</span>,</span><br><span class="line">  <span class="attr">"name"</span> : <span class="string">"John"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="JacksonInject"><a href="#JacksonInject" class="headerlink" title="@JacksonInject"></a>@JacksonInject</h4><p>Jackson注解@JacksonInject用于将值注入到解析的对象中，而不是从JSON中读取这些值。 例如，假设正在从各种不同的源下载Person JSON对象，并且想知道给定Person对象来自哪个源。 源本身可能不包含该信息，但是可以让Jackson将其注入到根据JSON对象创建的Java对象中。</p><p>要将Java类中的字段标记为需要由Jackson注入其值的字段，请在该字段上方添加@JacksonInject注解。</p><p>这是一个示例PersonInject类，在属性上方添加了@JacksonInject注解：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonInject</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>   id   = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> String name = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JacksonInject</span></span><br><span class="line">    <span class="keyword">public</span> String source = <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure><p>为了让Jackson将值注入属性，需要在创建Jackson ObjectMapper时做一些额外的工作。</p><p>这是让Jackson将值注入Java对象的过程：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">InjectableValues inject = new InjectableValues.Std().addValue(String.class, "jenkov.com");</span><br><span class="line">PersonInject personInject = <span class="keyword">new</span> ObjectMapper().reader(inject)</span><br><span class="line">                        .forType(PersonInject<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line">                        .readValue(new File("data/person.json"));</span><br></pre></td></tr></table></figure><p>请注意，如何在InjectableValues addValue()方法中设置要注入到source属性中的值。 还要注意，该值仅绑定到字符串类型-而不绑定到任何特定的字段名称。 @JacksonInject注解指定将值注入到哪个字段。</p><p>如果要从多个源下载人员JSON对象，并为每个源注入不同的源值，则必须为每个源重复以上代码。</p><h4 id="JsonDeserialize"><a href="#JsonDeserialize" class="headerlink" title="@JsonDeserialize"></a>@JsonDeserialize</h4><p>Jackson注解@JsonDeserialize用于为Java对象中给定的属性指定自定义反序列化器类。<br>例如，假设想优化布尔值false和true的在线格式，使其分别为0和1。</p><p>首先，需要将@JsonDeserialize注解添加到要为其使用自定义反序列化器的字段。 这是将@JsonDeserialize注解添加到字段的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonDeserialize</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>    id      = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> String  name    = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonDeserialize</span>(using = OptimizedBooleanDeserializer<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">    <span class="title">public</span> <span class="title">boolean</span> <span class="title">enabled</span> </span>= <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其次，这是@JsonDeserialize注解中引用的OptimizedBooleanDeserializer类的实例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OptimizedBooleanDeserializer</span></span></span><br><span class="line"><span class="class">    <span class="keyword">extends</span> <span class="title">JsonDeserializer</span>&lt;<span class="title">Boolean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Boolean <span class="title">deserialize</span><span class="params">(JsonParser jsonParser,</span></span></span><br><span class="line"><span class="function"><span class="params">            DeserializationContext deserializationContext)</span> <span class="keyword">throws</span></span></span><br><span class="line"><span class="function">        IOException, JsonProcessingException </span>&#123;</span><br><span class="line"></span><br><span class="line">        String text = jsonParser.getText();</span><br><span class="line">        <span class="keyword">if</span>(<span class="string">"0"</span>.equals(text)) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>请注意，OptimizedBooleanDeserializer类使用通用类型Boolean扩展了JsonDeserializer。 这样做会使deserialize()方法返回一个布尔对象。 如果要反序列化其他类型（例如java.util.Date），则必须在泛型括号内指定该类型。</p><p>可以通过调用jsonParser参数的getText()方法来获取要反序列化的字段的值。 然后，可以将该文本反序列化为任何值，然后输入反序列化程序所针对的类型（在此示例中为布尔值）。</p><p>最后，需要查看使用自定义反序列化器和@JsonDeserializer注解反序列化对象的格式：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PersonDeserialize person = objectMapper</span><br><span class="line">        .reader(PersonDeserialize<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line">        .readValue(new File("data/person-optimized-boolean.json"));</span><br></pre></td></tr></table></figure><p>注意，我们首先需要如何使用ObjectMapper的reader()方法为PersonDeserialize类创建一个阅读器，然后在该方法返回的对象上调用readValue()。</p><h3 id="Write注解"><a href="#Write注解" class="headerlink" title="Write注解"></a>Write注解</h3><p>Jackson还包含一组注解，这些注解可以影响Jackson将Java对象序列化（写入）到JSON的方式。 以下各节将介绍这些写（序列化）注解中的每一个。</p><h4 id="JsonInclude"><a href="#JsonInclude" class="headerlink" title="@JsonInclude"></a>@JsonInclude</h4><p>Jackson注解@JsonInclude告诉Jackson仅在某些情况下包括属性。 例如，仅当属性为非null，非空或具有非默认值时，才应包括该属性。 这是显示如何使用@JsonInclude注解的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.fasterxml.jackson.annotation.JsonInclude;</span><br><span class="line"></span><br><span class="line"><span class="meta">@JsonInclude</span>(JsonInclude.Include.NON_EMPTY)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonInclude</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>  personId = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> String name     = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果为该示例设置的值是非空的，则此示例将仅包括name属性，这意味着不为null且不是空字符串。</p><p>@JsonInclude注解的一个更通俗的名称应该是@JsonIncludeOnlyWhen，但是写起来会更长。</p><h4 id="JsonGetter"><a href="#JsonGetter" class="headerlink" title="@JsonGetter"></a>@JsonGetter</h4><p>@JsonGetter Jackson注解用于告诉Jackson，应该通过调用getter方法而不是通过直接字段访问来获取某个字段值。 如果您的Java类使用jQuery样式的getter和setter名称，则@JsonGetter注解很有用。</p><p>例如，您可能拥有方法personId()和personId（long id），而不是getPersonId()和setPersonId()。</p><p>这是一个名为PersonGetter的示例类，它显示了@JsonGetter注解的用法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonGetter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span>  personId = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonGetter</span>(<span class="string">"id"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">personId</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">this</span>.personId; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonSetter</span>(<span class="string">"id"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">personId</span><span class="params">(<span class="keyword">long</span> personId)</span> </span>&#123; <span class="keyword">this</span>.personId = personId; &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如您所见，personId()方法带有@JsonGetter注解。 @JsonGetter注解上设置的值是JSON对象中应使用的名称。 因此，用于JSON对象中personId的名称是id。 生成的JSON对象如下所示：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"id"</span>:<span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure><p>还要注意，personId（long personId）方法使用@JsonSetter注解进行注解，以使Jackson识别为与JSON对象中的id属性匹配的设置方法。 从JSON读取Java对象时使用@JsonSetter注解-将Java对象写入JSON时不使用。 为了完整起见，仅包含@JsonSetter注解。</p><h4 id="JsonAnyGetter"><a href="#JsonAnyGetter" class="headerlink" title="@JsonAnyGetter"></a>@JsonAnyGetter</h4><p>@JsonAnyGetter Jackson注解使您可以将Map用作要序列化为JSON的属性的容器。 这是在Java类中使用@JsonAnyGetter注解的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonAnyGetter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Object&gt; properties = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonAnyGetter</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title">properties</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> properties;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当看到@JsonAnyGetter注解时，Jackson将从@JsonAnyGetter注解的方法中获取返回的Map，并将该Map中的每个键值对都视为一个属性。 换句话说，Map中的所有键值对都将作为PersonAnyGetter对象的一部分序列化为JSON。</p><h4 id="JsonPropertyOrder"><a href="#JsonPropertyOrder" class="headerlink" title="@JsonPropertyOrder"></a>@JsonPropertyOrder</h4><p>@JsonPropertyOrder Jackson注解可用于指定将Java对象的字段序列化为JSON的顺序。 这是显示如何使用@JsonPropertyOrder注解的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@JsonPropertyOrder</span>(&#123;<span class="string">"name"</span>, <span class="string">"personId"</span>&#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonPropertyOrder</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>  personId  = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> String name     = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通常，Jackson会按照在类中找到的顺序序列化PersonPropertyOrder中的属性。 但是，@JsonPropertyOrder注解指定了不同的顺序，在序列化的JSON输出中，name属性将首先出现，personId属性将随后出现。</p><h4 id="JsonRawValue"><a href="#JsonRawValue" class="headerlink" title="@JsonRawValue"></a>@JsonRawValue</h4><p>@JsonRawValue Jackson注解告诉Jackson该属性值应直接写入JSON输出。 如果该属性是字符串，Jackson通常会将值括在引号中，但是如果使用@JsonRawValue属性进行注解，Jackson将不会这样做。</p><p>为了更清楚@JsonRawValue的作用，看看没有使用@JsonRawValue的此类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonRawValue</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>   personId = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String address  = <span class="string">"$#"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Jackson会将其序列化为以下JSON字符串：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"personId"</span>:<span class="number">0</span>,<span class="attr">"address"</span>:<span class="string">"$#"</span>&#125;</span><br></pre></td></tr></table></figure><p>现在，我们将@JsonRawValue添加到address属性，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonRawValue</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>   personId = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonRawValue</span></span><br><span class="line">    <span class="keyword">public</span> String address  = <span class="string">"$#"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，当对地址属性进行序列化时，杰克逊将省略引号。 因此，序列化的JSON如下所示：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"personId"</span>:<span class="number">0</span>,<span class="attr">"address"</span>:$#&#125;</span><br></pre></td></tr></table></figure><p>当然它是无效的JSON，那么为什么要这么做呢？</p><p>如果address属性包含一个JSON字符串，那么该JSON字符串将被序列化为最终的JSON对象，作为JSON对象结构的一部分，而不仅是序列化为JSON对象的address字段中的字符串。<br>要查看其工作原理，让我们像下面这样更改address属性的值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonRawValue</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>   personId = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonRawValue</span></span><br><span class="line">    <span class="keyword">public</span> String address  =</span><br><span class="line">            <span class="string">"&#123; \"street\" : \"Wall Street\", \"no\":1&#125;"</span>;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Jackson会将其序列化为以下JSON：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"personId"</span>:<span class="number">0</span>,<span class="attr">"address"</span>:&#123; <span class="attr">"street"</span> : <span class="string">"Wall Street"</span>, <span class="attr">"no"</span>:<span class="number">1</span>&#125;&#125;</span><br></pre></td></tr></table></figure><p>请注意，JSON字符串现在如何成为序列化JSON结构的一部分。</p><p>没有@JsonRawValue注解，Jackson会将对象序列化为以下JSON：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"personId"</span>:<span class="number">0</span>,<span class="attr">"address"</span>:<span class="string">"&#123; \"street\" : \"Wall Street\", \"no\":1&#125;"</span>&#125;</span><br></pre></td></tr></table></figure><p>请注意，address属性的值现在如何用引号引起来，并且值内的所有引号均被转义。</p><h4 id="JsonValue"><a href="#JsonValue" class="headerlink" title="@JsonValue"></a>@JsonValue</h4><p>Jackson注解@JsonValue告诉Jackson，Jackson不应该尝试序列化对象本身，而应在对象上调用将对象序列化为JSON字符串的方法。 请注意，Jackson将在自定义序列化返回的String内转义任何引号，因此不能返回例如 完整的JSON对象。 为此，应该改用@JsonRawValue（请参阅上一节）。</p><p>@JsonValue注解已添加到Jackson调用的方法中，以将对象序列化为JSON字符串。 这是显示如何使用@JsonValue注解的示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonValue</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">long</span>   personId = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">public</span> String name = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonValue</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toJson</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.personId + <span class="string">","</span> + <span class="keyword">this</span>.name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>要求Jackson序列化PersonValue对象所得到的输出是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"0,null"</span></span><br></pre></td></tr></table></figure><p>引号由Jackson添加。 请记住，对象返回的值字符串中的所有引号均会转义。</p><h4 id="JsonSerialize"><a href="#JsonSerialize" class="headerlink" title="@JsonSerialize"></a>@JsonSerialize</h4><p>@JsonSerialize Jackson注解用于为Java对象中的字段指定自定义序列化程序。 这是一个使用@JsonSerialize注解的Java类示例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PersonSerializer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将 long 序列化为 String，解决返回前端JS数值精度丢失问题</span></span><br><span class="line">    <span class="meta">@JsonSerialize</span>(using = ToStringSerializer<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">    <span class="title">public</span> <span class="title">long</span>   <span class="title">personId</span> </span>= <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String name     = <span class="string">"John"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@JsonSerialize</span>(using = OptimizedBooleanSerializer<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">    <span class="title">public</span> <span class="title">boolean</span> <span class="title">enabled</span> </span>= <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意启用字段上方的@JsonSerialize注解。</p><p>OptimizedBooleanSerializer将序列的真值序列化为1，将假值序列化为0。这是代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OptimizedBooleanSerializer</span> <span class="keyword">extends</span> <span class="title">JsonSerializer</span>&lt;<span class="title">Boolean</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">serialize</span><span class="params">(Boolean aBoolean, JsonGenerator jsonGenerator, </span></span></span><br><span class="line"><span class="function"><span class="params">        SerializerProvider serializerProvider)</span> </span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, JsonProcessingException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(aBoolean)&#123;</span><br><span class="line">            jsonGenerator.writeNumber(<span class="number">1</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            jsonGenerator.writeNumber(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="JsonTypeInfo-多态类型"><a href="#JsonTypeInfo-多态类型" class="headerlink" title="@JsonTypeInfo 多态类型"></a>@JsonTypeInfo 多态类型</h3><p>Jackson框架对json字段的序列化和反序列化默认策略是根据getter和setter方法，去掉get和set,再把首字母小写，便找到了对应的字段。通常情况，我们都是对普通的POJO进行serialization/deserialization。那么如果遇到了解析抽象类(或者接口)呢？如何定位到对应的实现类？实现类都找不到，谈何匹配到对应的字段反序列化。</p><p>jackson允许配置多态类型处理，当进行反序列话时，JSON数据匹配的对象可能有多个子类型，为了正确的读取对象的类型，我们需要添加一些类型信息。可以通过下面几个注解来实现：</p><ul><li><p>@JsonTypeInfo</p><ul><li>作用于类/接口，被用来开启多态类型处理，对基类/接口和子类/实现类都有效</li><li><code>@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = &quot;name&quot;)</code></li></ul></li><li><p>这个注解有一些属性:</p><ul><li>use:定义使用哪一种类型识别码，它有下面几个可选值：<ul><li><code>JsonTypeInfo.Id.CLASS</code>：使用完全限定类名做识别, (使用class name会使代码的可移植性变差。比如代码修改包名后，再按照json里的metadata反序列化，发现找不到类了)</li><li><code>JsonTypeInfo.Id.MINIMAL_CLASS</code>：若基类和子类在同一包类，使用类名(忽略包名)作为识别码</li><li><code>JsonTypeInfo.Id.NAME</code>：一个合乎逻辑的指定名称</li><li><code>JsonTypeInfo.Id.CUSTOM</code>：自定义识别码，由<code>@JsonTypeIdResolver</code>对应，稍后解释</li><li><code>JsonTypeInfo.Id.NONE</code>：不使用识别码</li></ul></li><li>include(可选):指定识别码是如何被包含进去的，它有下面几个可选值：<ul><li>JsonTypeInfo.As.PROPERTY：作为数据的兄弟属性</li><li>JsonTypeInfo.As.EXISTING_PROPERTY：作为POJO中已经存在的属性</li><li>JsonTypeInfo.As.EXTERNAL_PROPERTY：作为扩展属性</li><li>JsonTypeInfo.As.WRAPPER_OBJECT：作为一个包装的对象</li><li>JsonTypeInfo.As.WRAPPER_ARRAY：作为一个包装的数组</li></ul></li><li>property(可选):制定识别码的属性名称, 此属性只有当:<ul><li><code>use为JsonTypeInfo.Id.CLASS</code>（若不指定property则默认为@class）、<code>JsonTypeInfo.Id.MINIMAL_CLASS</code>(若不指定property则默认为@c)、<code>JsonTypeInfo.Id.NAME</code>(若不指定property默认为@type)</li><li><code>include为JsonTypeInfo.As.PROPERTY</code>、<code>JsonTypeInfo.As.EXISTING_PROPERTY</code>、<code>JsonTypeInfo.As.EXTERNAL_PROPERTY</code>时才有效</li></ul></li><li>defaultImpl(可选)：如果类型识别码不存在或者无效，可以使用该属性来制定反序列化时使用的默认类型</li><li>visible(可选，默认为false)：是否可见属性定义了类型标识符的值是否会通过JSON流成为反序列化器的一部分，默认为fale,也就是说,jackson会从JSON内容中处理和删除类型标识符再传递给JsonDeserializer。</li></ul></li><li><p>@JsonSubTypes</p><ul><li>作用于类/接口，用来列出给定类的子类，只有当子类类型无法被检测到时才会使用它,一般是配合@JsonTypeInfo在基类上使用</li><li>它的Type子类有两个属性，可以定义一个类的别名：<ul><li>value：给哪个子类起名字</li><li>name：起啥名字</li></ul></li></ul></li></ul><p><strong>基本使用</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@JsonTypeInfo</span>(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = <span class="string">"custom-type-name"</span>)</span><br><span class="line"><span class="meta">@JsonSubTypes</span>(value = &#123;</span><br><span class="line">    <span class="meta">@JsonSubTypes</span>.Type(value = Son1<span class="class">.<span class="keyword">class</span>, <span class="title">name</span> </span>= <span class="string">"FirstSon"</span>),</span><br><span class="line">    <span class="meta">@JsonSubTypes</span>.Type(value = Son2<span class="class">.<span class="keyword">class</span>, <span class="title">name</span> </span>= <span class="string">"SecondSon"</span>)</span><br><span class="line">&#125;)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">xxx</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// or public abstract class AbstractXXX &#123;&#125;</span></span><br></pre></td></tr></table></figure><p>生成如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"list"</span>:[&#123;<span class="attr">"custom-type-name"</span>:<span class="string">"SecondSon"</span>,<span class="attr">"a"</span>:<span class="number">5</span>,<span class="attr">"c"</span>:<span class="string">"10"</span>&#125;,&#123;<span class="attr">"custom-type-name"</span>:<span class="string">"FirstSon"</span>,<span class="attr">"a"</span>:<span class="number">5</span>,<span class="attr">"b"</span>:<span class="number">0</span>&#125;]&#125;</span><br></pre></td></tr></table></figure><p><strong>必须记录的多态类型</strong></p><p>从json的角度来看，就好像是对象除了a、c，还有一个custom-type-name属性一样。如果直接看json，这种新增了metadata的行为岂不是会让人产生误会？</p><p>先反过来想，如果不加metadata会怎样？</p><p>不加多态信息也能直接序列化，且不带metadata：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"list"</span>:[&#123;<span class="attr">"a"</span>:<span class="number">5</span>,<span class="attr">"c"</span>:<span class="string">"10"</span>&#125;,&#123;<span class="attr">"a"</span>:<span class="number">5</span>,<span class="attr">"b"</span>:<span class="number">0</span>&#125;]&#125;</span><br></pre></td></tr></table></figure><p>这的确是原汁原味的对象内容！但是反序列化的时候，发现反序列化不回来了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread "main" com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field "c" (class example.jackson.Family$Father), not marked as ignorable (one known property: "a"])</span><br><span class="line"> at [Source: (String)<span class="string">"&#123;"</span>list<span class="string">":[&#123;"</span>a<span class="string">":5,"</span>c<span class="string">":"</span><span class="number">10</span><span class="string">"&#125;,&#123;"</span>a<span class="string">":5,"</span>b<span class="string">":0&#125;]&#125;"</span>; line: <span class="number">1</span>, column: <span class="number">22</span>] (through reference chain: example.jackson.Family$D[<span class="string">"list"</span>]-&gt;java.util.ArrayList[<span class="number">0</span>]-&gt;example.jackson.Family$Father[<span class="string">"c"</span>])</span><br></pre></td></tr></table></figure><p>因为序列化的时候记录的信息不足，导致不知道究竟是哪个子类。</p><p>所以说，这个类型信息是必须被记录的，不管使用<code>@autotype</code>还是以普通property的形式去记录，总之都要记下来，然后用相对应的处理metadata的反序列化方法将json反序列化为对象。</p><p>但是这样序列化出来的json看起来会比较奇怪，总感觉不是“纯正的json”。json的好处就是可读，这么搞可读性稍稍下降了一些。json序列化框架使用了一种略微影响可读性的方式完成了对多态的序列化。</p><p>其他序列化方式（比如protobuf、avro）呢？可想而知，因为他们本身就是序列化为字节，不是给人看的，人们也不关心他们写了啥字节，他们自然想写啥写啥。比如protobuf可以用oneof指代一个field，至于这个field是Son1还是Son2，肯定通过字节标识出来了，要不然protobuf也是不可能发序列化回来的。</p><p>所以说，只要人类看不见，就不会逼逼赖赖了:D</p><p>说到这里，不禁想到了Java多态的本身：运行时，如果一个Son1赋值给Father的引用，理论上来讲只知道这是一个Father对象，实际上它可能是Son1也可能是Son2，那么调用具体的方法时，为什么Java能准确地调用Son1的override方法呢？</p><p>根据上面序列化的经验，可以猜想Java一定像json序列化一样，将子类型也记录了下来，才能在调用的时候找到真正的子类型：</p><ol><li>每个.class字节码文件在被ClassLoader加载之后都会在jvm中生成一个唯一的Class对象，该Class类型的对象含有该类的所有信息，比如类名、方法、field、构造函数等；</li><li>每一个该类new出来的对象，都有一个指向上述Class对象的引用。可通过Object的<code>public final native Class&lt;?&gt; getClass()</code>方法获得Class对象；</li><li>获取到了一个object的Class对象之后，关于这个object的一切类相关的信息都可以通过Class对象取得了。</li></ol><blockquote><p>这不是多态的实际实现，但说明了一个对象的实际类型实际上都是可以被检索到的。</p></blockquote><p>所以Java也是通过记录所有对象的类信息，以在运行时实时决定该对象类型，并在多态时调用合适的override方法。</p><p><strong>因此，解决多态问题的唯一途径就是记录下该对象究竟是哪一个子类型，无论是序列化时的多态还是运行时的多态！</strong></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://juejin.cn/post/6844904166809157639" target="_blank" rel="noopener">Jackson使用详解</a></li><li><a href="https://www.ibm.com/developerworks/cn/java/jackson-advanced-application/index.html" target="_blank" rel="noopener">Jackson 框架的高阶应用</a></li><li><a href="http://tutorials.jenkov.com/java-json/jackson-objectmapper.html#jackson-databind" target="_blank" rel="noopener">Jackson Installation</a></li><li><a href="http://tutorials.jenkov.com/java-json/jackson-installation.html" target="_blank" rel="noopener">Jackson ObjectMapper</a></li><li><a href="http://tutorials.jenkov.com/java-json/jackson-jsonnode.html" target="_blank" rel="noopener">Jackson JsonNode</a></li><li><a href="http://tutorials.jenkov.com/java-json/jackson-jsonparser.html" target="_blank" rel="noopener">Jackson JsonParser</a></li><li><a href="http://tutorials.jenkov.com/java-json/jackson-jsongenerator.html" target="_blank" rel="noopener">Jackson JsonGenerator</a></li><li><a href="http://tutorials.jenkov.com/java-json/jackson-annotations.html" target="_blank" rel="noopener">Jackson Annotations</a></li><li><a href="https://www.baeldung.com/jackson-annotations" target="_blank" rel="noopener">Jackson Annotation Examples</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Jackson 是用来序列化和反序列化 json 的 Java 的开源框架。Spring MVC 的默认 json 解析器便是 Jackson。与其他 Java 的 json 的框架 Gson 等相比，Jackson 解析大的 json 文件速度比较快；Jackson 运行时占用内存比较低，性能比较好；Jackson 有灵活的 API，可以很容易进行扩展和定制。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="https://blog.lichao.xin/categories/Java/"/>
    
    
      <category term="Spring" scheme="https://blog.lichao.xin/tags/Spring/"/>
    
      <category term="java" scheme="https://blog.lichao.xin/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>重学 Elastic Stack 之 Elasticsearch 搜索API大全</title>
    <link href="https://blog.lichao.xin/back-end/big-data/es-10/"/>
    <id>https://blog.lichao.xin/back-end/big-data/es-10/</id>
    <published>2021-02-17T15:45:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>Elasticsearch 搜索 API 整理。</p><a id="more"></a><h2 id="query-和-filter-区别"><a href="#query-和-filter-区别" class="headerlink" title="query 和 filter 区别"></a>query 和 filter 区别</h2><p>在正式进入到搜索部分之前，我们需要区分 <code>query</code>（查询）和 <code>filter</code>（过滤）的区别。</p><p>在进行 <code>query</code> 的时候，除了完成匹配的过程，我们实际上在问“这个结果到底有多匹配我们的搜索关键词”。在所有的返回结果的后面都会有一个 <code>_score</code> 字段表示这个结果的匹配程度，也就是<strong>相关性</strong>。相关性越高的结果就越排在前面，相关性越低就越靠后。当两个文档的相关性相同的时候，会根据 lucene 内部的 <code>doc_id</code> 字段来排序，这个字段对于用户是不可见的也不能控制。</p><p>而在进行 <strong>filter</strong> 的时候，仅仅是在问“这个文档符不符合要求”，这仅仅是一个过滤的操作判断文档是否满足我们的筛选要求，不会计算任何的相关性。比如 <code>timestamp</code> 的范围是否在2019和2020之间，<code>status</code> 状态是否是 1 等等。</p><p>在一个查询语句里面可以同时存在 <code>query</code> 和 <code>filter</code>，只不过只有 <code>query</code> 的查询字段会进行相关性 <code>_score</code> 的计算，而 <code>filter</code> 仅仅用来筛选。比如在下面的查询语句里面，只有 <code>title</code> 字段会进行相关性的计算，而下面的 <code>status</code> 只是为了筛选并不会计算相关性。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;<span class="attr">"match"</span>: &#123;<span class="attr">"title"</span>: <span class="string">"Search"</span>&#125;&#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"filter"</span>: [</span><br><span class="line">        &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"state"</span>: <span class="number">1</span>&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于在实际应用中应该用 <code>query</code> 还是用 <code>filter</code> 需要根据实际的业务场景来看。如果你的产品的搜索只是需要筛选得到最后的搜索结果并不需要 Elasticsearch 的相关性排序（你可能自定义了其他的排序规则），那么使用 <code>filter</code> 就完全能够满足要求并且能够有更好的性能（filter 不需要计算相关性而且会缓存结果）；如果需要考虑文档和搜索词的相关性，那么使用 <code>query</code> 就是最好的选择。</p><h2 id="相关性"><a href="#相关性" class="headerlink" title="相关性"></a>相关性</h2><p>Elasticsearch 的相似度计算主要是利用了全文检索领域的计算标准—— <strong>TF/IDF</strong>（Term Frequency/Inverted Document Frequency）也就是<strong>检索词频率</strong>和<strong>反向文档频率</strong></p><ol><li><strong>TF</strong>（检索词频率）：检索词在这个字段里面出现的频率越高，相关性越高。比如搜索词出现5次肯定比出现1次的文档相关性更高。</li><li><strong>IDF</strong>（反向文档频率）：包含检索词的文档的频率越高，这个检索词的相关性比重越低。如果一个检索词在所有的文档里面都出现了，比如中文的 <code>的</code>，那么这个检索词肯定就不重要，相对应的根据这个检索词匹配的文档的相关性权重应该下降。</li><li><strong>字段长度</strong>：注意这个字段是文档的里面被搜索的字段，不是检索词。如果这个字段的长度越长，相关性就越低。这个主要是因为这个检索词在字段内的重要性降低了，文档就相对来说不那么匹配了。</li></ol><p>在复合查询里面，比如 <code>bool</code> 查询，每个子查询计算出来的评分会根据特定的公式合并到综合评分里面，最后根据这个综合评分来排序。当我们想要修改不同的查询语句的在综合评分里面的比重的时候，可以在查询字段里面添加 <code>boost</code> 参数，这个值是相对于 1 来说的。如果大于 1 则这个查询参数的权重会提高；如果小于 1 ，权重就下降。</p><p>这个评分系统一般是系统默认的，我们可以根据需要定制化我们自己的相关性计算方法，比如通过脚本自定义评分。</p><h2 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h2><p>分析器是针对 <code>text</code> 字段进行文本分析的工具。文本分析是把非结构化的数据（比如产品描述或者邮件内容）转化成结构化的格式从而提高搜索效率的过程，通常在搜索引擎里面应用的比较多。</p><p><code>text</code> 格式的数据和 <code>keyword</code> 格式的数据在存储和索引的时候差别比较大。<code>keyword</code> 会直接被当成整个字符串保存在文档里面，而 <code>text</code> 格式数据，需要经过分析器解析之后，转化成结构化的文档再保存起来。比如对于 <code>the quick fox</code> 字符串，如果使用 <code>keyword</code> 类型，保存直接就是 <code>the quick fox</code>，使用 <code>the quick fox</code> 作为关键词可以直接匹配，但是使用 <code>the</code> 或者 <code>quick</code> 就不能匹配；但是如果使用 <code>text</code> 保存，那么分析器会把这句话解析成 <code>the</code>、<code>quick</code>、<code>fox</code> 三个 <code>token</code> 进行保存，使用 <code>the quick fox</code> 就无法匹配，但是单独用 <code>the</code>、<code>quick</code>、<code>fox</code> 三个字符串就可以匹配。所以对于<code>text</code> 类型的数据的搜索需要格外注意，如果你的搜索词得不到想要的结果，很有可能是你的搜索语句有问题。</p><p>分析器的工作过程大概分成两步：</p><ol><li><strong>分词</strong>（Tokenization）：根据<strong>停止词</strong>把文本分割成很多的小的 token，比如 <code>the quick fox</code> 会被分成 <code>the</code>、<code>quick</code>、<code>fox</code>，其中的停止词就是空格，还有很多其他的停止词比如&amp;或者#，大多数的标点符号都是停止词</li><li><strong>归一化</strong>（Normalization）：把分隔的token变成统一的形式方便匹配，比如下面几种<ul><li>把单词变成小写，<code>Quick</code> 会变成 <code>quick</code></li><li>提取词干，<code>foxes</code> 变成 <code>fox</code></li><li>合并同义词，<code>jump</code> 和 <code>leap</code> 是同义词，会被统一索引成 <code>jump</code></li></ul></li></ol><p>Elasticsearch 自带了一个分析器，是系统默认的标准分析器，使用标准分词器，大多数情况下都能够有不错的分析效果。用户也可以定义自己的分析器，用于满足不同的业务需求。</p><p>想要知道某个解析器的分析结果，可以直接在ES里面进行分析，执行下面的语句就行了：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">POST /_analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"analyzer"</span>: <span class="string">"standard"</span>,</span><br><span class="line">  <span class="attr">"text"</span>: <span class="string">"1 Fire's foxes"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 返回结果</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"tokens"</span> : [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"token"</span> : <span class="string">"1"</span>,</span><br><span class="line">      <span class="attr">"start_offset"</span> : <span class="number">0</span>,</span><br><span class="line">      <span class="attr">"end_offset"</span> : <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"type"</span> : <span class="string">"&lt;NUM&gt;"</span>,</span><br><span class="line">      <span class="attr">"position"</span> : <span class="number">0</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"token"</span> : <span class="string">"fire's"</span>,</span><br><span class="line">      <span class="attr">"start_offset"</span> : <span class="number">2</span>,</span><br><span class="line">      <span class="attr">"end_offset"</span> : <span class="number">8</span>,</span><br><span class="line">      <span class="attr">"type"</span> : <span class="string">"&lt;ALPHANUM&gt;"</span>,</span><br><span class="line">      <span class="attr">"position"</span> : <span class="number">1</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"token"</span> : <span class="string">"fox"</span>,</span><br><span class="line">      <span class="attr">"start_offset"</span> : <span class="number">9</span>,</span><br><span class="line">      <span class="attr">"end_offset"</span> : <span class="number">12</span>,</span><br><span class="line">      <span class="attr">"type"</span> : <span class="string">"&lt;ALPHANUM&gt;"</span>,</span><br><span class="line">      <span class="attr">"position"</span> : <span class="number">2</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回的 <code>tokens</code> 内部就是所有的解析结果，<code>token</code> 表示解析的词语部分，<code>start_offset</code> 和<code>end_offset</code> 分别表示 <code>token</code> 在原 <code>text</code> 内的起始和终止位置，<code>type</code> 表示类型，<code>position</code> 表示这个 token 在整个 tokens 列表里面的位置。</p><p>OK！有了上面的基础知识，就可以进行下面的搜索的介绍了。</p><h2 id="term-搜索"><a href="#term-搜索" class="headerlink" title="term 搜索"></a>term 搜索</h2><p>term 搜索不仅仅可以对 <code>keyword</code> 类型的字段使用，也可以对 <code>text</code> 类型的数据使用，前提是使用的搜索词必须要预先处理一下——不包含停止词并且都是小写（标准解析器），因为文档里面保存的 <code>text</code> 字段分词后的结果，用 <code>term</code> 是可以匹配的。</p><h2 id="term-搜索-exists"><a href="#term-搜索-exists" class="headerlink" title="term 搜索 - exists"></a>term 搜索 - exists</h2><p>返回所有指定字段不为空的文档，比如这个字段对应的值是 <code>null</code> 或者 <code>[]</code> 或者没有为这个字段建立索引。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"exists"</span>: &#123;</span><br><span class="line">      <span class="attr">"field"</span>: <span class="string">"user"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果字段是空字符串 <code>&quot;&quot;</code> 或者包含 <code>null</code> 的数组 <code>[null,&quot;foo&quot;]</code>，都会被当作字段存在。</p><p>这个方法可以用来搜索没有被索引的值或者不存在的值。</p><h2 id="term-搜索-fuzzy"><a href="#term-搜索-fuzzy" class="headerlink" title="term 搜索 - fuzzy"></a>term 搜索 - fuzzy</h2><p>fuzzy 查询是一种模糊查询，会根据检索词和检索字段的<strong>编辑距离</strong>（Levenshtein Distance）来判断是否匹配。一个编辑距离就是对单词进行一个字符的修改，这种修改可能是</p><ul><li>修改一个字符，比如 <code>box</code> 到 <code>fox</code></li><li>删除一个字符，比如 <code>black</code> 到 <code>lack</code></li><li>插入一个字符，比如 <code>sic</code> 到 <code>sick</code></li><li>交换两个相邻的字符的位置，比如 <code>act</code> 到 <code>cat</code></li></ul><p>在进行 fuzzy 搜索的时候，ES 会生成一系列的在特定编辑距离内的变形，然后返回这些变形的准确匹配。默认情况下，当检索词的长度在 <code>0..2</code> 中间时，必须准确匹配；长度在 <code>3..5</code> 之间的时候，编辑距离最大为 <code>1</code>；长度大于 <code>5</code> 的时候，最多允许编辑距离为 <code>2</code>。</p><p>可以通过配置 <code>fuzziness</code> 修改最大编辑距离，<code>max_expansions</code> 修改最多的变形的 <code>token</code> 的数量</p><p>比如搜索是以下条件的时候：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"fuzzy"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"Accha"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回结果有 <code>Iccha</code>、<code>AccHa</code>、<code>accha</code> 还有 <code>ccha</code></p><h2 id="term-搜索-ids"><a href="#term-搜索-ids" class="headerlink" title="term 搜索 - ids"></a>term 搜索 - ids</h2><p>根据文档的 <code>_id</code> 数组返回对应的文档信息</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"ids"</span>: &#123;</span><br><span class="line">      <span class="attr">"values"</span>: [<span class="string">"1"</span>,<span class="string">"4"</span>,<span class="string">"100"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="term-搜索-prefix"><a href="#term-搜索-prefix" class="headerlink" title="term 搜索 - prefix"></a>term 搜索 - prefix</h2><p>返回所有包含以检索词为前缀的字段的文档。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"prefix"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"ac"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回所有以 <code>ac</code> 开头的字段，比如 <code>acchu</code>、<code>achu</code>、<code>achar</code> 等等</p><p>在某些场景下面比如搜索框里面，需要用户在输入内容的同时也要实时展示与输入内容前缀匹配的搜索结果，就可以使用 prefix 查询。为了加速 prefix 查询，还可以在设置字段映射的时候，使用 <code>index_prefixes</code> 映射。ES 会额外建立一个长度在 2 和 5 之间索引，在进行前缀匹配的时候效率会有很大的提高。</p><h2 id="term-搜索-range"><a href="#term-搜索-range" class="headerlink" title="term 搜索 - range"></a>term 搜索 - range</h2><p>对字段进行范围的匹配。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"range"</span>: &#123;</span><br><span class="line">      <span class="attr">"age"</span>: &#123;</span><br><span class="line">        <span class="attr">"gte"</span>: <span class="number">10</span>,</span><br><span class="line">        <span class="attr">"lte"</span>: <span class="number">20</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>搜索年龄在10（包含）和20（包含）之间的结果</p><h2 id="term-搜索-regexp"><a href="#term-搜索-regexp" class="headerlink" title="term 搜索 - regexp"></a>term 搜索 - regexp</h2><p>正则表达式匹配。通过正则表达式来寻找匹配的字段，<code>lucene</code> 会在搜索的时候生成<strong>有限状态机</strong>，其中包含很多的<strong>状态</strong>，默认的最多状态数量是 10000</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"regexp"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"ac.*ha"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个搜索会匹配 <code>achha</code>、<code>achintha</code> 还有 <code>achutha</code></p><h2 id="term-搜索-term"><a href="#term-搜索-term" class="headerlink" title="term 搜索 - term"></a>term 搜索 - term</h2><p>根据检索词来准确匹配字段。官方文档建议不要用 <code>term</code> 去搜索 <code>text</code> 类型的字段，因为分析器的原因很有可能不会出现你想要的结果。但是直接使用 <code>term</code> 去搜索 <code>text</code> 字段还是可以工作的，前提是明白为什么会返回这些数据。比如通过下面的搜索：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"accha"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果 <code>name</code> 字段是 <code>keyword</code> 类型的，没有进行解析，那么只会匹配所有 <code>name</code> 是 <code>accha</code> 的文档。</p><p>如果 <code>name</code> 字段是 <code>text</code> 类型的，原字段经过分词、小写化处理之后，只能匹配到解析之后的单独 <code>token</code>，比如使用标准解析器，这个搜索会匹配 <code>Accha Baccha</code>、<code>so cute accha baccha</code> 或者<code>Accha Baccha Shivam</code> 等字段。</p><h2 id="term-搜索-terms"><a href="#term-搜索-terms" class="headerlink" title="term 搜索 - terms"></a>term 搜索 - terms</h2><p>根据检索词列表来批量搜索文档，每个检索词在搜索的时候相当于 <code>or</code> 的关系，只要一个匹配就行了。Elasticsearch 最多允许 <code>65536</code> 个 <code>term</code> 同时查询。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"terms"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: [</span><br><span class="line">        <span class="string">"accha"</span>,</span><br><span class="line">        <span class="string">"ghazali"</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的查询会匹配 <code>name</code> 字段为 <code>accha</code> 和 <code>ghazali</code> 的文档。</p><p>除了直接指定查询的 term 列表，还可以使用 <code>Terms lookUp</code> 功能，也就是指定某一个存在的文档的某一个字段（可能是数字、字符串或者列表）来作为搜索条件，进行 terms 搜索。</p><p>比如有一个文件 <code>index</code> 是 <code>my_doc</code>，<code>id</code> 是 <code>10</code>，<code>name</code> 字段是 <code>term</code> 并且值为 <code>accha</code>，搜索可以这样写：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"terms"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"my_doc"</span>,</span><br><span class="line">        <span class="attr">"id"</span>: <span class="string">"10"</span>,</span><br><span class="line">        <span class="attr">"path"</span>: <span class="string">"name"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样就可以返回所有 <code>name</code> 字段值是 <code>accha</code> 的文档里，这个通常可以用来查询所有和某个文档某个字段重复的文档并且不需要提前知道这个字段的值是什么。</p><h2 id="term-搜索-terms-set"><a href="#term-搜索-terms-set" class="headerlink" title="term 搜索 - terms_set"></a>term 搜索 - terms_set</h2><p><code>terms_set</code> 和 <code>terms</code> 十分类似，只不过是多了一个最少需要匹配数量 <code>minimum_should_match_field</code> 参数。当进行匹配的时候，只有至少包含了这么多的 <code>terms</code> 中的 <code>term</code> 的时候，才会返回对应的结果。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"terms_set"</span>: &#123;</span><br><span class="line">      <span class="attr">"programming_languages"</span>: &#123;</span><br><span class="line">        <span class="attr">"terms"</span>: [<span class="string">"c++"</span>,<span class="string">"java"</span>,<span class="string">"php"</span>],</span><br><span class="line">        <span class="attr">"minimum_should_match_field"</span>: <span class="string">"required_match"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"name"</span>:<span class="string">"Jane Smith"</span>,</span><br><span class="line">    <span class="attr">"programming_languages"</span>:[</span><br><span class="line">        <span class="string">"c++"</span>,</span><br><span class="line">        <span class="string">"java"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"required_matches"</span>:<span class="number">2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么只有 <code>programming_languages</code> 列表里面至少包含 <code>[&quot;c++&quot;, &quot;java&quot;, &quot;php&quot;]</code> 其中的 2 项才能满足条件</p><p>还可以使用 <code>minimum_should_match_script</code> 脚本来配置动态查询</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"terms_set"</span>: &#123;</span><br><span class="line">      <span class="attr">"programming_languages"</span>: &#123;</span><br><span class="line">        <span class="attr">"terms"</span>: [<span class="string">"c++"</span>,<span class="string">"java"</span>,<span class="string">"php"</span>],</span><br><span class="line">        <span class="attr">"minimum_should_match_script"</span>: &#123;</span><br><span class="line">          <span class="attr">"source"</span>: <span class="string">"Math.min(params.num_terms, doc['required_matches'].value)"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中 <code>params.num_terms</code> 是在 <code>terms</code> 字段中的元素的个数</p><h2 id="term-搜索-wildcard"><a href="#term-搜索-wildcard" class="headerlink" title="term 搜索 - wildcard"></a>term 搜索 - wildcard</h2><p>通配符匹配，返回匹配包含通配符的检索词的结果。</p><p>目前只支持两种通配符：</p><ul><li><code>?</code>：匹配任何单一的字符</li><li><code>*</code>：匹配 0 个或者多个字符</li></ul><p>在进行 <code>wildcard</code> 搜索的时候最好避免在检索词的开头使用 <code>*</code> 或者 <code>?</code>，这会降低搜索性能。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"wildcard"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"acc*"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个搜索会匹配 <code>acchu</code>、<code>acche</code> 或者 <code>accio</code> 父</p><h2 id="text-搜索"><a href="#text-搜索" class="headerlink" title="text 搜索"></a>text 搜索</h2><p><code>text</code> 搜索实际上是针对被定义为 <code>text</code> 类型的字段的搜索，通常搜索的时候不能根据输入的字符串的整体来理解，而是要预先处理一下，把搜索词变成小的 token，再来查看每个 token 的匹配。</p><h2 id="text-搜索-interval"><a href="#text-搜索-interval" class="headerlink" title="text 搜索 - interval"></a>text 搜索 - interval</h2><p>返回按照检索词的特定排列顺序排列的文档。这个查询比较复杂，这里只是简单的介绍，详细的介绍可以看<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-intervals-query.html" target="_blank" rel="noopener">官方文档</a></p><p>比如我们想查询同时包含 <code>raj</code> 和 <code>nayaka</code> 的字段并且 <code>ray</code> 正好在 <code>nayaka</code> 前面，查询语句如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">POST /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"intervals"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: &#123;</span><br><span class="line">        <span class="attr">"match"</span>: &#123;</span><br><span class="line">          <span class="attr">"query"</span>: <span class="string">"raj nayaka"</span>,</span><br><span class="line">          <span class="attr">"max_gaps"</span>: <span class="number">0</span>,</span><br><span class="line">          <span class="attr">"ordered"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的查询会匹配 <code>Raj Nayaka Acchu Valmiki</code> 和 <code>Yateesh Raj Nayaka</code>。</p><p>如果把 <code>ordered:true</code> 去掉，就会匹配 <code>nayaka raj</code>。</p><p>如果把 <code>max_gaps:0</code> 去掉，系统会用默认值 <code>-1</code> 也就是没有距离要求，就会匹配 <code>Raj Raja nayaka</code> 或者 <code>Raj Kumar Nayaka</code></p><p>其中有两个关键词 <code>ordered</code> 和 <code>max_gaps</code> 分别用来控制这个筛选条件是否需要排序以及两个 <code>token</code> 之间的最大间隔</p><h2 id="text-搜索-match"><a href="#text-搜索-match" class="headerlink" title="text 搜索 - match"></a>text 搜索 - match</h2><p>查找和检索词短语匹配的文档，这些检索词在进行搜索之前会先被分析器解析，检索词可以是文本、数字、日期或者布尔值。match 检索也可以进行模糊匹配。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"nagesh acchu"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上的查询会匹配 <code>NaGesh Acchu</code>、<code>Acchu Acchu</code> 和 <code>acchu</code>。系统默认是在分词后匹配任何一个<code>token</code> 都可以完成匹配，如果修改 <code>operator</code> 为 <code>AND</code>，则会匹配同时包含 <code>nagesh</code> 和 <code>acchu</code> 的字段。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: &#123;</span><br><span class="line">        <span class="attr">"query"</span>: <span class="string">"nagesh acchu"</span>,</span><br><span class="line">        <span class="attr">"operator"</span>: <span class="string">"and"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面这个查询就只会返回 <code>NaGesh Acchu</code></p><p>查询的时候也可以使用模糊查询，修改 <code>fuzziness</code> 参数</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: &#123;</span><br><span class="line">        <span class="attr">"query"</span>: <span class="string">"nagesh acchu"</span>,</span><br><span class="line">        <span class="attr">"operator"</span>: <span class="string">"and"</span>,</span><br><span class="line">        <span class="attr">"fuzziness"</span>: <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的语句会匹配 <code>NaGesh Acchu</code> 还有 <code>Nagesh Bacchu</code></p><h2 id="text-搜索-match-bool-prefix"><a href="#text-搜索-match-bool-prefix" class="headerlink" title="text 搜索 - match_bool_prefix"></a>text 搜索 - match_bool_prefix</h2><p><code>match_bool_prefix</code> 会解析检索词，然后生成一个 <code>bool</code> 复合检索语句。如果检索词由很多个 <code>token</code> 构成，除了最后一个会进行 <code>prefix</code> 匹配，其他的会进行 <code>term</code> 匹配。</p><p>比如使用 <code>nagesh ac</code> 进行 <code>match_bool_prefix</code> 搜索</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_bool_prefix"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"nagesh ac"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的查询会匹配 <code>Nagesh Nagesh</code>、<code>Rakshith Achar</code> 或者 <code>ACoco</code></p><p>实际查询等价于</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"should"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"term"</span>: &#123;</span><br><span class="line">            <span class="attr">"name"</span>: &#123;</span><br><span class="line">              <span class="attr">"value"</span>: <span class="string">"nagesh"</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"prefix"</span>: &#123;</span><br><span class="line">            <span class="attr">"name"</span>: &#123;</span><br><span class="line">              <span class="attr">"value"</span>: <span class="string">"ac"</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="text-搜索-match-phrase"><a href="#text-搜索-match-phrase" class="headerlink" title="text 搜索 - match_phrase"></a>text 搜索 - match_phrase</h2><p>词组匹配会先解析检索词，并且标注出每个的 token 相对位置，搜索匹配的字段的必须包含所有的检索词的token，并且他们的相对位置也要和检索词里面相同。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_phrase"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"Bade Acche"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个搜索会匹配 <code>Bade Acche Lagte</code>，但是不会匹配 <code>Acche Bade Lagte</code> 或者 <code>Bade Lagte Acche</code>。</p><p>如果我们不要求这两个单词相邻，希望放松一点条件，可以添加 <code>slop</code> 参数，比如设置成 <code>1</code>，代表两个 token 之间相隔的最多的距离（最多需要移动多少次才能相邻）。下面的查询语句会匹配 <code>Bade Lagte Acche</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_phrase"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: &#123;</span><br><span class="line">        <span class="attr">"query"</span>: <span class="string">"Bade Acche"</span>,</span><br><span class="line">        <span class="attr">"slop"</span>: <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="text-搜索-match-phrase-prefix"><a href="#text-搜索-match-phrase-prefix" class="headerlink" title="text 搜索 - match_phrase_prefix"></a>text 搜索 - match_phrase_prefix</h2><p>match_phrase_prefix 相当于是结合了 <code>match_bool_prefix</code> 和 <code>match_phrase</code>。ES 会先解析检索词，分成很多个 token，然后除去最后一个 token，对其他的 token 进行 match_phrase 的匹配，即全部都要匹配并且相对位置相同；对于最后一个 token，需要进行前缀匹配并且匹配的这个单词在前面的 match_phrase 匹配的结果的后面。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_phrase_prefix"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"acchu ac"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的查询能够匹配 <code>Acchu Acchu1</code> 和 <code>Acchu Acchu Papu</code>，但是不能匹配 <code>acc acchu</code> 或者<code>acchu pa</code></p><h2 id="text-搜索-multi-match"><a href="#text-搜索-multi-match" class="headerlink" title="text 搜索 - multi_match"></a>text 搜索 - multi_match</h2><p><code>multi_match</code> 可以同时对多个字段进行查询匹配，ES支持很多种不同的查询类型比如 <code>best_fields</code>（任何字段 <code>match</code> 检索词都表示匹配成功）、<code>phrase</code>（用 <code>match_phrase</code> 代替 <code>match</code>）还有<code>cross_field</code>（交叉匹配，通常用在所有的 token 必须在至少一个字段中出现）等等</p><p>下面是普通的 <code>best_fields</code> 的匹配</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"acchu"</span>,</span><br><span class="line">      <span class="attr">"fields"</span>: [</span><br><span class="line">        <span class="string">"name"</span>,</span><br><span class="line">        <span class="string">"intro"</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>只要 <code>name</code> 或者 <code>intro</code> 字段任何一个包含 <code>acchu</code> 都会完成匹配。</p><p>如果使用 <code>cross_fields</code> 匹配如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"call acchu"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"cross_fields"</span>,</span><br><span class="line">      <span class="attr">"fields"</span>: [</span><br><span class="line">        <span class="string">"name"</span>,</span><br><span class="line">        <span class="string">"intro"</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"operator"</span>: <span class="string">"and"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的匹配需要同时满足下面两个条件:</p><ul><li><code>name</code> 中出现 <code>call</code> 或 <code>intro</code> 中出现 <code>call</code></li><li><code>name</code> 中出现 <code>acchu</code> 或 <code>intro</code> 中出现 <code>acchu</code></li></ul><p>所以这个查询能够匹配 <code>name</code> 包含 <code>acchu</code> 和 <code>intro</code> 包含 <code>call</code> 的文档，或者匹配 <code>name</code> 同时包含 <code>call</code> 和 <code>acchu</code> 的文档。</p><h2 id="text-搜索-common"><a href="#text-搜索-common" class="headerlink" title="text 搜索 - common"></a>text 搜索 - common</h2><p>common 查询会把查询语句分成两个部分，较为重要的分为一个部分（这个部分的 token 通常在文章中出现频率比较低），不那么重要的为一个部分（出现频率比较高，以前可能被当作停止词），然后分别用<code>low_freq_operator</code>、<code>high_freq_operator</code> 以及 <code>minimum_should_match</code> 来控制这些语句的表现。</p><p>在进行查询之前需要指定一个区分高频和低频词的分界点，也就是 <code>cutoff_frequency</code>，它既可以是小数比如<code>0.001</code> 代表该字段所有的 token 的集合里面出现的频率也可以是大于 <code>1</code> 的整数代表这个词出现的次数。当 token 的频率高于这一个阈值的时候，他就会被当作高频词。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"common"</span>: &#123;</span><br><span class="line">      <span class="attr">"body"</span>: &#123;</span><br><span class="line">        <span class="attr">"query"</span>: <span class="string">"nelly the elephant as a cartoon"</span>,</span><br><span class="line">        <span class="attr">"cutoff_frequency"</span>: <span class="number">0.001</span>,</span><br><span class="line">        <span class="attr">"low_freq_operator"</span>: <span class="string">"and"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中高频词是 <code>the</code>、<code>a</code> 和 <code>as</code> ，低频词是 <code>nelly</code>、<code>elephant</code> 和 <code>cartoon</code>，上面的搜索大致等价于下面的查询</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"body"</span>: <span class="string">"nelly"</span>&#125;&#125;,</span><br><span class="line">        &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"body"</span>: <span class="string">"elephant"</span>&#125;&#125;,</span><br><span class="line">        &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"body"</span>: <span class="string">"cartoon"</span>&#125;&#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"should"</span>: [</span><br><span class="line">        &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"body"</span>: <span class="string">"the"</span>&#125;&#125;,</span><br><span class="line">        &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"body"</span>: <span class="string">"as"</span>&#125;&#125;,</span><br><span class="line">        &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"body"</span>: <span class="string">"a"</span>&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是第一个查询的效率要优于第二个，因为 <code>common</code> 语句有性能上的优化，只有重要的 <code>token</code> 匹配之后的文档，才会在不重要的文档的查询时候计算 <code>_score</code>；不重要的 token 在查询的时候不会计算 <code>_score</code></p><h2 id="text-搜索-query-string"><a href="#text-搜索-query-string" class="headerlink" title="text 搜索 - query_string"></a>text 搜索 - query_string</h2><p>输入一个查询语句，返回和这个查询语句匹配的所有的文档。</p><p>这个查询语句不是简单的检索词，而是包含特定语法的的搜索语句，里面包含操作符比如 <code>AND</code> 和 <code>OR</code>，在进行查询之前会被一个语法解析器解析，转化成可以执行的搜索语句进行搜索。用户可以生成一个特别复杂的查询语句，里面可能包含通配符、多字段匹配等等。在搜索之前 ES 会检查查询语句的语法，如果有语法错误会直接报错。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"query_string"</span>: &#123;</span><br><span class="line">      <span class="attr">"default_field"</span>: <span class="string">"name"</span>,</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"acchu AND nagesh"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的查询会匹配所有的同时包含 <code>acchu</code> 和 <code>nagesh</code> 的结果。简化一下可以这样写：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"query_string"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"name: acchu AND nagesh"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>query_string 里面还支持更加复杂的写法：</p><ul><li><code>name: acchu nagesh</code>：查询 <code>name</code> 包含 <code>acchu</code> 和 <code>nagesh</code> 其中的任意一个</li><li><code>book.\*:(quick OR brown)</code>：<code>book</code> 的任何子字段比如 <code>book.title</code> 和 <code>book.content</code>，包含 <code>quick</code> 或者 <code>brown</code></li><li><code>_exists_: title</code>：<code>title</code> 字段包含非 <code>null</code> 值</li><li><code>name: acch*</code>：通配符，匹配任何 <code>acch</code> 开头的字段</li><li><code>name:/joh?n(ath[oa]n)/</code>：正则表达式，需要把内容放到两个斜杠 <code>/</code> 中间</li><li><code>name: acch~</code>：模糊匹配，默认编辑距离为 2，不过80%的情况编辑距离为1就能解决问题 <code>name: acch~1</code></li><li><code>count:[1 TO 5]</code>：范围查询，或者 <code>count: &gt;10</code></li></ul><p>下面的查询允许匹配多个字段，字段之间时 <code>OR</code> 的关系</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"query_string"</span>: &#123;</span><br><span class="line">      <span class="attr">"fields"</span>: [</span><br><span class="line">        <span class="string">"name"</span>,</span><br><span class="line">        <span class="string">"intro"</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"nagesh"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="text-搜索-simple-query-string"><a href="#text-搜索-simple-query-string" class="headerlink" title="text 搜索 - simple_query_string"></a>text 搜索 - simple_query_string</h2><p>和上面的 <code>query_string</code> 类似，但是使用了更加简单的语法。使用了下面的操作符：</p><ul><li><code>+</code> 表示 <code>AND</code> 操作</li><li><code>|</code> 表示 <code>OR</code> 操作</li><li><code>-</code> 表示否定</li><li><code>&quot;</code> 用于圈定一个短语</li><li><code>*</code> 放在 token 的后面表示前缀匹配</li><li><code>()</code> 表示优先级</li><li><code>~N</code> 放在 token 后面表示模糊查询的最大编辑距离 <code>fuzziness</code></li><li><code>~N</code> 放在 phrase 后面表示模糊匹配短语的 <code>slop</code> 值</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"simple_query_string"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"acch* + foll~2 + -Karen"</span>,</span><br><span class="line">      <span class="attr">"fields"</span>: [</span><br><span class="line">        <span class="string">"intro"</span></span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的搜索相当于搜索包含前缀为 <code>acch</code> 的、和 <code>foll</code> 编辑距离最大是 <code>2</code> 的并且不包含 <code>Karen</code> 的字段，这样的语句会匹配 <code>call me acchu</code> 或者 <code>acchu follow me</code></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Elasticsearch 提供了强大的搜索功能，使用 <code>query</code> 匹配可以进行相关性的计算排序但是 <code>filter</code> 可能更加适用于大多数的过滤查询的情况，如果用户对于标准解析器不太满意可以自定义解析器或者第三方解析器比如支持中文的 <code>IK</code> 解析器。</p><p>在进行搜索的时候一定要注意搜索 <code>keyword</code> 和 <code>text</code> 字段时候的区别，使用 <code>term</code> 相关的查询只能匹配单个的 <code>token</code> 但是使用 <code>text</code> 相关的搜索可以利用前面的 <code>term</code> 搜索进行组合查询，<code>text</code> 搜索更加灵活强大，但是性能相对差一点。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《Elasticsearch核心技术与实战》</li><li><a href="https://www.cnblogs.com/sunshuyi/p/12716828.html" target="_blank" rel="noopener">https://www.cnblogs.com/sunshuyi/p/12716828.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/full-text-queries.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/full-text-queries.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/term-level-queries.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/term-level-queries.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Elasticsearch 搜索 API 整理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="BigData" scheme="https://blog.lichao.xin/categories/BigData/"/>
    
    
      <category term="Elastic Stack" scheme="https://blog.lichao.xin/tags/Elastic-Stack/"/>
    
      <category term="ES" scheme="https://blog.lichao.xin/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>基于 Flink SQL CDC 的实时数据同步方案</title>
    <link href="https://blog.lichao.xin/back-end/big-data/flink-sql-cdc/"/>
    <id>https://blog.lichao.xin/back-end/big-data/flink-sql-cdc/</id>
    <published>2021-02-14T16:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>鸽了……</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;鸽了……&lt;/p&gt;
    
    </summary>
    
    
      <category term="BigData" scheme="https://blog.lichao.xin/categories/BigData/"/>
    
    
      <category term="Elastic Stack" scheme="https://blog.lichao.xin/tags/Elastic-Stack/"/>
    
      <category term="ES" scheme="https://blog.lichao.xin/tags/ES/"/>
    
      <category term="Flink" scheme="https://blog.lichao.xin/tags/Flink/"/>
    
  </entry>
  
  <entry>
    <title>重学 Elastic Stack 之 Canal 数据同步方案</title>
    <link href="https://blog.lichao.xin/back-end/big-data/canal-sync-es/"/>
    <id>https://blog.lichao.xin/back-end/big-data/canal-sync-es/</id>
    <published>2021-02-13T13:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>鸽了……</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;鸽了……&lt;/p&gt;
    
    </summary>
    
    
      <category term="BigData" scheme="https://blog.lichao.xin/categories/BigData/"/>
    
    
      <category term="Elastic Stack" scheme="https://blog.lichao.xin/tags/Elastic-Stack/"/>
    
      <category term="ES" scheme="https://blog.lichao.xin/tags/ES/"/>
    
      <category term="Canal" scheme="https://blog.lichao.xin/tags/Canal/"/>
    
  </entry>
  
  <entry>
    <title>重学 Elastic Stack 之 ES 实战</title>
    <link href="https://blog.lichao.xin/back-end/big-data/es-09/"/>
    <id>https://blog.lichao.xin/back-end/big-data/es-09/</id>
    <published>2021-02-12T13:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>Spring Boot 整合 Elasticsearch。</p><a id="more"></a><h2 id="集成方式"><a href="#集成方式" class="headerlink" title="集成方式"></a>集成方式</h2><p>Spring Boot 中集成 ES 有以下几种方式：</p><ol><li><a href="https://github.com/searchbox-io/Jest" target="_blank" rel="noopener">Jest</a><ul><li>这是社区封装的 Client，比较老，目前仅支持到 6.x，看 Issues 已经不怎么更新了，不建议使用。</li></ul></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/index.html" target="_blank" rel="noopener">Java Client</a><ul><li>java client 使用 TransportClient，各种操作本质上都是异步的(可以用 listener，或返回 Future ）。</li><li>ES的发展规划中在7.0版本开始将废弃 TransportClient，8.0版本中将完全移除 TransportClient，取而代之的是High Level REST Client。High Level REST Client 中的操作API和java client 大多是一样的。</li></ul></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/index.html" target="_blank" rel="noopener">REST Client</a><ul><li>Java Low Level REST Client: 低级别的REST客户端，通过http与集群交互，用户需自己编组请求JSON串，及解析响应JSON串。兼容所有ES版本。</li><li>Java High Level REST Client: 高级别的REST客户端，基于低级别的REST客户端，增加了编组请求JSON串、解析响应JSON串等相关api。使用的版本需要保持和ES服务端的版本一致，否则会有版本问题。（官方推荐）</li></ul></li><li><a href="https://github.com/spring-projects/spring-data-elasticsearch" target="_blank" rel="noopener">Spring Data Elasticsearch</a><ul><li>Spring Data 项目的子项目，提供了 Elasticsearch 与 Spring 的集成。</li><li>高版本也是用的 High Level 封装。Repository 风格，上手简单，复杂查询提供原生访问能力。</li></ul></li></ol><h2 id="Elasticsearch-Rest-High-Level-Client"><a href="#Elasticsearch-Rest-High-Level-Client" class="headerlink" title="Elasticsearch Rest High Level Client"></a>Elasticsearch Rest High Level Client</h2><p>引入Maven 依赖：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.elasticsearch.client<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>elasticsearch-rest-high-level-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>7.11.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>初始化客户端：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RestHighLevelClient client = <span class="keyword">new</span> RestHighLevelClient(</span><br><span class="line">        RestClient.builder(</span><br><span class="line">                <span class="keyword">new</span> HttpHost(<span class="string">"localhost"</span>, <span class="number">9200</span>, <span class="string">"http"</span>),</span><br><span class="line">                <span class="keyword">new</span> HttpHost(<span class="string">"localhost"</span>, <span class="number">9201</span>, <span class="string">"http"</span>)));</span><br></pre></td></tr></table></figure><h2 id="Spring-Data-Elasticsearch"><a href="#Spring-Data-Elasticsearch" class="headerlink" title="Spring Data Elasticsearch"></a>Spring Data Elasticsearch</h2><p>Spring Data Elasticsearch 是 Spring Data 项目的子项目，提供了 Elasticsearch 与 Spring 的集成。实现了 Spring Data Repository 风格的 Elasticsearch 文档交互风格，让你轻松进行 Elasticsearch 客户端开发。</p><h2 id="分词技巧"><a href="#分词技巧" class="headerlink" title="分词技巧"></a>分词技巧</h2><p>索引时最小分词，搜索时最大分词，例如”Java知音”索引时分词包含Java、知音、音、知等，最小粒度分词可以让我们匹配更多的检索需求，但是我们搜索时应该设置最大分词，用“Java”和“知音”去匹配索引库，得到的结果更贴近我们的目的，</p><p>对分词字段同时也设置keyword，便于后续排查错误时可以精确匹配搜索，快速定位。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><h3 id="普通对象结构"><a href="#普通对象结构" class="headerlink" title="普通对象结构"></a>普通对象结构</h3><ul><li>ES 会做压扁处理（扁平化），对象会变 k -&gt; v，形式，对象数组会变 xxx.name -&gt; [“a”, “b”]</li><li>对象内部关联关系消失</li><li>无法做子对象内关联条件过滤</li><li>高亮无法对应位置，因为文档扁平化后对象边界消失</li></ul><h3 id="嵌套查询"><a href="#嵌套查询" class="headerlink" title="嵌套查询"></a>嵌套查询</h3><ul><li>ES 内部子对象会有多个隐藏文档</li><li>能做高亮和关联查询</li><li>保证不了事务的话很有可能会有数据相互覆盖的问题</li></ul><h3 id="父子文档"><a href="#父子文档" class="headerlink" title="父子文档"></a>父子文档</h3><ul><li>只能有一个 join 类型</li><li>可以设置多个子文档，子文档名称设置为数组就可以了</li></ul><h3 id="文章-关注案例"><a href="#文章-关注案例" class="headerlink" title="文章-关注案例"></a>文章-关注案例</h3><p>场景是 要查一个人关注的文章列表，就是我关注的文章功能，要能全文检索</p><p>分开存，es里放全量文章做全文搜索，mysql里放关注列表，搜的时候拿关注列表做前置或者后置过滤</p><p>关联你如果想把用户id缓存在es里，保证不了事务的话很有可能会有数据相互覆盖的问题</p><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><h3 id="Elasticsearch更新-Mapping-amp-重建索引"><a href="#Elasticsearch更新-Mapping-amp-重建索引" class="headerlink" title="Elasticsearch更新 Mapping&amp;重建索引"></a>Elasticsearch更新 Mapping&amp;重建索引</h3><p><strong>索引变成的场景：</strong></p><p>– 索引的 Mappings 发生变更：字段类型更改，分词器及字典更新<br>– 索引的 Settings 发⽣变更：索引的主分⽚数发⽣生改变<br>– 集群内，集群间需要做数据迁移</p><p><strong>索引变更的方式</strong></p><p>– Update By Query：在现有索引上重建<br>– Reindex：在其他索引上重建索引</p><p><strong>Update By Query</strong></p><p>使用场景：</p><p>– 为字段增加子字段<br>– 字段更换分词器<br>– 更新分词器词库</p><p>案例：使用 update by query 增加子字段</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"># 自动补全功能</span><br><span class="line"># 变更 mapping ，增加一个子字段，类型为 completion</span><br><span class="line">PUT blog/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    <span class="attr">"title"</span>: &#123;</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">      <span class="attr">"analyzer"</span>: <span class="string">"ik_max_word"</span>,</span><br><span class="line">      <span class="attr">"search_analyzer"</span>: <span class="string">"ik_smart"</span>,</span><br><span class="line">      <span class="attr">"fields"</span>: &#123;</span><br><span class="line">        <span class="attr">"keyword"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">          <span class="attr">"ignore_above"</span>: <span class="number">256</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"completion"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"completion"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 执行 update by query 使刚刚的变成生效</span><br><span class="line">POST blog/_update_by_query</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"># 自定补全查询</span><br><span class="line">POST blog/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"_source"</span>: [</span><br><span class="line">    <span class="string">"title"</span>,</span><br><span class="line">    <span class="string">"id"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"suggest"</span>: &#123;</span><br><span class="line">    <span class="attr">"blog-suggest"</span>: &#123;</span><br><span class="line">      <span class="attr">"prefix"</span>: <span class="string">"使用"</span>,</span><br><span class="line">      <span class="attr">"completion"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"title.completion"</span>,</span><br><span class="line">        <span class="attr">"skip_duplicates"</span>: <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Reindex</strong></p><p>使用场景：</p><p>– 修改字段类型. 需要先设置索引 mapping， 索引的设置和映射关系不会被复制<br>– 修改索引的主分片数<br>– 集群内迁移数据、跨集群迁移数据</p><p>reindex 一般是一个比较耗时的操作，但是直接调用 reindex api 的接口超时时间比较端，我们可以使用 wait_for_completion，这样不必等待 reindex 执行完成才返回。结合 _tasks 可以查看任务执行的进度。</p><p>案例：修改字段类型</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"># 修改索引：修改索引类型</span><br><span class="line"># 创建被迁移的索引</span><br><span class="line">PUT blog_reindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"id"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"long"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"createTime"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"date"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"lastTime"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"date"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"content"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"analyzer"</span>: <span class="string">"ik_max_word"</span>,</span><br><span class="line">        <span class="attr">"search_analyzer"</span>: <span class="string">"ik_smart"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"keyword"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">            <span class="attr">"ignore_above"</span>: <span class="number">10240</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"title"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"analyzer"</span>: <span class="string">"ik_max_word"</span>,</span><br><span class="line">        <span class="attr">"search_analyzer"</span>: <span class="string">"ik_smart"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"keyword"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">            <span class="attr">"ignore_above"</span>: <span class="number">256</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"status"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"type"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"content_filtered"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"analyzer"</span>: <span class="string">"ik_max_word"</span>,</span><br><span class="line">        <span class="attr">"search_analyzer"</span>: <span class="string">"ik_smart"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"keyword"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">            <span class="attr">"ignore_above"</span>: <span class="number">10240</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"comment_count"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"integer"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"new_field"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"integer"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: &#123;</span><br><span class="line">      <span class="attr">"number_of_shards"</span>: <span class="string">"1"</span>,</span><br><span class="line">      <span class="attr">"number_of_replicas"</span>: <span class="string">"0"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 重建索引</span><br><span class="line">POST _reindex?wait_for_completion=false</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"source"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blog"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"dest"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blog_reindex"</span>,</span><br><span class="line">    <span class="attr">"op_type"</span>: <span class="string">"create"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 查看迁移状态</span><br><span class="line">GET _tasks?detailed=true&amp;actions=*reindex</span><br></pre></td></tr></table></figure><h3 id="索引Mapping-模板操作"><a href="#索引Mapping-模板操作" class="headerlink" title="索引Mapping 模板操作"></a>索引Mapping 模板操作</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取模板</span></span><br><span class="line">GET _template/demo_template</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除索引模板</span></span><br><span class="line">DELETE _template/demo_template</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加模板</span></span><br><span class="line">PUT _template/demo_template</span><br><span class="line">&#123;</span><br><span class="line">  // ……</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="reindex-操作"><a href="#reindex-操作" class="headerlink" title="reindex 操作"></a>reindex 操作</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">POST _reindex?wait_for_completion=<span class="literal">false</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"conflicts"</span>: <span class="string">"proceed"</span>,</span><br><span class="line">  <span class="string">"source"</span>: &#123;</span><br><span class="line">    <span class="string">"index"</span>: <span class="string">"demo_index_v1"</span></span><br><span class="line">    <span class="string">"size"</span>: 5000</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"dest"</span>: &#123;</span><br><span class="line">    <span class="string">"index"</span>: <span class="string">"demo_index_v2"</span>,</span><br><span class="line">    <span class="string">"op_type"</span>: <span class="string">"create"</span>,</span><br><span class="line">    <span class="string">"version_type"</span>: <span class="string">"external"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看异步任务</span></span><br><span class="line">GET /_tasks/&#123;id&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对比迁移后的文档数是否一致</span></span><br><span class="line">GET /_cat/indices/demo_index_v1,demo_index_v2?v</span><br></pre></td></tr></table></figure><ul><li><p><code>conflicts: proceed</code>：默认情况下，版本冲突会导致_reindex操作终止，可以设置这个字段使该请求遇到冲突时不会终止，而是统计冲突数量；</p></li><li><p><code>version_type: extrenal</code>：_reindex指令会生成源索引的快照，它的目标索引必须是一个不同的索引[新索引]，以便避免版本冲突。如果不设置version_type字段，默认为internal，ES会直接将文档转存储到目标索引中(dest index)，直接覆盖任何具有相同类型和id的document，不会产生版本冲突。如果把version_type设置为extertral，那么ES会从源索引(source index)中读取version字段，当遇到具有相同类型和id的document时，只会保留new version，即最新的version对应的数据。此时可能会有冲突产生，比如当把op_tpye设置为create，对于产生的冲突现象，返回体中的 failures 会携带冲突的数据信息【类似详细的日志可以查看】。</p></li><li><p><code>op_type：op_type</code> 参数控制着写入数据的冲突处理方式，如果把 op_type 设置为 create【默认值】，在 _reindex API 中，表示写入时只在 dest index 中添加不存在的 doucment，如果相同的 document 已经存在，则会报 version confilct 的错误，那么索引操作就会失败。【这种方式与使用 _create API 时效果一致】。</p></li></ul><blockquote><p>可以执行远程夸集群 reindex，具体操作可以查看官方文档。注意：远程IP需要加入白名单配置。</p></blockquote><h3 id="别名操作"><a href="#别名操作" class="headerlink" title="别名操作"></a>别名操作</h3><p>零停机时间实现重新索引方式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST _aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"remove"</span>: &#123;</span><br><span class="line">        <span class="string">"index"</span>: <span class="string">"demo_index_v1"</span>,</span><br><span class="line">        <span class="string">"alias"</span>: <span class="string">"demo_latest"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"add"</span>: &#123;</span><br><span class="line">        <span class="string">"index"</span>: <span class="string">"demo_index_v2"</span>,</span><br><span class="line">        <span class="string">"alias"</span>: <span class="string">"demo_latest"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="http://elasticsearch-cheatsheet.jolicode.com" target="_blank" rel="noopener">http://elasticsearch-cheatsheet.jolicode.com</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spring Boot 整合 Elasticsearch。&lt;/p&gt;
    
    </summary>
    
    
      <category term="BigData" scheme="https://blog.lichao.xin/categories/BigData/"/>
    
    
      <category term="Elastic Stack" scheme="https://blog.lichao.xin/tags/Elastic-Stack/"/>
    
      <category term="ES" scheme="https://blog.lichao.xin/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>重学 Elastic Stack 之 ELK 数据分析</title>
    <link href="https://blog.lichao.xin/back-end/big-data/es-08/"/>
    <id>https://blog.lichao.xin/back-end/big-data/es-08/</id>
    <published>2021-02-10T22:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>鸽了……</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;鸽了……&lt;/p&gt;
    
    </summary>
    
    
      <category term="BigData" scheme="https://blog.lichao.xin/categories/BigData/"/>
    
    
      <category term="Elastic Stack" scheme="https://blog.lichao.xin/tags/Elastic-Stack/"/>
    
      <category term="ES" scheme="https://blog.lichao.xin/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>重学 Elastic Stack 之 Elasticsearch 集群管理</title>
    <link href="https://blog.lichao.xin/back-end/big-data/es-07/"/>
    <id>https://blog.lichao.xin/back-end/big-data/es-07/</id>
    <published>2021-02-09T22:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>深入了解 ES 集群管理、生产环境建议等。</p><a id="more"></a><h2 id="管集群身份认证与用户鉴权"><a href="#管集群身份认证与用户鉴权" class="headerlink" title="管集群身份认证与用户鉴权"></a>管集群身份认证与用户鉴权</h2><h3 id="数据泄露"><a href="#数据泄露" class="headerlink" title="数据泄露"></a>数据泄露</h3><p><img src="/images/big-data/es-07/1.jpg" alt="1"></p><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><ul><li>ES 在默认安装后，不提供任何形式的安全防护</li><li>错误的配置信息导致公网可以访问 ES 集群<ul><li>在 elasticsearch.yml 文件中，server.host 被错误的配置为 0.0.0.0</li></ul></li></ul><h3 id="数据安全性的基本需求"><a href="#数据安全性的基本需求" class="headerlink" title="数据安全性的基本需求"></a>数据安全性的基本需求</h3><ul><li>身份认证<ul><li>鉴定用户是否合法</li></ul></li><li>用户鉴权<ul><li>指定哪个用户可以访问哪个索引</li></ul></li><li>传输加密</li><li>日志审计</li></ul><p><img src="/images/big-data/es-07/2.jpg" alt="2"></p><h3 id="一些免费的方案"><a href="#一些免费的方案" class="headerlink" title="一些免费的方案"></a>一些免费的方案</h3><ul><li>设置 Nginx 的反向代理</li><li>安装免费的 Security 插件<ul><li>Search Guard - <a href="https://search-guard.com/" target="_blank" rel="noopener">https://search-guard.com/</a></li><li>ReadOnly REST - <a href="https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin" target="_blank" rel="noopener">https://github.com/sscarduzio/elasticsearch-readonlyrest-plugin</a></li></ul></li><li>X-Pack 的 Basic 版<ul><li>从 ES 6.8 &amp; ES 7.0 开始，Security 纳入 x-pack 的 Basic 版本中，免费使用一些基本的功能</li><li><a href="https://www.elastic.co/cn/what-is/elastic-stack-security" target="_blank" rel="noopener">https://www.elastic.co/cn/what-is/elastic-stack-security</a></li></ul></li></ul><h3 id="Anthentication-身份认证"><a href="#Anthentication-身份认证" class="headerlink" title="Anthentication - 身份认证"></a>Anthentication - 身份认证</h3><ul><li>认证体系的几种类型<ul><li>提供用户名和密码</li><li>提供秘钥或 Kerberos 票据</li></ul></li><li>Realms : X-Pack 中的认证服务<ul><li>内置 Realms （免费）<ul><li>File / Native (用户名密码保存在 Elasticsearch)</li></ul></li><li>外部 Realms （收费）<ul><li>LDAP / Active Directory / PKI / SAML / Kerberos</li></ul></li></ul></li></ul><h3 id="RBAC-用户鉴权"><a href="#RBAC-用户鉴权" class="headerlink" title="RBAC - 用户鉴权"></a>RBAC - 用户鉴权</h3><ul><li>什么是 RBAC：Role Based Access Control， 定义一个角色，并分配一组权限。权限包括索引级，字段级，集群级的不同的操作。然后通过将角色分配给用户，使得用户拥有这些权限<ul><li>User：The authenticated User</li><li>Role：A named set of permissions</li><li>Permission – A set of one or more privileges against a secured resource</li><li>Privilege – A named group of 1 or more actions that user may execute against a secured resource</li></ul></li></ul><h3 id="Privilege"><a href="#Privilege" class="headerlink" title="Privilege"></a>Privilege</h3><ul><li>Cluster Privileges<ul><li>all / monitor / manager / manage_index / manage_index_template / manage_rollup</li></ul></li><li>Indices Privileges<ul><li>all / create / create_index / delete / delete_index / index / manage / read /writeview_index_metadata</li></ul></li></ul><h3 id="创建内置的用户和角色"><a href="#创建内置的用户和角色" class="headerlink" title="创建内置的用户和角色"></a>创建内置的用户和角色</h3><ul><li>内置的角色与用户</li></ul><table><thead><tr><th align="left">用户</th><th align="left">角色</th></tr></thead><tbody><tr><td align="left">elastic</td><td align="left">Supper User</td></tr><tr><td align="left">kibana</td><td align="left">The user that is used by Kibana to connect and communicate with Elasticsearch.</td></tr><tr><td align="left">logstash_system</td><td align="left">The user that is used by Logstash when storing monitoring information in Elasticsearch.</td></tr><tr><td align="left">beats_system</td><td align="left">The user that the different Beats use when storing monitoring information in Elasticsearch.</td></tr><tr><td align="left">apm_system</td><td align="left">The user that the APM server uses when storing monitoring information in Elasticsearch.</td></tr><tr><td align="left">Remote_monitoring_user</td><td align="left">The user that is used by Metricbeat when collecting and storing monitoring information in Elasticsearch.</td></tr></tbody></table><h3 id="使用-Security-API-创建用户"><a href="#使用-Security-API-创建用户" class="headerlink" title="使用 Security API 创建用户"></a>使用 Security API 创建用户</h3><table><thead><tr><th align="left"></th><th></th></tr></thead><tbody><tr><td align="left">User</td><td>Create user <br/> Update user <br/> Delete user <br/> Enable / disable users <br/> Get users <br/> Change password</td></tr><tr><td align="left">Role</td><td>Create Role <br/> Update Role <br/> Delete Role <br/> Get roles</td></tr></tbody></table><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">POST /_security/user/richard</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"password"</span>: <span class="string">"123456"</span>,</span><br><span class="line">  <span class="attr">"roles"</span>: [<span class="string">"admin"</span>],</span><br><span class="line">  <span class="attr">"full_name"</span>: <span class="string">"Richard Xin"</span>,</span><br><span class="line">  <span class="attr">"email"</span>:<span class="string">"xinlichao2016@gmail.com"</span>,</span><br><span class="line">  <span class="attr">"metadata"</span>: &#123;</span><br><span class="line">    <span class="attr">"intelligence"</span>: <span class="number">7</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="开启并配置-X-Pack-的认证与鉴权"><a href="#开启并配置-X-Pack-的认证与鉴权" class="headerlink" title="开启并配置 X-Pack 的认证与鉴权"></a>开启并配置 X-Pack 的认证与鉴权</h3><ul><li>修改配置文件，打开认证于授权<ul><li><code>bin/elasticsearch -E node.name=node0 -E cluster.name=demo -E path.data=node0_data -E http.port=9200 -E xpack.security.enabled=true</code></li></ul></li><li>创建默认的用户和分组<ul><li><code>bin/elasticsearch-setup-passwords interactive</code></li></ul></li><li>当集群开启身份认证之后，配置 Kibana</li></ul><h3 id="配置-Kibana"><a href="#配置-Kibana" class="headerlink" title="配置 Kibana"></a>配置 Kibana</h3><ul><li>修改 kibana.yml<ul><li>elasticsearch.username: “kibana”</li><li>elasticsearch.password: “changeme”</li></ul></li></ul><h2 id="集群内部间的安全通信"><a href="#集群内部间的安全通信" class="headerlink" title="集群内部间的安全通信"></a>集群内部间的安全通信</h2><h3 id="为啥要加密通讯"><a href="#为啥要加密通讯" class="headerlink" title="为啥要加密通讯"></a>为啥要加密通讯</h3><ul><li>加密数据 - 避免数据抓包，敏感信息泄露</li><li>验证身份 - 避免 Imposter Node<ul><li>Data / Cluster State</li></ul></li></ul><p><img src="/images/big-data/es-07/3.jpg" alt="3"></p><h3 id="为节点创建证书"><a href="#为节点创建证书" class="headerlink" title="为节点创建证书"></a>为节点创建证书</h3><ul><li>TLS<ul><li>TLS 协议要求 Trusted Certificate Authority（CA）签发的 X.509 的证书</li></ul></li><li>证书认证的不同级别<ul><li>Certificate – 节点加入需要使用相同 CA 签发的证书</li><li>Full Verification – 节点加入集群需要相同 CA 签发的证书，还需要验证 Host name 或 IP 地址</li><li>No Verification – 任何节点都可以加入，开发环境中用于诊断目的</li></ul></li></ul><h3 id="生成节点证书"><a href="#生成节点证书" class="headerlink" title="生成节点证书"></a>生成节点证书</h3><ul><li>bin/elasticsearch-certutil ca</li><li>bin/elasticsearch-certutil cert –ca elastic-stack-ca.p12</li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/configuring-tls.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/configuring-tls.html</a></li></ul><h3 id="配置节点间通讯"><a href="#配置节点间通讯" class="headerlink" title="配置节点间通讯"></a>配置节点间通讯</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成证书</span></span><br><span class="line"><span class="comment"># 为您的Elasticearch集群创建一个证书颁发机构。例如，使用elasticsearch-certutil ca命令：</span></span><br><span class="line">bin/elasticsearch-certutil ca</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为群集中的每个节点生成证书和私钥。例如，使用elasticsearch-certutil cert 命令：</span></span><br><span class="line">bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将证书拷贝到 config/certs目录下</span></span><br><span class="line">elastic-certificates.p12</span><br><span class="line"></span><br><span class="line">bin/elasticsearch -E node.name=node0 -E cluster.name=demo -E path.data=node0_data -E http.port=9200 -E xpack.security.enabled=<span class="literal">true</span> -E xpack.security.transport.ssl.enabled=<span class="literal">true</span> -E xpack.security.transport.ssl.verification_mode=certificate -E xpack.security.transport.ssl.keystore.path=certs/elastic-certificates.p12 -E xpack.security.transport.ssl.truststore.path=certs/elastic-certificates.p12</span><br><span class="line"></span><br><span class="line">bin/elasticsearch -E node.name=node1 -E cluster.name=demo -E path.data=node1_data -E http.port=9201 -E xpack.security.enabled=<span class="literal">true</span> -E xpack.security.transport.ssl.enabled=<span class="literal">true</span> -E xpack.security.transport.ssl.verification_mode=certificate -E xpack.security.transport.ssl.keystore.path=certs/elastic-certificates.p12 -E xpack.security.transport.ssl.truststore.path=certs/elastic-certificates.p12</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不提供证书的节点，无法加入</span></span><br><span class="line">bin/elasticsearch -E node.name=node2 -E cluster.name=demo -E path.data=node2_data -E http.port=9202 -E xpack.security.enabled=<span class="literal">true</span> -E xpack.security.transport.ssl.enabled=<span class="literal">true</span> -E xpack.security.transport.ssl.verification_mode=certificate</span><br></pre></td></tr></table></figure><p><strong>elasticsearch.yml 配置</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">xpack.security.transport.ssl.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">xpack.security.transport.ssl.verification_mode:</span> <span class="string">certificate</span></span><br><span class="line"><span class="attr">xpack.security.transport.ssl.keystore.path:</span> <span class="string">certs/elastic-certificates.p12</span></span><br><span class="line"><span class="attr">xpack.security.transport.ssl.truststore.path:</span> <span class="string">certs/elastic-certificates.p12</span></span><br></pre></td></tr></table></figure><h2 id="集群与外部间的安全通信"><a href="#集群与外部间的安全通信" class="headerlink" title="集群与外部间的安全通信"></a>集群与外部间的安全通信</h2><h3 id="为什么需要-HTTPS"><a href="#为什么需要-HTTPS" class="headerlink" title="为什么需要 HTTPS"></a>为什么需要 HTTPS</h3><p><img src="/images/big-data/es-07/5.jpg" alt="5"></p><p>在外部通信的场景下需要 HTTPS 保护我们的数据。</p><h3 id="配置-Elasticsearch-for-HTTPS"><a href="#配置-Elasticsearch-for-HTTPS" class="headerlink" title="配置 Elasticsearch for HTTPS"></a>配置 Elasticsearch for HTTPS</h3><p><strong>elasticsearch.yml 配置</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">xpack.security.http.ssl.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">xpack.security.http.ssl.keystore.path:</span> <span class="string">certs/elastic-certificates.p12</span></span><br><span class="line"><span class="attr">xpack.security.http.ssl.truststore.path:</span> <span class="string">certs/elastic-certificates.p12</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ES 启用 https</span></span><br><span class="line">bin/elasticsearch -E node.name=node0 -E cluster.name=demo -E path.data=node0_data -E http.port=9200 -E xpack.security.enabled=<span class="literal">true</span> -E xpack.security.transport.ssl.enabled=<span class="literal">true</span> -E xpack.security.transport.ssl.verification_mode=certificate -E xpack.security.transport.ssl.keystore.path=certs/elastic-certificates.p12 -E xpack.security.http.ssl.enabled=<span class="literal">true</span> -E xpack.security.http.ssl.keystore.path=certs/elastic-certificates.p12 -E xpack.security.http.ssl.truststore.path=certs/elastic-certificates.p12</span><br></pre></td></tr></table></figure><h3 id="配置-Kibana-连接-ES-HTTPS"><a href="#配置-Kibana-连接-ES-HTTPS" class="headerlink" title="配置 Kibana 连接 ES HTTPS"></a>配置 Kibana 连接 ES HTTPS</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为kibana生成pem</span></span><br><span class="line">openssl pkcs12 -<span class="keyword">in</span> elastic-certificates.p12 -cacerts -nokeys -out elastic-ca.pem</span><br></pre></td></tr></table></figure><p><strong>config/kibana.yml</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">elasticsearch.hosts:</span> <span class="string">["https://localhost:9200"]</span></span><br><span class="line"><span class="attr">elasticsearch.ssl.certificateAuthorities:</span> <span class="string">[</span> <span class="string">"/Users/richard/demo/kibana/config/certs/elastic-ca.pem"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">elasticsearch.ssl.verificationMode:</span> <span class="string">certificate</span></span><br></pre></td></tr></table></figure><h3 id="配置使用-HTTPS-访问-Kibana"><a href="#配置使用-HTTPS-访问-Kibana" class="headerlink" title="配置使用 HTTPS 访问 Kibana"></a>配置使用 HTTPS 访问 Kibana</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为 Kibna 配置 HTTPS</span></span><br><span class="line"><span class="comment"># 在 ES 中执行</span></span><br><span class="line"><span class="comment"># 生成了一个 elastic-stac-ca.zip文件，解压，包含了 instance.crt 和 instance.key</span></span><br><span class="line">bin/elasticsearch-certutil ca --pem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将这两个文件复制到 kibana/config/certs</span></span><br></pre></td></tr></table></figure><p><strong>config/kibana.yml</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server.ssl.enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">server.ssl.certificate:</span> <span class="string">config/certs/instance.crt</span></span><br><span class="line"><span class="attr">server.ssl.key:</span> <span class="string">config/certs/instance.key</span></span><br></pre></td></tr></table></figure><blockquote><p>自签的证书会报一些错误</p></blockquote><h2 id="常见的集群部署方式"><a href="#常见的集群部署方式" class="headerlink" title="常见的集群部署方式"></a>常见的集群部署方式</h2><h3 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h3><ul><li>不同角色的节点<ul><li>Master eligible / Data / Ingest / Coordinating / Machine Learning</li></ul></li><li>在开发环境中，一个节点可承担多种角色</li><li>在生产环境中<ul><li>根据数据量，写入和查询的吞吐量，选择适合的部署方式</li><li>建议设置单一角色的节点（dedicated node）</li></ul></li></ul><h3 id="节点参数配置"><a href="#节点参数配置" class="headerlink" title="节点参数配置"></a>节点参数配置</h3><p>一个节点在默认情况下会同时扮演： master eligible，data node 和 ingest node</p><table><thead><tr><th align="center">节点类型</th><th align="center">配置参数</th><th align="center">默认值</th></tr></thead><tbody><tr><td align="center">maste eligible</td><td align="center">node.master</td><td align="center">true</td></tr><tr><td align="center">data</td><td align="center">node.data</td><td align="center">true</td></tr><tr><td align="center">ingest</td><td align="center">node.ingest</td><td align="center">true</td></tr><tr><td align="center">coordinating only</td><td align="center">无</td><td align="center">每个节点默认都是 coordinating 节点。coordinating only 设置其他类型全部为false</td></tr><tr><td align="center">machine learning</td><td align="center">node.ml</td><td align="center">true（需enablex-pack）</td></tr></tbody></table><h3 id="单一职责的节点"><a href="#单一职责的节点" class="headerlink" title="单一职责的节点"></a>单一职责的节点</h3><p>一个节点只承担一个角色</p><p><img src="/images/big-data/es-07/6.jpg" alt="6"></p><h3 id="单一角色：职责分离的好处"><a href="#单一角色：职责分离的好处" class="headerlink" title="单一角色：职责分离的好处"></a>单一角色：职责分离的好处</h3><ul><li>Dedicated master eligible nodes：负责集群状态（cluster state）的管理<ul><li>使用低配置的 CPU, RAM 和磁盘</li></ul></li><li>Dedicated data nodes：负责数据存储及处理客户端请求<ul><li>使用高配置的 CPU, RAM 和磁盘</li></ul></li><li>Dedicated ingest nodes：负责数据处理<ul><li>使用高配置的 CPU; 中等配置的 RAM; 低配置的磁盘</li></ul></li></ul><h3 id="Dedicate-Coordinating-Only-Node-Client-Node"><a href="#Dedicate-Coordinating-Only-Node-Client-Node" class="headerlink" title="Dedicate Coordinating Only Node (Client Node)"></a>Dedicate Coordinating Only Node (Client Node)</h3><ul><li>配置：将 Master，Data，Ingest 都配置成 Flase<ul><li>Medium / High CUP; Medium / High RAM; Low Disk</li></ul></li><li>生产环境中，建议为一些大的集群配置 Coordinating Only Nodes<ul><li>扮演 Load Balancers。 降低 Master 和 Data Nodes 的负载</li><li>负载搜索结果的 Gather / Reduce</li><li>有时候无法预知客户端会发生怎样的请求<ul><li>大量占用内存的结合操作，一个深度聚合可能引发 OOM</li></ul></li></ul></li></ul><h3 id="Dedicate-Master-Node"><a href="#Dedicate-Master-Node" class="headerlink" title="Dedicate Master Node"></a>Dedicate Master Node</h3><ul><li>从高可用 &amp; 避免脑裂的角色出发<ul><li>一般在生产环境中配置 3 台</li><li>一个集群只有 1 台活跃的主节点<ul><li>负载分片管理，索引创建，集群管理等操作</li></ul></li></ul></li><li>如果和数据节点或者 Coordinate 节点混合部署<ul><li>数据节点相对有比较大的内存占用</li><li>Coordinate 节点有时候可能会有开销很高的查询，导致 OOM</li><li>这些都有可能影响 Master 节点，导致集群的不稳定</li></ul></li></ul><h3 id="基本部署：增减节点，水平扩展"><a href="#基本部署：增减节点，水平扩展" class="headerlink" title="基本部署：增减节点，水平扩展"></a>基本部署：增减节点，水平扩展</h3><p>当磁盘容量无法满足需求时，可以增加数据节点；磁盘读写压力大时，增加数据节点</p><p><img src="/images/big-data/es-07/7.jpg" alt="7"></p><h3 id="水平扩展：Coordinating-Only-Node"><a href="#水平扩展：Coordinating-Only-Node" class="headerlink" title="水平扩展：Coordinating Only Node"></a>水平扩展：Coordinating Only Node</h3><p>当系统中有大量的复杂查询及聚合时候，增加 Coordinating 节点，增加查询的性能</p><p><img src="/images/big-data/es-07/8.jpg" alt="8"></p><h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p><img src="/images/big-data/es-07/9.jpg" alt="9"></p><h3 id="在集群里部署-Kibana"><a href="#在集群里部署-Kibana" class="headerlink" title="在集群里部署 Kibana"></a>在集群里部署 Kibana</h3><p><img src="/images/big-data/es-07/10.jpg" alt="10"></p><h3 id="异地多活的部署"><a href="#异地多活的部署" class="headerlink" title="异地多活的部署"></a>异地多活的部署</h3><p>集群处在三个数据中心；数据三写；GTM 分发读请求</p><p><img src="/images/big-data/es-07/11.jpg" alt="11"></p><h2 id="Hot-amp-Warm-架构与-Shard-Filtering"><a href="#Hot-amp-Warm-架构与-Shard-Filtering" class="headerlink" title="Hot &amp; Warm 架构与 Shard Filtering"></a>Hot &amp; Warm 架构与 Shard Filtering</h2><h3 id="日志类应用的部署结构"><a href="#日志类应用的部署结构" class="headerlink" title="日志类应用的部署结构"></a>日志类应用的部署结构</h3><p><img src="/images/big-data/es-07/12.jpg" alt="12"></p><h3 id="什么是-Hot-amp-Warm-Architecture"><a href="#什么是-Hot-amp-Warm-Architecture" class="headerlink" title="什么是 Hot &amp; Warm Architecture"></a>什么是 Hot &amp; Warm Architecture</h3><ul><li>Hot &amp; Warm Architecture<ul><li>数据通常不会有 Update 操作；适用于 Time based 索引数据（生命周期管理），同时数据量比较大的<br>场景</li><li>引入 Warm 节点，低配置大容量的机器存放老数据，以降低部署成本</li></ul></li><li>两类数据节点，不同的硬件配置<ul><li>Hot 节点（通常使用 SSD）：索引有不断有新文档写入。通常使用 SSD</li><li>Warm 节点（通常使用 HDD）：索引不存在新数据的写入；同时也不存在大量的数据查询</li></ul></li></ul><h3 id="Hot-Nodes"><a href="#Hot-Nodes" class="headerlink" title="Hot Nodes"></a>Hot Nodes</h3><ul><li>用于数据的写入<ul><li>Indexing 对 CPU 和 IO 都有很高的要求。所以需要使用高配置的机器</li><li>存储的性能要好。建议使用 SSD</li></ul></li></ul><p><img src="/images/big-data/es-07/13.jpg" alt="13"></p><h3 id="Warm-Nodes"><a href="#Warm-Nodes" class="headerlink" title="Warm Nodes"></a>Warm Nodes</h3><ul><li>用于保存只读的索引，比较旧的数据<ul><li>通常使用大容量的磁盘（通常是 Spinning Disks）</li></ul></li></ul><p><img src="/images/big-data/es-07/14.jpg" alt="14"></p><h3 id="配置-Hot-amp-Warm-Architecture"><a href="#配置-Hot-amp-Warm-Architecture" class="headerlink" title="配置 Hot &amp; Warm Architecture"></a>配置 Hot &amp; Warm Architecture</h3><ul><li>使用 Shard Filtering，步骤分为以下几步<ul><li>标记节点 （Tagging）</li><li>配置索引到 Hot Node</li><li>配置索引到 Warm 节点</li></ul></li></ul><h3 id="标记节点"><a href="#标记节点" class="headerlink" title="标记节点"></a>标记节点</h3><ul><li>需要通过 “node.attr” 来标记一个节点<ul><li>节点的 attribute 可以是任何的 key/value</li><li>可以通过 elasticsearch.yml 或者通过 –E 命令指定</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标记一个 Hot 节点</span></span><br><span class="line">bin/elasticsearch  -E node.name=hotnode -E cluster.name=demo -E path.data=hot_data -E node.attr.my_node_type=hot</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标记一个 warm 节点</span></span><br><span class="line">bin/elasticsearch  -E node.name=warmnode -E cluster.name=demo -E path.data=warm_data -E node.attr.my_node_type=warm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看节点</span></span><br><span class="line">GET /_cat/nodeattrs?v</span><br></pre></td></tr></table></figure><h3 id="配置-Hot-数据"><a href="#配置-Hot-数据" class="headerlink" title="配置 Hot 数据"></a>配置 Hot 数据</h3><p>创建索引时候，指定将其创建在 hot 节点上</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 配置到 Hot节点</span></span><br><span class="line">PUT logs-2019-06-27</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>:&#123;</span><br><span class="line">    <span class="attr">"number_of_shards"</span>:<span class="number">2</span>,</span><br><span class="line">    <span class="attr">"number_of_replicas"</span>:<span class="number">0</span>,</span><br><span class="line">    <span class="attr">"index.routing.allocation.require.my_node_type"</span>:<span class="string">"hot"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET _cat/shards?v</span><br></pre></td></tr></table></figure><h3 id="旧数据移动到-Warm-节点"><a href="#旧数据移动到-Warm-节点" class="headerlink" title="旧数据移动到 Warm 节点"></a>旧数据移动到 Warm 节点</h3><ul><li><code>Index.routing.allocation</code> 是一个索引级的 dynamic setting，可以通过 API 在后期进行设定<ul><li>Curator / Index Life Cycle Management Tool</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 配置到 warm 节点</span></span><br><span class="line">PUT logs-2019-06-27/_settings</span><br><span class="line">&#123;  </span><br><span class="line">  <span class="attr">"index.routing.allocation.require.my_node_type"</span>:<span class="string">"warm"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Rack-Awareness"><a href="#Rack-Awareness" class="headerlink" title="Rack Awareness"></a>Rack Awareness</h3><ul><li>ES 的节点可能分布在不同的机架<ul><li>当一个机架断电，可能会同时丢失几个节点</li><li>如果一个索引相同的主分片和副本分片，同时在这个机架上，就有可能导致数据的丢失</li><li>通过 Rack Awareness 的机制，就可以尽可能避免将同一个索引的主副分片同时分配在一个机架的节点上</li><li>一个机架断电，数据可以恢复</li></ul></li></ul><p><img src="/images/big-data/es-07/15.jpg" alt="15"></p><h3 id="标记-Rack-节点-配置集群"><a href="#标记-Rack-节点-配置集群" class="headerlink" title="标记 Rack 节点 + 配置集群"></a>标记 Rack 节点 + 配置集群</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标记一个 rack 1</span></span><br><span class="line">bin/elasticsearch  -E node.name=node1 -E cluster.name=deom -E path.data=node1_data -E node.attr.my_rack_id=rack1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标记一个 rack 2</span></span><br><span class="line">bin/elasticsearch  -E node.name=node2 -E cluster.name=demo -E path.data=node2_data -E node.attr.my_rack_id=rack2</span><br><span class="line"></span><br><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"persistent"</span>: &#123;</span><br><span class="line">    <span class="string">"cluster.routing.allocation.awareness.attributes"</span>: <span class="string">"my_rack_id"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_index1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"settings"</span>:&#123;</span><br><span class="line">    <span class="string">"number_of_shards"</span>:2,</span><br><span class="line">    <span class="string">"number_of_replicas"</span>:1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_index1/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"key"</span>:<span class="string">"value"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET _cat/shards?v</span><br><span class="line">DELETE my_index1/_doc/1</span><br></pre></td></tr></table></figure><h3 id="Fore-awareness"><a href="#Fore-awareness" class="headerlink" title="Fore awareness"></a>Fore awareness</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"cluster.routing.allocation.awareness.attributes"</span>: <span class="string">"my_rack_id"</span>,</span><br><span class="line">    <span class="attr">"cluster.routing.allocation.awareness.force.my_rack_id.values"</span>: <span class="string">"rack1,rack2"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">GET _cluster/settings</span><br><span class="line"></span><br><span class="line"><span class="comment">// 集群黄色</span></span><br><span class="line">GET _cluster/health</span><br><span class="line"></span><br><span class="line"><span class="comment">// 副本无法分配</span></span><br><span class="line">GET _cat/shards?v</span><br><span class="line"></span><br><span class="line">GET _cluster/allocation/explain?pretty</span><br></pre></td></tr></table></figure><h3 id="Shard-Filtering"><a href="#Shard-Filtering" class="headerlink" title="Shard Filtering"></a>Shard Filtering</h3><ul><li>Shard Filtering<ul><li>node.attr - 标记节点</li><li>index.routing.allocation – 分配索引到节点</li></ul></li></ul><table><thead><tr><th align="left">设置</th><th align="left">分配索引到节点，节点的属性规则</th></tr></thead><tbody><tr><td align="left"><code>Index.routing.allocation.include.{attr}</code></td><td align="left">至少包含一个值</td></tr><tr><td align="left"><code>Index.routing.allocation.exclude.{attr}</code></td><td align="left">不能包含任何一个值</td></tr><tr><td align="left"><code>Index.routing.allocation.require.{attr}</code></td><td align="left">所有值都需要包含</td></tr></tbody></table><h2 id="分片设定及管理"><a href="#分片设定及管理" class="headerlink" title="分片设定及管理"></a>分片设定及管理</h2><h3 id="单个分片"><a href="#单个分片" class="headerlink" title="单个分片"></a>单个分片</h3><ul><li>7.0 开始，新创建一个索引时，默认只有一个主分片<ul><li>单个分片，查询算分，聚合不准的问题都可以得以避免</li></ul></li><li>单个索引，单个分片时候，集群无法实现水平扩展<ul><li>即使增加新的节点，无法实现水平扩展</li></ul></li></ul><p><img src="/images/big-data/es-07/16.jpg" alt="16"></p><h3 id="两个分片"><a href="#两个分片" class="headerlink" title="两个分片"></a>两个分片</h3><p>集群增加一个节点后，Elasticsearch 会自动进行分片的移动，也叫 Shard Rebalancing</p><p><img src="/images/big-data/es-07/17.jpg" alt="17"></p><h3 id="如何设计分片数"><a href="#如何设计分片数" class="headerlink" title="如何设计分片数"></a>如何设计分片数</h3><ul><li>当分片数 &gt; 节点数时<ul><li>一旦集群中有新的数据节点加入，分片就可以自动进行分配</li><li>分片在重新分配时，系统不会有 downtime</li></ul></li><li>多分片的好处：一个索引如果分布在不同的节点，多个节点可以并行执行<ul><li>查询可以并行执行</li><li>数据写入可以分散到多个机器</li></ul></li></ul><h3 id="一些例子"><a href="#一些例子" class="headerlink" title="一些例子"></a>一些例子</h3><ul><li>案例 1<ul><li>每天 1 GB 的数据，一个索引一个主分片，一个副本分片</li><li>需保留半年的数据，接近 360 GB 的数据量</li></ul></li><li>案例 2<ul><li>5 个不同的日志，每天创建一个日志索引。每个日志索引创建 10 个主分片</li><li>保留半年的数据</li><li><code>5 * 10 * 30 * 6 = 9000</code> 个分片</li></ul></li></ul><h3 id="分片过多所带来的副作用"><a href="#分片过多所带来的副作用" class="headerlink" title="分片过多所带来的副作用"></a>分片过多所带来的副作用</h3><ul><li>Shard 是 Elasticsearch 实现集群水平扩展的最小单位</li><li>过多设置分片数会带来一些潜在的问题<ul><li>每个分片是一个 Lucene 的 索引，会使用机器的资源。过多的分片会导致额外的性能开销<ul><li>Lucene Indices / File descriptors / RAM / CPU</li><li>每次搜索的请求，需要从每个分片上获取数据</li><li>分片的 Meta 信息由 Master 节点维护。过多，会增加管理的负担。经验值，控制分片总数在 10 W 以内</li></ul></li></ul></li></ul><h3 id="如何确定主分片数"><a href="#如何确定主分片数" class="headerlink" title="如何确定主分片数"></a>如何确定主分片数</h3><ul><li>从存储的物理角度看<ul><li>日志类应用，单个分片不要大于 50 GB</li><li>搜索类应用，单个分片不要超过 20 GB</li></ul></li><li>为什么要控制分片存储大小<ul><li>提高 Update 的性能</li><li>Merge 时，减少所需的资源</li><li>丢失节点后，具备更快的恢复速度 / 便于分片在集群内 Rebalancing</li></ul></li></ul><h3 id="如何确定副本分片数"><a href="#如何确定副本分片数" class="headerlink" title="如何确定副本分片数"></a>如何确定副本分片数</h3><ul><li>副本是主分片的拷贝<ul><li>提高系统可用性：相应查询请求，防止数据丢失</li><li>需要占用和主分片一样的资源</li></ul></li><li>对性能的影响<ul><li>副本会降低数据的索引速度：有几份副本就会有几倍的 CPU 资源消耗在索引上</li><li>会减缓对主分片的查询压力，但是会消耗同样的内存资源<ul><li>如果机器资源充分，提高副本数，可以提高整体的查询 QPS</li></ul></li></ul></li></ul><h3 id="调整分片总数设定，避免分配不均衡"><a href="#调整分片总数设定，避免分配不均衡" class="headerlink" title="调整分片总数设定，避免分配不均衡"></a>调整分片总数设定，避免分配不均衡</h3><ul><li>ES 的分片策略会尽量保证节点上的分片数大致相同<ul><li>扩容的新节点没有数据，导致新索引集中在新的节点</li><li>热点数据过于集中，可能会产生新能问题</li></ul></li></ul><p><img src="/images/big-data/es-07/18.jpg" alt="18"></p><h3 id="如何对集群进行容量规划"><a href="#如何对集群进行容量规划" class="headerlink" title="如何对集群进行容量规划"></a>如何对集群进行容量规划</h3><h3 id="容量规划"><a href="#容量规划" class="headerlink" title="容量规划"></a>容量规划</h3><ul><li>一个集群总共需要多少个节点？ 一个索引需要设置几个分片？<ul><li>规划上需要保持一定的余量，当负载出现波动，节点出现丢失时，还能正常运行</li></ul></li><li>做容量规划时，一些需要考虑的因素<ul><li>机器的软硬件配置</li><li>单条文档的尺寸 / 文档的总数据量 / 索引的总数据量（Time base 数据保留的时间）/ 副本分片数</li><li>文档是如何写入的（Bulk 的尺寸）</li><li>文档的复杂度，文档是如何进行读取的（怎么样的查询和聚合）</li></ul></li></ul><h3 id="评估业务的性能需求"><a href="#评估业务的性能需求" class="headerlink" title="评估业务的性能需求"></a>评估业务的性能需求</h3><ul><li>数据吞吐及性能需求<ul><li>数据写入的吞吐量，每秒要求写入多少数据？</li><li>查询的吞吐量？</li><li>单条查询可接受的最大返回时间？</li></ul></li><li>了解你的数据<ul><li>数据的格式和数据的 Mapping</li><li>实际的查询和聚合长的是什么样的</li></ul></li></ul><h3 id="常见用例"><a href="#常见用例" class="headerlink" title="常见用例"></a>常见用例</h3><ul><li>搜索：固定大小的数据集<ul><li>搜索的数据集增长相对比较缓慢</li></ul></li><li>日志：基于时间序列的数据<ul><li>使用 ES 存放日志与性能指标。数据每天不断写入，增长速度较快</li><li>结合 Warm Node 做数据的老化处理</li></ul></li></ul><h3 id="硬件配置"><a href="#硬件配置" class="headerlink" title="硬件配置"></a>硬件配置</h3><ul><li>选择合理的硬件，<strong>数据节点尽可能使用 SSD</strong></li><li>搜索等性能要求高的场景，建议 SSD<ul><li>按照 1 ：10 的比例配置内存和硬盘</li></ul></li><li>日志类和查询并发低的场景，可以考虑使用机械硬盘存储<ul><li>按照 1：50 的比例配置内存和硬盘</li></ul></li><li>单节点数据建议控制在 2 TB 以内，最大不建议超过 5 TB<ul><li>JVM 配置机器内存的一半，JVM 内存配置不建议超过 32 G</li></ul></li></ul><h3 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a>部署方式</h3><ul><li>按需选择合理的部署方式</li><li>如果需要考虑可靠性高可用，建议部署 3 台 dedicated 的 Master 节点</li><li>如果有复杂的查询和聚合，建议设置 Coordinating 节点</li></ul><h3 id="容量规划案例-1-固定大小的数据集"><a href="#容量规划案例-1-固定大小的数据集" class="headerlink" title="容量规划案例 1: 固定大小的数据集"></a>容量规划案例 1: 固定大小的数据集</h3><ul><li>一些案例：唱片信息库 / 产品信息</li><li>一些特性<ul><li>被搜索的数据集很大，但是增长相对比较慢（不会有大量的写入）。更关心搜索和聚合的读取性能</li><li>数据的重要性与时间范围无关。关注的是搜索的相关度</li></ul></li><li>估算索引的的数据量，然后确定分片的大小<ul><li>单个分片的数据不要超过 20 GB</li><li>可以通过增加副本分片，提高查询的吞吐量</li></ul></li></ul><h3 id="拆分索引"><a href="#拆分索引" class="headerlink" title="拆分索引"></a>拆分索引</h3><ul><li>如果业务上有大量的查询是基于一个字段进行 Filter，该字段又是一个数量有限的枚举值<ul><li>例如订单所在的地区</li></ul></li><li>如果在单个索引有大量的数据，可以考虑将索引拆分成多个索引<ul><li>查询性能可以得到提高</li><li>如果要对多个索引进行查询，还是可以在查询中指定多个索引得以实现</li></ul></li><li>如果业务上有大量的查询是基于一个字段进行 Filter，该字段数值并不固定<ul><li>可以启用 Routing 功能，按照 filter 字段的值分布到集群中不同的 shard，降低查询时相关的 shard， 提高 CPU 利用率</li></ul></li></ul><h3 id="容量规划案例-2-基于时间序列的数据"><a href="#容量规划案例-2-基于时间序列的数据" class="headerlink" title="容量规划案例 2: 基于时间序列的数据"></a>容量规划案例 2: 基于时间序列的数据</h3><ul><li>相关的用案<ul><li>日志 / 指标 / 安全相关的 Events</li><li>舆情分析</li></ul></li><li>一些特性<ul><li>每条数据都有时间戳；文档基本不会被更新（日志和指标数据）</li><li>用户更多的会查询近期的数据；对旧的数据查询相对较少</li><li>对数据的写入性能要求比较高</li></ul></li></ul><h3 id="创建基于时间序列的索引"><a href="#创建基于时间序列的索引" class="headerlink" title="创建基于时间序列的索引"></a>创建基于时间序列的索引</h3><ul><li>创建 time-based 索引<ul><li>在索引的名字中增加时间信息</li><li>按照 每天 / 每周 / 每月 的方式进行划分</li></ul></li><li>带来的好处<ul><li>更加合理的组织索引，例如随着时间推移，便于对索引做的老化处理<ul><li>利用 Hot &amp; Warm Architecture</li><li>备份和删除以及删除的效率高。（ Delete By Query 执行速度慢，底层也不会立刻释放空间，而 Merge 时又很消耗资源）</li></ul></li></ul></li></ul><h3 id="写入时间序列的数据：基于-Date-Math-的方式"><a href="#写入时间序列的数据：基于-Date-Math-的方式" class="headerlink" title="写入时间序列的数据：基于 Date Math 的方式"></a>写入时间序列的数据：基于 Date Math 的方式</h3><ul><li>容易使用</li><li>如果时间发生变化，需要重新部署代码</li></ul><p><img src="/images/big-data/es-07/19.jpg" alt="19"></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// POST /&lt;logs-&#123;now/d&#125;/_search </span></span><br><span class="line">POST /%3Clogs-%7Bnow%2Fd%7D%3E/_search</span><br></pre></td></tr></table></figure><h3 id="写入时间序列的数据-–-基于-Index-Alias"><a href="#写入时间序列的数据-–-基于-Index-Alias" class="headerlink" title="写入时间序列的数据 – 基于 Index Alias"></a>写入时间序列的数据 – 基于 Index Alias</h3><ul><li>Time-based 索引<ul><li>创建索引，每天 / 每周 / 每月</li><li>在索引的名字中增加时间信息</li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">PUT logs_2019-06-27</span><br><span class="line">PUT logs_2019-06-26</span><br><span class="line"></span><br><span class="line">POST _aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"logs_2019-06-27"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"logs_write"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"remove"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"logs_2019-06-26"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"logs_write"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// POST /&lt;logs-&#123;now/d&#125;/_search</span></span><br><span class="line">POST /%3Clogs-%7Bnow%2Fd%7D%3E/_search</span><br><span class="line"></span><br><span class="line"><span class="comment">// POST /&lt;logs-&#123;now/w&#125;/_search</span></span><br><span class="line">POST /%3Clogs-%7Bnow%2Fw%7D%3E/_search</span><br></pre></td></tr></table></figure><h3 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h3><ul><li>增加 Coordinating / Ingest Node<ul><li>解决 CPU 和 内存开销的问题</li></ul></li><li>增加数据节点<ul><li>解决存储的容量的问题</li><li>为避免分片分布不均的问题，要提前监控磁盘空间，提前清理数据或增加节点（70%）</li></ul></li></ul><p><strong>小结</strong></p><ul><li>根据 ES 的使用场景，建议将搜索类和日志类的应用部署在不同的 ES 群上<ul><li>可以针对写入和读取做优化</li></ul></li><li>根据场景选择合适的部署方式</li><li>硬件配置，数据节点推荐使用 SSD<ul><li>对于日志类的应用，可以选择使用冷热架构</li></ul></li><li>索引的设计，分片的设计也至关重要<ul><li>时间序列的索引 / 单个分片的尺寸，搜索类保持在 20G 以内，日志类保持在 50G以内</li></ul></li></ul><h2 id="在私有云上管理与部署-Elasticsearch-集群"><a href="#在私有云上管理与部署-Elasticsearch-集群" class="headerlink" title="在私有云上管理与部署 Elasticsearch 集群"></a>在私有云上管理与部署 Elasticsearch 集群</h2><h3 id="管理单个集群"><a href="#管理单个集群" class="headerlink" title="管理单个集群"></a>管理单个集群</h3><ul><li>集群容量不够时，需手工增加节点<ul><li>有节点丢失时，手工修复或更换节点</li><li>确保 Rack Awareness</li></ul></li><li>集群版本升级;数据备份;滚动升级<ul><li>完全手动，管理成本高</li><li>无法统一管理，例如整合变更管理等</li></ul></li></ul><h3 id="ECE，帮助你管理多个-ES-集群"><a href="#ECE，帮助你管理多个-ES-集群" class="headerlink" title="ECE，帮助你管理多个 ES 集群"></a>ECE，帮助你管理多个 ES 集群</h3><ul><li>ECE - Elastic Cloud Enterprise<ul><li><a href="https://www.elastic.co/cn/ece" target="_blank" rel="noopener">https://www.elastic.co/cn/ece</a></li><li><a href="https://www.elastic.co/cn/downloads/enterprise" target="_blank" rel="noopener">https://www.elastic.co/cn/downloads/enterprise</a></li></ul></li><li>通过单个控制台，管理多个集群<ul><li>支持不同方式的集群部署（支持各类部署）/ 跨数据中心 / 部署 Anti Affinity</li><li>统一监控所有集群的状态</li><li>图形化操作<ul><li>增加删除节点</li><li>升级集群 / 滚动更新 / 自动数据备份</li></ul></li></ul></li></ul><h3 id="基于-Kubernetes-的方案"><a href="#基于-Kubernetes-的方案" class="headerlink" title="基于 Kubernetes 的方案"></a>基于 Kubernetes 的方案</h3><ul><li>基于容器技术，使用 Operator 模式进行编排管理</li><li>配置，管理监控多个集群</li><li>支持 Hot &amp; Warm</li><li>数据快照和恢复</li><li><a href="https://www.elastic.co/cn/downloads/elastic-cloud-kubernetes" target="_blank" rel="noopener">https://www.elastic.co/cn/downloads/elastic-cloud-kubernetes</a></li></ul><h3 id="构建自己的管理系统"><a href="#构建自己的管理系统" class="headerlink" title="构建自己的管理系统"></a>构建自己的管理系统</h3><ul><li>基于虚拟机的编排管理方式<ul><li>Puppet Infrastructure (Puppet / Elasticsearch Puppet Module/ Foreman)</li><li>Workflow based Provision &amp; Management</li></ul></li><li>基于 Kubernetes 的容器化编排管理方式<ul><li>基于 Operator 模式</li><li>Kubernetes - CRD (Customer Resource Definition)</li></ul></li></ul><h3 id="将-Elasticsearch-部署在-Kubernetes"><a href="#将-Elasticsearch-部署在-Kubernetes" class="headerlink" title="将 Elasticsearch 部署在 Kubernetes"></a>将 Elasticsearch 部署在 Kubernetes</h3><p><img src="/images/big-data/es-07/23.jpg" alt="23"></p><h3 id="什么是-Kubernetes-Operator-模式"><a href="#什么是-Kubernetes-Operator-模式" class="headerlink" title="什么是 Kubernetes Operator 模式"></a>什么是 Kubernetes Operator 模式</h3><p><img src="/images/big-data/es-07/24.jpg" alt="24"></p><blockquote><p><a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener">https://github.com/operator-framework/operator-sdk</a></p></blockquote><p><strong>相关阅读</strong></p><ul><li><a href="https://www.elastic.co/cn/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond?elektra=products&amp;storm=sub1" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond?elektra=products&amp;storm=sub1</a></li><li><a href="https://www.elastic.co/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond" target="_blank" rel="noopener">https://www.elastic.co/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond</a></li><li><a href="https://github.com/operator-framework" target="_blank" rel="noopener">https://github.com/operator-framework</a></li><li><a href="https://github.com/upmc-enterprises/elasticsearch-operator" target="_blank" rel="noopener">https://github.com/upmc-enterprises/elasticsearch-operator</a></li></ul><h2 id="在公有云上管理与部署-Elasticsearch-集群"><a href="#在公有云上管理与部署-Elasticsearch-集群" class="headerlink" title="在公有云上管理与部署 Elasticsearch 集群"></a>在公有云上管理与部署 Elasticsearch 集群</h2><ul><li>Elastic Cloud<ul><li><a href="https://www.elastic.co/cn/cloud/" target="_blank" rel="noopener">https://www.elastic.co/cn/cloud/</a></li></ul></li><li>阿里云<ul><li><a href="https://www.aliyun.com/product/bigdata/product/elasticsearch" target="_blank" rel="noopener">https://www.aliyun.com/product/bigdata/product/elasticsearch</a></li></ul></li><li>腾讯云<ul><li><a href="https://cloud.tencent.com/product/es" target="_blank" rel="noopener">https://cloud.tencent.com/product/es</a></li></ul></li></ul><p><strong>相关阅读</strong></p><ul><li><a href="https://data.aliyun.com/product/elasticsearch" target="_blank" rel="noopener">https://data.aliyun.com/product/elasticsearch</a></li><li><a href="https://www.elastic.co/cn/blog/elasticsearch-service-on-elastic-cloud-introduces-new-pricing-with-reduced-costs" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/elasticsearch-service-on-elastic-cloud-introduces-new-pricing-with-reduced-costs</a></li></ul><h2 id="生产环境常用配置和上线清单"><a href="#生产环境常用配置和上线清单" class="headerlink" title="生产环境常用配置和上线清单"></a>生产环境常用配置和上线清单</h2><h3 id="Development-vs-Production-Mode"><a href="#Development-vs-Production-Mode" class="headerlink" title="Development vs. Production Mode"></a>Development vs. Production Mode</h3><ul><li>从 ES 5 开始，支持 Development 和 Production 两种运行模式<ul><li>开发模式</li><li>生产模式</li></ul></li><li>ES 会检测是否是 loopback，来判定是什么模式</li></ul><p><img src="/images/big-data/es-07/20.jpg" alt="20"></p><h3 id="Bootstrap-Checks"><a href="#Bootstrap-Checks" class="headerlink" title="Bootstrap Checks"></a>Bootstrap Checks</h3><ul><li>一个集群在 Production Mode 时，启动时必须通过所有 Bootstrap 检测，否则会启动失败</li><li>Bootstrap Checks 可以分为两类：JVM &amp; Linux Checks。Linux Checks 只针对 Linux 系统</li></ul><p><img src="/images/big-data/es-07/21.jpg" alt="21"></p><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/bootstrap-checks.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/master/bootstrap-checks.html</a></p></blockquote><h3 id="JVM-设定"><a href="#JVM-设定" class="headerlink" title="JVM 设定"></a>JVM 设定</h3><ul><li>从 ES 6 开始， 只支持 64 位 的JVM<ul><li>配置 <code>config/vm.options</code></li></ul></li><li>避免修改默认配置<ul><li>将内存 Xms 和 Xmx 设置成一样，避免 heap resize 时引发停顿</li><li>Xmx 设置不要超过物理内存的 50%；单个节点上，最大内存建议不要超过 32G 内存<ul><li><a href="https://www.elastic.co/cn/blog/a-heap-of-trouble" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/a-heap-of-trouble</a></li></ul></li><li>生产环境，JVM 必须使用 Server 模式</li><li>关闭 JVM Swapping</li></ul></li></ul><h3 id="集群的-API-设定"><a href="#集群的-API-设定" class="headerlink" title="集群的 API 设定"></a>集群的 API 设定</h3><ul><li>静态设置和动态设定<ul><li>静态配置文件尽量简洁：按照文档设置所有相关系统参数。elasticsearch.yml 配置文件 中尽量只写必备参数</li></ul></li><li>其他的设置项可以通过 API 动态进行设定。 动态设定分 transient 和 persistent 两种， 都会覆盖 elasticsearch.yaml 中的设置<ul><li>Transient 在集群重启后会丢失</li><li>Persistent 在集群中重启后不会丢失</li></ul></li></ul><p><img src="/images/big-data/es-07/22.jpg" alt="22"></p><h3 id="系统设置"><a href="#系统设置" class="headerlink" title="系统设置"></a>系统设置</h3><ul><li>参照文档 “Setup Elasticsearch&gt; Important System Configuration”<ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/system-config.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/system-config.html</a> </li><li>Disable Swapping, Increase file descriptor, 虚拟内存, number of thread</li></ul></li></ul><h3 id="最佳实践：网络"><a href="#最佳实践：网络" class="headerlink" title="最佳实践：网络"></a>最佳实践：网络</h3><ul><li>单个集群不要跨数据中心进行部署（不要使用 WAN）</li><li>节点之间的 hops 越少越好</li><li>如果有多块网卡，最好将 transport 和 http 绑定到不同的网卡，并设置不同的防火墙 Rules</li><li>按需为 Coordinating Node 或 Ingest Node 配置负载均衡</li></ul><h3 id="最佳实践：内存设定计算实例"><a href="#最佳实践：内存设定计算实例" class="headerlink" title="最佳实践：内存设定计算实例"></a>最佳实践：内存设定计算实例</h3><ul><li>内存大小要根据 Node 需要存储的数据来进行估算<ul><li>搜索类的比例建议：1:16</li><li>日志类：1:48 - 1:96 之间</li></ul></li><li>总数据量 1 T， 设置一个副本 = 2T 总数据量<ul><li>如果搜索类的项目，每个节点 31*16 = 496 G，加上预留空间。所以每个节点最多 400G 数据，至少需要 5 个数据节点</li><li>如果是日志类项目，每个节点 31*50 = 1550 GB，2 个数据节点即可</li></ul></li></ul><h3 id="最佳实践：存储"><a href="#最佳实践：存储" class="headerlink" title="最佳实践：存储"></a>最佳实践：存储</h3><ul><li>推荐使用 SSD，使用本地存储（Local Disk）。避免使用 SAN NFS / AWS / Azure filesystem</li><li>可以在本地指定多个 “path.data”，以支持使用多块磁盘</li><li>ES 本身提供了很好的 HA 机制；无需使用 RAID 1/5/10</li><li>可以在 Warm 节点上使用 Spinning Disk，但是需要关闭 Concurrent Merges<ul><li><code>Index.merge.scheduler.max_thread_count: 1</code></li></ul></li><li>Trim 你的 SSD<ul><li><a href="https://www.elastic.co/cn/blog/is-your-elasticsearch-trimmed" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/is-your-elasticsearch-trimmed</a></li></ul></li></ul><h3 id="最佳实践：服务器硬件"><a href="#最佳实践：服务器硬件" class="headerlink" title="最佳实践：服务器硬件"></a>最佳实践：服务器硬件</h3><ul><li>建议使用中等配置的机器，不建议使用过于强劲的硬件配置<ul><li>Medium machine over large machine</li></ul></li><li>不建议在一台服务器上运行多个节点</li></ul><h3 id="集群设置：Throttles-限流"><a href="#集群设置：Throttles-限流" class="headerlink" title="集群设置：Throttles 限流"></a>集群设置：Throttles 限流</h3><ul><li>为 Relocation 和 Recovery 设置限流，避免过多任务对集群产生性能影响</li><li>Recovery<ul><li><code>Cluster.routing.allocation.node_concurrent_recoveries: 2</code></li></ul></li><li>Relocation<ul><li><code>Cluster.routing.allocation.cluster_concurrent_rebalance: 2</code></li></ul></li></ul><h3 id="集群设置：关闭-Dynamic-Indexes"><a href="#集群设置：关闭-Dynamic-Indexes" class="headerlink" title="集群设置：关闭 Dynamic Indexes"></a>集群设置：关闭 Dynamic Indexes</h3><ul><li>可以考虑关闭动态索引创建的功能</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"action.auto_create_index"</span>:<span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>或者通过模版设置白名单</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"action.auto_create_index"</span>:<span class="string">"logstash-*,.kibana*"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="集群安全设定"><a href="#集群安全设定" class="headerlink" title="集群安全设定"></a>集群安全设定</h3><ul><li>为 Elasticsearch 和 Kibana 配置安全功能<ul><li>打开 Authentication &amp; Authorization</li><li>实现索引和和字段级的安全控制</li></ul></li><li>节点间通信加密</li><li>Enable HTTPS</li><li>Audit logs</li></ul><h2 id="监控-Elasticsearch-集群"><a href="#监控-Elasticsearch-集群" class="headerlink" title="监控 Elasticsearch 集群"></a>监控 Elasticsearch 集群</h2><h3 id="Elasticsearch-Stats-相关的-API"><a href="#Elasticsearch-Stats-相关的-API" class="headerlink" title="Elasticsearch Stats 相关的 API"></a>Elasticsearch Stats 相关的 API</h3><ul><li>Elasticsearch 提供了多个监控相关的 API<ul><li>Node Stats： _nodes/stats</li><li>Cluster Stats: _cluster/stats</li><li>Index Stats: index_name/_stats</li></ul></li></ul><h3 id="Elasticsearch-Task-API"><a href="#Elasticsearch-Task-API" class="headerlink" title="Elasticsearch Task API"></a>Elasticsearch Task API</h3><ul><li>查看 Task 相关的 API<ul><li>Pending Cluster Tasks API：GET _cluster/pending_tasks</li><li>Task Management API：GET _tasks (可以用来 Cancel 一个 Task)</li></ul></li><li>监控 Thread Pools<ul><li>GET _nodes/thread_pool</li><li>GET _nodes/stats/thread_pool</li><li>GET _cat/thread_pool?v</li><li>GET _nodes/hot_threads</li></ul></li></ul><h3 id="The-Index-amp-Query-Slow-Log"><a href="#The-Index-amp-Query-Slow-Log" class="headerlink" title="The Index &amp; Query Slow Log"></a>The Index &amp; Query Slow Log</h3><ul><li>支持将分片上，Search 和 Fetch 阶段的慢查询写入文件</li><li>支持为 Query 和 Fetch 分别定义阈值</li><li>索引级的动态设置，可以按需设置，或者通过 Index Template 统一设定</li><li>Slog log 文件通过 log4j2.properties 配置</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置 Index Slowlogs</span></span><br><span class="line"><span class="comment">// the first 1000 characters of the doc's source will be logged</span></span><br><span class="line">PUT my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"index.indexing.slowlog"</span>:&#123;</span><br><span class="line">    <span class="attr">"threshold.index"</span>:&#123;</span><br><span class="line">      <span class="attr">"warn"</span>:<span class="string">"10s"</span>,</span><br><span class="line">      <span class="attr">"info"</span>: <span class="string">"4s"</span>,</span><br><span class="line">      <span class="attr">"debug"</span>:<span class="string">"2s"</span>,</span><br><span class="line">      <span class="attr">"trace"</span>:<span class="string">"0s"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"level"</span>:<span class="string">"trace"</span>,</span><br><span class="line">    <span class="attr">"source"</span>:<span class="number">1000</span>  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置查询</span></span><br><span class="line">DELETE my_index</span><br><span class="line"><span class="comment">//"0" logs all queries</span></span><br><span class="line">PUT my_index/</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.search.slowlog.threshold"</span>: &#123;</span><br><span class="line">      <span class="attr">"query.warn"</span>: <span class="string">"10s"</span>,</span><br><span class="line">      <span class="attr">"query.info"</span>: <span class="string">"3s"</span>,</span><br><span class="line">      <span class="attr">"query.debug"</span>: <span class="string">"2s"</span>,</span><br><span class="line">      <span class="attr">"query.trace"</span>: <span class="string">"0s"</span>,</span><br><span class="line">      <span class="attr">"fetch.warn"</span>: <span class="string">"1s"</span>,</span><br><span class="line">      <span class="attr">"fetch.info"</span>: <span class="string">"600ms"</span>,</span><br><span class="line">      <span class="attr">"fetch.debug"</span>: <span class="string">"400ms"</span>,</span><br><span class="line">      <span class="attr">"fetch.trace"</span>: <span class="string">"0s"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET my_index</span><br></pre></td></tr></table></figure><h3 id="如何创建监控-Dashboard"><a href="#如何创建监控-Dashboard" class="headerlink" title="如何创建监控 Dashboard"></a>如何创建监控 Dashboard</h3><ul><li>开发 Elasticsearch plugin，通过读取相关的监控 API，将数据发送到 ES，或者 TSDB</li><li>使用 Metricbeats 搜集相关指标</li><li>使用 Kibana 或 Grafana 创建 Dashboard</li><li>可以开发 Elasticsearch Exporter，通过 Prometheus 监控 Elasticsearch 集群</li></ul><h2 id="诊断集群的潜在问题"><a href="#诊断集群的潜在问题" class="headerlink" title="诊断集群的潜在问题"></a>诊断集群的潜在问题</h2><h3 id="集群运维所面临的挑战"><a href="#集群运维所面临的挑战" class="headerlink" title="集群运维所面临的挑战"></a>集群运维所面临的挑战</h3><ul><li>用户集群数量多，业务场景差异大</li><li>使用与配置不当，优化不够<ul><li>如何让用户更加高效和正确的使用 ES</li><li>如何让用户更全面的了解自己的集群的使用状况</li></ul></li><li>发现问题滞后，需要防患于未然<ul><li>需要 “有迹可循”，做到 “有则改之，无则加勉”</li><li>Elastic 有提供 <a href="https://github.com/elastic/support-diagnostics" target="_blank" rel="noopener">Support Diagnostics Tool</a></li></ul></li></ul><h3 id="集群绿色，是否意味着足够好"><a href="#集群绿色，是否意味着足够好" class="headerlink" title="集群绿色，是否意味着足够好"></a>集群绿色，是否意味着足够好</h3><ul><li>绿色只是其中一项指标。显示分片是否都已正常分配</li><li>监控指标多并且分散<ul><li>指标的含义不够明确直观</li></ul></li><li>问题分析定位的门槛较高<ul><li>需要具备专业知识</li></ul></li></ul><h3 id="为什么要诊断集群的潜在问题"><a href="#为什么要诊断集群的潜在问题" class="headerlink" title="为什么要诊断集群的潜在问题"></a>为什么要诊断集群的潜在问题</h3><ul><li>防患于未然，避免集群奔溃<ul><li>Master 节点 / 数据节点当机 – 负载过高，导致节点失联</li><li>副本丢失，导致数据可靠性受损</li><li>集群压力过大，数据写入失败</li></ul></li><li>提升集群性能<ul><li>数据节点负载不均衡（避免单节点瓶颈） / 优化分片，segment</li><li>规范操作方式（利用别名 / 避免 Dynamic Mapping 引发过多字段，对索引的合理性进行管控）</li></ul></li></ul><h3 id="eBay-Diagnostic-Tool"><a href="#eBay-Diagnostic-Tool" class="headerlink" title="eBay Diagnostic Tool"></a>eBay Diagnostic Tool</h3><ul><li>集群健康状态，是否有节点丢失</li><li>索引合理性<ul><li>索引总数不能过大 / 副本分片尽量不要设置为 0 / 主分片尺 寸检测 / 索引的字段总数（Dynamic Mapping 关闭）/ 索引是 否分配不均衡 / 索引 segment 大小诊断分析</li></ul></li><li>资源使用合理性<ul><li>CPU 内存和 磁盘的使用状况分析 / 是否存在节点负载不平衡 / 是否需要增加节点</li></ul></li><li>业务操作合理性<ul><li>集群状态变更频率，是否在业务高峰期有频繁操作</li><li>慢查询监控与分析</li></ul></li></ul><h4 id="集群中索引的诊断"><a href="#集群中索引的诊断" class="headerlink" title="集群中索引的诊断"></a>集群中索引的诊断</h4><ul><li>索引的总数是否过大</li><li>是否存在字段过多的情况</li><li>索引的分片个数是否设置合理</li><li>单个节点的分片数是否过多</li><li>数据节点之间的负载偏差是否过大</li><li>冷热数据分配是否正确（例如，Cold 节点 上的索引是否设置成只读）</li></ul><h3 id="阿里云-EYOU-智能运维工具"><a href="#阿里云-EYOU-智能运维工具" class="headerlink" title="阿里云 - EYOU 智能运维工具"></a>阿里云 - EYOU 智能运维工具</h3><ul><li>每天凌晨定时诊断，也可以自主诊断。每次诊断耗时 3 分钟</li><li><a href="https://help.aliyun.com/document_detail/90391.html" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/90391.html</a></li></ul><p><img src="/images/big-data/es-07/25.jpg" alt="25"></p><p><strong>诊断 Shard 数</strong></p><p><img src="/images/big-data/es-07/26.jpg" alt="26"></p><p><strong>磁盘容量估算</strong></p><p><img src="/images/big-data/es-07/27.jpg" alt="27"></p><h3 id="多维度检查，构建自己的诊断工具"><a href="#多维度检查，构建自己的诊断工具" class="headerlink" title="多维度检查，构建自己的诊断工具"></a>多维度检查，构建自己的诊断工具</h3><p><img src="/images/big-data/es-07/28.jpg" alt="28"></p><p><strong>相关阅读</strong></p><ul><li><a href="https://elasticsearch.cn/slides/162" target="_blank" rel="noopener">https://elasticsearch.cn/slides/162</a></li><li><a href="https://yq.aliyun.com/articles/657712" target="_blank" rel="noopener">https://yq.aliyun.com/articles/657712</a></li><li><a href="https://yq.aliyun.com/articles/657108" target="_blank" rel="noopener">https://yq.aliyun.com/articles/657108</a></li><li><a href="https://help.aliyun.com/document_detail/90391.html" target="_blank" rel="noopener">https://help.aliyun.com/document_detail/90391.html</a></li></ul><h2 id="解决集群-Yellow-与-Red-的问题"><a href="#解决集群-Yellow-与-Red-的问题" class="headerlink" title="解决集群 Yellow 与 Red 的问题"></a>解决集群 Yellow 与 Red 的问题</h2><h3 id="集群健康度"><a href="#集群健康度" class="headerlink" title="集群健康度"></a>集群健康度</h3><ul><li>分片健康<ul><li>红：至少有一个主分片没有分配</li><li>黄：至少有一个副本没有分配</li><li>绿：主副本分片全部正常分配</li></ul></li><li>索引健康：最差的分片的状态</li><li>集群健康：最差的索引的状态</li></ul><h3 id="Health-相关的-API"><a href="#Health-相关的-API" class="headerlink" title="Health 相关的 API"></a>Health 相关的 API</h3><table><thead><tr><th align="left"></th><th align="left"></th></tr></thead><tbody><tr><td align="left">GET _cluster/health</td><td align="left">集群的状态（检查 节点数量）</td></tr><tr><td align="left">GET _cluster/health?level=indices</td><td align="left">所有索引的健康状态 （查看有问题的索引)</td></tr><tr><td align="left">GET _cluster/health/my_index</td><td align="left">单个索引的健康状态（查看具体的索引）</td></tr><tr><td align="left">GET _cluster/health?level=shards</td><td align="left">分片级的索引</td></tr><tr><td align="left">GET _cluster/allocation/explain</td><td align="left">返回第一个未分配 Shard 的原因</td></tr></tbody></table><p><img src="/images/big-data/es-07/29.jpg" alt="29"></p><h3 id="案例-1"><a href="#案例-1" class="headerlink" title="案例 1"></a>案例 1</h3><ul><li>症状：集群变红</li><li>分析：通过 Allocation Explain API 发现 创建索引失败，因为无法找到标记了相应 box type<br>的节点</li><li>解决：删除索引，集群变绿。重新创建索引，并且指定正确的 routing box type，索引创建成<br>功。集群保持绿色状态</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">PUT mytest</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>:&#123;</span><br><span class="line">    <span class="attr">"number_of_shards"</span>:<span class="number">3</span>,</span><br><span class="line">    <span class="attr">"number_of_replicas"</span>:<span class="number">0</span>,</span><br><span class="line">    <span class="attr">"index.routing.allocation.require.box_type"</span>:<span class="string">"hott"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 检查集群状态，查看是否有节点丢失，有多少分片无法分配</span></span><br><span class="line">GET /_cluster/health/</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看索引级别,找到红色的索引</span></span><br><span class="line">GET /_cluster/health?level=indices</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看索引的分片</span></span><br><span class="line">GET _cluster/health?level=shards</span><br><span class="line"></span><br><span class="line"><span class="comment">// Explain 变红的原因</span></span><br><span class="line">GET /_cluster/allocation/explain</span><br><span class="line"><span class="comment">//return </span></span><br><span class="line">"deciders" : [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"decider"</span> : <span class="string">"filter"</span>,</span><br><span class="line">          <span class="attr">"decision"</span> : <span class="string">"NO"</span>,</span><br><span class="line">          <span class="attr">"explanation"</span> : <span class="string">""</span><span class="string">"node does not match index setting [index.routing.allocation.require] filters [box_type:"</span>hott<span class="string">"]"</span><span class="string">""</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line"></span><br><span class="line">GET /_cat/shards/mytest</span><br><span class="line"></span><br><span class="line">GET _cat/nodeattrs</span><br><span class="line"></span><br><span class="line">DELETE mytest</span><br><span class="line"><span class="comment">// 查看集群 集群变绿</span></span><br><span class="line">GET /_cluster/health/</span><br><span class="line"></span><br><span class="line">PUT mytest</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>:&#123;</span><br><span class="line">    <span class="attr">"number_of_shards"</span>:<span class="number">3</span>,</span><br><span class="line">    <span class="attr">"number_of_replicas"</span>:<span class="number">0</span>,</span><br><span class="line">    <span class="attr">"index.routing.allocation.require.box_type"</span>:<span class="string">"hot"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="案例-2"><a href="#案例-2" class="headerlink" title="案例 2"></a>案例 2</h3><ul><li>症状：集群变黄</li><li>分析：通过 Allocation Explain API 发现无法在相同的节点上创建副本</li><li>解决：将索引的副本数设置为 0，或者通过增加节点解决</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">PUT mytest</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"settings"</span>:&#123;</span><br><span class="line">  <span class="attr">"number_of_shards"</span>:<span class="number">2</span>,</span><br><span class="line">  <span class="attr">"number_of_replicas"</span>:<span class="number">1</span>,</span><br><span class="line">  <span class="attr">"index.routing.allocation.require.box_type"</span>:<span class="string">"hot"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">GET _cluster/health</span><br><span class="line">GET _cat/shards/mytest</span><br><span class="line">GET /_cluster/allocation/explain</span><br><span class="line">PUT mytest/_settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"number_of_replicas"</span>: <span class="number">0</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="分片没有被分配的一些原因"><a href="#分片没有被分配的一些原因" class="headerlink" title="分片没有被分配的一些原因"></a>分片没有被分配的一些原因</h3><ul><li>INDEX_CREATE: 创建索引导致。在索引的全部分片分配完成之前，会有短暂的 Red，不一定代表有问题</li><li>CLUSTER_RECOVER：集群重启阶段，会有这个问题</li><li>INDEX_REOPEN：Open 一个之前 Close 的索引</li><li>DANGLING_INDEX_IMPORTED：一个节点离开集群期间，有索引被删除。这个节点重新返回时，会导致 Dangling 的问题</li></ul><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cat-shards.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cat-shards.html</a></p></blockquote><h3 id="常见问题与解决方法"><a href="#常见问题与解决方法" class="headerlink" title="常见问题与解决方法"></a>常见问题与解决方法</h3><ul><li>集群变红，需要检查是否有节点离线。如果有，通常通过重启离线的节点可以解决问题</li><li>由于配置导致的问题，需要修复相关的配置（例如错误的 box_type，错误的副本数）<ul><li>如果是测试的索引，可以直接删除</li></ul></li><li>因为磁盘空间限制，分片规则（Shard Filtering）引发的，需要调整规则或者增加节点</li><li>对于节点返回集群，导致的 dangling 变红，可直接删除 dangling 索引</li></ul><h3 id="集群-Red-amp-Yellow-问题的总结"><a href="#集群-Red-amp-Yellow-问题的总结" class="headerlink" title="集群 Red &amp; Yellow 问题的总结"></a>集群 Red &amp; Yellow 问题的总结</h3><ul><li>Red &amp; Yellow 是集群运维中常见的问题</li><li>除了集群故障，一些创建，增加副本等操作，都会导致集群短暂的 Red 和 Yellow，所以监控和报警时需要设置一定的延时</li><li>通过检查节点数，使用 ES 提供的相关 API，找到真正的原因</li><li>可以指定 Move 或者 Reallocate 分片</li></ul><p><img src="/images/big-data/es-07/30.jpg" alt="30"></p><h2 id="提升集群写性能"><a href="#提升集群写性能" class="headerlink" title="提升集群写性能"></a>提升集群写性能</h2><h3 id="提高写入性能的方法"><a href="#提高写入性能的方法" class="headerlink" title="提高写入性能的方法"></a>提高写入性能的方法</h3><ul><li>写性能优化的目标：增大写吞吐量（Events Per Second），越高越好</li><li>客户端：多线程，批量写<ul><li>可以通过性能测试，确定最佳文档数量</li><li>多线程：需要观察是否有 HTTP 429 返回，实现 Retry 以及线程数量的自动调节</li></ul></li><li>服务器端：单个性能问题，往往是多个因素造成的。需要先分解问题，在单个节点上进行调整并 且结合测试，尽可能压榨硬件资源，以达到最高吞吐量<ul><li>使用更好的硬件。观察 CPU / IO Block</li><li>线程切换 / 堆栈状况</li></ul></li></ul><h3 id="服务器端优化写入性能的一些手段"><a href="#服务器端优化写入性能的一些手段" class="headerlink" title="服务器端优化写入性能的一些手段"></a>服务器端优化写入性能的一些手段</h3><ul><li>降低 IO 操作<ul><li>使用 ES 自动生成的文档 Id / 一些相关的 ES 配置，如 Refresh Interval</li></ul></li><li>降低 CPU 和存储开销<ul><li>减少不必要分词 / 避免不需要的 doc_values / 文档的字段尽量保证相同的顺序，可以提高文档的压缩率</li></ul></li><li>尽可能做到写入和分片的均衡负载，实现水平扩展<ul><li>Shard Filtering / Write Load Balancer</li></ul></li><li>调整 Bulk 线程池和队列</li></ul><h3 id="优化写入性能"><a href="#优化写入性能" class="headerlink" title="优化写入性能"></a>优化写入性能</h3><ul><li>ES 的默认设置，已经综合考虑了数据可靠性，搜索的实时性质，写入速度，一般不要盲目修改</li><li>一切优化，都要基于<strong>高质量的数据建模</strong></li></ul><h3 id="关闭无关的功能"><a href="#关闭无关的功能" class="headerlink" title="关闭无关的功能"></a>关闭无关的功能</h3><ul><li>只需要聚合不需要搜索，Index 设置成 false</li><li>不需要算分， Norms 设置成 false</li><li>不要对字符串使用默认的 dynamic mapping。字段 数量过多，会对性能产生比较大的影响</li><li>Index_options 控制在创建倒排索引时，哪些内容会被添加到倒排索引中。优化这些设置，一定程度 可以节约 CPU</li><li>关闭 _source，减少 IO 操作；（适合指标型数据）</li></ul><p><img src="/images/big-data/es-07/31.jpg" alt="31"></p><h3 id="针对性能的取舍"><a href="#针对性能的取舍" class="headerlink" title="针对性能的取舍"></a>针对性能的取舍</h3><ul><li>如果需要追求极致的写入速度，可以牺牲数据可靠性及搜索实时性以换取性能<ul><li>牺牲可靠性：将副本分片设置为 0，写入完毕再调整回去</li><li>牺牲搜索实时性：增加 Refresh Interval 的时间</li><li>牺牲可靠性：修改 Translog 的配置</li></ul></li></ul><h3 id="数据写入的过程"><a href="#数据写入的过程" class="headerlink" title="数据写入的过程"></a>数据写入的过程</h3><ul><li>Refresh<ul><li>将文档先保存在 Index buffer 中， <strong>以 refresh_interval 为间隔时间</strong>，定期清空 buffer，生成 segment，借助文件系统缓存的特性，先将 segment 放在文件系统缓存中，并开放查询，以提升搜索的实时性</li></ul></li><li>Translog<ul><li>Segment 没有写入磁盘，即便发生了当机，重启后，数据也能恢复，<strong>默认配置是每次请求都会落盘</strong></li></ul></li><li>Flush<ul><li>删除旧的 translog 文件</li><li>生成 Segment 并写入磁盘 / 更新 commit point 并写入磁盘。<strong>ES 自动完成，可优化点不多</strong></li></ul></li></ul><h3 id="Refresh-Interval"><a href="#Refresh-Interval" class="headerlink" title="Refresh Interval"></a>Refresh Interval</h3><ul><li>降低 Refresh 的频率<ul><li>增加 refresh_interval 的数值。默认为 1s ，如果设置成 -1 ，会禁止自动 refresh<ul><li>避免过于频繁的 refresh，而生成过多的 segment 文件</li><li>但是会降低搜索的实时性</li></ul></li><li>增大静态配置参数 <code>indices.memory.index_buffer_size</code><ul><li>默认是 10%， 会导致自动触发 refresh</li></ul></li></ul></li></ul><h3 id="Translog"><a href="#Translog" class="headerlink" title="Translog"></a>Translog</h3><ul><li>降低写磁盘的频率，但是会降低容灾能力<ul><li><code>Index.translog.durability</code>：默认是 request，每个请求都落盘。设置成 async，异步写入</li><li><code>Index.translog.sync_interval</code> 设置为 60s，每分钟执行一次</li><li><code>Index.translog.flush_threshod_size</code>: 默认 512 mb，可以适当调大。当 translog 超过该值，会触发 flush</li></ul></li></ul><h3 id="分片设定"><a href="#分片设定" class="headerlink" title="分片设定"></a>分片设定</h3><ul><li>副本在写入时设为 0，完成后再增加</li><li>合理设置主分片数，确保均匀分配在所有数据节点上<ul><li><code>Index.routing.allocation.total_share_per_node</code>: 限定每个索引在每个节点上可分配的分片数（replicas and primaries）</li><li>5 个节点的集群。 索引有 5 个主分片，1 个副本，应该如何设置？<ul><li>(5+5) / 5 = 2</li><li>生产环境中要适当调大这个数字，避免有节点下线时，分片无法正常迁移</li></ul></li></ul></li></ul><h3 id="Bulk，线程池和队列大小"><a href="#Bulk，线程池和队列大小" class="headerlink" title="Bulk，线程池和队列大小"></a>Bulk，线程池和队列大小</h3><ul><li>客户端<ul><li>单个 bulk 请求体的数据量不要太大，官方建议大约 5-15mb</li><li>写入端的 bulk 请求超时需要足够长，建议 60s 以上</li><li>写入端尽量将数据轮询打到不同节点。</li></ul></li><li>服务器端<ul><li>索引创建属于计算密集型任务，应该使用固定大小的线程池来配置。来不及处理的放入队列，线程数应该 配置成 CPU 核心数 +1 ，避免过多的上下文切换</li><li>队列大小可以适当增加，不要过大，否则占用的内存会成为 GC 的负担</li></ul></li></ul><h3 id="一个索引设定的例子"><a href="#一个索引设定的例子" class="headerlink" title="一个索引设定的例子"></a>一个索引设定的例子</h3><p><img src="/images/big-data/es-07/32.jpg" alt="32"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">DELETE myindex</span><br><span class="line">PUT myindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: &#123;</span><br><span class="line">      <span class="attr">"refresh_interval"</span>: <span class="string">"30s"</span>,</span><br><span class="line">      <span class="attr">"number_of_shards"</span>: <span class="string">"2"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"routing"</span>: &#123;</span><br><span class="line">      <span class="attr">"allocation"</span>: &#123;</span><br><span class="line">        <span class="attr">"total_shards_per_node"</span>: <span class="string">"3"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"translog"</span>: &#123;</span><br><span class="line">      <span class="attr">"sync_interval"</span>: <span class="string">"30s"</span>,</span><br><span class="line">      <span class="attr">"durability"</span>: <span class="string">"async"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"number_of_replicas"</span>: <span class="number">0</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"dynamic"</span>: <span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="提升集群读性能"><a href="#提升集群读性能" class="headerlink" title="提升集群读性能"></a>提升集群读性能</h2><h3 id="尽量-Denormalize-数据"><a href="#尽量-Denormalize-数据" class="headerlink" title="尽量 Denormalize 数据"></a>尽量 Denormalize 数据</h3><ul><li>Elasticsearch != 关系型数据库</li><li>尽可能 Denormalize 数据，从而获取最佳的性能<ul><li>使用 Nested 类型的数据。查询速度会慢几倍</li><li>使用 Parent / Child 关系。查询速度会慢几百倍</li></ul></li></ul><h3 id="数据建模"><a href="#数据建模" class="headerlink" title="数据建模"></a>数据建模</h3><ul><li>尽量将数据先行计算，然后保存到 Elasticsearch 中。尽量避免查询时的 Script 计算</li><li>尽量使用 Filter Context，利用缓存机制，减少不必要的算分</li><li>结合 profile，explain API 分析慢查询的问题，持续优化数据模型<ul><li>严禁使用 * 开头通配符 Terms 查询</li></ul></li></ul><h3 id="避免查询时脚本"><a href="#避免查询时脚本" class="headerlink" title="避免查询时脚本"></a>避免查询时脚本</h3><ul><li>可以在 Index 文档时，使用 Ingest Pipeline，计算并写入某个字段</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">PUT blogs/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"elasticsearch"</span></span><br><span class="line">&#125;</span><br><span class="line">GET blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;<span class="attr">"match"</span>: &#123;</span><br><span class="line">          <span class="attr">"title"</span>: <span class="string">"elasticsearch"</span></span><br><span class="line">        &#125;&#125;</span><br><span class="line">      ],</span><br><span class="line">      </span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"script"</span>: &#123;</span><br><span class="line">          <span class="attr">"script"</span>: &#123;</span><br><span class="line">            <span class="attr">"source"</span>: <span class="string">"doc['title.keyword'].value.length()&gt;5"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="常见的查询性能问题-使用-Query-Context"><a href="#常见的查询性能问题-使用-Query-Context" class="headerlink" title="常见的查询性能问题 - 使用 Query Context"></a>常见的查询性能问题 - 使用 Query Context</h3><p><img src="/images/big-data/es-07/33.jpg" alt="33"></p><h3 id="聚合文档消耗内存"><a href="#聚合文档消耗内存" class="headerlink" title="聚合文档消耗内存"></a>聚合文档消耗内存</h3><ul><li>聚合查询会消耗内存，特别是针对很大的数据集进行聚合运算<ul><li>如果可以控制聚合的数量，就能减少内存的开销</li></ul></li><li>当需要使用不同的 Query Scope，可以使用 <strong>Filter Bucket</strong></li></ul><p><img src="/images/big-data/es-07/35.jpg" alt="35"></p><h3 id="通配符开始的正则表达"><a href="#通配符开始的正则表达" class="headerlink" title="通配符开始的正则表达"></a>通配符开始的正则表达</h3><ul><li>通配符开头的正则，性能非常糟糕，需避免使用</li></ul><p><img src="/images/big-data/es-07/36.jpg" alt="36"></p><h3 id="优化分片"><a href="#优化分片" class="headerlink" title="优化分片"></a>优化分片</h3><ul><li>避免 Over Sharing<ul><li>一个查询需要访问每一个分片，分片过多，会导致不必要的查询开销</li></ul></li><li>结合应用场景，控制单个分片的尺寸<ul><li>Search：20GB</li><li>Logging：40GB</li></ul></li><li>Force-merge Read-only 索引<ul><li>使用基于时间序列的索引，将只读的索引进行 force merge，减少 segment 数</li></ul></li></ul><h3 id="读性能优化"><a href="#读性能优化" class="headerlink" title="读性能优化"></a>读性能优化</h3><ul><li>影响查询性能的一些因素<ul><li>数据模型和索引配置是否优化</li><li>数据规模是否过大，通过 Filter 减少不必要的数据计算</li><li>查询语句是否优化</li></ul></li></ul><h2 id="集群压力测试"><a href="#集群压力测试" class="headerlink" title="集群压力测试"></a>集群压力测试</h2><h3 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h3><ul><li>压力测试的目的<ul><li>容量规划 / 性能优化 / 版本间性能比较 / 性能问题诊断</li><li>确定系统稳定性，考察系统功能极限和隐患</li></ul></li><li>压力测试的方法与步骤<ul><li>测试计划（确定测试场景和测试数据集）</li><li>脚本开发</li><li>测试环境搭建（不同的软硬件配置） &amp; 运行测试</li><li>分析比较结果</li></ul></li></ul><h3 id="测试目标-amp-测试数据"><a href="#测试目标-amp-测试数据" class="headerlink" title="测试目标 &amp; 测试数据"></a>测试目标 &amp; 测试数据</h3><ul><li>测试目标<ul><li>测试集群的读写性能 / 做集群容量规划</li><li>对 ES 配置参数进行修改，评估优化效果</li><li>修改 Mapping 和 Setting，对数据建模进行优化，并测试评估性能改进</li><li>测试 ES 新版本，结合实际场景和老版本进行比较，评估是否进行升级</li></ul></li><li>测试数据<ul><li>数据量 / 数据分布</li></ul></li></ul><h3 id="测试脚本"><a href="#测试脚本" class="headerlink" title="测试脚本"></a>测试脚本</h3><ul><li>ES 本身提供了 REST API，所以，可以通过很多传统的性能测试工具<ul><li>Load Runner （商业软件，支持录制 + 重放 + DSL ）</li><li>JMeter （ Apache 开源 ，Record &amp; Play）</li><li>Gatling （开源，支持写 Scala 代码 + DSL）</li></ul></li><li>专门为 Elasticsearch 设计的工具<ul><li>ES Pref &amp; Elasticsearch-stress-test</li><li>Elastic Rally</li></ul></li></ul><h3 id="ES-Rally-简介"><a href="#ES-Rally-简介" class="headerlink" title="ES Rally 简介"></a>ES Rally 简介</h3><ul><li>Elastic 官方开源，基于 Python 3 的压力测试工具<ul><li><a href="https://github.com/elastic/rally" target="_blank" rel="noopener">https://github.com/elastic/rally</a></li><li>性能测试结果比较：<a href="https://elasticsearch-benchmarks.elastic.co" target="_blank" rel="noopener">https://elasticsearch-benchmarks.elastic.co</a></li></ul></li><li>功能介绍<ul><li>自动创建，配置，运行测试，并且销毁 ES 集群</li><li>支持不同的测试数据的比较，也支持将数据导入 ES 集群，进行二次分析</li><li>支持测试时指标数据的搜集，方便对测试结果进行深度的分析</li></ul></li></ul><h3 id="Rally-的安装以及入门"><a href="#Rally-的安装以及入门" class="headerlink" title="Rally 的安装以及入门"></a>Rally 的安装以及入门</h3><ul><li>安装运行<ul><li>Python 3.4+ 和 pip3 / JDK 8 /git 1.9+</li><li>运行 <code>pip3 install esrally</code></li><li>运行 <code>esrally configure</code></li></ul></li><li>运行<ul><li>运行 <code>esrally –distribution-version=7.1.0</code></li><li>运行 1000 条测试数据：<code>esrally –distribution-version=7.1.0 –test-mode</code></li></ul></li></ul><h3 id="Rally-基本概念讲解"><a href="#Rally-基本概念讲解" class="headerlink" title="Rally 基本概念讲解"></a>Rally 基本概念讲解</h3><ul><li>Tournament – 定义测试目标，由多个 race 组成<ul><li>Esrally list races</li></ul></li><li>Track – 赛道：测试数据和测试场景与策 略<ul><li><a href="https://github.com/elastic/rallytracks" target="_blank" rel="noopener">https://github.com/elastic/rallytracks</a></li><li>esrally list tracks</li></ul></li><li>Car – 执行测试方案<ul><li>不同配置的 es 实例</li></ul></li><li>Award – 测试结果和报告</li></ul><h3 id="什么是压测的流程"><a href="#什么是压测的流程" class="headerlink" title="什么是压测的流程"></a>什么是压测的流程</h3><ul><li>Pipeline 指的是压测的一个流程<ul><li>Esrally list pipelines</li></ul></li><li>默认的流程<ul><li>From-source-complete</li><li>From-source-skip-build</li><li>From-distribution</li><li>Benchmak-only (对已有的集群进行测试)</li></ul></li></ul><h3 id="自定义-amp-分布式测试"><a href="#自定义-amp-分布式测试" class="headerlink" title="自定义 &amp; 分布式测试"></a>自定义 &amp; 分布式测试</h3><ul><li>Car<ul><li><a href="https://esrally.readthedocs.io/en/latest/car.html" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/latest/car.html</a></li><li>使用自建的集群</li></ul></li><li>Track<ul><li>自带的测试数据集：Nyc_taxis 4.5 G /logging 1.2G</li><li>更多的测试数据集：<a href="https://github.com/elastic/rally-tracks" target="_blank" rel="noopener">https://github.com/elastic/rally-tracks</a></li></ul></li><li>分布式测试<ul><li><a href="https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-loaddriver" target="_blank" rel="noopener">https://esrally.readthedocs.io/en/latest/recipes.html#recipe-distributed-loaddriver</a></li></ul></li></ul><h3 id="实例：比较不同的版本的性能"><a href="#实例：比较不同的版本的性能" class="headerlink" title="实例：比较不同的版本的性能"></a>实例：比较不同的版本的性能</h3><ul><li>测试<ul><li><code>esrally race –distribution-version=6.0.0 –track=nyc_taxis –challenge=append-noconflicts –user-tag=&quot;version:6.0.0&quot;</code></li><li><code>esrally race –distribution-version=7.1.0 –track=nyc_taxis –challenge=append-noconflicts –user-tag=&quot;version:7.1.0&quot;</code></li></ul></li><li>比较结果<ul><li><code>esrally list races</code></li><li><code>esrally compare –baseline=[6.0.0 race] –contender=[7.1.0 race]</code></li></ul></li></ul><h3 id="实例：比较不同-Mapping-的性能"><a href="#实例：比较不同-Mapping-的性能" class="headerlink" title="实例：比较不同 Mapping 的性能"></a>实例：比较不同 Mapping 的性能</h3><ul><li>测试<ul><li><code>esrally race –distribution-version=7.1.0 –track=nyc_taxis –challenge=append-noconflicts –user-tag=&quot;enableSource:true&quot; –include-tasks=&quot;type:index&quot;</code></li><li>修改：<code>benchmarks/tracks/default/nyc_taxis/mappings.json</code>，修改 <code>_source.enabled 为 false</code></li><li><code>esrally race –distribution-version=7.1.0 –track=nyc_taxis –challenge=append-noconflicts –user-tag=&quot;enableSource:false&quot; –include-tasks=&quot;type:index&quot;</code></li></ul></li><li>比较<ul><li><code>esrally compare –baseline=[enableAll race] –contender=[disableAll race]</code></li></ul></li></ul><h3 id="实例：测试现有集群的性能"><a href="#实例：测试现有集群的性能" class="headerlink" title="实例：测试现有集群的性能"></a>实例：测试现有集群的性能</h3><ul><li>测试<ul><li><code>esrally race –pipeline=benchmark-only –target-hosts=127.0.0.1:9200 –track=geonames -challenge=append-no-conflicts</code></li></ul></li></ul><p><strong>相关阅读</strong></p><ul><li><a href="https://github.com/elastic/rally" target="_blank" rel="noopener">https://github.com/elastic/rally</a></li><li><a href="https://github.com/elastic/rally-tracks" target="_blank" rel="noopener">https://github.com/elastic/rally-tracks</a></li><li><a href="https://logz.io/blog/rally/" target="_blank" rel="noopener">https://logz.io/blog/rally/</a></li></ul><h2 id="段合并优化及注意事项"><a href="#段合并优化及注意事项" class="headerlink" title="段合并优化及注意事项"></a>段合并优化及注意事项</h2><h3 id="Lucene-Index-原理回顾"><a href="#Lucene-Index-原理回顾" class="headerlink" title="Lucene Index 原理回顾"></a>Lucene Index 原理回顾</h3><ul><li>在 Lucene 中，单个倒排索引文件被称为 Segment。Segment 是自包含的，<strong>不可变更</strong>的。 多个 Segments 汇总在一起，称为 Lucene 的 Index，其对应的就是 ES 中的 Shard</li><li>当有新文档写入时，并且执行 Refresh，就会生成一个新 Segment。 Lucene 中有一个文 件，用来记录所有 Segments 信息，叫做 Commit Point。查询时会同时查询所有 Segments，并且对结果汇总。</li><li>删除的文档信息，保存在 “.del” 文件中，查询后会进行过滤。</li><li>Segment 会定期 Merge，合并成一个，同时删除已删除文档</li></ul><p><img src="/images/big-data/es-07/37.jpg" alt="37"></p><h3 id="Merge-优化"><a href="#Merge-优化" class="headerlink" title="Merge 优化"></a>Merge 优化</h3><ul><li>ES 和 Lucene 会自动进行 Merge 操作</li><li>Merge 操作相对比较重，需要优化，降低对系统的影响</li><li>优化点一：降低分段产生的数量 / 频率<ul><li>可以将 Refresh Interval 调整到分钟级别 / <code>indices.memory.index_buffer_size</code> (默认是 10%)</li><li>尽量避免文档的更新操作</li></ul></li><li>优化点二：降低最大分段大小，避免较大的分段继续参与 Merge，节省系统资源。（最终会有多个分段）<ul><li><code>Index.merge.policy.segments_per_tier</code>，默认为 10， 越小需要越多的合并操作</li><li><code>Index.merge.policy.max_merged_segment</code>, 默认 5 GB， 操作此大小以后，就不再参与后续的合并操作</li></ul></li></ul><h3 id="Force-Merge"><a href="#Force-Merge" class="headerlink" title="Force Merge"></a>Force Merge</h3><ul><li>当 Index 不再有写入操作的时候，建议对其进行 force merge<ul><li>提升查询速度 / 减少内存开销</li></ul></li><li>最终分成几个 segments 比较合适？<ul><li>越少越好，最好可以 force merge 成 1 个，但是，Force Merge 会占用大量的网络，IO 和 CPU</li><li>如果不能在业务高峰期之前做完，就需要考虑增大最终的分段数<ul><li>Shard 的大小 / <code>Index.merge.policy.max_merged_segment</code> 的大小</li></ul></li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">POST geonames/_forcemerge?max_num_segments=1</span><br><span class="line"></span><br><span class="line">GET _cat/segments/geonames?v</span><br></pre></td></tr></table></figure><h2 id="缓存及使用-Circuit-Breaker-限制内存使用"><a href="#缓存及使用-Circuit-Breaker-限制内存使用" class="headerlink" title="缓存及使用 Circuit Breaker 限制内存使用"></a>缓存及使用 Circuit Breaker 限制内存使用</h2><h3 id="Inside-the-JVM-Heap"><a href="#Inside-the-JVM-Heap" class="headerlink" title="Inside the JVM Heap"></a>Inside the JVM Heap</h3><ul><li>Elasticsearch 的缓存主要分成三大类<ul><li>Node Query Cache （Filter Context）</li><li>Shard Query Cache （Cache Query 的结果）</li><li>Fielddata Cache</li></ul></li></ul><p><img src="/images/big-data/es-07/38.jpg" alt="38"></p><h3 id="Node-Query-Cache"><a href="#Node-Query-Cache" class="headerlink" title="Node Query Cache"></a>Node Query Cache</h3><ul><li>每一个节点有一个 Node Query 缓存<ul><li>由该节点的所有 Shard 共享，只缓存 Filter Context 相关内容</li><li>Cache 采用 LRU 算法</li></ul></li><li>静态配置，需要设置在每个 Data Node 上<ul><li>Node Level - <code>indices.queries.cache.size: &quot;10%&quot;</code></li><li>Index Level - <code>index.queries.cache.enabled: true</code></li></ul></li></ul><h3 id="Shard-Request-Cache"><a href="#Shard-Request-Cache" class="headerlink" title="Shard Request Cache"></a>Shard Request Cache</h3><ul><li>缓存每个分片上的查询结果<ul><li>只会缓存设置了 size=0 的查询对应的结果。不会缓存 hits。但是会缓存 Aggregations 和 Suggestions</li></ul></li><li>Cache Key<ul><li>LRU 算法，将整个 JSON 查询串作为 Key，与 JSON 对 象的顺序相关</li></ul></li><li>静态配置<ul><li>数据节点：<code>indices.requests.cache.size: &quot;1%&quot;</code></li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.requests.cache.enable"</span>: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 会报错</span></span><br><span class="line">GET /my_index/_search?request_cache=true</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"popular_colors"</span>: &#123;</span><br><span class="line">      <span class="attr">"field"</span>: <span class="string">"colors"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Fielddata-Cache"><a href="#Fielddata-Cache" class="headerlink" title="Fielddata Cache"></a>Fielddata Cache</h3><ul><li>除了 Text 类型，默认都采用 doc_values。节约了内存<ul><li>Aggregation 的 Global ordinals 也保存在 Fielddata cache 中</li></ul></li><li>Text 类型的字段需要打开 Fileddata 才能对其进行聚合和排序<ul><li>Text 经过分词，排序和聚合效果不佳，建议不要轻易使用</li></ul></li><li>配置<ul><li>可以控制 <code>Indices.fielddata.cache.size</code>, 避免产生 GC （默认无限制）</li></ul></li></ul><h3 id="缓存失效"><a href="#缓存失效" class="headerlink" title="缓存失效"></a>缓存失效</h3><ul><li>Node Query Cache<ul><li>保存的是 Segment 级缓存命中的结果。Segment 被合并后，缓存会失效</li></ul></li><li>Shard Request Cache<ul><li>分片 Refresh 时候，Shard Request Cache 会失效。如果 Shard 对应的数据频繁发生变化，该缓存的效率会很差</li></ul></li><li>Fielddata Cache<ul><li>Segment 被合并后，会失效</li></ul></li></ul><h3 id="管理内存的重要性"><a href="#管理内存的重要性" class="headerlink" title="管理内存的重要性"></a>管理内存的重要性</h3><ul><li>Elasticsearch 高效运维依赖于内存的合理分配<ul><li>可用内存一半分配给 JVM，一半留给操作系统，缓存索引文件</li></ul></li><li>内存问题，引发的问题<ul><li>长时间 GC，影响节点，导致集群响应缓慢</li><li>OOM，导致丢节点</li></ul></li></ul><h3 id="诊断内存状况"><a href="#诊断内存状况" class="headerlink" title="诊断内存状况"></a>诊断内存状况</h3><ul><li>查看各个节点的内存状况<ul><li><code>GET _cat/nodes?v</code></li><li><code>GET _nodes/stats/indices?pretty</code></li><li><code>GET _cat/nodes?v&amp;h=name,queryCacheMemory,queryCacheEvictions,requestCacheMemory,reques tCacheHitCount,request_cache.miss_count</code></li><li><code>GET _cat/nodes?h=name,port,segments.memory,segments.index_writer_memory,fielddata.memo ry_size,query_cache.memory_size,request_cache.memory_size&amp;v</code></li></ul></li></ul><h3 id="一些常见的内存问题"><a href="#一些常见的内存问题" class="headerlink" title="一些常见的内存问题"></a>一些常见的内存问题</h3><ul><li><p>Segments 个数过多，导致 full GC</p><ul><li>现象：集群整体响应缓慢，也没有特别多的数据读写。但是发现节点在持续进行 Full GC</li><li>分析：查看 Elasticsearch 的内存使用，发现 segments.memory 占用很大空间</li><li>解决：通过 force merge，把 segments 合并成一个</li><li>建议：对于不在写入和更新的索引，可以将其设置成只读。同时，进行 force merge 操作。如果问题依然存在，则需要考虑扩容。此外，对索引进行 force merge，还可以减少对 global_ordinals 数据结构的构建，减少对 fielddata cache 的开销</li></ul></li><li><p>Field data cache 过大，导致 full GC</p><ul><li>现象：集群整体响应缓慢，也没有特别多的数据读写。但是发现节点在持续进行 Full GC</li><li>分析：查看 Elasticsearch 的内存使用，发现 fielddata.memory.size 占用很大空间。同时，数据不存在写入和更新，也执行过 segments merge。</li><li>解决：将 <code>indices.fielddata.cache.size</code> 设小，重启节点，堆内存恢复正常</li><li>建议：Field data cache 的构建比较重，Elasticsearch 不会主动释放，所以这个值应该设置的保守一些。如果业务上确实有所需要，可以通过增加节点，扩容解决</li></ul></li><li><p>复杂的嵌套聚合，导致集群 full GC</p><ul><li>现象：节点响应缓慢，持续进行 Full GC</li><li>分析：导出 Dump 分析。发现内存中有大量 bucket 对象，查看 日志，发现复杂的嵌套聚合</li><li>解决：优化聚合</li><li>建议：在大量数据集上进行嵌套聚合查询，需要很大的堆内存来完成。如果业务场景确实需要。 则需要增加硬件进行扩展。同时，为了避免这类查询影响整个集群，需要设置 Circuit Breaker 和 search.max_buckets 的数值</li></ul></li></ul><h3 id="Circuit-Breaker"><a href="#Circuit-Breaker" class="headerlink" title="Circuit Breaker"></a>Circuit Breaker</h3><ul><li>包含多种断路器，避免不合理操作引发的 OOM，每个断路器可以指定内存使用的限制<ul><li>Parent circuit breaker：设置所有的熔断器可以使用的内存的总量</li><li>Fielddata circuit breaker：加载 fielddata 所需要的内存</li><li>Request circuit breaker：防止每个请求级数据结构超过一定的内存（例如聚合计算的内存）</li><li>In flight circuit breaker：Request 中的断路器</li><li>Accounting request circuit breaker：请求结束后不能释放的对象所占用的内存</li></ul></li></ul><h3 id="Circuit-Breaker-统计信息"><a href="#Circuit-Breaker-统计信息" class="headerlink" title="Circuit Breaker 统计信息"></a>Circuit Breaker 统计信息</h3><ul><li><code>GET /_nodes/stats/breaker?</code><ul><li>Tripped 大于 0， 说明有过熔断</li><li>Limit size 与 estimated size 约接近，越可能引发熔断</li></ul></li><li>千万不要触发了熔断，就盲目调大参数，有可能会导致集群出问题，也不因该盲目调小，需要进行评估</li><li>建议将集群升级到 7.x，更好的 Circuit Breaker 实现机制<ul><li>增加了 <code>indices.breaker.total.use_real_memory</code> 配置项，可以更加精准的分析内存状况，避免 OOM</li></ul></li></ul><p><img src="/images/big-data/es-07/39.jpg" alt="39"></p><blockquote><p><a href="https://www.elastic.co/blog/improving-node-resiliency-with-the-real-memory-circuit-breaker" target="_blank" rel="noopener">https://www.elastic.co/blog/improving-node-resiliency-with-the-real-memory-circuit-breaker</a></p></blockquote><h2 id="一些运维相关的建议"><a href="#一些运维相关的建议" class="headerlink" title="一些运维相关的建议"></a>一些运维相关的建议</h2><h3 id="集群的生命周期管理"><a href="#集群的生命周期管理" class="headerlink" title="集群的生命周期管理"></a>集群的生命周期管理</h3><ul><li>预上线<ul><li>评估用户的需求及使用场景 / 数据建模 / 容量规划 / 选择合适的部署架构 / 性能测试</li></ul></li><li>上线<ul><li>监控流量 / 定期检查潜在问题 （防患于未然，发现错误的使用方式，及时增加机器）</li><li>对索引进行优化（Index Lifecycle Management），检测是否存在不均衡而导致有部分节点过热</li><li>定期数据备份 / 滚动升级</li></ul></li><li>下架前监控流量，实现 Stage Decommission</li></ul><h3 id="部署的建议"><a href="#部署的建议" class="headerlink" title="部署的建议"></a>部署的建议</h3><ul><li>根据实际场景，选择合适的部署方式，选择合理的硬件配置<ul><li>搜索类</li><li>日志 / 指标</li></ul></li><li>部署要考虑，反亲和性（Anti-Affinity）<ul><li>尽量将机器分散在不同的机架。例如，3 台 Master 节点必须分散在不同的机架上</li><li>善用 Shard Filtering 进行配置</li></ul></li></ul><h3 id="使用要遵循一定的规范"><a href="#使用要遵循一定的规范" class="headerlink" title="使用要遵循一定的规范"></a>使用要遵循一定的规范</h3><ul><li>Mapping<ul><li>生产环境中索引应考虑禁止 Dynamic Index Mapping，避免过多字段导致 Cluster State 占用过多</li><li>禁止索引自动创建的功能，创建时必须提供 Mapping 或通过 Index Template 进行设定</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"action.auto_create_index"</span>: <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"action.auto_create_index"</span>: <span class="string">".monitoring-*,logstash-*"</span></span><br><span class="line">  &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>设置 Slowlogs，发现一些性能不好，甚至是错误的使用 Pattern<ul><li>例如：错误的将网址映射成 keyword，然后用通配符查询。应该使用 Text，结合 URL 分词器</li><li>严禁一切 “*” 开头的通配符查询</li></ul></li></ul><h3 id="对重要的数据进行备份"><a href="#对重要的数据进行备份" class="headerlink" title="对重要的数据进行备份"></a>对重要的数据进行备份</h3><ul><li>集群备份</li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/modules-snapshots.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/modules-snapshots.html</a></li></ul><h3 id="定期更新到新版本"><a href="#定期更新到新版本" class="headerlink" title="定期更新到新版本"></a>定期更新到新版本</h3><ul><li>ES 在新版本中会持续对性能作出优化；提供更多的新功能<ul><li>Circuit breaker 实现的改进</li></ul></li><li>修复一些已知的 bug 和安全隐患</li></ul><h3 id="ES-的版本"><a href="#ES-的版本" class="headerlink" title="ES 的版本"></a>ES 的版本</h3><ul><li>Elasticsearch 的版本格式是： X.Y.Z<ul><li>X: Major</li><li>Y: Minor</li><li>Z: Patch</li></ul></li><li>Elasticsearch 可以使用上一个主版本的索引<ul><li>7.x 可以使用 6.x / 7.x 不支持使用 5.x</li><li>5.x 可以使用 2.x</li></ul></li></ul><h3 id="Rolling-Upgrade-v-s-Full-Cluster-Restart"><a href="#Rolling-Upgrade-v-s-Full-Cluster-Restart" class="headerlink" title="Rolling Upgrade v.s Full Cluster Restart"></a>Rolling Upgrade v.s Full Cluster Restart</h3><ul><li>Rolling Upgrade<ul><li>没有 Downtime</li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/rolling-upgrades.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/rolling-upgrades.html</a></li></ul></li><li>Full Cluster Restart<ul><li>集群在更新期间不可用</li><li>升级更快</li></ul></li></ul><h3 id="Full-Restart-的步骤"><a href="#Full-Restart-的步骤" class="headerlink" title="Full Restart 的步骤"></a>Full Restart 的步骤</h3><ul><li>停止索引数据，同时备份集群</li><li>Disable Shard Allocation （Persistent）</li><li>执行 Synced Flush</li><li>关闭并更新所有节点</li><li>先运行所有 Master 节点 / 再运行其他节点</li><li>等集群变黄后打开 Shard Allocation</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"cluster.routing.allocation.enable"</span>: <span class="string">"primaries"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Force a synced flush</span></span><br><span class="line">POST _flush/synced</span><br></pre></td></tr></table></figure><h3 id="运维-Cheat-Sheet：移动分片"><a href="#运维-Cheat-Sheet：移动分片" class="headerlink" title="运维 Cheat Sheet：移动分片"></a>运维 Cheat Sheet：移动分片</h3><ul><li>从一个节点移动分片到另外一个节点</li><li>使用场景：<ul><li>当一个数据节点上有过多 Hot Shards；可以通过手动分配分片到特定的节点解决</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 移动一个分片从一个节点到另外一个节点</span></span><br><span class="line">POST _cluster/reroute</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"commands"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"move"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"index_name"</span>,</span><br><span class="line">        <span class="attr">"shard"</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="attr">"from_node"</span>: <span class="string">"node_name_1"</span>,</span><br><span class="line">        <span class="attr">"to_node"</span>: <span class="string">"node_name_2"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Fore the allocation of an unassinged shard with a reason</span></span><br><span class="line">POST _cluster/reroute?explain</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"commands"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"allocate"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"index_name"</span>,</span><br><span class="line">        <span class="attr">"shard"</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="attr">"node"</span>: <span class="string">"nodename"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运维-Cheat-Sheet：从集群中移除一个节点"><a href="#运维-Cheat-Sheet：从集群中移除一个节点" class="headerlink" title="运维 Cheat Sheet：从集群中移除一个节点"></a>运维 Cheat Sheet：从集群中移除一个节点</h3><ul><li>使用场景：当你想移除一个节点，或者对一个机器进行维护。同时你又不希望导致集群的颜色变黄或者变红</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// remove the nodes from cluster </span></span><br><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"transient"</span>: &#123;</span><br><span class="line">    <span class="attr">"cluster.routing.allocation.exclude._ip"</span>:<span class="string">"the_IP_of_your_node"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运维-Cheat-Sheet：控制-Allocation-和-Recovery"><a href="#运维-Cheat-Sheet：控制-Allocation-和-Recovery" class="headerlink" title="运维 Cheat Sheet：控制 Allocation 和 Recovery"></a>运维 Cheat Sheet：控制 Allocation 和 Recovery</h3><ul><li>使用场景：控制 Allocation 和 Recovery 的速率</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// change the number of moving shards to balance the cluster</span></span><br><span class="line">PUT /_cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"transient"</span>: &#123;<span class="attr">"cluster.routing.allocation.cluster_concurrent_rebalance"</span>:<span class="number">2</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// change the number of shards being recovered simultanceously per node</span></span><br><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"transient"</span>: &#123;<span class="attr">"cluster.routing.allocation.node_concurrent_recoveries"</span>:<span class="number">5</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Change the recovery speed</span></span><br><span class="line">PUT /_cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"transient"</span>: &#123;<span class="attr">"indices.recovery.max_bytes_per_sec"</span>: <span class="string">"80mb"</span>&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Change the number of concurrent streams for a recovery on a single node</span></span><br><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"transient"</span>: &#123;<span class="attr">"indices.recovery.concurrent_streams"</span>:<span class="number">6</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运维-Cheat-Sheet：Synced-Flush"><a href="#运维-Cheat-Sheet：Synced-Flush" class="headerlink" title="运维 Cheat Sheet：Synced Flush"></a>运维 Cheat Sheet：Synced Flush</h3><ul><li>使用场景：需要重启一个节点。<ul><li>通过 synced flush，可以在索引上放置一个 sync ID。这样可以提供这些分片的 Recovery 的时间</li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Force a synced flush</span></span><br><span class="line">POST _flush/synced</span><br></pre></td></tr></table></figure><h3 id="运维-Cheat-Sheet：清空节点上的缓存"><a href="#运维-Cheat-Sheet：清空节点上的缓存" class="headerlink" title="运维 Cheat Sheet：清空节点上的缓存"></a>运维 Cheat Sheet：清空节点上的缓存</h3><ul><li>使用场景：节点上出现了高内存占用。可以执行清除缓存的操作。这个操作会影响集群的性能，但是会避免你的集群出现 OOM 的问题</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Clear the cache on a node</span></span><br><span class="line">POST _cache/clear</span><br></pre></td></tr></table></figure><h3 id="运维-Cheat-Sheet：清控制搜索的队列"><a href="#运维-Cheat-Sheet：清控制搜索的队列" class="headerlink" title="运维 Cheat Sheet：清控制搜索的队列"></a>运维 Cheat Sheet：清控制搜索的队列</h3><ul><li>使用场景：当搜索的响应时间过长，看到有 “reject” 指标的增加，都可以适当增加该数值</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Change the sinze of the search queue</span></span><br><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"transient"</span>: &#123;</span><br><span class="line">    <span class="attr">"threadpool.search.queue_size"</span>: <span class="number">2000</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运维-Cheat-Sheet：设置-Circuit-Breaker"><a href="#运维-Cheat-Sheet：设置-Circuit-Breaker" class="headerlink" title="运维 Cheat Sheet：设置 Circuit Breaker"></a>运维 Cheat Sheet：设置 Circuit Breaker</h3><ul><li>使用场景：设置各类 Circuit Breaker。避免 OOM 的发生</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Adjust the circuit breakers</span></span><br><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"indices.breaker.total.limit"</span>:<span class="string">"40%"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="运维建议"><a href="#运维建议" class="headerlink" title="运维建议"></a>运维建议</h3><ul><li>了解用户场景，选择合适部署</li><li>定期检查，发现潜在问题</li><li>对重要的数据进行备份</li><li>保持版本升级</li></ul><h2 id="使用-Shrink-与-RolloverAPI-有效的管理索引"><a href="#使用-Shrink-与-RolloverAPI-有效的管理索引" class="headerlink" title="使用 Shrink 与 RolloverAPI 有效的管理索引"></a>使用 Shrink 与 RolloverAPI 有效的管理索引</h2><ul><li>Open / Close Index∶ 索引关闭后无法进行读写，但是索引数据不会被删除</li><li>Shrink Index∶ 可以将索引的主分片数收缩到较小的值</li><li>Split Index∶ 可以扩大主分片个数</li><li>Rollover Index∶ 类似 Log4J 记录日志的方式，索引尺寸或者时间超过一定值后，创建新的</li><li>Rollup Index∶ 对数据进行处理后，重新写入，减少数据量</li></ul><h3 id="Open-Close-Index-API"><a href="#Open-Close-Index-API" class="headerlink" title="Open / Close Index API"></a>Open / Close Index API</h3><ul><li>索引关闭后，对集群的相关开销基本降低为 0</li><li>但是无法被读取和搜索</li><li>当需要的时候，可以重新打开</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">DELETE test</span><br><span class="line">PUT test/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"key"</span>:<span class="string">"value"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 关闭索引</span></span><br><span class="line">POST /test/_close</span><br><span class="line"><span class="comment">// 查看索引是否存在</span></span><br><span class="line">HEAD test</span><br><span class="line"><span class="comment">// 无法查询</span></span><br><span class="line">POST test/_count</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打开索引</span></span><br><span class="line">POST /test/_open</span><br><span class="line">POST test/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">POST test/_count</span><br></pre></td></tr></table></figure><h3 id="Shrink-API"><a href="#Shrink-API" class="headerlink" title="Shrink API"></a>Shrink API</h3><ul><li>ES 5.x 后推出的一个新功能，使用场景<ul><li>索引保存的数据量比较小，需要重新设定主分片数</li><li>索引从 Hot 移动到 Warm 后，需要降低主分片数</li></ul></li><li>会使用和源索引<strong>相同的配置</strong>创建一个新的索引，仅仅<strong>降低主分片数</strong><ul><li>源分片数必须是目标分片数的倍数。如果源分片数是素数，目标分片数只能为 1</li><li>如果文件系统支持硬链接，会将 Segments 硬连接到目标索引，所以性能好</li></ul></li><li>完成后，可以删除源索引</li></ul><p><img src="/images/big-data/es-07/40.jpg" alt="40"></p><ul><li>分片必须只读</li><li>所有的分片必须在同一个节点上</li><li>集群健康状态为 Green</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在一个 hot-warm-cold的集群上进行测试</span></span><br><span class="line">GET _cat/nodes</span><br><span class="line">GET _cat/nodeattrs</span><br><span class="line"></span><br><span class="line">DELETE my_source_index</span><br><span class="line">DELETE my_target_index</span><br><span class="line">PUT my_source_index</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"settings"</span>: &#123;</span><br><span class="line">   <span class="attr">"number_of_shards"</span>: <span class="number">4</span>,</span><br><span class="line">   <span class="attr">"number_of_replicas"</span>: <span class="number">0</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_source_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"key"</span>:<span class="string">"value"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET _cat/shards/my_source_index</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分片数3，会失败</span></span><br><span class="line">POST my_source_index/_shrink/my_target_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.number_of_replicas"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"index.number_of_shards"</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="attr">"index.codec"</span>: <span class="string">"best_compression"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"aliases"</span>: &#123;</span><br><span class="line">    <span class="attr">"my_search_indices"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 报错，因为没有置成 readonly</span></span><br><span class="line">POST my_source_index/_shrink/my_target_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.number_of_replicas"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"index.number_of_shards"</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"index.codec"</span>: <span class="string">"best_compression"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"aliases"</span>: &#123;</span><br><span class="line">    <span class="attr">"my_search_indices"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将 my_source_index 设置为只读</span></span><br><span class="line">PUT /my_source_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.blocks.write"</span>: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 报错，必须都在一个节点</span></span><br><span class="line">POST my_source_index/_shrink/my_target_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.number_of_replicas"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"index.number_of_shards"</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"index.codec"</span>: <span class="string">"best_compression"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"aliases"</span>: &#123;</span><br><span class="line">    <span class="attr">"my_search_indices"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">DELETE my_source_index</span><br><span class="line"><span class="comment">// 确保分片都在 hot</span></span><br><span class="line">PUT my_source_index</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"settings"</span>: &#123;</span><br><span class="line">   <span class="attr">"number_of_shards"</span>: <span class="number">4</span>,</span><br><span class="line">   <span class="attr">"number_of_replicas"</span>: <span class="number">0</span>,</span><br><span class="line">   <span class="attr">"index.routing.allocation.include.box_type"</span>:<span class="string">"hot"</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_source_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"key"</span>:<span class="string">"value"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET _cat/shards/my_source_index</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置为只读</span></span><br><span class="line">PUT /my_source_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.blocks.write"</span>: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST my_source_index/_shrink/my_target_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.number_of_replicas"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"index.number_of_shards"</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"index.codec"</span>: <span class="string">"best_compression"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"aliases"</span>: &#123;</span><br><span class="line">    <span class="attr">"my_search_indices"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET _cat/shards/my_target_index</span><br><span class="line"></span><br><span class="line"><span class="comment">// My target_index状态为也只读</span></span><br><span class="line">PUT my_target_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"key"</span>:<span class="string">"value"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Split-API"><a href="#Split-API" class="headerlink" title="Split API"></a>Split API</h3><ul><li>跟 Shrink API 相反</li></ul><p><img src="/images/big-data/es-07/41.jpg" alt="41"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Split Index</span></span><br><span class="line">DELETE my_source_index</span><br><span class="line">DELETE my_target_index</span><br><span class="line"></span><br><span class="line">PUT my_source_index</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"settings"</span>: &#123;</span><br><span class="line">   <span class="attr">"number_of_shards"</span>: <span class="number">4</span>,</span><br><span class="line">   <span class="attr">"number_of_replicas"</span>: <span class="number">0</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_source_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"key"</span>:<span class="string">"value"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET _cat/shards/my_source_index</span><br><span class="line"></span><br><span class="line"><span class="comment">// 必须是倍数</span></span><br><span class="line">POST my_source_index/_split/my_target</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.number_of_shards"</span>: <span class="number">10</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 必须是只读</span></span><br><span class="line">POST my_source_index/_split/my_target</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.number_of_shards"</span>: <span class="number">8</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置为只读</span></span><br><span class="line">PUT /my_source_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.blocks.write"</span>: <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST my_source_index/_split/my_target_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"index.number_of_shards"</span>: <span class="number">8</span>,</span><br><span class="line">    <span class="attr">"index.number_of_replicas"</span>:<span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET _cat/shards/my_target_index</span><br><span class="line"></span><br><span class="line"><span class="comment">// write block</span></span><br><span class="line">PUT my_target_index/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"key"</span>:<span class="string">"value"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="一个时间序列索引的实际场景"><a href="#一个时间序列索引的实际场景" class="headerlink" title="一个时间序列索引的实际场景"></a>一个时间序列索引的实际场景</h3><p><img src="/images/big-data/es-07/42.jpg" alt="42"></p><ul><li>比如说在第一天写入 index0 90G，这个主分片数设置为 5，单个分片数就没有超过 20GB</li><li>第二天写入 index1 520G，出现暴增，超出了合理的值</li><li>Rotation：可以设置一个值，超过这个值就创建个新的索引写入</li></ul><h3 id="Rollover-API"><a href="#Rollover-API" class="headerlink" title="Rollover API"></a>Rollover API</h3><ul><li>当满足一系列的条件，Rollover API 支持将一个 Alias 指向一个新的索引<ul><li>存活的时间 / 最大文档数 / 最大的文件尺寸</li></ul></li><li>应用场景<ul><li>当一个索引数据量过大</li></ul></li><li>一般需要和 Index Lifecycle Management Policies 结合使用<ul><li><strong>只有调用 Rollover API 时，才会去做相应的检测</strong>。ES 并不会自动去监控这些索引</li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">DELETE nginx-logs*</span><br><span class="line"><span class="comment">// 不设定 is_write_true</span></span><br><span class="line"><span class="comment">// 名字符合命名规范</span></span><br><span class="line">PUT /nginx-logs-000001</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"aliases"</span>: &#123;</span><br><span class="line">    <span class="attr">"nginx_logs_write"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 多次写入文档</span></span><br><span class="line">POST nginx_logs_write/_doc</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"log"</span>:<span class="string">"something"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /nginx_logs_write/_rollover</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"conditions"</span>: &#123;</span><br><span class="line">    <span class="attr">"max_age"</span>: <span class="string">"1d"</span>,</span><br><span class="line">    <span class="attr">"max_docs"</span>:  <span class="number">5</span>,</span><br><span class="line">    <span class="attr">"max_size"</span>: <span class="string">"5gb"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /nginx_logs_write/_count</span><br><span class="line"><span class="comment">// 查看 Alias信息</span></span><br><span class="line">GET /nginx_logs_write</span><br><span class="line"></span><br><span class="line">DELETE apache-logs*</span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置 is_write_index</span></span><br><span class="line">PUT apache-logs1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"aliases"</span>: &#123;</span><br><span class="line">    <span class="attr">"apache_logs"</span>: &#123;</span><br><span class="line">      <span class="attr">"is_write_index"</span>:<span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">POST apache_logs/_count</span><br><span class="line"></span><br><span class="line">POST apache_logs/_doc</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"key"</span>:<span class="string">"value"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 需要指定 target 的名字</span></span><br><span class="line">POST /apache_logs/_rollover/apache-logs8xxxx</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"conditions"</span>: &#123;</span><br><span class="line">    <span class="attr">"max_age"</span>:   <span class="string">"1d"</span>,</span><br><span class="line">    <span class="attr">"max_docs"</span>:  <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"max_size"</span>:  <span class="string">"5gb"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看 Alias信息</span></span><br><span class="line">GET /apache_logs</span><br></pre></td></tr></table></figure><h2 id="索引全生命周期管理及工具介绍"><a href="#索引全生命周期管理及工具介绍" class="headerlink" title="索引全生命周期管理及工具介绍"></a>索引全生命周期管理及工具介绍</h2><h3 id="时间序列的索引"><a href="#时间序列的索引" class="headerlink" title="时间序列的索引"></a>时间序列的索引</h3><ul><li>特点<ul><li>索引中的数据随着时间，持续不断增长</li></ul></li><li>按照时间序列划分索引的好处 &amp; 挑战<ul><li>按照时间进行划分索引，会使得管理更加简单。例如，完整删除一个索引，性能比 delete by query 好</li><li>如何进行自动化管理，减少人工操作<ul><li>从 Hot 移动到 Warm</li><li>定期关闭或者删除索引</li></ul></li></ul></li></ul><h3 id="索引生命周期常见的阶段"><a href="#索引生命周期常见的阶段" class="headerlink" title="索引生命周期常见的阶段"></a>索引生命周期常见的阶段</h3><p><img src="/images/big-data/es-07/43.jpg" alt="43"></p><ul><li>Hot∶ 索引还存在着大量的读写操作</li><li>Warm∶ 索引不存在写操作，还有被查询的需要</li><li>Cold∶ 数据不存在写操作，读操作也不多</li><li>Delete∶ 索引不再需要，可以被安全删除</li></ul><h3 id="Elasticsearch-Curator"><a href="#Elasticsearch-Curator" class="headerlink" title="Elasticsearch Curator"></a>Elasticsearch Curator</h3><ul><li>Elastic 官方推出的工具<ul><li>基于 python 的命令行工具</li></ul></li><li>配置 Actions<ul><li>内置 10 多种 Index 相关的操作</li><li>每个动作可以顺序执行</li></ul></li><li>Filters<ul><li>支持各种条件，过滤出需要操作的索引</li></ul></li></ul><p><img src="/images/big-data/es-07/44.jpg" alt="44"></p><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html</a></p></blockquote><h3 id="eBay-Lifecycle-Management-Tool"><a href="#eBay-Lifecycle-Management-Tool" class="headerlink" title="eBay Lifecycle Management Tool"></a>eBay Lifecycle Management Tool</h3><ul><li>eBay Pronto team 自研图形化工具<ul><li>支持 Curator 的功能</li><li>一个界面，管理多个 ES 集群</li><li>支持不同的 ES 版本</li></ul></li><li>支持图形化配置</li><li>Job 定时触发</li><li>系统高可用</li></ul><h3 id="工具比较"><a href="#工具比较" class="headerlink" title="工具比较"></a>工具比较</h3><table><thead><tr><th align="left">Function</th><th align="left">Gurator</th><th align="left">_rollover</th><th align="left">Index Managemen Service</th></tr></thead><tbody><tr><td align="left">index Action</td><td align="left">All supported</td><td align="left">Create, <br/> Alias rotation</td><td align="left">Create, <br/> Close, <br/> Delete, <br/> Index settings, <br/> Alias rotation</td></tr><tr><td align="left">Version Compatbility <br/> On ES 2.x 5.x 6.x</td><td align="left">Not fully covered</td><td align="left">Not fully covered</td><td align="left">All covered</td></tr><tr><td align="left">Job Scheduling</td><td align="left">No</td><td align="left">No</td><td align="left">Yes</td></tr><tr><td align="left">Web Portal</td><td align="left">No</td><td align="left">No</td><td align="left">Yes</td></tr><tr><td align="left">High Availability</td><td align="left">No</td><td align="left">No</td><td align="left">Yes</td></tr><tr><td align="left">Multi-cluster Support</td><td align="left">No</td><td align="left">No</td><td align="left">Yes</td></tr></tbody></table><blockquote><p>eBay(Index Managemen Service) 不开源，再好也用不上……</p></blockquote><h3 id="Index-Lifecycle-Management"><a href="#Index-Lifecycle-Management" class="headerlink" title="Index Lifecycle Management"></a>Index Lifecycle Management</h3><ul><li>Elasticsearch 6.6 推出的新功能<ul><li>基于 X-Pack Basic License，可免费使用</li></ul></li><li>ILM 概念<ul><li>Policy</li><li>Phase</li><li>Action</li></ul></li></ul><h3 id="ILM-Policy"><a href="#ILM-Policy" class="headerlink" title="ILM Policy"></a>ILM Policy</h3><p><img src="/images/big-data/es-07/45.jpg" alt="45"></p><ul><li>集群中支持定义多个 Policy</li><li>每个索引可以使用相同或不相同的 Policy</li></ul><h3 id="Index-Lifecycle-Policies-图形化界面"><a href="#Index-Lifecycle-Policies-图形化界面" class="headerlink" title="Index Lifecycle Policies 图形化界面"></a>Index Lifecycle Policies 图形化界面</h3><ul><li>通过 Kibana Management 设定</li><li>Hot phase 是必须要的<ul><li>可以 enable rollover</li></ul></li><li>其他 Phase 按需设失</li><li>Watch-history-ilm policy<ul><li>创建 7 天后自动删除</li></ul></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《Elasticsearch核心技术与实战》</li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/configuring-security.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/configuring-security.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-tls.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-tls.html</a></li><li><a href="https://www.elastic.co/cn/blog/sizing-hot-warm-architectures-for-logging-and-metrics-in-the-elasticsearch-service-on-elastic-cloud" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/sizing-hot-warm-architectures-for-logging-and-metrics-in-the-elasticsearch-service-on-elastic-cloud</a></li><li><a href="https://www.elastic.co/cn/blog/deploying-a-hot-warm-logging-cluster-on-the-elasticsearch-service" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/deploying-a-hot-warm-logging-cluster-on-the-elasticsearch-service</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cluster-reroute.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cluster-reroute.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-forcemerge.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-forcemerge.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/allocation-total-shards.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/allocation-total-shards.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/capacity-planning.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/guide/current/capacity-planning.html</a></li><li><a href="https://yq.aliyun.com/articles/670118" target="_blank" rel="noopener">https://yq.aliyun.com/articles/670118</a></li><li><a href="https://www.elastic.co/cn/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond?elektra=products&amp;storm=sub1" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond?elektra=products&amp;storm=sub1</a></li><li><a href="https://www.elastic.co/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond" target="_blank" rel="noopener">https://www.elastic.co/blog/introducing-elastic-cloud-on-kubernetes-the-elasticsearch-operator-and-beyond</a></li><li><a href="https://github.com/operator-framework" target="_blank" rel="noopener">https://github.com/operator-framework</a></li><li><a href="https://github.com/upmc-enterprises/elasticsearch-operator" target="_blank" rel="noopener">https://github.com/upmc-enterprises/elasticsearch-operator</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-indexing-speed.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-shrink-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-shrink-index.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-rollover-index.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/indices-rollover-index.html</a></li></ul><style>  img {    zoom: 80%;  }</style>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;深入了解 ES 集群管理、生产环境建议等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="BigData" scheme="https://blog.lichao.xin/categories/BigData/"/>
    
    
      <category term="Elastic Stack" scheme="https://blog.lichao.xin/tags/Elastic-Stack/"/>
    
      <category term="ES" scheme="https://blog.lichao.xin/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>重学 Elastic Stack 之 Elasticsearch 深入了解(二)</title>
    <link href="https://blog.lichao.xin/back-end/big-data/es-06/"/>
    <id>https://blog.lichao.xin/back-end/big-data/es-06/</id>
    <published>2021-02-08T22:10:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>深入了解 ES 集群、分页、聚合分析、父子文档、数据建模等。</p><a id="more"></a><h2 id="集群分布式模型与选主与脑裂问题"><a href="#集群分布式模型与选主与脑裂问题" class="headerlink" title="集群分布式模型与选主与脑裂问题"></a>集群分布式模型与选主与脑裂问题</h2><h3 id="分布式特性"><a href="#分布式特性" class="headerlink" title="分布式特性"></a>分布式特性</h3><ul><li>ES 的分布式架构带来的好处<ul><li>储存的水平扩容，支持 PB 级数据</li><li>提高系统的可用性，部分节点停止服务，整个集群的服务不受影响</li></ul></li><li>ES 的分布式架构<ul><li>不同的集群通过不同的名字来区分，默认名字 “elasticsearch”</li><li>通过配置文件的修改，或者在命令行中 <code>-E cluster.name=xxx</code> 设定</li></ul></li></ul><h3 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h3><ul><li>节点是一个 ES 的实例<ul><li>其本质就是一个 JAVA 进程</li><li>一台机器可以运行多个 ES 进程，但是生产环境一般建议一台机器就运行一个 ES 实例</li></ul></li><li>每一个节点都有名字，通过配置文件配置，或者启动时候 <code>-E node.name=xxx</code> 指定</li><li>每一个节点在启动之后，都会分配一个 UID，保存在 data 目录下</li></ul><h3 id="Coordinating-Node"><a href="#Coordinating-Node" class="headerlink" title="Coordinating Node"></a>Coordinating Node</h3><ul><li>处理请求的节点，叫 Coordinating Node<ul><li>路由请求到正确的节点，例如创建索引的请求，需要路由到 Master 节点</li></ul></li><li>所有节点默认都是 Coordinating Node</li><li>通过将其他类型设置成 False ，使其成为 Dedicated Coordinating Node</li></ul><h3 id="Data-Node"><a href="#Data-Node" class="headerlink" title="Data Node"></a>Data Node</h3><ul><li>可以保存数据的节点，叫做 Data Node<ul><li>节点启动后，默认就是数据节点。可以设置 <code>node.data:false</code> 禁止</li></ul></li><li>Data Node 的职责<ul><li>保存分片数据。在数据扩展上起到了至关重要的作用（由 Master Node 决定把分片分发到数据节点上）</li></ul></li><li>通过增加数据节点<ul><li>可以解决数据<strong>水平扩展</strong>和解决<strong>数据单点</strong>的问题</li></ul></li></ul><h3 id="Master-Node"><a href="#Master-Node" class="headerlink" title="Master Node"></a>Master Node</h3><ul><li>Master Node 的职责<ul><li>处理创建，删除索引等请求 / 决定分片被分配到哪个节点 / 负责索引的创建与删除</li><li>维护并且更新 Cluster State</li></ul></li><li>Master Node 的最佳实践<ul><li>Master 节点非常重要，在部署上需要考虑解决单点的问题</li><li>为一个集群设置多个 Master 节点 / 每个节点值承担 Master 的单一角色</li></ul></li></ul><h3 id="Master-Eligible-Nodes-amp-选主流程"><a href="#Master-Eligible-Nodes-amp-选主流程" class="headerlink" title="Master Eligible Nodes &amp; 选主流程"></a>Master Eligible Nodes &amp; 选主流程</h3><ul><li>一个集群，支持配置多个 Master Eligble 节点。这些节点可以在必要时（如 Master 节点出现故障，网络故障时）参与选主流程，成为 Master 节点</li><li>每个节点启动后，默认就是一个 Master eligible 节点<ul><li>可以设置 <code>node.master:false</code></li></ul></li><li>当集群内的第一个 Master eligible 节点启动的时候，它会将自己选举成 Master 节点</li></ul><h3 id="集群状态"><a href="#集群状态" class="headerlink" title="集群状态"></a>集群状态</h3><ul><li>集群状态信息（Cluster State），维护了一个集群中，必要的信息<ul><li>所有的节点信息</li><li>所有的索引和其相关的 Mapping 与 Setting 信息</li><li>分片的路由信息</li></ul></li><li>在每个节点都保存了集群的状态信息</li><li>但是，只有 Master 节点才能修改集群的状态信息，并负责同步给其他节点<ul><li>因为，任意节点都能修改信息会导致 Cluster State 信息不一致</li></ul></li></ul><h3 id="Master-Eligbile-Nodes-amp-选主的过程"><a href="#Master-Eligbile-Nodes-amp-选主的过程" class="headerlink" title="Master Eligbile Nodes &amp; 选主的过程"></a>Master Eligbile Nodes &amp; 选主的过程</h3><ul><li>互相 ping 对方。<strong>Node Id</strong> 低的会被成为被选举的节点</li><li>其他节点会加入集群，但是不承担 Master 节点的角色。一旦发现被选中的主节点丢失，就会选举出新的 Master 节点</li></ul><p><img src="/images/big-data/es-06/1.jpg" alt="1"></p><h3 id="脑裂问题"><a href="#脑裂问题" class="headerlink" title="脑裂问题"></a>脑裂问题</h3><ul><li>Split-Brain ，分布式系统的经典网络问题，当出现网络问题，一个节点和其他节点无法连接<ul><li>Node 2 和 Node 3 会被重新选举 Master</li><li>Node 1 自己还是作为 Master，组成一个集群，同时更新 Cluster State</li><li>导致 2 个 master，维护不同的 cluster state。当网络恢复是，无法选择正确恢复</li></ul></li></ul><p><img src="/images/big-data/es-06/2.jpg" alt="2"></p><h3 id="如何避免脑裂问题"><a href="#如何避免脑裂问题" class="headerlink" title="如何避免脑裂问题"></a>如何避免脑裂问题</h3><ul><li>限定一个选举条件，这是 quorum（仲裁），只有在 Master eligble 节点数大于 quorum 时，才能进行选举<ul><li>Quorum = (master 节点总数 / 2) + 1</li><li>当 3 个 master eligible 时，设置 <strong>discovery.zen.minimum_master_nodes</strong> 为 2 ，即可避免脑裂</li></ul></li><li>从 7.0 开始，无需这个配置<ul><li>移除 minimum_master_nodes 参数，让 ES 自己选择可以形成冲裁的节点</li><li>典型的主节点选举现在只需要很短的时间可以完成。集群的伸缩变得更加安全，更容易，并且可能造成丢失数据的系统配置选项更少了</li><li>节点更清楚的记录它们的状态，有助于诊断为什么它们不能加入集群或为什么无法选举除主节点</li></ul></li></ul><h3 id="为什么高可用是奇数节点？"><a href="#为什么高可用是奇数节点？" class="headerlink" title="为什么高可用是奇数节点？"></a>为什么高可用是奇数节点？</h3><p>为了避免脑裂，同时也为了避免浪费资源（机器），Raft 算法为：</p><p>N 为 master 节点总数，可容忍 <strong>(N-1)/2</strong> 失败数，quorum 需要 <strong>(N/2)+1</strong></p><h3 id="分布式共识算法"><a href="#分布式共识算法" class="headerlink" title="分布式共识算法"></a>分布式共识算法</h3><p>一致性往往指分布式系统中多个副本对外呈现的数据的状态。共识则描述了分布式系统中多个节点之间，彼此对某个状态达成一致结果的过程。因此，一致性描述的是结果状态，共识则是一种手段。达成某种共识并不意味着就保障了一致性。</p><p>对于分布式系统来讲，各个节点通常都是相同的确定性状态机模型（又称为状态机复制问题，state-machine replication），从相同初始状态开始接收相同顺序的指令，则可以保证相同的结果状态。因此，系统中多个节点最关键的是对多个事件的顺序进行共识，即排序。</p><p><strong>问题与挑战</strong></p><p>一般地，把出现故障（crash或fail-stop，即不响应）但不会伪造信息的情况称为“非拜占庭错误”（non-byzantine fault）或“故障错误”（Crash Fault）；伪造信息恶意响应的情况称为“拜占庭错误”（Byzantine Fault），对应节点为拜占庭节点。</p><p><strong>常见算法</strong></p><p>根据解决的是非拜占庭的普通错误情况还是拜占庭错误情况，共识算法可以分为Crash Fault Tolerance（CFT）类算法和Byzantine Fault Tolerance（BFT）类算法。</p><p>对于非拜占庭错误：已经存在一些经典的解决算法，包括Paxos、Raft及其变种等。这类容错算法往往性能比较好，处理较快，容忍不超过一半的故障节点。</p><p>对于拜占庭错误：一般包括PBFT（Practical Byzantine Fault Tolerance）为代表的确定性系列算法、PoW为代表的概率算法等。对于确定性算法，一旦达成对某个结果的共识就不可逆转，即共识是最终结果；而对于概率类算法，共识结果则是临时的，随着时间推移或某种强化，共识结果被推翻的概率越来越小，成为事实上的最终结果。拜占庭类容错算法往往性能较差，容忍不超过1/3的故障节点。</p><p>此外，XFT（Cross Fault Tolerance）等改进算法可以提供类似CFT的处理响应速度，并能在大多数节点正常工作时提供BFT保障。</p><p>crash fault tolerance 的系统，节点数需要满足 n=2f+1 （ f 为会崩溃的节点数），所以最小的系统需要 3 个节点。</p><p>拜占庭容错系统的节点数是 n=3f+1 （ f 为拜占庭节点数量）。所以拜占庭容错系统需要至少 4 个节点才能容忍 1 个拜占庭节点。</p><p>相关的理论可以看 Paxos，Raft，pbft 等著名论文。主要思想是：保证正常运作的节点数量过系统的半数（过半机制）。</p><ul><li><a href="https://www.the-paper-trail.org/post/2008-08-13-a-brief-tour-of-flp-impossibility/" target="_blank" rel="noopener">FLP 不可能定理</a></li><li><a href="https://www.usenix.org/system/files/conference/atc14/atc14-paper-ongaro.pdf" target="_blank" rel="noopener">Raft 共识算法论文</a></li></ul><h3 id="配置节点类型"><a href="#配置节点类型" class="headerlink" title="配置节点类型"></a>配置节点类型</h3><ul><li>一个节点默认下是一个 Master eligible ，data and ingest node</li></ul><table><thead><tr><th align="left">节点类型</th><th align="left">配置参数</th><th align="left">默认值</th></tr></thead><tbody><tr><td align="left">maste eligible</td><td align="left">node.master</td><td align="left">true</td></tr><tr><td align="left">data</td><td align="left">node.data</td><td align="left">true</td></tr><tr><td align="left">ingest</td><td align="left">node.ingest</td><td align="left">ture</td></tr><tr><td align="left">coordinating only</td><td align="left">⽆</td><td align="left">设置上⾯三个参数全部为 false</td></tr><tr><td align="left">machine learning</td><td align="left">node.ml</td><td align="left">true (需要 enable x-pack)</td></tr></tbody></table><blockquote><p>配置版本基于 7.1，相关配置可能已发生改动详情看 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html" target="_blank" rel="noopener">官网</a></p></blockquote><h2 id="分片与集群的故障转移"><a href="#分片与集群的故障转移" class="headerlink" title="分片与集群的故障转移"></a>分片与集群的故障转移</h2><h3 id="Primary-Shard-提升系统存储容量"><a href="#Primary-Shard-提升系统存储容量" class="headerlink" title="Primary Shard - 提升系统存储容量"></a>Primary Shard - 提升系统存储容量</h3><ul><li>分片是 ES 分布式储存的基石<ul><li>主分片 / 副本分片</li></ul></li><li>通过主分片，将数据分布在所有节点上<ul><li>Primary Shard , 可以将一份索引的数据，分散在多个 Data Node 上，实现储存的水平扩展</li><li>主分片（Primary Shard）数在索引创建时候指定，后续默认不能修改，如要修改，需重建索引</li></ul></li></ul><h3 id="Replica-Shard-提高数据可用性"><a href="#Replica-Shard-提高数据可用性" class="headerlink" title="Replica Shard - 提高数据可用性"></a>Replica Shard - 提高数据可用性</h3><ul><li>数据可用性<ul><li>通过引入副本分片（Replica Shard）提高数据的可用性。一旦主分片丢失，副本分片可以在 Promote 成主分片。副本分片数可以动态调整的。每个节点上都有完备的数据。如果不设置副本分片，一旦出现节点硬件故障，就有可能造成数据丢失。</li></ul></li><li>提高系统的读取性能<ul><li>副本分片由主分片（Primary Shard）同步。通过支持增加 Replica 个数，一定程度可以提高读取的吞吐量</li></ul></li></ul><h3 id="分片数的设置"><a href="#分片数的设置" class="headerlink" title="分片数的设置"></a>分片数的设置</h3><ul><li>如何规划一个索引的主分片数和副本分片数<ul><li>主分片数过小：例如创建一个 1 个 Primary Shard 的 index<ul><li>如果该索引增长很快，集群无法通过增加节点实现对这个索引的数据扩展</li></ul></li><li>主分片数设置过大：导致单个 Shard 容量很小，引发一个节点上有过多分片，影响性能</li><li>副本分片设置过多，会降低集群整体的写入性能</li></ul></li></ul><h3 id="单节点集群"><a href="#单节点集群" class="headerlink" title="单节点集群"></a>单节点集群</h3><ul><li>副本无法分片，集群状态为黄色</li></ul><p><img src="/images/big-data/es-06/3.jpg" alt="3"></p><blockquote><p>使用 cerebro 观察集群状态 <a href="https://github.com/lmenezes/cerebro" target="_blank" rel="noopener">https://github.com/lmenezes/cerebro</a></p></blockquote><h3 id="增加一个数据节点"><a href="#增加一个数据节点" class="headerlink" title="增加一个数据节点"></a>增加一个数据节点</h3><ul><li>集群状态转为绿色</li><li>集群具备故障转移能力</li><li>尝试着将 Replica 设置成 2 和 3，查看集群的状况</li></ul><p><img src="/images/big-data/es-06/4.jpg" alt="4"></p><h3 id="在增加一个节点"><a href="#在增加一个节点" class="headerlink" title="在增加一个节点"></a>在增加一个节点</h3><ul><li>集群具备故障转移能力</li><li>Master 节点会决定分片分配到哪个节点</li><li>通过增加节点数，提高集群的计算能力</li></ul><p><img src="/images/big-data/es-06/5.jpg" alt="5"></p><h3 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h3><ul><li>3 个节点共同组成。包含 1 个索引，索引设置了 3 个 Primary Shard 和 1 个 Replica</li><li>节点 1 是 Master 节点，节点意外出现故障。集群重新选举 Master 节点</li><li>Node3 上的 R0 提升成 P0 ，集群变黄</li><li>R0 和 R1 分配，集群变绿</li></ul><p><img src="/images/big-data/es-06/6.jpg" alt="6"></p><h3 id="集群健康状态"><a href="#集群健康状态" class="headerlink" title="集群健康状态"></a>集群健康状态</h3><ul><li>Green : 健康状态，所有的主分片和副本分片都可用</li><li>Yellow: 亚健康，所有的主分片可用，部分副本分片不可用</li><li>Red：不健康状态，部分主分片不可用</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_cluster/health</span><br></pre></td></tr></table></figure><p><strong>Demo</strong></p><ul><li>启动一个节点，3 个 Primary shard，1 个 Replica，集群黄色，因为无法分片 Replica</li><li>启动 3 个节点，1 个索引上包含 3 个 Primary Shard，一个 Replica</li><li>关闭 Node 1（Master）</li><li>查看 Master Node 重新选举</li><li>集群变黄，然后重新分配</li></ul><p><strong>小结</strong></p><ul><li>主分片，副本分片的作用<ul><li>主分片的分片数，设置后不能修改，除非重新索引数据</li><li>副本分片可以随时修改</li></ul></li><li>集群的故障转移<ul><li>需要集群具备故障转移的能力，必须将索引的副本分片数设置为1，否则，一点有节点就是，就会造成数据丢失</li></ul></li></ul><h2 id="文档分布式存储"><a href="#文档分布式存储" class="headerlink" title="文档分布式存储"></a>文档分布式存储</h2><h3 id="文档储存在分片上"><a href="#文档储存在分片上" class="headerlink" title="文档储存在分片上"></a>文档储存在分片上</h3><ul><li>文档会存储在具体的某个主分片和副本分片上：例如文档 1，会储存在 P0 和 R0 分片上</li><li>文档到分片的映射算法<ul><li>确保文档能均匀分布在所用分片上，充分利用硬件资源，避免部分机器空闲，部门机器繁忙</li><li>潜在的算法<ul><li>随机 / Round Robin. 当查询文档 1，分片数很多，需要多次查询才能查档文档 1</li><li>维护文档到分片的映射关系，当文档数据量大的时候，维护成本高</li><li>实时计算，通过文档 1，自动算出，需要去哪个分片上获取文档</li></ul></li></ul></li></ul><h3 id="文档到分片的路由算法"><a href="#文档到分片的路由算法" class="headerlink" title="文档到分片的路由算法"></a>文档到分片的路由算法</h3><ul><li>shard = hash(_routing) % number_of_primary_shards<ul><li>Hash 算法确保文档均匀分散到分片中</li><li>默认的_routing 值是文档 id</li><li>可以自行制定 routing 数值，例如用相同国家的商品，都分配到制定的 shard</li><li>设置 Index Setting 后，<strong>Primary 数，不能随意修改的根本原因</strong></li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PUT posts/_doc/100?routing=bigdata</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>: <span class="string">"Mastering Elasticsearch"</span>,</span><br><span class="line">  <span class="attr">"body"</span>: <span class="string">"Let's Rock"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h3><ul><li>顺序：index -&gt; hash -&gt; route -&gt; delete -&gt; index -&gt; success -&gt; response</li></ul><p><img src="/images/big-data/es-06/7.jpg" alt="7"></p><h3 id="删除一个文档"><a href="#删除一个文档" class="headerlink" title="删除一个文档"></a>删除一个文档</h3><ul><li>顺序 ：detele -&gt; hash&amp;route -&gt; delete -&gt; delete replica -&gt; success -&gt; deleted -&gt; response</li></ul><p><img src="/images/big-data/es-06/8.jpg" alt="8"></p><p><strong>小结</strong></p><ul><li>可以设置 Index Settings ，控制数据的分片</li><li>Primary Shard 的值不能修改，修改需要重新 Index。默认值是 5，从版本 7 开始，默认值为 1</li><li>索引写入数据后，Replica 值可以修改。增加副本，可提高大并发下的读取性能</li><li>通过控制集群的节点数，设置 Primary Shard 数，实现水平扩展</li></ul><h2 id="分片及其生命周期"><a href="#分片及其生命周期" class="headerlink" title="分片及其生命周期"></a>分片及其生命周期</h2><h3 id="分片的内部原理"><a href="#分片的内部原理" class="headerlink" title="分片的内部原理"></a>分片的内部原理</h3><ul><li>什么是 ES 的分片<ul><li>ES 中最小的工作单元 / 是一个 Lucence 的 Index</li></ul></li><li>一些问题：<ul><li>为什么 ES 的搜索时近实时的（1 秒后被搜到）</li><li>ES 如何保证在断电时数据也不会丢失</li><li>为什么删除文档，并不会立刻释放空间</li></ul></li></ul><h3 id="倒排索引的不可变性"><a href="#倒排索引的不可变性" class="headerlink" title="倒排索引的不可变性"></a>倒排索引的不可变性</h3><ul><li>倒排索引采用 Immutable Design, 一旦生成，不可更改</li><li>不可变性，带来了的好处如下：<ul><li>无需考虑并发写文件的问题，避免了锁机制带来的性能问题</li><li>一旦读入内核的文件系统缓存，便留在那里，只要文件系统存有足够的空间，大部分请求就会直接请求内存，不会命中磁盘，提高了很大的性能</li><li>缓存容易生成和维护 / 数据可以被压缩</li></ul></li><li>不可变更性，带来了的挑战：如果需要让一个新的文档可以被搜索，需要重建整个索引</li></ul><h3 id="Lucence-index"><a href="#Lucence-index" class="headerlink" title="Lucence index"></a>Lucence index</h3><ul><li>在 Lucene 中，单个倒排索引文件被称为 Segment。Segment 是自包含的，不可变更的。多个 Segments 汇总在一起，称为 Lucene 的 Index，其对应的就是 ES 中的 Shard</li><li>当有新文档写入时，会生成新的 Segment, 查询时会同时查询所有的 Segments，并且对结果汇总。Luncene 中有个文件，用来记录所有的 Segments 的信息，叫做 Commit Point</li><li>删除的文档信息，保存在”.del” 文件中</li></ul><p><img src="/images/big-data/es-06/9.jpg" alt="9"></p><h3 id="Refresh"><a href="#Refresh" class="headerlink" title="Refresh"></a>Refresh</h3><ul><li>将 Index buffer 写入 Segment 的过程叫做 Refresh。Refresh 不执行 fsync 操作</li><li>Refresh 频率：默认 1 秒发生一次，可通过 index.refresh_interval 配置。Refresh 后，数据就可以被搜索到了。这也就是为什么 ES 被称为近实时搜索</li><li>如果系统有大量的数据写入，那就会产生很多的 Segment</li><li>Index Buffer 被占满时，会触发 Refresh, 默认值是 JVM 的 10%</li></ul><p><img src="/images/big-data/es-06/10.jpg" alt="10"></p><h3 id="Transaction-Log"><a href="#Transaction-Log" class="headerlink" title="Transaction Log"></a>Transaction Log</h3><ul><li>Segment 写入磁盘的过程相对耗时，借助文件系统缓存，Refresh 时，先将 Segment 写入缓存以开放查询</li><li>蔚来保证数据不会丢失。所有在 Index 文档时，同时写 Transaction Log，高版本开始，Transaction Log 默认落盘。每个分片都有一个 Transaction Log</li><li>当 ES Refresh 时，Index Buffer 被清空，Transaction Log 不会清空</li></ul><p><img src="/images/big-data/es-06/11.jpg" alt="11"></p><h3 id="Flush"><a href="#Flush" class="headerlink" title="Flush"></a>Flush</h3><ul><li>ES Flush &amp; Lucene Commit<ul><li>调用 Refresh ，Index Buffer 清空并且 Refresh</li><li>调用 fsync, 将缓存中的 Segments 写入磁盘</li><li>清空（删除）Transaction Log</li><li>默认 30 分钟调用一次</li><li>Transaction Log 满（默认 512M）</li></ul></li></ul><p><img src="/images/big-data/es-06/12.jpg" alt="12"></p><h3 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h3><ul><li>Segment 很多，需要定期被合并<ul><li>减少 Segments / 删除已经删除的文档</li></ul></li><li>ES 和 Lucene 会自动进行 Merge 操作<ul><li>POST my_index/_forcemerge</li></ul></li></ul><h2 id="剖析分布式查询及相关性算法"><a href="#剖析分布式查询及相关性算法" class="headerlink" title="剖析分布式查询及相关性算法"></a>剖析分布式查询及相关性算法</h2><h3 id="分布式搜索的运行机制"><a href="#分布式搜索的运行机制" class="headerlink" title="分布式搜索的运行机制"></a>分布式搜索的运行机制</h3><ul><li>ES 的搜索，会分两阶段进行<ul><li>第一阶段 - Query</li><li>第二阶段 - Fetch</li></ul></li><li>Query-then-Fetch</li></ul><h3 id="Query-阶段"><a href="#Query-阶段" class="headerlink" title="Query 阶段"></a>Query 阶段</h3><ul><li>用户发出搜索请求到 ES 节点。节点收到请求后，会以 Coordinating 节点的身份，在 6 个主副分片中随机选择 3 个分片，发送查询请求</li><li>被选中的分片执行查询，进行排序。然后，每个分片都会返回 From + Size 个排序后的文档 Id 和排序值给 Coordinating 节点</li></ul><p><img src="/images/big-data/es-06/13.jpg" alt="13"></p><h3 id="Fetch-阶段"><a href="#Fetch-阶段" class="headerlink" title="Fetch 阶段"></a>Fetch 阶段</h3><ul><li>Coordinating Node 会将 Query 阶段，从每个分片获取的排序后的文档 Id 列表，重新进行排序。选取 From 到 From + Size 个文档的 Id</li><li>以 multi get 请求的方式，到相应的分片获取详细的文档数据</li></ul><h3 id="Query-Then-Fetch-潜在的问题"><a href="#Query-Then-Fetch-潜在的问题" class="headerlink" title="Query Then Fetch 潜在的问题"></a>Query Then Fetch 潜在的问题</h3><ul><li>性能问题<ul><li>每个分片上需要查的文档个数 = from + size</li><li>最终协调节点需要处理：number_of_shard * (from + size)</li><li>深度分页 (可以使用 Search After)</li></ul></li><li>相关性算分<ul><li>每个分片都基于自己的分片上的数据进行相关度计算。这会导致打分偏离的情况，特别是数据量很少时。相关性算分在分片之间是相互独立。当文档总数很少的情况下，如果主分片大于 1，主分片越多，相关性算分会越不准。</li></ul></li></ul><h3 id="解决算分不准的方法"><a href="#解决算分不准的方法" class="headerlink" title="解决算分不准的方法"></a>解决算分不准的方法</h3><ul><li>数据量不大的时候，可以将主分片数设置为 1<ul><li>当数据量足够大时候，只要保证文档均匀分散在各个分片上，结果一般就不会出现偏差</li></ul></li><li>使用 DFS Query Then Fetch<ul><li>搜索的 URL 中指定参数 “_search?search_type=dfs_query_then_fetch”</li><li>到每个分片把各分片的词频和文档频率进行搜集，然后完整的进行一次相关性算分，消耗更加多的 CPU 和内存，执行性能低下，一般不建议使用</li></ul></li></ul><h3 id="相关性算分问题-Demo"><a href="#相关性算分问题-Demo" class="headerlink" title="相关性算分问题 Demo"></a>相关性算分问题 Demo</h3><ul><li>写入 3 条记录 “Good” / “Good moring” / “good morning everyone”</li><li>使用 1 个主分片测试，Good 应该排在第一，Good DF 数值应该是 3</li><li>和 20 个主分片测试</li><li>当多个主分片时，3 个文档的算分都一样。可以通过 Explain API 进行分析</li><li>在 3 个主分片上执行 DFS Query Then Fetch ，结果和一个分片上一致</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">DELETE message</span><br><span class="line">PUT message</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"number_of_shards"</span>: <span class="number">20</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">GET message</span><br><span class="line">POST message/_doc?routing=1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"good"</span></span><br><span class="line">&#125;</span><br><span class="line">POST message/_doc?routing=2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"good morning"</span></span><br><span class="line">&#125;</span><br><span class="line">POST message/_doc?routing=3</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"good morning everyone"</span></span><br><span class="line">&#125;</span><br><span class="line">POST message/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST message/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"content"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"good"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST message/_search?search_type=dfs_query_then_fetch</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"content"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"good"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="排序及-Doc-Values-amp-Field-Data"><a href="#排序及-Doc-Values-amp-Field-Data" class="headerlink" title="排序及 Doc Values &amp; Field Data"></a>排序及 Doc Values &amp; Field Data</h2><h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><ul><li>ES 默认采用相关性算分对结果进行降序排序</li><li>可以通过设置 sorting 参数，自行设定排序</li><li>如果不指定 _score, 算分为 null</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST /kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">5</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"sort"</span>: [</span><br><span class="line">    &#123;<span class="attr">"order_date"</span>: &#123;<span class="attr">"order"</span>: <span class="string">"desc"</span>&#125;&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="多字段进行排序"><a href="#多字段进行排序" class="headerlink" title="多字段进行排序"></a>多字段进行排序</h3><ul><li>组合多个条件</li><li>优先考虑写在前面的排序</li><li>支持对相关性算分进行排序</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">POST /kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">5</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"sort"</span>: [</span><br><span class="line">    &#123;<span class="attr">"order_date"</span>: &#123;<span class="attr">"order"</span>: <span class="string">"desc"</span>&#125;&#125;,</span><br><span class="line">    &#123;<span class="attr">"_doc"</span>:&#123;<span class="attr">"order"</span>: <span class="string">"asc"</span>&#125;&#125;,</span><br><span class="line">    &#123;<span class="attr">"_score"</span>:&#123; <span class="attr">"order"</span>: <span class="string">"desc"</span>&#125;&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="对-Text-类型排序"><a href="#对-Text-类型排序" class="headerlink" title="对 Text 类型排序"></a>对 Text 类型排序</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">GET kibana_sample_data_ecommerce/_mapping</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对 text 字段进行排序。默认会报错，需打开fielddata</span></span><br><span class="line">POST /kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">5</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"sort"</span>: [</span><br><span class="line">    &#123;<span class="attr">"customer_full_name"</span>: &#123;<span class="attr">"order"</span>: <span class="string">"desc"</span>&#125;&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打开 text的 fielddata</span></span><br><span class="line">PUT kibana_sample_data_ecommerce/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    <span class="attr">"customer_full_name"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fielddata"</span>: <span class="literal">true</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="排序的过程"><a href="#排序的过程" class="headerlink" title="排序的过程"></a>排序的过程</h3><ul><li>排序是针对字段原始内容进行的。倒排索引无法发挥作用</li><li>需要用到正排索引。通过文档 ID 和字段快速得到字段原始内容</li><li>ES 有 2 种实现方式<ul><li>Fielddata</li><li>Doc Values (列式存储，对 Text 类型无效）</li></ul></li></ul><h3 id="Doc-Values-vs-Field-Data"><a href="#Doc-Values-vs-Field-Data" class="headerlink" title="Doc Values vs. Field Data"></a>Doc Values vs. Field Data</h3><table><thead><tr><th align="left"></th><th align="left">Doc Values</th><th align="left">Field data</th></tr></thead><tbody><tr><td align="left">何时创建</td><td align="left">索引时，和倒排索引一起创建</td><td align="left">搜索时候动态创建</td></tr><tr><td align="left">创建位置</td><td align="left">磁盘文件</td><td align="left">JVM Heap</td></tr><tr><td align="left">优点</td><td align="left">避免大量内存占用</td><td align="left">索引速度快，不占用额外的磁盘空间</td></tr><tr><td align="left">缺点</td><td align="left">降低索引速度，占用额外磁盘空间</td><td align="left">文档过多时，动态创建开销大，占用过多 JVM Heap</td></tr><tr><td align="left">缺省值</td><td align="left">ES 2.x 之后</td><td align="left">ES1.x 及之前</td></tr></tbody></table><h3 id="打开-Fielddata"><a href="#打开-Fielddata" class="headerlink" title="打开 Fielddata"></a>打开 Fielddata</h3><ul><li>默认关闭，可以通过 Mapping 设置打开。修改设置后，即时生效，无需缩减索引</li><li>其他字段类型不支持，支持对 Text 进行设定</li><li>打开后，可以对 Text 字段进行排序，但是是对分词后的 term 排序，所以，结果往往无法满足预期，不建议使用</li><li>部分情况下打开，满足一些聚合分析的特定需求</li></ul><h3 id="关闭-Doc-Values"><a href="#关闭-Doc-Values" class="headerlink" title="关闭 Doc Values"></a>关闭 Doc Values</h3><ul><li>默认启动，可以通过 Mapping 设置关闭<ul><li>增加索引的速度 / 减少磁盘空间</li></ul></li><li>如果重新打开，需要重建索引</li><li>什么时候需要关闭<ul><li>明确不需要做排序及聚合分析</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 关闭 keyword的 doc values</span></span><br><span class="line">PUT test_keyword</span><br><span class="line">PUT test_keyword/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    <span class="attr">"user_name"</span>:&#123;</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">      <span class="attr">"doc_values"</span>:<span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="获取-Doc-Values-amp-Fielddata-中储存的内容"><a href="#获取-Doc-Values-amp-Fielddata-中储存的内容" class="headerlink" title="获取 Doc Values &amp; Fielddata 中储存的内容"></a>获取 Doc Values &amp; Fielddata 中储存的内容</h3><ul><li>Text 类型的不支持 Doc Values</li><li>Text 类型打开 Fielddata 后，可以查看分词后的数据</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">DELETE temp_users</span><br><span class="line">PUT temp_users</span><br><span class="line">PUT temp_users/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"properties"</span>: &#123;</span><br><span class="line">    <span class="attr">"name"</span>:&#123;<span class="attr">"type"</span>: <span class="string">"text"</span>,<span class="attr">"fielddata"</span>: <span class="literal">true</span>&#125;,</span><br><span class="line">    <span class="attr">"desc"</span>:&#123;<span class="attr">"type"</span>: <span class="string">"text"</span>,<span class="attr">"fielddata"</span>: <span class="literal">true</span>&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST temp_users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"Jack"</span>,<span class="attr">"desc"</span>:<span class="string">"Jack is a good boy!"</span>,<span class="attr">"age"</span>:<span class="number">10</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 打开fielddata 后，查看 docvalue_fields数据</span></span><br><span class="line">POST  temp_users/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"docvalue_fields"</span>: [</span><br><span class="line">    <span class="string">"name"</span>,<span class="string">"desc"</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看整型字段的docvalues</span></span><br><span class="line">POST  temp_users/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"docvalue_fields"</span>: [</span><br><span class="line">    <span class="string">"age"</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>Fielddata Demo</strong></p><ul><li>对Text字段设置fielddata ，支持随时修改</li><li>Doc Values 可以在Mapping 中关闭，但是需要重新索引</li><li>Text 不支持Doc Values</li><li>使用docvalue_fields 查看存储的信息</li></ul><h2 id="分页与遍历-From-Size-Search-After-amp-Scorll-API"><a href="#分页与遍历-From-Size-Search-After-amp-Scorll-API" class="headerlink" title="分页与遍历 - From, Size, Search After &amp; Scorll API"></a>分页与遍历 - From, Size, Search After &amp; Scorll API</h2><h3 id="From-Size"><a href="#From-Size" class="headerlink" title="From / Size"></a>From / Size</h3><ul><li>默认情况下，查询按照相关度算分排序，返回前 10 条记录</li><li>容易理解的分页方案<ul><li>From: 开始位置</li><li>Size: 期望获取文档的总数</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">POST kibana_sample_data_ecommerce/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"from"</span>: <span class="number">10</span>,</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">20</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="分布式系统中深度分页的问题"><a href="#分布式系统中深度分页的问题" class="headerlink" title="分布式系统中深度分页的问题"></a>分布式系统中深度分页的问题</h3><ul><li>ES 天生就是分布式，查询信息，但是数据分别保存在多个分片，多台机器，ES 天生就需要满足排序的需要（按照相关性算分）</li><li>当一个查询：From = 990 ，Size =10<ul><li>会在每个分片上先获取 1000 个文档。然后，通过 Coordinating Node 聚合所有结果。最后在通过排序选取前 1000 个文档</li><li>页数越深，占用内容越多。为了避免深度分页带来的内存开销。ES 有个设定，默认限定到 10000 个文档<ul><li>index.max_result_window</li></ul></li></ul></li></ul><p><img src="/images/big-data/es-06/14.jpg" alt="14"></p><h3 id="Search-After-避免深度分页的问题"><a href="#Search-After-避免深度分页的问题" class="headerlink" title="Search After 避免深度分页的问题"></a>Search After 避免深度分页的问题</h3><ul><li>避免深度分页的性能问题，可以实时获取下一页文档信息<ul><li>不支持指定页数（From）</li><li>不能往下翻</li></ul></li><li>第一步搜索需要指定 sort，并且保证值是唯一的（可以通过加入_id 保证唯一性）</li><li>然后使用上一次，最后一个文档的 sort 值进行查询</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">DELETE users</span><br><span class="line"></span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user1"</span>,<span class="attr">"age"</span>:<span class="number">10</span>&#125;</span><br><span class="line"></span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user2"</span>,<span class="attr">"age"</span>:<span class="number">11</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user2"</span>,<span class="attr">"age"</span>:<span class="number">12</span>&#125;</span><br><span class="line"></span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user2"</span>,<span class="attr">"age"</span>:<span class="number">13</span>&#125;</span><br><span class="line"></span><br><span class="line">POST users/_count</span><br><span class="line"></span><br><span class="line">POST users/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"size"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"match_all"</span>: &#123;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"sort"</span>: [</span><br><span class="line">        &#123;<span class="attr">"age"</span>: <span class="string">"desc"</span>&#125; ,</span><br><span class="line">        &#123;<span class="attr">"_id"</span>: <span class="string">"asc"</span>&#125;    </span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST users/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"size"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"match_all"</span>: &#123;&#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"search_after"</span>:</span><br><span class="line">        [</span><br><span class="line">          <span class="number">10</span>,</span><br><span class="line">          <span class="string">"ZQ0vYGsBrR8X3IP75QqX"</span>],</span><br><span class="line">    <span class="attr">"sort"</span>: [</span><br><span class="line">        &#123;<span class="attr">"age"</span>: <span class="string">"desc"</span>&#125; ,</span><br><span class="line">        &#123;<span class="attr">"_id"</span>: <span class="string">"asc"</span>&#125;    </span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Search-After-是如何解决深度分页的问题"><a href="#Search-After-是如何解决深度分页的问题" class="headerlink" title="Search After 是如何解决深度分页的问题"></a>Search After 是如何解决深度分页的问题</h3><ul><li>假设 Size 是 10</li><li>当查询 990 - 1000</li><li>通过唯一排序值定位，将每次要处理的文档都控制在 10</li></ul><p><img src="/images/big-data/es-06/15.jpg" alt="15"></p><h3 id="Scoll-API"><a href="#Scoll-API" class="headerlink" title="Scoll API"></a>Scoll API</h3><ul><li>创建一个快照，有新的数据写入以后，无法被查找</li><li>每次查询后，输入上一次的 Sroll ID</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">DELETE users</span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user1"</span>,<span class="attr">"age"</span>:<span class="number">10</span>&#125;</span><br><span class="line"></span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user2"</span>,<span class="attr">"age"</span>:<span class="number">20</span>&#125;</span><br><span class="line"></span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user3"</span>,<span class="attr">"age"</span>:<span class="number">30</span>&#125;</span><br><span class="line"></span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user4"</span>,<span class="attr">"age"</span>:<span class="number">40</span>&#125;</span><br><span class="line"></span><br><span class="line">POST /users/_search?scroll=5m</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"size"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"match_all"</span> : &#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST users/_doc</span><br><span class="line">&#123;<span class="attr">"name"</span>:<span class="string">"user5"</span>,<span class="attr">"age"</span>:<span class="number">50</span>&#125;</span><br><span class="line">POST /_search/scroll</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"scroll"</span> : <span class="string">"1m"</span>,</span><br><span class="line">    <span class="attr">"scroll_id"</span> : <span class="string">"DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAWAWbWdoQXR2d3ZUd2kzSThwVTh4bVE0QQ=="</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="不同的搜索类型和使用场景"><a href="#不同的搜索类型和使用场景" class="headerlink" title="不同的搜索类型和使用场景"></a>不同的搜索类型和使用场景</h3><ul><li>Regular<ul><li>需要实时获取顶部的部分文档。例如查询最新的订单</li></ul></li><li>Scorll<ul><li>需要全部文档，例如导出全部数据</li></ul></li><li>Pagination<ul><li>From 和 Size</li></ul></li><li>如何需要深度分页，则选用 Search After</li></ul><h2 id="处理并发读写操作"><a href="#处理并发读写操作" class="headerlink" title="处理并发读写操作"></a>处理并发读写操作</h2><h3 id="并发控制的必要性"><a href="#并发控制的必要性" class="headerlink" title="并发控制的必要性"></a>并发控制的必要性</h3><ul><li>两个 Web 程序同时更新某个文档，如果缺乏有效的并发，会导致更改的数据丢失</li><li>悲观并发控制<ul><li>假定有变更冲突的可能，会对资源加锁，防止冲突。例如数据库行锁</li></ul></li><li>乐观并发控制<ul><li>假设突然是不会发生的，不会阻塞正在尝试的操作。如果数据在读写中被修改，更新将会失败。应用程序决定如何解决冲突，例如重试更新，使用新的数据，或者将错误报告给用户</li></ul></li><li>ES 采用的乐观并发控制</li></ul><p><img src="/images/big-data/es-06/16.jpg" alt="16"></p><h3 id="ES-的乐观并发控制"><a href="#ES-的乐观并发控制" class="headerlink" title="ES 的乐观并发控制"></a>ES 的乐观并发控制</h3><ul><li>ES 中的文档是不可变更的。如果你更新一个文档，会将会文档标记为删除，同时增加一个全新当文档，同时文档的 version 字段加 1</li><li>内部版本控制<ul><li>If_seq_no + If_primary_term</li></ul></li><li>使用外部版本（使用其他数据库作为主要数据存储）<ul><li>version + version_type = external</li></ul></li></ul><p><img src="/images/big-data/es-06/17.jpg" alt="17"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">DELETE products</span><br><span class="line">PUT products</span><br><span class="line">PUT products/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"iphone"</span>,</span><br><span class="line">  <span class="attr">"count"</span>:<span class="number">100</span></span><br><span class="line">&#125;</span><br><span class="line">GET products/_doc/1</span><br><span class="line"><span class="comment">//只能执行一次</span></span><br><span class="line">PUT products/_doc/1?if_seq_no=0&amp;if_primary_term=1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"iphone"</span>,</span><br><span class="line">  <span class="attr">"count"</span>:<span class="number">110</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//数据库版本号为主</span></span><br><span class="line">PUT products/_doc/1?version=23&amp;version_type=external</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"iphone"</span>,</span><br><span class="line">  <span class="attr">"count"</span>:<span class="number">130</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Bucket-amp-Metric-聚合分析及嵌套聚合"><a href="#Bucket-amp-Metric-聚合分析及嵌套聚合" class="headerlink" title="Bucket &amp; Metric 聚合分析及嵌套聚合"></a>Bucket &amp; Metric 聚合分析及嵌套聚合</h2><h3 id="Bucket-amp-Metric-Aggregation"><a href="#Bucket-amp-Metric-Aggregation" class="headerlink" title="Bucket &amp; Metric Aggregation"></a>Bucket &amp; Metric Aggregation</h3><ul><li>Metric 一些系列的统计方法</li><li>Bucket 一组满足条件的文档</li></ul><p><img src="/images/big-data/es-06/18.jpg" alt="18"></p><h3 id="Aggregation-的语法"><a href="#Aggregation-的语法" class="headerlink" title="Aggregation 的语法"></a>Aggregation 的语法</h3><p>Aggregation 属于 Search 的一部分。一般情况下，建议将其 Size 指定为 0</p><p><img src="/images/big-data/es-06/19.jpg" alt="19"></p><p><strong>例子: 工资统计信息</strong></p><p><img src="/images/big-data/es-06/20.jpg" alt="20"></p><h3 id="Mertric-Aggregation"><a href="#Mertric-Aggregation" class="headerlink" title="Mertric Aggregation"></a>Mertric Aggregation</h3><ul><li>单值分析：只输出一个分析结果<ul><li>min，max，avg，sum</li><li>Cardinality（类似 distinct Count）</li></ul></li><li>多值分析：输出多个分析结果<ul><li>stats, extended stats</li><li>percentile, percentile rank</li><li>top hits （排在前面的示例）</li></ul></li></ul><h3 id="Metric-聚合的具体-Demo"><a href="#Metric-聚合的具体-Demo" class="headerlink" title="Metric 聚合的具体 Demo"></a>Metric 聚合的具体 Demo</h3><ul><li>查看最低工资</li><li>查看最高工资</li><li>一个聚合输出多个值</li><li>一次查询包含多个聚合<ul><li>同时查看最低, 最高和平均工资</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line">DELETE /employees</span><br><span class="line">PUT /employees/</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span> : &#123;</span><br><span class="line">      <span class="attr">"properties"</span> : &#123;</span><br><span class="line">        <span class="attr">"age"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"integer"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"gender"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"job"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">50</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"name"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"salary"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"integer"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /employees/_bulk</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"1"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Emma"</span>,<span class="attr">"age"</span>:<span class="number">32</span>,<span class="attr">"job"</span>:<span class="string">"Product Manager"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>:<span class="number">35000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"2"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Underwood"</span>,<span class="attr">"age"</span>:<span class="number">41</span>,<span class="attr">"job"</span>:<span class="string">"Dev Manager"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">50000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"3"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Tran"</span>,<span class="attr">"age"</span>:<span class="number">25</span>,<span class="attr">"job"</span>:<span class="string">"Web Designer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>:<span class="number">18000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"4"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Rivera"</span>,<span class="attr">"age"</span>:<span class="number">26</span>,<span class="attr">"job"</span>:<span class="string">"Web Designer"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>: <span class="number">22000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"5"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Rose"</span>,<span class="attr">"age"</span>:<span class="number">25</span>,<span class="attr">"job"</span>:<span class="string">"QA"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>:<span class="number">18000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"6"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Lucy"</span>,<span class="attr">"age"</span>:<span class="number">31</span>,<span class="attr">"job"</span>:<span class="string">"QA"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>: <span class="number">25000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"7"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Byrd"</span>,<span class="attr">"age"</span>:<span class="number">27</span>,<span class="attr">"job"</span>:<span class="string">"QA"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>:<span class="number">20000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"8"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Foster"</span>,<span class="attr">"age"</span>:<span class="number">27</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">20000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"9"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Gregory"</span>,<span class="attr">"age"</span>:<span class="number">32</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>:<span class="number">22000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"10"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Bryant"</span>,<span class="attr">"age"</span>:<span class="number">20</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">9000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"11"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Jenny"</span>,<span class="attr">"age"</span>:<span class="number">36</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>:<span class="number">38000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"12"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Mcdonald"</span>,<span class="attr">"age"</span>:<span class="number">31</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">32000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"13"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Jonthna"</span>,<span class="attr">"age"</span>:<span class="number">30</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>:<span class="number">30000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"14"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Marshall"</span>,<span class="attr">"age"</span>:<span class="number">32</span>,<span class="attr">"job"</span>:<span class="string">"Javascript Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">25000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"15"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"King"</span>,<span class="attr">"age"</span>:<span class="number">33</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>:<span class="number">28000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"16"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Mccarthy"</span>,<span class="attr">"age"</span>:<span class="number">21</span>,<span class="attr">"job"</span>:<span class="string">"Javascript Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">16000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"17"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Goodwin"</span>,<span class="attr">"age"</span>:<span class="number">25</span>,<span class="attr">"job"</span>:<span class="string">"Javascript Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">16000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"18"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Catherine"</span>,<span class="attr">"age"</span>:<span class="number">29</span>,<span class="attr">"job"</span>:<span class="string">"Javascript Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>: <span class="number">20000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"19"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Boone"</span>,<span class="attr">"age"</span>:<span class="number">30</span>,<span class="attr">"job"</span>:<span class="string">"DBA"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">30000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"20"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Kathy"</span>,<span class="attr">"age"</span>:<span class="number">29</span>,<span class="attr">"job"</span>:<span class="string">"DBA"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>: <span class="number">20000</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Metric 聚合，找到最低的工资</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"min_salary"</span>: &#123;</span><br><span class="line">      <span class="attr">"min"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Metric 聚合，找到最高的工资</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"max_salary"</span>: &#123;</span><br><span class="line">      <span class="attr">"max"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 多个 Metric 聚合，找到最低最高和平均工资</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"max_salary"</span>: &#123;</span><br><span class="line">      <span class="attr">"max"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"min_salary"</span>: &#123;</span><br><span class="line">      <span class="attr">"min"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">      <span class="attr">"avg"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 一个聚合，输出多值</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"stats_salary"</span>: &#123;</span><br><span class="line">      <span class="attr">"stats"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Bucket"><a href="#Bucket" class="headerlink" title="Bucket"></a>Bucket</h3><ul><li>按照一定的规则，将文档分配到不同的桶中，从而达到分类的目的。ES 提供的一些常见的 Bucket Aggregation<ul><li>Terms</li><li>数字类型</li><li>Range / Date Range</li><li>Histogram / Data Histogram</li></ul></li><li>支持嵌套：也就在桶里在做分桶</li></ul><p><img src="/images/big-data/es-06/21.jpg" alt="21"></p><h3 id="Terms-Aggregation"><a href="#Terms-Aggregation" class="headerlink" title="Terms Aggregation"></a>Terms Aggregation</h3><ul><li>字段需要打开 fielddata，才能进行 Terms Aggregation<ul><li>Keyword 默认支持 doc_values</li><li>Text 需要在 Mapping 中 enable ，会按照分词后的结果进行分</li></ul></li><li>Demo<ul><li>对 job 和 job.keyword 进行聚合</li><li>对性别进行 Terms 聚合</li><li>指定 bucket size</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对keword 进行聚合</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"job.keyword"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对 Text 字段进行 terms 聚合查询，失败</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"job"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对 Text 字段打开 fielddata，支持terms aggregation</span></span><br><span class="line">PUT employees/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"properties"</span> : &#123;</span><br><span class="line">    <span class="attr">"job"</span>:&#123;</span><br><span class="line">       <span class="attr">"type"</span>:     <span class="string">"text"</span>,</span><br><span class="line">       <span class="attr">"fielddata"</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对job.keyword 和 job 进行 terms 聚合，分桶的总数并不一样</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"cardinate"</span>: &#123;</span><br><span class="line">      <span class="attr">"cardinality"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 对 性别的 keyword 进行聚合</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"gender"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"gender"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Cardinality"><a href="#Cardinality" class="headerlink" title="Cardinality"></a>Cardinality</h3><p>类似 SQL 中的 Distinct</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"cardinate"</span>: &#123;</span><br><span class="line">      <span class="attr">"cardinality"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"job.keyword"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Bucket-Size-amp-Top-Hists-Demo"><a href="#Bucket-Size-amp-Top-Hists-Demo" class="headerlink" title="Bucket Size &amp; Top Hists Demo"></a>Bucket Size &amp; Top Hists Demo</h3><ul><li>应用场景：当后去分桶后，桶内最匹配的顶部文档列表</li><li>Size : 按年龄分桶，找出指定数据量的分桶信息</li><li>Top Hits：查看各个工种中，年纪最大的 3 名员工</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指定 bucket 的 size</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"ages_5"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"age"</span>,</span><br><span class="line">        <span class="attr">"size"</span>:<span class="number">3</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指定size，不同工种中，年纪最大的3个员工的具体信息</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"job.keyword"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>:&#123;</span><br><span class="line">        <span class="attr">"old_employee"</span>:&#123;</span><br><span class="line">          <span class="attr">"top_hits"</span>:&#123;</span><br><span class="line">            <span class="attr">"size"</span>:<span class="number">3</span>,</span><br><span class="line">            <span class="attr">"sort"</span>:[</span><br><span class="line">              &#123;</span><br><span class="line">                <span class="attr">"age"</span>:&#123;</span><br><span class="line">                  <span class="attr">"order"</span>:<span class="string">"desc"</span></span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="优化-Terms-聚合的性能"><a href="#优化-Terms-聚合的性能" class="headerlink" title="优化 Terms 聚合的性能"></a>优化 Terms 聚合的性能</h3><p>在聚合经常发生，性能高的，索引不断写入</p><p><img src="/images/big-data/es-06/22.jpg" alt="22"></p><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html</a></p></blockquote><h3 id="Range-amp-Histogram-聚合"><a href="#Range-amp-Histogram-聚合" class="headerlink" title="Range &amp; Histogram 聚合"></a>Range &amp; Histogram 聚合</h3><ul><li>按照数字的范围，进行分桶</li><li>在 Range Aggregation 中，可以自定义 Key</li><li>Demo：<ul><li>按照工资的 Range 分桶</li><li>按照工资的间隔（Histogram）分桶</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Salary Ranges 分桶，可以自己定义 key</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"salary_range"</span>: &#123;</span><br><span class="line">      <span class="attr">"range"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"salary"</span>,</span><br><span class="line">        <span class="attr">"ranges"</span>:[</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="attr">"to"</span>:<span class="number">10000</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="attr">"from"</span>:<span class="number">10000</span>,</span><br><span class="line">            <span class="attr">"to"</span>:<span class="number">20000</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="attr">"key"</span>:<span class="string">"&gt;20000"</span>,</span><br><span class="line">            <span class="attr">"from"</span>:<span class="number">20000</span></span><br><span class="line">          &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Salary Histogram,工资0到10万，以 5000一个区间进行分桶</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"salary_histrogram"</span>: &#123;</span><br><span class="line">      <span class="attr">"histogram"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"salary"</span>,</span><br><span class="line">        <span class="attr">"interval"</span>:<span class="number">5000</span>,</span><br><span class="line">        <span class="attr">"extended_bounds"</span>:&#123;</span><br><span class="line">          <span class="attr">"min"</span>:<span class="number">0</span>,</span><br><span class="line">          <span class="attr">"max"</span>:<span class="number">100000</span></span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Bucket-Metric-Aggregation"><a href="#Bucket-Metric-Aggregation" class="headerlink" title="Bucket + Metric Aggregation"></a>Bucket + Metric Aggregation</h3><ul><li>Bucket 聚合分析允许通过添加子聚合分析进一步分析，子聚合分析可以是<ul><li>Bucket</li><li>Metric</li></ul></li><li>Demo<ul><li>按照工作类型进行分桶，并统计工资信息</li><li>先按照工作类型分桶，然后按性别分桶，并统计工资信息</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 嵌套聚合1，按照工作类型分桶，并统计工资信息</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"Job_salary_stats"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job.keyword"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"salary"</span>: &#123;</span><br><span class="line">          <span class="attr">"stats"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 多次嵌套。根据工作类型分桶，然后按照性别分桶，计算工资的统计信息</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"Job_gender_stats"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job.keyword"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"gender_stats"</span>: &#123;</span><br><span class="line">          <span class="attr">"terms"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"gender"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">            <span class="attr">"salary_stats"</span>: &#123;</span><br><span class="line">              <span class="attr">"stats"</span>: &#123;</span><br><span class="line">                <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Pipeline-聚合分析"><a href="#Pipeline-聚合分析" class="headerlink" title="Pipeline 聚合分析"></a>Pipeline 聚合分析</h2><h3 id="一个例子：Pipeline：min-bucket"><a href="#一个例子：Pipeline：min-bucket" class="headerlink" title="一个例子：Pipeline：min_bucket"></a>一个例子：Pipeline：min_bucket</h3><ul><li>在员工数最多的工种里，找出平均工资最低的工种</li></ul><p><img src="/images/big-data/es-06/23.jpg" alt="23"></p><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><ul><li>管道的概念：支持对聚合分析的结果，再次进行聚合分析</li><li>Pipeline 的分析结果会输出到原结果汇总，根据位置的不同，分为两类<ul><li>Sibling - 结果和现有分析结果同级<ul><li>Max, min, Avg &amp; Sum Bucket</li><li>Stats, Extened Status Bucket</li><li>Percentiles Bucket</li></ul></li><li>Parent - 结果内嵌到现有的聚合分析结果之中<ul><li>Derivative（求导）</li><li>Cumultive Sum（累计求和）</li><li>Moving Function（滑动窗口）</li></ul></li></ul></li></ul><h3 id="Sibling-Pipeline-的例子"><a href="#Sibling-Pipeline-的例子" class="headerlink" title="Sibling Pipeline 的例子"></a>Sibling Pipeline 的例子</h3><ul><li>对不同类型工作的，平均工资<ul><li>求最大</li><li>平均</li><li>统计信息</li><li>百分位数</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">DELETE employees</span><br><span class="line">PUT /employees/_bulk</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"1"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Emma"</span>,<span class="attr">"age"</span>:<span class="number">32</span>,<span class="attr">"job"</span>:<span class="string">"Product Manager"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>:<span class="number">35000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"2"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Underwood"</span>,<span class="attr">"age"</span>:<span class="number">41</span>,<span class="attr">"job"</span>:<span class="string">"Dev Manager"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">50000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"3"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Tran"</span>,<span class="attr">"age"</span>:<span class="number">25</span>,<span class="attr">"job"</span>:<span class="string">"Web Designer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>:<span class="number">18000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"4"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Rivera"</span>,<span class="attr">"age"</span>:<span class="number">26</span>,<span class="attr">"job"</span>:<span class="string">"Web Designer"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>: <span class="number">22000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"5"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Rose"</span>,<span class="attr">"age"</span>:<span class="number">25</span>,<span class="attr">"job"</span>:<span class="string">"QA"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>:<span class="number">18000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"6"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Lucy"</span>,<span class="attr">"age"</span>:<span class="number">31</span>,<span class="attr">"job"</span>:<span class="string">"QA"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>: <span class="number">25000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"7"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Byrd"</span>,<span class="attr">"age"</span>:<span class="number">27</span>,<span class="attr">"job"</span>:<span class="string">"QA"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>:<span class="number">20000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"8"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Foster"</span>,<span class="attr">"age"</span>:<span class="number">27</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">20000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"9"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Gregory"</span>,<span class="attr">"age"</span>:<span class="number">32</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>:<span class="number">22000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"10"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Bryant"</span>,<span class="attr">"age"</span>:<span class="number">20</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">9000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"11"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Jenny"</span>,<span class="attr">"age"</span>:<span class="number">36</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>:<span class="number">38000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"12"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Mcdonald"</span>,<span class="attr">"age"</span>:<span class="number">31</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">32000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"13"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Jonthna"</span>,<span class="attr">"age"</span>:<span class="number">30</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>:<span class="number">30000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"14"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Marshall"</span>,<span class="attr">"age"</span>:<span class="number">32</span>,<span class="attr">"job"</span>:<span class="string">"Javascript Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">25000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"15"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"King"</span>,<span class="attr">"age"</span>:<span class="number">33</span>,<span class="attr">"job"</span>:<span class="string">"Java Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>:<span class="number">28000</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"16"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Mccarthy"</span>,<span class="attr">"age"</span>:<span class="number">21</span>,<span class="attr">"job"</span>:<span class="string">"Javascript Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">16000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"17"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Goodwin"</span>,<span class="attr">"age"</span>:<span class="number">25</span>,<span class="attr">"job"</span>:<span class="string">"Javascript Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">16000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"18"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Catherine"</span>,<span class="attr">"age"</span>:<span class="number">29</span>,<span class="attr">"job"</span>:<span class="string">"Javascript Programmer"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>: <span class="number">20000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"19"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Boone"</span>,<span class="attr">"age"</span>:<span class="number">30</span>,<span class="attr">"job"</span>:<span class="string">"DBA"</span>,<span class="attr">"gender"</span>:<span class="string">"male"</span>,<span class="attr">"salary"</span>: <span class="number">30000</span>&#125;</span><br><span class="line">&#123; <span class="attr">"index"</span> : &#123;  <span class="attr">"_id"</span> : <span class="string">"20"</span> &#125; &#125;</span><br><span class="line">&#123; <span class="attr">"name"</span> : <span class="string">"Kathy"</span>,<span class="attr">"age"</span>:<span class="number">29</span>,<span class="attr">"job"</span>:<span class="string">"DBA"</span>,<span class="attr">"gender"</span>:<span class="string">"female"</span>,<span class="attr">"salary"</span>: <span class="number">20000</span>&#125;</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 平均工资最低的工作类型</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job.keyword"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">          <span class="attr">"avg"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"min_salary_by_job"</span>:&#123;</span><br><span class="line">      <span class="attr">"min_bucket"</span>: &#123;</span><br><span class="line">        <span class="attr">"buckets_path"</span>: <span class="string">"jobs&gt;avg_salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 平均工资最高的工作类型</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job.keyword"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">          <span class="attr">"avg"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"max_salary_by_job"</span>:&#123;</span><br><span class="line">      <span class="attr">"max_bucket"</span>: &#123;</span><br><span class="line">        <span class="attr">"buckets_path"</span>: <span class="string">"jobs&gt;avg_salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 平均工资的平均工资</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job.keyword"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">          <span class="attr">"avg"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"avg_salary_by_job"</span>:&#123;</span><br><span class="line">      <span class="attr">"avg_bucket"</span>: &#123;</span><br><span class="line">        <span class="attr">"buckets_path"</span>: <span class="string">"jobs&gt;avg_salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 平均工资的统计分析</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job.keyword"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">          <span class="attr">"avg"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"stats_salary_by_job"</span>:&#123;</span><br><span class="line">      <span class="attr">"stats_bucket"</span>: &#123;</span><br><span class="line">        <span class="attr">"buckets_path"</span>: <span class="string">"jobs&gt;avg_salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 平均工资的百分位数</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job.keyword"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">          <span class="attr">"avg"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"percentiles_salary_by_job"</span>:&#123;</span><br><span class="line">      <span class="attr">"percentiles_bucket"</span>: &#123;</span><br><span class="line">        <span class="attr">"buckets_path"</span>: <span class="string">"jobs&gt;avg_salary"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Parent-Pipeline-Derivative"><a href="#Parent-Pipeline-Derivative" class="headerlink" title="Parent Pipeline: Derivative"></a>Parent Pipeline: Derivative</h3><p>按年龄、对工资进行求导（看工资发展的趋势）</p><p><img src="/images/big-data/es-06/24.jpg" alt="24"></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 按照年龄对平均工资求导 </span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line"><span class="attr">"aggs"</span>: &#123;</span><br><span class="line">  <span class="attr">"age"</span>: &#123;</span><br><span class="line">    <span class="attr">"histogram"</span>: &#123;</span><br><span class="line">      <span class="attr">"field"</span>: <span class="string">"age"</span>,</span><br><span class="line">      <span class="attr">"min_doc_count"</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"interval"</span>: <span class="number">1</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">      <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"derivative_avg_salary"</span>:&#123;</span><br><span class="line">        <span class="attr">"derivative"</span>: &#123;</span><br><span class="line">          <span class="attr">"buckets_path"</span>: <span class="string">"avg_salary"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//return </span></span><br><span class="line">"aggregations" : &#123;</span><br><span class="line">  "age" : &#123;</span><br><span class="line">    "buckets" : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"key"</span> : <span class="number">20.0</span>,</span><br><span class="line">        <span class="attr">"doc_count"</span> : <span class="number">1</span>,</span><br><span class="line">        <span class="attr">"avg_salary"</span> : &#123;</span><br><span class="line">          <span class="attr">"value"</span> : <span class="number">9000.0</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"key"</span> : <span class="number">21.0</span>,</span><br><span class="line">        <span class="attr">"doc_count"</span> : <span class="number">1</span>,</span><br><span class="line">        <span class="attr">"avg_salary"</span> : &#123;</span><br><span class="line">          <span class="attr">"value"</span> : <span class="number">16000.0</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"derivative_avg_salary"</span> : &#123;</span><br><span class="line">          <span class="attr">"value"</span> : <span class="number">7000.0</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Parent-Pipeline"><a href="#Parent-Pipeline" class="headerlink" title="Parent Pipeline"></a>Parent Pipeline</h3><ul><li>年龄直方图划分的平均工资<ul><li>Cumulative Sum</li><li>Moving Function</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Cumulative_sum</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"age"</span>: &#123;</span><br><span class="line">      <span class="attr">"histogram"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"age"</span>,</span><br><span class="line">        <span class="attr">"min_doc_count"</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">"interval"</span>: <span class="number">1</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">          <span class="attr">"avg"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"cumulative_salary"</span>:&#123;</span><br><span class="line">          <span class="attr">"cumulative_sum"</span>: &#123;</span><br><span class="line">            <span class="attr">"buckets_path"</span>: <span class="string">"avg_salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Moving Function</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"age"</span>: &#123;</span><br><span class="line">      <span class="attr">"histogram"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"age"</span>,</span><br><span class="line">        <span class="attr">"min_doc_count"</span>: <span class="number">1</span>,</span><br><span class="line">        <span class="attr">"interval"</span>: <span class="number">1</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">          <span class="attr">"avg"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"moving_avg_salary"</span>:&#123;</span><br><span class="line">          <span class="attr">"moving_fn"</span>: &#123;</span><br><span class="line">            <span class="attr">"buckets_path"</span>: <span class="string">"avg_salary"</span>,</span><br><span class="line">            <span class="attr">"window"</span>:<span class="number">10</span>,</span><br><span class="line">            <span class="attr">"script"</span>: <span class="string">"MovingFunctions.min(values)"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="聚合的作用范围及排序"><a href="#聚合的作用范围及排序" class="headerlink" title="聚合的作用范围及排序"></a>聚合的作用范围及排序</h2><h3 id="聚合的作用范围"><a href="#聚合的作用范围" class="headerlink" title="聚合的作用范围"></a>聚合的作用范围</h3><ul><li>ES 聚合分析的默认作用范围是 query 的查询结果集</li><li>同时 ES 还支持以下方式改变聚合的作用范围<ul><li>Filter</li><li>Post_Filter</li><li>Global</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Query</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"range"</span>: &#123;</span><br><span class="line">      <span class="attr">"age"</span>: &#123;</span><br><span class="line">        <span class="attr">"gte"</span>: <span class="number">20</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"job.keyword"</span></span><br><span class="line">        </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h3><p><img src="/images/big-data/es-06/25.jpg" alt="25"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Filter</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"older_person"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>:&#123;</span><br><span class="line">        <span class="attr">"range"</span>:&#123;</span><br><span class="line">          <span class="attr">"age"</span>:&#123;</span><br><span class="line">            <span class="attr">"from"</span>:<span class="number">35</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>:&#123;</span><br><span class="line">         <span class="attr">"jobs"</span>:&#123;</span><br><span class="line">           <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"job.keyword"</span></span><br><span class="line">      &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;&#125;,</span><br><span class="line">    <span class="attr">"all_jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"job.keyword"</span></span><br><span class="line">        </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Post-Filter"><a href="#Post-Filter" class="headerlink" title="Post_Filter"></a>Post_Filter</h3><ul><li>是对聚合分析后的文档进行再次过滤</li><li>Size 无需设置为 0</li><li>使用场景<ul><li>一条语句，获取聚合信息 + 获取符合条件的文档</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Post field. 一条语句，找出所有的job类型。还能找到聚合后符合条件的结果</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"job.keyword"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"post_filter"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"job.keyword"</span>: <span class="string">"Dev Manager"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Global"><a href="#Global" class="headerlink" title="Global"></a>Global</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// global</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"range"</span>: &#123;</span><br><span class="line">      <span class="attr">"age"</span>: &#123;</span><br><span class="line">        <span class="attr">"gte"</span>: <span class="number">40</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"job.keyword"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"all"</span>:&#123;</span><br><span class="line">      <span class="attr">"global"</span>: &#123;&#125;, <span class="comment">// Golbal，无视query，对全部文档进行统计</span></span><br><span class="line">      <span class="attr">"aggs"</span>:&#123;</span><br><span class="line">        <span class="attr">"salary_avg"</span>:&#123;</span><br><span class="line">          <span class="attr">"avg"</span>:&#123;</span><br><span class="line">            <span class="attr">"field"</span>:<span class="string">"salary"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="排序-1"><a href="#排序-1" class="headerlink" title="排序"></a>排序</h3><ul><li>指定 order，按照 count 和 key 排序<ul><li>默认情况，按照 count 降序排序</li><li>指定 size，就能返回相应的桶</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 排序 order</span></span><br><span class="line"><span class="comment">// count正序 and key倒叙</span></span><br><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">  <span class="attr">"range"</span>: &#123;</span><br><span class="line">    <span class="attr">"age"</span>: &#123;</span><br><span class="line">      <span class="attr">"gte"</span>: <span class="number">20</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;,</span><br><span class="line"><span class="attr">"aggs"</span>: &#123;</span><br><span class="line">  <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">    <span class="attr">"terms"</span>: &#123;</span><br><span class="line">      <span class="attr">"field"</span>: <span class="string">"job.keyword"</span>,</span><br><span class="line">      <span class="attr">"order"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"_count"</span>: <span class="string">"asc"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"_key"</span>: <span class="string">"desc"</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="基于子聚合的值排序"><a href="#基于子聚合的值排序" class="headerlink" title="基于子聚合的值排序"></a>基于子聚合的值排序</h3><ul><li>基于子聚合的数值进行排序</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line"><span class="attr">"aggs"</span>: &#123;</span><br><span class="line">  <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">    <span class="attr">"terms"</span>: &#123;</span><br><span class="line">      <span class="attr">"field"</span>: <span class="string">"job.keyword"</span>,</span><br><span class="line">      <span class="attr">"order"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"avg_salary"</span>: <span class="string">"desc"</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">      <span class="attr">"avg_salary"</span>: &#123;</span><br><span class="line">        <span class="attr">"avg"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>使用子聚合，Aggregation name</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">POST employees/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line"><span class="attr">"aggs"</span>: &#123;</span><br><span class="line">  <span class="attr">"jobs"</span>: &#123;</span><br><span class="line">    <span class="attr">"terms"</span>: &#123;</span><br><span class="line">      <span class="attr">"field"</span>: <span class="string">"job.keyword"</span>,</span><br><span class="line">      <span class="attr">"order"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"stats_salary.min"</span>: <span class="string">"desc"</span></span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">      <span class="attr">"stats_salary"</span>: &#123;</span><br><span class="line">        <span class="attr">"stats"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"salary"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="聚合分析的原理及精准度问题"><a href="#聚合分析的原理及精准度问题" class="headerlink" title="聚合分析的原理及精准度问题"></a>聚合分析的原理及精准度问题</h2><h3 id="分布式系统的近似统计算法"><a href="#分布式系统的近似统计算法" class="headerlink" title="分布式系统的近似统计算法"></a>分布式系统的近似统计算法</h3><p><img src="/images/big-data/es-06/26.jpg" alt="26"></p><h3 id="Min-聚合分析的执行流程"><a href="#Min-聚合分析的执行流程" class="headerlink" title="Min 聚合分析的执行流程"></a>Min 聚合分析的执行流程</h3><p><img src="/images/big-data/es-06/28.jpg" alt="28"></p><h3 id="Terms-Aggregation-的返回值"><a href="#Terms-Aggregation-的返回值" class="headerlink" title="Terms Aggregation 的返回值"></a>Terms Aggregation 的返回值</h3><ul><li>在 Terms Aggregation 的返回中有两个特殊的数值<ul><li>doc_count_error_upper_bound：被遗漏的 term 分桶，包含的文档，有可能的最大值</li><li>sum_other_doc_count: 除了返回结果 bucket 的 terms 以外，其他 terms 的文档总数（总数 - 返回的总数）</li></ul></li></ul><p><img src="/images/big-data/es-06/29.jpg" alt="29"></p><h3 id="Terms-聚合分析的执行流程"><a href="#Terms-聚合分析的执行流程" class="headerlink" title="Terms 聚合分析的执行流程"></a>Terms 聚合分析的执行流程</h3><p><img src="/images/big-data/es-06/30.jpg" alt="30"></p><h3 id="Terms-不正确的案例"><a href="#Terms-不正确的案例" class="headerlink" title="Terms 不正确的案例"></a>Terms 不正确的案例</h3><p><img src="/images/big-data/es-06/31.jpg" alt="31"></p><h3 id="如何解决-Terms-不准的问题：提升-shard-size-的参数"><a href="#如何解决-Terms-不准的问题：提升-shard-size-的参数" class="headerlink" title="如何解决 Terms 不准的问题：提升 shard_size 的参数"></a>如何解决 Terms 不准的问题：提升 shard_size 的参数</h3><ul><li>Terms 聚合分析不准的原因，数据分散在多个分片上，Coordinating Node 无法获取数据全貌</li><li>解决方案 1：当数据量不大时，设置 Primary Shard 为 1；实现准确性</li><li>解决方案 2：在分布式数据上，设置 shard_size 参数，提高精确度<ul><li>原理：每次从 Shard 上额外多获取数据，提升准确率</li></ul></li></ul><p><img src="/images/big-data/es-06/32.jpg" alt="32"></p><h3 id="打开-show-term-doc-count-error"><a href="#打开-show-term-doc-count-error" class="headerlink" title="打开 show_term_doc_count_error"></a>打开 show_term_doc_count_error</h3><p><img src="/images/big-data/es-06/33.jpg" alt="33"></p><h3 id="shard-size-设定"><a href="#shard-size-设定" class="headerlink" title="shard_size 设定"></a>shard_size 设定</h3><ul><li>调整 shard size 大小，降低 doc_count_error_upper_bound 来提升准确度<ul><li>增加整体计算量，提高了准确率，但会降低相应时间</li></ul></li><li>Shard Size 默认大小设定<ul><li>shard size = size * 1.5 +10</li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.2/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-approximate-counts" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.2/search-aggregations-bucket-terms-aggregation.html#search-aggregations-bucket-terms-aggregation-approximate-counts</a></li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">DELETE my_flights</span><br><span class="line">PUT my_flights</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"number_of_shards"</span>: <span class="number">20</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"mappings"</span> : &#123;</span><br><span class="line">      <span class="attr">"properties"</span> : &#123;</span><br><span class="line">        <span class="attr">"AvgTicketPrice"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"float"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"Cancelled"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"boolean"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"Carrier"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"Dest"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"DestAirportID"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"DestCityName"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"DestCountry"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"DestLocation"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"geo_point"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"DestRegion"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"DestWeather"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"DistanceKilometers"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"float"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"DistanceMiles"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"float"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"FlightDelay"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"boolean"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"FlightDelayMin"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"integer"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"FlightDelayType"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"FlightNum"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"FlightTimeHour"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"FlightTimeMin"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"float"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"Origin"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"OriginAirportID"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"OriginCityName"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"OriginCountry"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"OriginLocation"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"geo_point"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"OriginRegion"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"OriginWeather"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"dayOfWeek"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"integer"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"timestamp"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"date"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"source"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"kibana_sample_data_flights"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"dest"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"my_flights"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET kibana_sample_data_flights/_count</span><br><span class="line">GET my_flights/_count</span><br><span class="line"></span><br><span class="line">get kibana_sample_data_flights/_search</span><br><span class="line"></span><br><span class="line">GET kibana_sample_data_flights/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"weather"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"OriginWeather"</span>,</span><br><span class="line">        <span class="attr">"size"</span>:<span class="number">5</span>,</span><br><span class="line">        <span class="attr">"show_term_doc_count_error"</span>:<span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET my_flights/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"weather"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"OriginWeather"</span>,</span><br><span class="line">        <span class="attr">"size"</span>:<span class="number">1</span>,</span><br><span class="line">        <span class="attr">"shard_size"</span>:<span class="number">1</span>,</span><br><span class="line">        <span class="attr">"show_term_doc_count_error"</span>:<span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="对象及-Nested-对象"><a href="#对象及-Nested-对象" class="headerlink" title="对象及 Nested 对象"></a>对象及 Nested 对象</h2><h3 id="数据的关联关系"><a href="#数据的关联关系" class="headerlink" title="数据的关联关系"></a>数据的关联关系</h3><ul><li>真实世界中有很多重要的关联关系<ul><li>博客、作者、评论</li><li>银行账户有多次交易记录</li><li>客户有很多银行账户</li><li>目录文件有很多文件和子目录</li></ul></li></ul><h3 id="关系型数据库的范式化设计"><a href="#关系型数据库的范式化设计" class="headerlink" title="关系型数据库的范式化设计"></a>关系型数据库的范式化设计</h3><ul><li>范式化设计（Normalization）的主要目标是 “减少不必要的更新”</li><li>副作用：一个完全范式化设计的数据库经常面临 “查询缓慢” 的问题<ul><li>数据库越范式化，就需要 Join 越多的表</li></ul></li><li>范式化节省了储存空间，但是储存空间越来越便宜</li><li>范式化简化了更新，但是数据 “读” 取操作可能越多</li></ul><p><img src="/images/big-data/es-06/34.jpg" alt="34"></p><h3 id="Denormalization"><a href="#Denormalization" class="headerlink" title="Denormalization"></a>Denormalization</h3><ul><li>反范式化设计<ul><li>数据 “Flattening”, 不使用关联关系，而是在文档中保存冗余的数据拷贝</li></ul></li><li>优点：无需处理 Joins 操作，数据读取性能好<ul><li>Elasticsearch 通过压缩_source 字段，减少磁盘空间的开销</li></ul></li><li>缺点：不适合在数据频繁修改的场景<ul><li>一条数据（用户名）的改动，可能会引起很多数据的更新</li></ul></li></ul><h3 id="在-Elasticsearch-中处理关联关系"><a href="#在-Elasticsearch-中处理关联关系" class="headerlink" title="在 Elasticsearch 中处理关联关系"></a>在 Elasticsearch 中处理关联关系</h3><ul><li>关系型数据库，一般会考虑 Normalize 数据；在 Elasticsearch，往往考虑 Denormalize 数据<ul><li>Denormalize 的好处：读的速度变快、无需表连接、无需行锁</li></ul></li><li>Elasticsearch 并不擅长处理关联关系，我们一般采用以下四种方法处理关联<ul><li>对象类型</li><li>嵌套对象（Nested Object）</li><li>父子关联关系（Parent / Child）</li><li>应用端关联</li></ul></li></ul><h3 id="案例-1：博客和其作者信息"><a href="#案例-1：博客和其作者信息" class="headerlink" title="案例 1：博客和其作者信息"></a>案例 1：博客和其作者信息</h3><ul><li>对象类型<ul><li>在每个博客的问下中都保留作者的信息</li><li>如果作者信息发生变化，需要修改相关的博客文档</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">DELETE blog</span><br><span class="line"><span class="comment">// 设置blog的 Mapping</span></span><br><span class="line">PUT /blog</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"content"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"time"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"date"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"user"</span>: &#123;</span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">          <span class="attr">"city"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"userid"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"long"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"username"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 插入一条 Blog 信息</span></span><br><span class="line">PUT blog/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"I like Elasticsearch"</span>,</span><br><span class="line">  <span class="attr">"time"</span>:<span class="string">"2019-01-01T00:00:00"</span>,</span><br><span class="line">  <span class="attr">"user"</span>:&#123;</span><br><span class="line">    <span class="attr">"userid"</span>:<span class="number">1</span>,</span><br><span class="line">    <span class="attr">"username"</span>:<span class="string">"Jack"</span>,</span><br><span class="line">    <span class="attr">"city"</span>:<span class="string">"Shanghai"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过一条查询语句即可获取到博客和作者信息</span></span><br><span class="line"><span class="comment">// 查询 Blog 信息</span></span><br><span class="line">POST blog/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;<span class="attr">"match"</span>: &#123;<span class="attr">"content"</span>: <span class="string">"Elasticsearch"</span>&#125;&#125;,</span><br><span class="line">        &#123;<span class="attr">"match"</span>: &#123;<span class="attr">"user.username"</span>: <span class="string">"Jack"</span>&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="案例-2：包含对象数组的文档"><a href="#案例-2：包含对象数组的文档" class="headerlink" title="案例 2：包含对象数组的文档"></a>案例 2：包含对象数组的文档</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">DELETE my_movies</span><br><span class="line"><span class="comment">// 电影的Mapping信息</span></span><br><span class="line">PUT my_movies</span><br><span class="line">&#123;</span><br><span class="line">      <span class="attr">"mappings"</span> : &#123;</span><br><span class="line">      <span class="attr">"properties"</span> : &#123;</span><br><span class="line">        <span class="attr">"actors"</span> : &#123;</span><br><span class="line">          <span class="attr">"properties"</span> : &#123;</span><br><span class="line">            <span class="attr">"first_name"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"last_name"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"title"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入一条电影信息</span></span><br><span class="line">POST my_movies/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"Speed"</span>,</span><br><span class="line">  <span class="attr">"actors"</span>:[</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"first_name"</span>:<span class="string">"Keanu"</span>,</span><br><span class="line">      <span class="attr">"last_name"</span>:<span class="string">"Reeves"</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"first_name"</span>:<span class="string">"Dennis"</span>,</span><br><span class="line">      <span class="attr">"last_name"</span>:<span class="string">"Hopper"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询电影信息</span></span><br><span class="line">POST my_movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;<span class="attr">"match"</span>: &#123;<span class="attr">"actors.first_name"</span>: <span class="string">"Keanu"</span>&#125;&#125;,</span><br><span class="line">        &#123;<span class="attr">"match"</span>: &#123;<span class="attr">"actors.last_name"</span>: <span class="string">"Hopper"</span>&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="为啥会搜到不需要的结果？"><a href="#为啥会搜到不需要的结果？" class="headerlink" title="为啥会搜到不需要的结果？"></a>为啥会搜到不需要的结果？</h3><ul><li>储存时，内部对象的边界没有在考虑在内，JSON 格式被处理成扁平键值对的结构</li><li>当对多个字段进行查询时，导致了意外的搜索结果</li><li>可以用 Nested Data Type 解决这个问题</li></ul><h3 id="Nested-Data-Type"><a href="#Nested-Data-Type" class="headerlink" title="Nested Data Type"></a>Nested Data Type</h3><ul><li>Nested 数据类型：允许对象数组中的对象被独立索引</li><li>使用 nested 和 properties 关键词，将所有 actors 索引到多个分隔的文档</li><li>在内部，Nested 文档会被保存在两个 Lucene 文档中，查询时做 Join 处理</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">PUT my_movies</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span> : &#123;</span><br><span class="line">    <span class="attr">"properties"</span> : &#123;</span><br><span class="line">      <span class="attr">"actors"</span> : &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"nested"</span>,</span><br><span class="line">        <span class="attr">"properties"</span> : &#123;</span><br><span class="line">          <span class="attr">"first_name"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"keyword"</span>&#125;,</span><br><span class="line">          <span class="attr">"last_name"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"keyword"</span>&#125;</span><br><span class="line">        &#125;&#125;,</span><br><span class="line">      <span class="attr">"title"</span> : &#123;</span><br><span class="line">        <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"fields"</span> : &#123;<span class="attr">"keyword"</span>:&#123;<span class="attr">"type"</span>:<span class="string">"keyword"</span>,<span class="attr">"ignore_above"</span>:<span class="number">256</span>&#125;&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="嵌套查询"><a href="#嵌套查询" class="headerlink" title="嵌套查询"></a>嵌套查询</h3><p>在内部，Nested 文档被保存在两个 Lucene 文档中，会在查询时做 Join 处理</p><p><img src="/images/big-data/es-06/35.jpg" alt="35"></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Nested 查询</span></span><br><span class="line">POST my_movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;<span class="attr">"match"</span>: &#123;<span class="attr">"title"</span>: <span class="string">"Speed"</span>&#125;&#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"nested"</span>: &#123;</span><br><span class="line">            <span class="attr">"path"</span>: <span class="string">"actors"</span>,</span><br><span class="line">            <span class="attr">"query"</span>: &#123;</span><br><span class="line">              <span class="attr">"bool"</span>: &#123;</span><br><span class="line">                <span class="attr">"must"</span>: [</span><br><span class="line">                  &#123;<span class="attr">"match"</span>: &#123;</span><br><span class="line">                    <span class="attr">"actors.first_name"</span>: <span class="string">"Keanu"</span></span><br><span class="line">                  &#125;&#125;,</span><br><span class="line">                  &#123;<span class="attr">"match"</span>: &#123;</span><br><span class="line">                    <span class="attr">"actors.last_name"</span>: <span class="string">"Hopper"</span></span><br><span class="line">                  &#125;&#125;</span><br><span class="line">                ]</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//返回</span></span><br><span class="line"> "hits" : &#123;</span><br><span class="line">    "total" : &#123;</span><br><span class="line">      "value" : 0,</span><br><span class="line">      "relation" : "eq"</span><br><span class="line">    &#125;,</span><br><span class="line">    "max_score" : null,</span><br><span class="line">    "hits" : [ ]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="嵌套聚合"><a href="#嵌套聚合" class="headerlink" title="嵌套聚合"></a>嵌套聚合</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># Nested Aggregation</span><br><span class="line">POST my_movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"actors"</span>: &#123;</span><br><span class="line">      <span class="attr">"nested"</span>: &#123;</span><br><span class="line">        <span class="attr">"path"</span>: <span class="string">"actors"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">        <span class="attr">"actor_name"</span>: &#123;</span><br><span class="line">          <span class="attr">"terms"</span>: &#123;</span><br><span class="line">            <span class="attr">"field"</span>: <span class="string">"actors.first_name"</span>,</span><br><span class="line">            <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 普通 aggregation不工作</span></span><br><span class="line">POST my_movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"NAME"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"actors.first_name"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="文档的父子关系"><a href="#文档的父子关系" class="headerlink" title="文档的父子关系"></a>文档的父子关系</h2><h3 id="Parent-Child"><a href="#Parent-Child" class="headerlink" title="Parent / Child"></a>Parent / Child</h3><ul><li>对象和 Nested 对象的局限性<ul><li>每次更新，需要重新索引整个对象（包括跟对象和嵌套对象）</li></ul></li><li>ES 提供了类似关系型数据库中 Join 的实现。使用 Join 数据类型实现，可以通过维护 Parent / Child 的关系，从而分离两个对象<ul><li>父文档和子文档是两个独立的文档</li><li>更新父文档无需重新索引整个子文档。子文档被新增，更改和删除也不会影响到父文档和其他子文档。</li></ul></li></ul><h3 id="父子关系"><a href="#父子关系" class="headerlink" title="父子关系"></a>父子关系</h3><ul><li>定义父子关系的几个步骤<ul><li>设置索引的 Mapping</li><li>索引父文档</li><li>索引子文档</li><li>按需查询文档</li></ul></li></ul><h3 id="设置-Mapping"><a href="#设置-Mapping" class="headerlink" title="设置 Mapping"></a>设置 Mapping</h3><p><img src="/images/big-data/es-06/36.jpg" alt="36"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">DELETE my_blogs</span><br><span class="line"><span class="comment">// 设定 Parent/Child Mapping</span></span><br><span class="line">PUT my_blogs</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"number_of_shards"</span>: <span class="number">2</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"blog_comments_relation"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"join"</span>,</span><br><span class="line">        <span class="attr">"relations"</span>: &#123;</span><br><span class="line">          <span class="attr">"blog"</span>: <span class="string">"comment"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"content"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"title"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="索引父文档"><a href="#索引父文档" class="headerlink" title="索引父文档"></a>索引父文档</h3><p><img src="/images/big-data/es-06/37.jpg" alt="37"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">PUT my_blogs/_doc/blog1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"Learning Elasticsearch"</span>,</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"learning ELK @ geektime"</span>,</span><br><span class="line">  <span class="attr">"blog_comments_relation"</span>:&#123;</span><br><span class="line">    <span class="attr">"name"</span>:<span class="string">"blog"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_blogs/_doc/blog2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"Learning Hadoop"</span>,</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"learning Hadoop"</span>,</span><br><span class="line">    <span class="attr">"blog_comments_relation"</span>:&#123;</span><br><span class="line">    <span class="attr">"name"</span>:<span class="string">"blog"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="索引子文档"><a href="#索引子文档" class="headerlink" title="索引子文档"></a>索引子文档</h3><ul><li>父文档和子文档必须存在相同的分片上<ul><li>确保查询 join 的性能</li></ul></li><li>当指定子文档时候，必须指定它的父文档 ID<ul><li>使用 route 参数来保证，分配到相同的分片</li></ul></li></ul><p><img src="/images/big-data/es-06/38.jpg" alt="38"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 索引子文档</span></span><br><span class="line">PUT my_blogs/_doc/comment1?routing=blog1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"comment"</span>:<span class="string">"I am learning ELK"</span>,</span><br><span class="line">  <span class="attr">"username"</span>:<span class="string">"Jack"</span>,</span><br><span class="line">  <span class="attr">"blog_comments_relation"</span>:&#123;</span><br><span class="line">    <span class="attr">"name"</span>:<span class="string">"comment"</span>,</span><br><span class="line">    <span class="attr">"parent"</span>:<span class="string">"blog1"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_blogs/_doc/comment2?routing=blog2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"comment"</span>:<span class="string">"I like Hadoop!!!!!"</span>,</span><br><span class="line">  <span class="attr">"username"</span>:<span class="string">"Jack"</span>,</span><br><span class="line">  <span class="attr">"blog_comments_relation"</span>:&#123;</span><br><span class="line">    <span class="attr">"name"</span>:<span class="string">"comment"</span>,</span><br><span class="line">    <span class="attr">"parent"</span>:<span class="string">"blog2"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_blogs/_doc/comment3?routing=blog2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"comment"</span>:<span class="string">"Hello Hadoop"</span>,</span><br><span class="line">  <span class="attr">"username"</span>:<span class="string">"Bob"</span>,</span><br><span class="line">  <span class="attr">"blog_comments_relation"</span>:&#123;</span><br><span class="line">    <span class="attr">"name"</span>:<span class="string">"comment"</span>,</span><br><span class="line">    <span class="attr">"parent"</span>:<span class="string">"blog2"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Parent-Child-所支持的查询"><a href="#Parent-Child-所支持的查询" class="headerlink" title="Parent / Child 所支持的查询"></a>Parent / Child 所支持的查询</h3><ul><li>查询所有文档</li><li>Parent Id 查询</li><li>Has Child 查询</li><li>Has Parent 查询</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 查询所有文档</span></span><br><span class="line">POST my_blogs/_search</span><br><span class="line">&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据父文档ID查看</span></span><br><span class="line">GET my_blogs/_doc/blog2</span><br><span class="line"></span><br><span class="line"><span class="comment">// Parent Id 查询,返回所有子文档</span></span><br><span class="line"><span class="comment">// 查询 ID 为 blog2 父文档的所有子文档</span></span><br><span class="line">POST my_blogs/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">  <span class="attr">"parent_id"</span>: &#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"comment"</span>,</span><br><span class="line">    <span class="attr">"id"</span>: <span class="string">"blog2"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Has Child 查询，返回父文档</span></span><br><span class="line"><span class="comment">// 查询 user 包含 Jack 的所有子文档的父文档</span></span><br><span class="line">POST my_blogs/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">  <span class="attr">"has_child"</span>: &#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"comment"</span>,</span><br><span class="line">    <span class="attr">"query"</span> : &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">              <span class="attr">"username"</span> : <span class="string">"Jack"</span></span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Has Parent 查询，返回相关的子文档</span></span><br><span class="line"><span class="comment">// 查询 title 包含 Learning Hadoop 的父文档的所有子文档</span></span><br><span class="line">POST my_blogs/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">  <span class="attr">"has_parent"</span>: &#123;</span><br><span class="line">    <span class="attr">"parent_type"</span>: <span class="string">"blog"</span>,</span><br><span class="line">    <span class="attr">"query"</span> : &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">              <span class="attr">"title"</span> : <span class="string">"Learning Hadoop"</span></span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用-has-child-查询"><a href="#使用-has-child-查询" class="headerlink" title="使用 has_child 查询"></a>使用 has_child 查询</h3><ul><li>返回父文档</li><li>通过对子文档进行查询<ul><li>返回具体相关子文档的父文档</li><li>父子文档在相同的分片上，因此 Join 效率高</li></ul></li></ul><p><img src="/images/big-data/es-06/39.jpg" alt="39"></p><h3 id="使用-has-parent-查询"><a href="#使用-has-parent-查询" class="headerlink" title="使用 has_parent 查询"></a>使用 has_parent 查询</h3><ul><li>返回相关性的子文档</li><li>通过对父文档进行查询<ul><li>返回相关的子文档</li></ul></li></ul><p><img src="/images/big-data/es-06/40.jpg" alt="40"></p><h3 id="使用-parent-id-查询"><a href="#使用-parent-id-查询" class="headerlink" title="使用 parent_id 查询"></a>使用 parent_id 查询</h3><ul><li>返回所有相关子文档</li><li>通过对付文档 Id 进行查询<ul><li>返回所有相关的子文档</li></ul></li></ul><p><img src="/images/big-data/es-06/41.jpg" alt="41"></p><h3 id="访问子文档"><a href="#访问子文档" class="headerlink" title="访问子文档"></a>访问子文档</h3><p>需指定父文档 routing 参数</p><p><img src="/images/big-data/es-06/42.jpg" alt="42"></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过ID ，访问子文档</span></span><br><span class="line">GET my_blogs/_doc/comment2</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过ID和routing ，访问子文档</span></span><br><span class="line">GET my_blogs/_doc/comment3?routing=blog2</span><br></pre></td></tr></table></figure><h3 id="更新子文档"><a href="#更新子文档" class="headerlink" title="更新子文档"></a>更新子文档</h3><p>更新子文档不会影响到父文档</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 更新子文档</span></span><br><span class="line">PUT my_blogs/_doc/comment3?routing=blog2</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"comment"</span>: <span class="string">"Hello Hadoop??"</span>,</span><br><span class="line">    <span class="attr">"blog_comments_relation"</span>: &#123;</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"comment"</span>,</span><br><span class="line">      <span class="attr">"parent"</span>: <span class="string">"blog2"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="多子文档-和-多级父子文档"><a href="#多子文档-和-多级父子文档" class="headerlink" title="多子文档 和 多级父子文档"></a>多子文档 和 多级父子文档</h3><p>除了上面常见的父子文档类型，ES Join 还支持 多子文档 和 多级父子文档 的设置。如下：</p><p><strong>构建多个子文档</strong></p><p>Join 类型一个父文档可以配置多个子文档，创建方式如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"my_join_field"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"join"</span>,</span><br><span class="line">        <span class="attr">"relations"</span>: &#123;</span><br><span class="line">          <span class="attr">"question"</span>: [<span class="string">"answer"</span>, <span class="string">"comment"</span>]  </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>构建多级父子关系</strong></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"my_join_field"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"join"</span>,</span><br><span class="line">        <span class="attr">"relations"</span>: &#123;</span><br><span class="line">          <span class="attr">"question"</span>: [<span class="string">"answer"</span>, <span class="string">"comment"</span>],  </span><br><span class="line">          <span class="attr">"answer"</span>: <span class="string">"vote"</span> </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面创建的父子文档层级如下图所示：</p><p><img src="/images/big-data/es-06/63.jpg" alt="63"></p><h3 id="父子关系的应用"><a href="#父子关系的应用" class="headerlink" title="父子关系的应用"></a>父子关系的应用</h3><ul><li>如果要更改文档的父文档，不能仅仅 update 或者 reindex 旧文档(新的父文档可能在不同分片上)，需要先删除旧文档再重新索引。</li><li>看到 parent-child 关系，我们很容易想到的是像 SQL 那样的各种 JOIN 操作——比如查询某个文档并一并取回所有的父或子文档等。</li><li>然而，ES 中不支持类似的 JOIN 查询。在 ES 中的 parent-child 关系基本可以理解为仅仅是一个过滤条件。</li></ul><h3 id="嵌套对象-v-s-父子文档"><a href="#嵌套对象-v-s-父子文档" class="headerlink" title="嵌套对象 v.s 父子文档"></a>嵌套对象 v.s 父子文档</h3><table><thead><tr><th align="left"></th><th align="left">Nested Object</th><th align="left">Parent / Child</th></tr></thead><tbody><tr><td align="left">优点</td><td align="left">文档存储在一起，读取性能高</td><td align="left">父子文档可以独立更新</td></tr><tr><td align="left">缺点</td><td align="left">更新嵌套的子文档时，需要更新整个文档</td><td align="left">需要额外的内存去维护关系。读取性能相对差</td></tr><tr><td align="left">适用场景</td><td align="left">子文档偶尔更新，以查询为主</td><td align="left">子文档更新频繁</td></tr></tbody></table><h2 id="Update-By-Query-amp-Reindex-API"><a href="#Update-By-Query-amp-Reindex-API" class="headerlink" title="Update By Query &amp; Reindex API"></a>Update By Query &amp; Reindex API</h2><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><ul><li>一般在以下几种情况时，我们需要重建索引：<ul><li>索引的 Mappings 发生变更：字段类型更改，分词器及字典更新</li><li>索引的 Setting 发生变更：索引的主分片数发生改变</li><li>集群内，集群间需要做数据迁移</li></ul></li><li>ElastiicSearch 的内置提供的 API<ul><li>Update By Query : 在现有索引上重建</li><li>Reindex：在其他索引上重建索引</li></ul></li></ul><h3 id="案例一：为索引增加子字段"><a href="#案例一：为索引增加子字段" class="headerlink" title="案例一：为索引增加子字段"></a>案例一：为索引增加子字段</h3><ul><li>改变 Mapping ， 增加子字段，使用英文分词器</li><li>此时尝试对子字段进行查询</li><li>虽然有数据已经存在，但是没有返回结果</li></ul><p><img src="/images/big-data/es-06/43.jpg" alt="43"></p><h3 id="Update-By-Query"><a href="#Update-By-Query" class="headerlink" title="Update By Query"></a>Update By Query</h3><ul><li>执行 Update By Query</li><li>尝试对 Multi-Fields 查询查询</li><li>返回结果</li></ul><p><img src="/images/big-data/es-06/44.jpg" alt="44"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 写入文档</span></span><br><span class="line">PUT blogs/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"Hadoop is cool"</span>,</span><br><span class="line">  <span class="attr">"keyword"</span>:<span class="string">"hadoop"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 修改 Mapping，增加子字段，使用英文分词器</span></span><br><span class="line">PUT blogs/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"properties"</span> : &#123;</span><br><span class="line">    <span class="attr">"content"</span> : &#123;</span><br><span class="line">      <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">      <span class="attr">"fields"</span> : &#123;</span><br><span class="line">        <span class="attr">"english"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"analyzer"</span>:<span class="string">"english"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 写入文档</span></span><br><span class="line">PUT blogs/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"Elasticsearch rocks"</span>,</span><br><span class="line">  <span class="attr">"keyword"</span>:<span class="string">"elasticsearch"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询新写入文档</span></span><br><span class="line">POST blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"content.english"</span>: <span class="string">"Elasticsearch"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询 Mapping 变更前写入的文档</span></span><br><span class="line">POST blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"content.english"</span>: <span class="string">"hadoop"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Update所有文档</span></span><br><span class="line">POST blogs/_update_by_query</span><br><span class="line">&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="案例二：更改已有字段类型的-Mappings"><a href="#案例二：更改已有字段类型的-Mappings" class="headerlink" title="案例二：更改已有字段类型的 Mappings"></a>案例二：更改已有字段类型的 Mappings</h3><ul><li>ES 不允许在原有 Mapping 上对字段类型进行修改</li><li>只能创建新的索引，并设定正确的字段类型，在重新导入数据</li></ul><p><img src="/images/big-data/es-06/45.jpg" alt="45"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建新的索引并且设定新的Mapping</span></span><br><span class="line">PUT blogs_fix/</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"content"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"english"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">            <span class="attr">"analyzer"</span>: <span class="string">"english"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"keyword"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Reindx API</span></span><br><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"source"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"dest"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs_fix"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET  blogs_fix/_doc/1</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试 Term Aggregation</span></span><br><span class="line">POST blogs_fix/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"blog_keyword"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Reindex-API"><a href="#Reindex-API" class="headerlink" title="Reindex API"></a>Reindex API</h3><ul><li>Reindex API 支持把文档从一个索引拷贝到另外一个索引</li><li>使用 Reindex API 的一些场景<ul><li>修改索引的主分片数</li><li>改变字段的 Mapping 中的字段类型</li><li>集群中数据迁移、跨集群的数据迁移</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Reindx API，version Type Internal</span></span><br><span class="line">POST  _reindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"source"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"dest"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs_fix"</span>,</span><br><span class="line">    <span class="attr">"version_type"</span>: <span class="string">"internal"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 文档版本号增加</span></span><br><span class="line">GET  blogs_fix/_doc/1</span><br><span class="line"></span><br><span class="line"><span class="comment">// Reindx API，version Type Internal</span></span><br><span class="line">POST  _reindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"source"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"dest"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs_fix"</span>,</span><br><span class="line">    <span class="attr">"version_type"</span>: <span class="string">"external"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Reindx API，version Type Internal</span></span><br><span class="line">POST  _reindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"source"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"dest"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs_fix"</span>,</span><br><span class="line">    <span class="attr">"version_type"</span>: <span class="string">"external"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"conflicts"</span>: <span class="string">"proceed"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="两个注意点"><a href="#两个注意点" class="headerlink" title="两个注意点"></a>两个注意点</h3><ul><li>索引的 mapping _source 要开启</li><li>先创建一个新索引，然后在执行 reindex</li></ul><h3 id="OP-Type"><a href="#OP-Type" class="headerlink" title="OP Type"></a>OP Type</h3><ul><li>_reindex 指挥创建不存在的文档</li><li>文档如果存在，会导致版本冲突</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Reindx API，version Type Internal</span></span><br><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"source"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"dest"</span>: &#123;</span><br><span class="line">    <span class="attr">"index"</span>: <span class="string">"blogs_fix"</span>,</span><br><span class="line">    <span class="attr">"op_type"</span>: <span class="string">"create"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="跨集群-ReIndex"><a href="#跨集群-ReIndex" class="headerlink" title="跨集群 ReIndex"></a>跨集群 ReIndex</h3><p><img src="/images/big-data/es-06/46.jpg" alt="46"></p><h3 id="查看-Task-API"><a href="#查看-Task-API" class="headerlink" title="查看 Task API"></a>查看 Task API</h3><p><img src="/images/big-data/es-06/47.jpg" alt="47"></p><h3 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h3><ul><li>Update By Query 使用场景： 为字段新增子字段；字段更改分词器；更新分词器词库</li><li>Reindex API 使用场景：修改字段类型<ul><li>需要先对新索引设置 Mapping，索引的设置和映射关系不会被复制</li></ul></li><li>通过查看 Task API，了解 Reindex 的状况</li><li>Remote ReIndex ，需要修改 elasticsearch.yml 配置并且重启</li><li>一定要尽量使用 Index Alias 读写数据。即便发生 Reindex，也能实现零停机维护</li></ul><h2 id="Ingest-Pipeline-与-Painless-Script"><a href="#Ingest-Pipeline-与-Painless-Script" class="headerlink" title="Ingest Pipeline 与 Painless Script"></a>Ingest Pipeline 与 Painless Script</h2><h3 id="需求：修复与增强写入的数据"><a href="#需求：修复与增强写入的数据" class="headerlink" title="需求：修复与增强写入的数据"></a>需求：修复与增强写入的数据</h3><ul><li>Tags 字段中，逗号分割的文本应该是数组，而不是一个字符串</li><li>需求：后期需要对 Tags 进行 Aggregation 统计信息</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Blog数据，包含3个字段，tags用逗号间隔</span></span><br><span class="line">PUT tech_blogs/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"Introducing big data......"</span>,</span><br><span class="line">  <span class="attr">"tags"</span>:<span class="string">"hadoop,elasticsearch,spark"</span>,</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"You konw, for big data"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Ingest-Node"><a href="#Ingest-Node" class="headerlink" title="Ingest Node"></a>Ingest Node</h3><ul><li>Elasticsearch 5.0 后，引入的一种新的节点类型。默认配置下，每个节点都是 Ingest Node<ul><li>具有预处理数据的能力，可拦截 Index 或者 Bulck API 的请求</li><li>对数据进行转换，并重新返回给 Index 和 Bluck API</li></ul></li><li>无需 Logstash ，就可以进行数据的预处理，例如<ul><li>为某个字段设置默认值；重命名某个字段的字段名；对字段值进行 Split 操作</li><li>支持设置 Painless 脚本，对数据进行更加复杂的加工</li></ul></li></ul><h3 id="Pipeline-amp-Processor"><a href="#Pipeline-amp-Processor" class="headerlink" title="Pipeline &amp; Processor"></a>Pipeline &amp; Processor</h3><ul><li>Pipeline - 管道会对通过的数据（文档），按照顺序进行加工</li><li>Processor - Elasticsearch 对一些加工的行为进行了抽象包装<ul><li>Elasticsearch 有很多内置的 Processors。也支持通过插件的方式，实现自己的 Processsor</li></ul></li></ul><p><img src="/images/big-data/es-06/48.jpg" alt="48"></p><h3 id="使用-Pipeline-切分字符串"><a href="#使用-Pipeline-切分字符串" class="headerlink" title="使用 Pipeline 切分字符串"></a>使用 Pipeline 切分字符串</h3><p><img src="/images/big-data/es-06/49.jpg" alt="49"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 测试split tags</span></span><br><span class="line">POST _ingest/pipeline/_simulate</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"pipeline"</span>: &#123;</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"to split blog tags"</span>,</span><br><span class="line">    <span class="attr">"processors"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"split"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"tags"</span>,</span><br><span class="line">          <span class="attr">"separator"</span>: <span class="string">","</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"docs"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"_index"</span>: <span class="string">"index"</span>,</span><br><span class="line">      <span class="attr">"_id"</span>: <span class="string">"id"</span>,</span><br><span class="line">      <span class="attr">"_source"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"Introducing big data......"</span>,</span><br><span class="line">        <span class="attr">"tags"</span>: <span class="string">"hadoop,elasticsearch,spark"</span>,</span><br><span class="line">        <span class="attr">"content"</span>: <span class="string">"You konw, for big data"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"_index"</span>: <span class="string">"index"</span>,</span><br><span class="line">      <span class="attr">"_id"</span>: <span class="string">"idxx"</span>,</span><br><span class="line">      <span class="attr">"_source"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"Introducing cloud computering"</span>,</span><br><span class="line">        <span class="attr">"tags"</span>: <span class="string">"openstack,k8s"</span>,</span><br><span class="line">        <span class="attr">"content"</span>: <span class="string">"You konw, for cloud"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="为文档增加字段"><a href="#为文档增加字段" class="headerlink" title="为文档增加字段"></a>为文档增加字段</h3><p><img src="/images/big-data/es-06/50.jpg" alt="50"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 同时为文档，增加一个字段。blog查看量</span></span><br><span class="line">POST _ingest/pipeline/_simulate</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"pipeline"</span>: &#123;</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"to split blog tags"</span>,</span><br><span class="line">    <span class="attr">"processors"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"split"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"tags"</span>,</span><br><span class="line">          <span class="attr">"separator"</span>: <span class="string">","</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"set"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"views"</span>,</span><br><span class="line">          <span class="attr">"value"</span>: <span class="number">0</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"docs"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"_index"</span>: <span class="string">"index"</span>,</span><br><span class="line">      <span class="attr">"_id"</span>: <span class="string">"id"</span>,</span><br><span class="line">      <span class="attr">"_source"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"Introducing big data......"</span>,</span><br><span class="line">        <span class="attr">"tags"</span>: <span class="string">"hadoop,elasticsearch,spark"</span>,</span><br><span class="line">        <span class="attr">"content"</span>: <span class="string">"You konw, for big data"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"_index"</span>: <span class="string">"index"</span>,</span><br><span class="line">      <span class="attr">"_id"</span>: <span class="string">"idxx"</span>,</span><br><span class="line">      <span class="attr">"_source"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"Introducing cloud computering"</span>,</span><br><span class="line">        <span class="attr">"tags"</span>: <span class="string">"openstack,k8s"</span>,</span><br><span class="line">        <span class="attr">"content"</span>: <span class="string">"You konw, for cloud"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Pipeline-API"><a href="#Pipeline-API" class="headerlink" title="Pipeline API"></a>Pipeline API</h3><p><img src="/images/big-data/es-06/51.jpg" alt="51"></p><h3 id="添加-Pipeline-并测试"><a href="#添加-Pipeline-并测试" class="headerlink" title="添加 Pipeline 并测试"></a>添加 Pipeline 并测试</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 为ES添加一个 Pipeline</span></span><br><span class="line">PUT _ingest/pipeline/blog_pipeline</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"description"</span>: <span class="string">"a blog pipeline"</span>,</span><br><span class="line">  <span class="attr">"processors"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"split"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"tags"</span>,</span><br><span class="line">        <span class="attr">"separator"</span>: <span class="string">","</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"set"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"views"</span>,</span><br><span class="line">        <span class="attr">"value"</span>: <span class="number">0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//查看Pipleline</span></span><br><span class="line">GET _ingest/pipeline/blog_pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment">//测试pipeline</span></span><br><span class="line">POST _ingest/pipeline/blog_pipeline/_simulate</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"docs"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"_source"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"Introducing cloud computering"</span>,</span><br><span class="line">        <span class="attr">"tags"</span>: <span class="string">"openstack,k8s"</span>,</span><br><span class="line">        <span class="attr">"content"</span>: <span class="string">"You konw, for cloud"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Index-amp-Update-By-Query"><a href="#Index-amp-Update-By-Query" class="headerlink" title="Index &amp; Update By Query"></a>Index &amp; Update By Query</h3><p><img src="/images/big-data/es-06/52.jpg" alt="52"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//不使用pipeline更新数据</span></span><br><span class="line">PUT tech_blogs/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"Introducing big data......"</span>,</span><br><span class="line">  <span class="attr">"tags"</span>:<span class="string">"hadoop,elasticsearch,spark"</span>,</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"You konw, for big data"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//使用pipeline更新数据</span></span><br><span class="line">PUT tech_blogs/_doc/2?pipeline=blog_pipeline</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>: <span class="string">"Introducing cloud computering"</span>,</span><br><span class="line">  <span class="attr">"tags"</span>: <span class="string">"openstack,k8s"</span>,</span><br><span class="line">  <span class="attr">"content"</span>: <span class="string">"You konw, for cloud"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//查看两条数据，一条被处理，一条未被处理</span></span><br><span class="line">POST tech_blogs/_search</span><br><span class="line">&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//update_by_query 会导致错误</span></span><br><span class="line">POST tech_blogs/_update_by_query?pipeline=blog_pipeline</span><br><span class="line">&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//增加update_by_query的条件</span></span><br><span class="line">POST tech_blogs/_update_by_query?pipeline=blog_pipeline</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must_not"</span>: &#123;</span><br><span class="line">        <span class="attr">"exists"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"views"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="一些内置的-Processors"><a href="#一些内置的-Processors" class="headerlink" title="一些内置的 Processors"></a>一些内置的 Processors</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html</a></p><ul><li>Split Processor （例如：将给定字段分成一个数组）</li><li>Remove / Rename Processor （移除一个重命名字段）</li><li>Append（为商品增加一个新的标签）</li><li>Convert （将商品价格，从字符串转换成 float 类型）</li><li>Date / JSON （日期格式转换，字符串转 JSON 对象）</li><li>Date Index Name Processor （将通过该处理器的文档，分配到指定时间格式的索引中）</li><li>Fail Processor （一旦出现异常，该 Pipeline 指定的错误信息能返回给用户）</li><li>Foreach Process （数组字段，数组的每个元素都会使用到一个相同的处理器）</li><li>Grok Processor （日志的日志格式切割）</li><li>Gsub / Join / Split （字符串替换、数组转字符串、字符串转数组）</li><li>Lowercase / Upcase（大小写转换）</li></ul><h3 id="Ingest-Node-v-s-Logstash"><a href="#Ingest-Node-v-s-Logstash" class="headerlink" title="Ingest Node v.s Logstash"></a>Ingest Node v.s Logstash</h3><table><thead><tr><th align="left"></th><th align="left">Logstash</th><th align="left">Ingest Node</th></tr></thead><tbody><tr><td align="left">数据输入与输出</td><td align="left">支持从不同的数据源读取，并写入不同的数据源</td><td align="left">支持从 ES REST API 获取数据，并且写入 ES</td></tr><tr><td align="left">数据源缓冲</td><td align="left">实现了简单的数据队列，支持重写</td><td align="left">不支持缓冲</td></tr><tr><td align="left">数据处理</td><td align="left">支持大量的的插件，也支持定制开发</td><td align="left">内置的插件，可以开发 Plugin 进行扩展（Plugin 更新需要重启）</td></tr><tr><td align="left">配置和使用</td><td align="left">增加了一定的架构复杂度</td><td align="left">无需额外部署</td></tr></tbody></table><blockquote><p><a href="https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes</a></p></blockquote><h3 id="Painless-简介"><a href="#Painless-简介" class="headerlink" title="Painless 简介"></a>Painless 简介</h3><ul><li>自 ES 5.x 后引入，专门为 ES 设置，扩展了 Java 的语法</li><li>6.0 开始，ES 只支持 Painless。Grooby ,JavaScript 和 Python 都不在支持</li><li>Painless 支持所有的 Java 的数据类型及 Java API 子集</li><li>Painless Script 具备以下特性<ul><li>高性能 / 安全</li><li>支持显示类型或者动态定义类型</li></ul></li></ul><h3 id="Painless-的用途"><a href="#Painless-的用途" class="headerlink" title="Painless 的用途"></a>Painless 的用途</h3><ul><li>可以对文档字段进行加工处理<ul><li>更新或者删除字段，处理数据聚合操作</li><li>Script Field： 对返回的字段提前进行计算</li><li>Function Score：对文档的算分进行处理</li></ul></li><li>在 Ingest Pipeline 中执行脚本</li><li>在 Reindex API，Update By Query 时，对数据进行处理</li></ul><h3 id="通过-Painless-脚本访问字段"><a href="#通过-Painless-脚本访问字段" class="headerlink" title="通过 Painless 脚本访问字段"></a>通过 Painless 脚本访问字段</h3><table><thead><tr><th align="left">上下文</th><th align="left">语法</th></tr></thead><tbody><tr><td align="left">Ingestion</td><td align="left">ctx.field_name</td></tr><tr><td align="left">Update</td><td align="left">ctx._source.field_name</td></tr><tr><td align="left">Search &amp; Aggregation</td><td align="left">doc{“field_name”]</td></tr></tbody></table><h3 id="案例-1：Script-Processsor"><a href="#案例-1：Script-Processsor" class="headerlink" title="案例 1：Script Processsor"></a>案例 1：Script Processsor</h3><p><img src="/images/big-data/es-06/53.jpg" alt="53"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 增加一个 Script Prcessor</span></span><br><span class="line">POST _ingest/pipeline/_simulate</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"pipeline"</span>: &#123;</span><br><span class="line">    <span class="attr">"description"</span>: <span class="string">"to split blog tags"</span>,</span><br><span class="line">    <span class="attr">"processors"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"split"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"tags"</span>,</span><br><span class="line">          <span class="attr">"separator"</span>: <span class="string">","</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"script"</span>: &#123;</span><br><span class="line">          <span class="attr">"source"</span>: <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">          if(ctx.containsKey("</span>content<span class="string">"))&#123;</span></span><br><span class="line"><span class="string">            ctx.content_length = ctx.content.length();</span></span><br><span class="line"><span class="string">          &#125;else&#123;</span></span><br><span class="line"><span class="string">            ctx.content_length=0;</span></span><br><span class="line"><span class="string">          &#125;</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"set"</span>: &#123;</span><br><span class="line">          <span class="attr">"field"</span>: <span class="string">"views"</span>,</span><br><span class="line">          <span class="attr">"value"</span>: <span class="number">0</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"docs"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"_index"</span>: <span class="string">"index"</span>,</span><br><span class="line">      <span class="attr">"_id"</span>: <span class="string">"id"</span>,</span><br><span class="line">      <span class="attr">"_source"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"Introducing big data......"</span>,</span><br><span class="line">        <span class="attr">"tags"</span>: <span class="string">"hadoop,elasticsearch,spark"</span>,</span><br><span class="line">        <span class="attr">"content"</span>: <span class="string">"You konw, for big data"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"_index"</span>: <span class="string">"index"</span>,</span><br><span class="line">      <span class="attr">"_id"</span>: <span class="string">"idxx"</span>,</span><br><span class="line">      <span class="attr">"_source"</span>: &#123;</span><br><span class="line">        <span class="attr">"title"</span>: <span class="string">"Introducing cloud computering"</span>,</span><br><span class="line">        <span class="attr">"tags"</span>: <span class="string">"openstack,k8s"</span>,</span><br><span class="line">        <span class="attr">"content"</span>: <span class="string">"You konw, for cloud"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="案例-2：文档更新计数"><a href="#案例-2：文档更新计数" class="headerlink" title="案例 2：文档更新计数"></a>案例 2：文档更新计数</h3><p><img src="/images/big-data/es-06/54.jpg" alt="54"></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">DELETE tech_blogs</span><br><span class="line">PUT tech_blogs/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"Introducing big data......"</span>,</span><br><span class="line">  <span class="attr">"tags"</span>:<span class="string">"hadoop,elasticsearch,spark"</span>,</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"You konw, for big data"</span>,</span><br><span class="line">  <span class="attr">"views"</span>:<span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST tech_blogs/_update/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"script"</span>: &#123;</span><br><span class="line">    <span class="attr">"source"</span>: <span class="string">"ctx._source.views += params.new_views"</span>,</span><br><span class="line">    <span class="attr">"params"</span>: &#123;</span><br><span class="line">      <span class="attr">"new_views"</span>:<span class="number">100</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看views计数</span></span><br><span class="line">POST tech_blogs/_search</span><br></pre></td></tr></table></figure><h3 id="案例-3：搜索时的-Script-字段"><a href="#案例-3：搜索时的-Script-字段" class="headerlink" title="案例 3：搜索时的 Script 字段"></a>案例 3：搜索时的 Script 字段</h3><p><img src="/images/big-data/es-06/55.jpg" alt="55"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">GET tech_blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"script_fields"</span>: &#123;</span><br><span class="line">    <span class="attr">"rnd_views"</span>: &#123;</span><br><span class="line">      <span class="attr">"script"</span>: &#123;</span><br><span class="line">        <span class="attr">"lang"</span>: <span class="string">"painless"</span>,</span><br><span class="line">        <span class="attr">"source"</span>: <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">          java.util.Random rnd = new Random();</span></span><br><span class="line"><span class="string">          doc['views'].value+rnd.nextInt(1000);</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Script-Inline-v-s-Stored"><a href="#Script-Inline-v-s-Stored" class="headerlink" title="Script: Inline v.s Stored"></a>Script: Inline v.s Stored</h3><p><img src="/images/big-data/es-06/56.jpg" alt="56"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//保存脚本在 Cluster State</span></span><br><span class="line">POST _scripts/update_views</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"script"</span>:&#123;</span><br><span class="line">    <span class="attr">"lang"</span>: <span class="string">"painless"</span>,</span><br><span class="line">    <span class="attr">"source"</span>: <span class="string">"ctx._source.views += params.new_views"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST tech_blogs/_update/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"script"</span>: &#123;</span><br><span class="line">    <span class="attr">"id"</span>: <span class="string">"update_views"</span>,</span><br><span class="line">    <span class="attr">"params"</span>: &#123;</span><br><span class="line">      <span class="attr">"new_views"</span>:<span class="number">1000</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="脚本缓存"><a href="#脚本缓存" class="headerlink" title="脚本缓存"></a>脚本缓存</h3><ul><li>编译的开销相较大</li><li>Elasticsearch 会将甲苯编译后缓存在 Cache 中<ul><li>Inline scripts 和 Stored Scripts 都会被缓存</li><li>默认缓存 100 个脚本</li></ul></li></ul><table><thead><tr><th align="left">参数</th><th align="left">说明</th></tr></thead><tbody><tr><td align="left">script.cache.max_size</td><td align="left">设置最大缓存数</td></tr><tr><td align="left">script.cache.expire</td><td align="left">设置缓存超时</td></tr><tr><td align="left">script.max_compilations_rate</td><td align="left">默认5分钟最多75次编译 （75/5m）</td></tr></tbody></table><h2 id="Elasticsearch-数据建模实例"><a href="#Elasticsearch-数据建模实例" class="headerlink" title="Elasticsearch 数据建模实例"></a>Elasticsearch 数据建模实例</h2><h3 id="什么是数据建模"><a href="#什么是数据建模" class="headerlink" title="什么是数据建模"></a>什么是数据建模</h3><ul><li>数据建模（Data modeling），是创建数据模型的过程。<ul><li>数据模型是对真实世界进行抽象描述的一种工具和方法，实现对现实世界的映射<ul><li>博客、作者、用户评论</li></ul></li><li>三个过程：概念模型 =&gt; 逻辑模型 =&gt; 数据模型（第三范式）<ul><li>数据模型：结合具体的数据库，在满足业务读写性能等需求的前提下，确定最终的定义</li></ul></li></ul></li></ul><h3 id="数据建模：功能需求-性能需求"><a href="#数据建模：功能需求-性能需求" class="headerlink" title="数据建模：功能需求 + 性能需求"></a>数据建模：功能需求 + 性能需求</h3><p><img src="/images/big-data/es-06/57.jpg" alt="57"></p><h3 id="如何对字段进行建模"><a href="#如何对字段进行建模" class="headerlink" title="如何对字段进行建模"></a>如何对字段进行建模</h3><p><img src="/images/big-data/es-06/58.jpg" alt="58"></p><h3 id="字段类型-：-Text-v-s-Keyword"><a href="#字段类型-：-Text-v-s-Keyword" class="headerlink" title="字段类型 ： Text v.s Keyword"></a>字段类型 ： Text v.s Keyword</h3><ul><li>Text<ul><li>用于全文本字段，文本会被 Analyzer 分词</li><li>默认不支持聚合分析及排序。需要设置 fielddata 为 true</li></ul></li><li>Keyword<ul><li>用于 id ，枚举及不需要分词的文本。例如电话号码，email 地址，手机号码，邮政编码，性别等</li><li>适用于 Filter（精确匹配），Sorting 和 Aggregations</li></ul></li><li>设置多字段类型<ul><li>默认会为文本类型设置成 text ，并且设置一个 keyword 的子字段</li><li>在处理人类语言时，通过增加 “英文”，“拼音” 和 “标准” 分词器，提高搜索结构</li></ul></li></ul><h3 id="字段类型：结构化数据"><a href="#字段类型：结构化数据" class="headerlink" title="字段类型：结构化数据"></a>字段类型：结构化数据</h3><ul><li>数据类型<ul><li>尽量选择贴近的类型。例如可以用 byte，就不要用 long</li></ul></li><li>枚举类型<ul><li>设置为 keyword 。即便是数字，也应该设置成 keyword ，获取更好的性能</li></ul></li><li>其他<ul><li>日期、布尔、地理信息</li></ul></li></ul><h3 id="检索"><a href="#检索" class="headerlink" title="检索"></a>检索</h3><ul><li>如不需要检索，排序和聚合分析<ul><li>Enable 设置成 false</li></ul></li><li>如不需要检索<ul><li>index 设置成 false</li></ul></li><li>对需要检索的字段，可以通过如下配置，设置存储粒度<ul><li>Index_options / Norms : 不需要归一化数据时，可以关闭</li></ul></li></ul><h3 id="聚合及排序"><a href="#聚合及排序" class="headerlink" title="聚合及排序"></a>聚合及排序</h3><ul><li>如不需要检索，排序和聚合分析<ul><li>Enable 设置成 false</li></ul></li><li>如不需要排序或者聚合分析功能<ul><li>Doc_values / fielddata 设置成 false</li></ul></li><li>更新频繁，聚合查询频繁的 keyword 类型的字段<ul><li>推荐将 eager_global_ordinals 设置为 true</li></ul></li></ul><h3 id="额外的存储"><a href="#额外的存储" class="headerlink" title="额外的存储"></a>额外的存储</h3><ul><li>是否需要专门存储当前字段数据<ul><li>Store 设置为 true ，可以存储该字段的原始数据</li><li>一般结合 _source 的 enabled 为 false 时候使用</li></ul></li><li>Disable _source ： 节约磁盘，适用于指标型数据<ul><li>一般建议先考虑增加压缩比</li><li>无法看到 _source 字段，无法做 ReIndex，无法做 Update</li><li>Kibana 中无法做 discovery</li></ul></li></ul><h3 id="一个数据建模的实例"><a href="#一个数据建模的实例" class="headerlink" title="一个数据建模的实例"></a>一个数据建模的实例</h3><ul><li>图书的索引<ul><li>书名</li><li>简介</li><li>作者</li><li>发行日期</li><li>图书封面</li></ul></li></ul><p><img src="/images/big-data/es-06/59.jpg" alt="59"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">PUT books/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"Mastering ElasticSearch 5.0"</span>,</span><br><span class="line">  <span class="attr">"description"</span>:<span class="string">"Master the searching, indexing, and aggregation features in ElasticSearch Improve users’ search experience with Elasticsearch’s functionalities and develop your own Elasticsearch plugins"</span>,</span><br><span class="line">  <span class="attr">"author"</span>:<span class="string">"Bharvi Dixit"</span>,</span><br><span class="line">  <span class="attr">"public_date"</span>:<span class="string">"2017"</span>,</span><br><span class="line">  <span class="attr">"cover_url"</span>:<span class="string">"https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"</span></span><br><span class="line">&#125;</span><br><span class="line">GET books/_mapping</span><br><span class="line"><span class="comment">// return </span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"books"</span> : &#123;</span><br><span class="line">    <span class="attr">"mappings"</span> : &#123;</span><br><span class="line">      <span class="attr">"properties"</span> : &#123;</span><br><span class="line">        <span class="attr">"author"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"cover_url"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"description"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"public_date"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"title"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="优化字段的设定"><a href="#优化字段的设定" class="headerlink" title="优化字段的设定"></a>优化字段的设定</h3><ul><li>图书的索引<ul><li>书名：支持全文和精确匹配</li><li>简介：支持全文</li><li>作者：精确值</li><li>发行日期：日期类型</li><li>图书封面：精确值</li></ul></li></ul><p><img src="/images/big-data/es-06/60.jpg" alt="60"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 优化字段类型</span></span><br><span class="line">PUT books</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span> : &#123;</span><br><span class="line">    <span class="attr">"properties"</span> : &#123;</span><br><span class="line">      <span class="attr">"author"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"keyword"</span>&#125;,</span><br><span class="line">      <span class="attr">"cover_url"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"keyword"</span>,<span class="attr">"index"</span>: <span class="literal">false</span>&#125;,</span><br><span class="line">      <span class="attr">"description"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"text"</span>&#125;,</span><br><span class="line">      <span class="attr">"public_date"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"date"</span>&#125;,</span><br><span class="line">      <span class="attr">"title"</span> : &#123;</span><br><span class="line">        <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"fields"</span> : &#123;</span><br><span class="line">          <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">            <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">            <span class="attr">"ignore_above"</span> : <span class="number">100</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Cover URL index 设置成false，无法对该字段进行搜索</span></span><br><span class="line">POST books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"cover_url"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Cover URL index 设置成false，依然支持聚合分析</span></span><br><span class="line">POST books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"cover"</span>: &#123;</span><br><span class="line">      <span class="attr">"terms"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"cover_url"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">10</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="需求变更"><a href="#需求变更" class="headerlink" title="需求变更"></a>需求变更</h3><ul><li>新需求：增加图书内容的字段，并要求能被搜索同时支持高亮显示</li><li>新需求会导致 _source 的内容过大<ul><li>Source Filtering 只是传输给客户端进行过滤，Fetch 数据时，ES 节点还是会传输 _source 中的数据</li></ul></li><li>解决方法<ul><li>关闭 _source</li><li>然后将每个字段的 “store” 设置成 true</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">DELETE books</span><br><span class="line"><span class="comment">// 新增 Content字段。数据量很大。选择将Source 关闭</span></span><br><span class="line">PUT books</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span> : &#123;</span><br><span class="line">    <span class="attr">"_source"</span>: &#123;<span class="attr">"enabled"</span>: <span class="literal">false</span>&#125;,</span><br><span class="line">    <span class="attr">"properties"</span> : &#123;</span><br><span class="line">      <span class="attr">"author"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"keyword"</span>,<span class="attr">"store"</span>: <span class="literal">true</span>&#125;,</span><br><span class="line">      <span class="attr">"cover_url"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"keyword"</span>,<span class="attr">"index"</span>: <span class="literal">false</span>,<span class="attr">"store"</span>: <span class="literal">true</span>&#125;,</span><br><span class="line">      <span class="attr">"description"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"text"</span>,<span class="attr">"store"</span>: <span class="literal">true</span>&#125;,</span><br><span class="line">       <span class="attr">"content"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"text"</span>,<span class="attr">"store"</span>: <span class="literal">true</span>&#125;,</span><br><span class="line">      <span class="attr">"public_date"</span> : &#123;<span class="attr">"type"</span> : <span class="string">"date"</span>,<span class="attr">"store"</span>: <span class="literal">true</span>&#125;,</span><br><span class="line">      <span class="attr">"title"</span> : &#123;</span><br><span class="line">        <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"fields"</span> : &#123;</span><br><span class="line">          <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">            <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">            <span class="attr">"ignore_above"</span> : <span class="number">100</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"store"</span>: <span class="literal">true</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="查询图书：解决字段过大引发的性能问题"><a href="#查询图书：解决字段过大引发的性能问题" class="headerlink" title="查询图书：解决字段过大引发的性能问题"></a>查询图书：解决字段过大引发的性能问题</h3><ul><li>返回结果不包含 _source 字段</li><li>对于需要显示的信息，可以在查询中指定 “store_fields”</li><li>禁止 _source 字段后，还是支持使用 hignlights API ，高亮显示 content 中的匹配的相关信息</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Index 一本书的信息,包含Content</span></span><br><span class="line">PUT books/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:<span class="string">"Mastering ElasticSearch 5.0"</span>,</span><br><span class="line">  <span class="attr">"description"</span>:<span class="string">"Master the searching, indexing, and aggregation features in ElasticSearch Improve users’ search experience with Elasticsearch’s functionalities and develop your own Elasticsearch plugins"</span>,</span><br><span class="line">  <span class="attr">"content"</span>:<span class="string">"The content of the book......Indexing data, aggregation, searching.    something else. something in the way............"</span>,</span><br><span class="line">  <span class="attr">"author"</span>:<span class="string">"Bharvi Dixit"</span>,</span><br><span class="line">  <span class="attr">"public_date"</span>:<span class="string">"2017"</span>,</span><br><span class="line">  <span class="attr">"cover_url"</span>:<span class="string">"https://images-na.ssl-images-amazon.com/images/I/51OeaMFxcML.jpg"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查询结果中，Source不包含数据</span></span><br><span class="line">POST books/_search</span><br><span class="line">&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 搜索，通过store 字段显示数据，同时高亮显示 conent的内容</span></span><br><span class="line">POST books/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"stored_fields"</span>: [<span class="string">"title"</span>,<span class="string">"author"</span>,<span class="string">"public_date"</span>],</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"content"</span>: <span class="string">"searching"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"highlight"</span>: &#123;</span><br><span class="line">    <span class="attr">"fields"</span>: &#123;</span><br><span class="line">      <span class="attr">"content"</span>:&#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Mapping-字段的相关设置"><a href="#Mapping-字段的相关设置" class="headerlink" title="Mapping 字段的相关设置"></a>Mapping 字段的相关设置</h3><ul><li>Enabled - 设置成 false，仅做存储，不支持搜索和聚合分析 （数据保存在_source 中）</li><li>Index - 是否构倒排索引。设置成 false，无法被搜索，但还是支持 aggregation，并出现在 _source<br>中</li><li>Norms - 如果字段用来过滤和聚合分析，可以关闭，节约存储</li><li>Doc_values - 是否启用 doc_values，用于排序和聚合分析</li><li>Field_data - 如果要对 text 类型启用排序和聚合分析， fielddata 需要设置成true</li><li>Store - 默认不存储，数据默认存储在 _source</li><li>Coerce - 默认开启，是否开启数据类型的自动转换（例如，字符串转数字）</li><li>Multifields 多字段特性</li><li>Dynamic - true / false / strict 控制 Mapping 的自动更新</li></ul><blockquote><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html</a></p></blockquote><h3 id="一些相关的-API"><a href="#一些相关的-API" class="headerlink" title="一些相关的 API"></a>一些相关的 API</h3><ul><li>Index Template &amp; Dynamic Template<ul><li>根据索引的名字匹配不同的 Mappings 和 Settings</li><li>可以在⼀个 Mapping 上动态的设定字段类型</li></ul></li><li>Index Alias<ul><li>⽆需停机，⽆需修改程序，即可进⾏修改</li></ul></li><li>Update By Query &amp; Reindex</li></ul><h2 id="Elasticsearch-数据建模佳实践"><a href="#Elasticsearch-数据建模佳实践" class="headerlink" title="Elasticsearch 数据建模佳实践"></a>Elasticsearch 数据建模佳实践</h2><h3 id="建模建议（一）：如何处理关联关系"><a href="#建模建议（一）：如何处理关联关系" class="headerlink" title="建模建议（一）：如何处理关联关系"></a>建模建议（一）：如何处理关联关系</h3><ul><li>Object ： 优先考虑 Denormailzation</li><li>Nested ： 当数据包含多数值对象（对个演员），同时有查询需求</li><li>Child/Parent: 关联文档更新非常频繁时</li></ul><h3 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h3><ul><li>Kibana 目前暂不支持 nested 类型 和 parent /child 类型，在未来有可能会支持</li><li>如果需要使用 Kibana 进行数据分析，在数据建模时仍需要对嵌套和父子关联类型作出取舍</li></ul><h3 id="建模建议（二）：避免过多字段"><a href="#建模建议（二）：避免过多字段" class="headerlink" title="建模建议（二）：避免过多字段"></a>建模建议（二）：避免过多字段</h3><ul><li>一个文档中，最好避免大量的字段<ul><li>过多的字段数不容易维护</li><li>Mapping 信息保存在 Cluster State 中， 数据量过大，对集群性能会有影响（Cluster State 信息需要和所有的节点同步）</li><li>删除或者修改数据需要 reindex</li></ul></li><li>默认最大字段数是 1000，可以设置 <code>index.mapping.total_fields.limit</code> 限制最大的字段数</li><li>什么原因会导致文档中会有成百上千的字段？</li></ul><h3 id="Dynamic-v-s-Strict"><a href="#Dynamic-v-s-Strict" class="headerlink" title="Dynamic v.s Strict"></a>Dynamic v.s Strict</h3><ul><li>Dynamic （生产环境中，尽量不要打开 Dynamic）<ul><li>true - 未知字段会被自动加入</li><li>false - 新字段不会被索引，但是会保存在 _source</li><li>strict - 新增字段不会被索引，文档写入失败</li></ul></li><li>Strict<ul><li>可以控制到字段级别</li></ul></li></ul><h3 id="一个例子：-Cookie-Service-的数据"><a href="#一个例子：-Cookie-Service-的数据" class="headerlink" title="一个例子： Cookie Service 的数据"></a>一个例子： Cookie Service 的数据</h3><ul><li>来自 Cookie Service 的数据<ul><li>Cookie 的键值对很多</li><li>当 Dynamic 设置为 True</li><li>同时采用扁平化的设计，必然导致字段数量的膨胀</li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">##索引数据，dynamic mapping 会不断加入新增字段</span><br><span class="line">PUT cookie_service/_doc/1</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"url"</span>:<span class="string">"www.google.com"</span>,</span><br><span class="line"> <span class="attr">"cookies"</span>:&#123;</span><br><span class="line">   <span class="attr">"username"</span>:<span class="string">"tom"</span>,</span><br><span class="line">   <span class="attr">"age"</span>:<span class="number">32</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT cookie_service/_doc/2</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"url"</span>:<span class="string">"www.amazon.com"</span>,</span><br><span class="line"> <span class="attr">"cookies"</span>:&#123;</span><br><span class="line">   <span class="attr">"login"</span>:<span class="string">"2019-01-01"</span>,</span><br><span class="line">   <span class="attr">"email"</span>:<span class="string">"xyz@abc.com"</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET cookie_service/_mapping</span><br></pre></td></tr></table></figure><h3 id="解决方案：Nested-Object-amp-Key-Value"><a href="#解决方案：Nested-Object-amp-Key-Value" class="headerlink" title="解决方案：Nested Object &amp; Key Value"></a>解决方案：Nested Object &amp; Key Value</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">DELETE cookie_service</span><br><span class="line"><span class="comment">// 使用 Nested 对象，增加key/value</span></span><br><span class="line">PUT cookie_service</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"cookies"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"nested"</span>,</span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">          <span class="attr">"name"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"dateValue"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"date"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"keywordValue"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"IntValue"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"integer"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"url"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"keyword"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"keyword"</span>,</span><br><span class="line">            <span class="attr">"ignore_above"</span>: <span class="number">256</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="写入-amp-查询"><a href="#写入-amp-查询" class="headerlink" title="写入 &amp; 查询"></a>写入 &amp; 查询</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">PUT cookie_service/_doc/1</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"url"</span>:<span class="string">"www.google.com"</span>,</span><br><span class="line"> <span class="attr">"cookies"</span>:[</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>:<span class="string">"username"</span>,</span><br><span class="line">      <span class="attr">"keywordValue"</span>:<span class="string">"tom"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>:<span class="string">"age"</span>,</span><br><span class="line">      <span class="attr">"intValue"</span>:<span class="number">32</span></span><br><span class="line">    &#125;</span><br><span class="line">   ]</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line">PUT cookie_service/_doc/2</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"url"</span>:<span class="string">"www.amazon.com"</span>,</span><br><span class="line"> <span class="attr">"cookies"</span>:[</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>:<span class="string">"login"</span>,</span><br><span class="line">      <span class="attr">"dateValue"</span>:<span class="string">"2019-01-01"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"name"</span>:<span class="string">"email"</span>,</span><br><span class="line">      <span class="attr">"IntValue"</span>:<span class="number">32</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Nested 查询，通过bool查询进行过滤</span></span><br><span class="line">POST cookie_service/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"nested"</span>: &#123;</span><br><span class="line">      <span class="attr">"path"</span>: <span class="string">"cookies"</span>,</span><br><span class="line">      <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"bool"</span>: &#123;</span><br><span class="line">          <span class="attr">"filter"</span>: [</span><br><span class="line">            &#123;</span><br><span class="line">            <span class="attr">"term"</span>: &#123;</span><br><span class="line">              <span class="attr">"cookies.name"</span>: <span class="string">"age"</span></span><br><span class="line">            &#125;&#125;,</span><br><span class="line">            &#123;</span><br><span class="line">              <span class="attr">"range"</span>:&#123;</span><br><span class="line">                <span class="attr">"cookies.intValue"</span>:&#123;</span><br><span class="line">                  <span class="attr">"gte"</span>:<span class="number">30</span></span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通过-Nested-对象保存-Key-Value-的一些不足"><a href="#通过-Nested-对象保存-Key-Value-的一些不足" class="headerlink" title="通过 Nested 对象保存 Key / Value 的一些不足"></a>通过 Nested 对象保存 Key / Value 的一些不足</h3><ul><li>可以减少字段数量，解决 Cluster State 中 保存过多 Meta 信息的问题，但是<ul><li>导致查询语句复杂度增加</li><li>Nested 对象 ，不利于在 Kibana 汇总实现可视化分析</li></ul></li></ul><h3 id="建模建议（三）：避免正则查询"><a href="#建模建议（三）：避免正则查询" class="headerlink" title="建模建议（三）：避免正则查询"></a>建模建议（三）：避免正则查询</h3><ul><li>问题：<ul><li>正则，通配符查询，前缀查询属于 Term 查询，但是性能不够好</li><li>特别是将通配符放在开头，会导致性能的灾难</li></ul></li><li>案例：<ul><li>文档中某个字段包含了 ES 的版本信息，例如 version：“7.1.0”</li><li>搜索所有是 bug fix 的版本？每个主要版本号所关联的文档？</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在Mapping中加入元信息，便于管理</span></span><br><span class="line">PUT softwares/</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"_meta"</span>: &#123;</span><br><span class="line">      <span class="attr">"software_version_mapping"</span>: <span class="string">"1.0"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET softwares/_mapping</span><br><span class="line">PUT softwares/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"software_version"</span>:<span class="string">"7.1.0"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="解决方案：将字符串转换为对象"><a href="#解决方案：将字符串转换为对象" class="headerlink" title="解决方案：将字符串转换为对象"></a>解决方案：将字符串转换为对象</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 优化, 使用inner object</span></span><br><span class="line">PUT softwares/</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"_meta"</span>: &#123;</span><br><span class="line">      <span class="attr">"software_version_mapping"</span>: <span class="string">"1.1"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"version"</span>: &#123;</span><br><span class="line">        <span class="attr">"properties"</span>: &#123;</span><br><span class="line">          <span class="attr">"display_name"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"keyword"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"hot_fix"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"byte"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"marjor"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"byte"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"minor"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"byte"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过 Inner Object 写入多个文档</span></span><br><span class="line">PUT softwares/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"version"</span>: &#123;</span><br><span class="line">    <span class="attr">"display_name"</span>: <span class="string">"7.1.0"</span>,</span><br><span class="line">    <span class="attr">"marjor"</span>: <span class="number">7</span>,</span><br><span class="line">    <span class="attr">"minor"</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="attr">"hot_fix"</span>: <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT softwares/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"version"</span>: &#123;</span><br><span class="line">    <span class="attr">"display_name"</span>: <span class="string">"7.2.0"</span>,</span><br><span class="line">    <span class="attr">"marjor"</span>: <span class="number">7</span>,</span><br><span class="line">    <span class="attr">"minor"</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"hot_fix"</span>: <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT softwares/_doc/3</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"version"</span>: &#123;</span><br><span class="line">    <span class="attr">"display_name"</span>: <span class="string">"7.2.1"</span>,</span><br><span class="line">    <span class="attr">"marjor"</span>: <span class="number">7</span>,</span><br><span class="line">    <span class="attr">"minor"</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="attr">"hot_fix"</span>: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="搜索过滤"><a href="#搜索过滤" class="headerlink" title="搜索过滤"></a>搜索过滤</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 通过 bool 查询，实现 filter 过滤，避免正则查询，大大提升性能。</span></span><br><span class="line">POST softwares/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"version.marjor"</span>: <span class="number">7</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"version.minor"</span>: <span class="number">2</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="建模建议（四）：避免空置引起的聚合不准"><a href="#建模建议（四）：避免空置引起的聚合不准" class="headerlink" title="建模建议（四）：避免空置引起的聚合不准"></a>建模建议（四）：避免空置引起的聚合不准</h3><p><img src="/images/big-data/es-06/61.jpg" alt="61"></p><h3 id="使用-Null-Value-解决空值的问题"><a href="#使用-Null-Value-解决空值的问题" class="headerlink" title="使用 Null_Value 解决空值的问题"></a>使用 Null_Value 解决空值的问题</h3><p><img src="/images/big-data/es-06/62.jpg" alt="62"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Not Null 解决聚合的问题</span></span><br><span class="line">DELETE ratings</span><br><span class="line">PUT ratings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">      <span class="attr">"properties"</span>: &#123;</span><br><span class="line">        <span class="attr">"rating"</span>: &#123;</span><br><span class="line">          <span class="attr">"type"</span>: <span class="string">"float"</span>,</span><br><span class="line">          <span class="attr">"null_value"</span>: <span class="number">1.0</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT ratings/_doc/1</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"rating"</span>:<span class="number">5</span></span><br><span class="line">&#125;</span><br><span class="line">PUT ratings/_doc/2</span><br><span class="line">&#123;</span><br><span class="line"> <span class="attr">"rating"</span>:<span class="literal">null</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">POST ratings/_search</span><br><span class="line">POST ratings/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"aggs"</span>: &#123;</span><br><span class="line">    <span class="attr">"avg"</span>: &#123;</span><br><span class="line">      <span class="attr">"avg"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"rating"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST ratings/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"rating"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="建模建议（五）：为索引的-Mapping-加入-Meta-的信息"><a href="#建模建议（五）：为索引的-Mapping-加入-Meta-的信息" class="headerlink" title="建模建议（五）：为索引的 Mapping 加入 Meta 的信息"></a>建模建议（五）：为索引的 Mapping 加入 Meta 的信息</h3><ul><li>Mappings 设置非常重要，需要从两个维度进行考虑<ul><li>功能：索引，聚合，排序</li><li>性能：存储的开销；内存的开销；搜索的性能</li></ul></li><li>Mappings 设置是一个迭代的过程<ul><li>加入新的字段容易（必要时需要 update_by_query）</li><li>更新删除字段不允许（需要 Reindex 重建数据）</li><li>最好能对 Mappings 加入 Meta 信息，更好的进行版本管理</li><li>可以考虑 Mapping 文件上传 git 进行管理</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 在Mapping中加入元信息，便于管理</span></span><br><span class="line">PUT softwares/</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"_meta"</span>: &#123;</span><br><span class="line">      <span class="attr">"software_version_mapping"</span>: <span class="string">"1.0"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>《Elasticsearch核心技术与实战》</li><li><a href="https://www.elastic.co/cn/blog/a-new-era-for-cluster-coordination-in-elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/a-new-era-for-cluster-coordination-in-elasticsearch</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-metrics.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-metrics.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-bucket.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-bucket.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-pipeline.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-aggregations-pipeline.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-nested-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-nested-query.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-child-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-child-query.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-parent-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-has-parent-query.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-parent-id-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-parent-id-query.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-reindex.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-reindex.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-update-by-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/docs-update-by-query.html</a></li><li><a href="https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes" target="_blank" rel="noopener">https://www.elastic.co/cn/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-apis.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-apis.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/ingest-processors.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-lang-spec.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-lang-spec.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-api-reference.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/painless/7.1/painless-api-reference.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/general-recommendations.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/general-recommendations.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-disk-usage.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-disk-usage.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/tune-for-search-speed.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/nested.html</a></li></ul><style>  img {    zoom: 50%;  }</style>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;深入了解 ES 集群、分页、聚合分析、父子文档、数据建模等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="BigData" scheme="https://blog.lichao.xin/categories/BigData/"/>
    
    
      <category term="Elastic Stack" scheme="https://blog.lichao.xin/tags/Elastic-Stack/"/>
    
      <category term="ES" scheme="https://blog.lichao.xin/tags/ES/"/>
    
  </entry>
  
  <entry>
    <title>重学 Elastic Stack 之 Elasticsearch 深入了解(一)</title>
    <link href="https://blog.lichao.xin/back-end/big-data/es-05/"/>
    <id>https://blog.lichao.xin/back-end/big-data/es-05/</id>
    <published>2021-02-06T15:00:00.000Z</published>
    <updated>2021-06-14T01:33:22.379Z</updated>
    
    <content type="html"><![CDATA[<p>深入了解 ES 高级搜索、相关性评分、搜索建议、自动补全等。</p><a id="more"></a><h2 id="基于词项和基于全文的搜索"><a href="#基于词项和基于全文的搜索" class="headerlink" title="基于词项和基于全文的搜索"></a>基于词项和基于全文的搜索</h2><h3 id="基于-Term-的查询"><a href="#基于-Term-的查询" class="headerlink" title="基于 Term 的查询"></a>基于 Term 的查询</h3><ul><li>Term 的 重要性<ul><li><strong>Term 是表达语意的最小单位</strong>。搜索和利用统计语言模型进行自然语言处理都需要处理 Term</li></ul></li><li>特点<ul><li>Term Level Query：Term Query / Range Query / Exists Query / Prefix Query / Wildcard Query</li><li>在 ES 中，Term 查询，对输入<strong>不做分词</strong>。会将输入作为一个整体，在倒排索引中查找准确的词项，并且使用相关度算分公式为每个包含该词项的文档进行<strong>相关度算分</strong> - 例如 “Apple Store”</li><li>可以通过 Constant Score 将查询转换换成一个 Filtering，<strong>避免算分，并利用缓存</strong>，提交性能</li></ul></li></ul><p><strong>Demo</strong> </p><ul><li>插入数据</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">DELETE products</span><br><span class="line">PUT products</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"settings"</span>: &#123;</span><br><span class="line">    <span class="attr">"number_of_shards"</span>: <span class="number">1</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /products/_bulk</span><br><span class="line">&#123; <span class="attr">"index"</span>: &#123; <span class="attr">"_id"</span>: <span class="number">1</span> &#125;&#125;</span><br><span class="line">&#123; <span class="attr">"productID"</span> : <span class="string">"XHDK-A-1293-#fJ3"</span>,<span class="attr">"desc"</span>:<span class="string">"iPhone"</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span>: &#123; <span class="attr">"_id"</span>: <span class="number">2</span> &#125;&#125;</span><br><span class="line">&#123; <span class="attr">"productID"</span> : <span class="string">"KDKE-B-9947-#kL5"</span>,<span class="attr">"desc"</span>:<span class="string">"iPad"</span> &#125;</span><br><span class="line">&#123; <span class="attr">"index"</span>: &#123; <span class="attr">"_id"</span>: <span class="number">3</span> &#125;&#125;</span><br><span class="line">&#123; <span class="attr">"productID"</span> : <span class="string">"JODL-X-1937-#pV7"</span>,<span class="attr">"desc"</span>:<span class="string">"MBP"</span> &#125;</span><br></pre></td></tr></table></figure><ul><li>查询</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 多字段 Mapping 和 Term 查询</span></span><br><span class="line">GET /products/_mapping</span><br><span class="line"></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"desc"</span>: &#123;</span><br><span class="line">        <span class="comment">//"value": "iPhone"</span></span><br><span class="line">        <span class="attr">"value"</span>:<span class="string">"iphone"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"desc.keyword"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"iPhone"</span> <span class="comment">//查不到数据，term查询</span></span><br><span class="line">        <span class="comment">//"value":"iphone" // 查到数据 term查询会做分词</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"productID"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"XHDK-A-1293-#fJ3"</span>  <span class="comment">// 无结果</span></span><br><span class="line">        <span class="comment">// "value": "xhdk" //有一条数据</span></span><br><span class="line">        <span class="comment">// "value": "xhdk-a-1293-#fj3"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//如果对值进行查询</span></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">//"explain": true,</span></span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"productID.keyword"</span>: &#123;</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"XHDK-A-1293-#fJ3"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="复合查询-Constant-Score-转为-Filter"><a href="#复合查询-Constant-Score-转为-Filter" class="headerlink" title="复合查询 - Constant Score 转为 Filter"></a>复合查询 - Constant Score 转为 Filter</h3><ul><li>将 Query 转成 Filter，忽略 TF-IDF 计算，避免相关性算分的开销</li><li>Filter 可以有效利用缓存</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"term"</span>: &#123;</span><br><span class="line">          <span class="attr">"productID.keyword"</span>: <span class="string">"XHDK-A-1293-#fJ3"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="基于全文本的查询"><a href="#基于全文本的查询" class="headerlink" title="基于全文本的查询"></a>基于全文本的查询</h3><ul><li>基于全文本的查找<ul><li>Match Query / Match Phrase Query / Query String Query</li></ul></li><li>特点<ul><li>索引和搜索时会进行分词，查询字符串先传递到一个合适的分词器，然后生成一个供查询的词项列表</li><li>查询时候，先<strong>会对输入的查询进行分词</strong>。然后每个词项逐个进行底层的查询，最终将结果进行合并。并未每个文档生成一个算分。 例如查 “Martix reloaded”, 会查到包括 Matrix 或者 reload 的所有结果。</li></ul></li></ul><h4 id="Match-Query-Result"><a href="#Match-Query-Result" class="headerlink" title="Match Query Result"></a>Match Query Result</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">POST movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>:&#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>:&#123;</span><br><span class="line">        <span class="attr">"query"</span>: <span class="string">"Matrix reloaded"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Operator"><a href="#Operator" class="headerlink" title="Operator"></a>Operator</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">POST movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>:&#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>:&#123;</span><br><span class="line">        <span class="attr">"query"</span>: <span class="string">"Matrix reloaded"</span>,</span><br><span class="line">        <span class="attr">"operator"</span>: <span class="string">"AND"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Minimun-should-match"><a href="#Minimun-should-match" class="headerlink" title="Minimun_should_match"></a>Minimun_should_match</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>:<span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>:&#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>:&#123;</span><br><span class="line">        <span class="attr">"query"</span>: <span class="string">"Matrix reloaded"</span>,</span><br><span class="line">        <span class="attr">"minimum_should_match"</span>: <span class="number">2</span> </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Match-Phrase-Query"><a href="#Match-Phrase-Query" class="headerlink" title="Match Phrase Query"></a>Match Phrase Query</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>:<span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>:&#123;</span><br><span class="line">    <span class="attr">"match_phrase"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>:&#123;</span><br><span class="line">        <span class="attr">"query"</span>: <span class="string">"Matrix reloaded"</span>,</span><br><span class="line">        <span class="attr">"slop"</span>: <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Match-Query-查询过程"><a href="#Match-Query-查询过程" class="headerlink" title="Match Query 查询过程"></a>Match Query 查询过程</h3><ul><li>基于全文本的查找<ul><li>Match Query / Match Phrase Query / Query String Query</li></ul></li><li>基于全文本的查询的特点<ul><li>索引和搜索时都会进行分词，查询字符串先传递到一个合适的分词器，然后生成一个供查询的词项列表</li><li>查询会对每个词项逐个进行底层的查询，再将结果进行合并，并未每个文档生成一个算分</li></ul></li></ul><p><img src="/images/big-data/es-05/1.jpg" alt="1"></p><p><strong>小结</strong></p><ul><li>基于词项的查找 vs 基于全文的查找</li><li>通过字段 Mapping 控制字段的分词<ul><li>“Text” vs “Keyword”</li></ul></li><li>通过参数控制查询的 Precision &amp; Recall</li><li>复合查询<ul><li>即使是对 Keyword 进行 Term 查询，同样会进行算分</li><li>可以将查询转为 Filtering，取消相关性算分的环节，以提高性能</li></ul></li></ul><h2 id="结构化搜索"><a href="#结构化搜索" class="headerlink" title="结构化搜索"></a>结构化搜索</h2><ul><li>结构化搜索（Structured search） 是指对结构化数据的搜索<ul><li>日期，布尔类型和数字都是结构化</li></ul></li><li>文本也可以是结构化的<ul><li>如彩色笔可以有离散的颜色集合：红（red）、绿（green）、蓝（blue）</li><li>一个博客可能被标记了标签，例如，分布式（distributed）和搜索（search）</li><li>电商网站上的商品都有 UPCs（通用产品码 Universal Product Codes）或其他的唯一标识，它们都遵从严格规定的、结构化的格式</li></ul></li></ul><h3 id="ES-中的机构化搜索"><a href="#ES-中的机构化搜索" class="headerlink" title="ES 中的机构化搜索"></a>ES 中的机构化搜索</h3><ul><li>布尔、时间，日期和数字这类结构化数据：有精确的格式，我们可以对这些格式进行逻辑操作。包括比较数字或时间的范围，或判断两个值的大小</li><li>结构化的文本可以做到精确匹配或者部分匹配<ul><li>Term 查询 / Prefix 前缀查询</li></ul></li><li>结构化结构只有 “是” 或 “否” 两个值<ul><li>根据场景需要，可以决定结构化搜索是否需要打分</li></ul></li></ul><p><strong>Demo</strong> </p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">DELETE products</span><br><span class="line">POST /products/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">1</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"price"</span>:<span class="number">10</span>,<span class="attr">"avaliable"</span>:<span class="literal">true</span>,<span class="attr">"date"</span>:<span class="string">"2018-01-01"</span>,<span class="attr">"productID"</span>:<span class="string">"XHDK-A-1293-#fJ3"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">2</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"price"</span>:<span class="number">20</span>,<span class="attr">"avaliable"</span>:<span class="literal">true</span>,<span class="attr">"date"</span>:<span class="string">"2019-01-01"</span>,<span class="attr">"productID"</span>:<span class="string">"KDKE-B-9947-#kL5"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">3</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"price"</span>:<span class="number">30</span>,<span class="attr">"avaliable"</span>:<span class="literal">true</span>,<span class="attr">"productID"</span>:<span class="string">"JODL-X-1937-#pV7"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">4</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"price"</span>:<span class="number">30</span>,<span class="attr">"avaliable"</span>:<span class="literal">false</span>,<span class="attr">"productID"</span>:<span class="string">"QQPX-R-3956-#aD8"</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 查看mapping</span></span><br><span class="line">GET products/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"products"</span> : &#123;</span><br><span class="line">    <span class="attr">"mappings"</span> : &#123;</span><br><span class="line">      <span class="attr">"properties"</span> : &#123;</span><br><span class="line">        <span class="attr">"avaliable"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"boolean"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"date"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"date"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"price"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"long"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"productID"</span> : &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"text"</span>,</span><br><span class="line">          <span class="attr">"fields"</span> : &#123;</span><br><span class="line">            <span class="attr">"keyword"</span> : &#123;</span><br><span class="line">              <span class="attr">"type"</span> : <span class="string">"keyword"</span>,</span><br><span class="line">              <span class="attr">"ignore_above"</span> : <span class="number">256</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>对布尔值 match 查询，有算分</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"avaliable"</span>: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>对布尔值，通过 constant score 转成 filtering，没有算分</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"term"</span>: &#123;</span><br><span class="line">          <span class="attr">"avaliable"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"boost"</span>: <span class="number">1.2</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>数字类型 Term</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"term"</span>: &#123;</span><br><span class="line">          <span class="attr">"price"</span>: <span class="number">30</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"boost"</span>: <span class="number">1.2</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>数字类型 terms</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"terms"</span>: &#123;</span><br><span class="line">          <span class="attr">"price"</span>: [</span><br><span class="line">              <span class="string">"20"</span>,</span><br><span class="line">              <span class="string">"30"</span></span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>数字 Range 查询<ul><li>gt 大于</li><li>lt 小于</li><li>gte 大于等于</li><li>lte 小于等于</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"range"</span>: &#123;</span><br><span class="line">          <span class="attr">"price"</span>: &#123;</span><br><span class="line">             <span class="attr">"gte"</span>: <span class="number">20</span>,</span><br><span class="line">             <span class="attr">"lte"</span>:<span class="number">30</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>日期 range<ul><li>Date Match Expressions</li><li><code>2020-01-01 00:00:00 || +1M</code></li></ul></li></ul><p><img src="/images/big-data/es-05/2.jpg" alt="2"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">  <span class="attr">"constant_score"</span>: &#123;</span><br><span class="line">    <span class="attr">"filter"</span>: &#123;</span><br><span class="line">      <span class="attr">"range"</span>: &#123;</span><br><span class="line">        <span class="attr">"date"</span>: &#123;</span><br><span class="line">           <span class="attr">"gte"</span>: <span class="string">"now-1y"</span>  <span class="comment">//当前时间减1年</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>exists 查询 - 非空查询</li></ul><p>类似于SQL：<code>IS NOT NULL</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"query"</span> : &#123;</span><br><span class="line">        <span class="attr">"constant_score"</span> : &#123;</span><br><span class="line">            <span class="attr">"filter"</span> : &#123;</span><br><span class="line">                <span class="attr">"exists"</span>: &#123;</span><br><span class="line">                    <span class="attr">"field"</span>:<span class="string">"date"</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类似于SQL：<code>IS NULL</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line"><span class="attr">"bool"</span>: &#123;</span><br><span class="line"><span class="attr">"must_not"</span>: [</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"exists"</span>: &#123;</span><br><span class="line"><span class="attr">"field"</span>: <span class="string">"date"</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>字符类型 terms</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"terms"</span>: &#123;</span><br><span class="line">          <span class="attr">"productID.keyword"</span>: [</span><br><span class="line">            <span class="string">"QQPX-R-3956-#aD8"</span>,</span><br><span class="line">            <span class="string">"JODL-X-1937-#pV7"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>处理多值字段</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">POST /movies/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">1</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title"</span>:<span class="string">"Father of the Bridge Part II"</span>,<span class="attr">"year"</span>:<span class="number">1995</span>,<span class="attr">"genre"</span>:<span class="string">"Comedy"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">2</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title"</span>:<span class="string">"Dave"</span>,<span class="attr">"year"</span>:<span class="number">1993</span>,<span class="attr">"genre"</span>:[<span class="string">"Comedy"</span>,<span class="string">"Romance"</span>]&#125;</span><br></pre></td></tr></table></figure><ul><li>处理多值字段，term 查询是包含，而不是等于</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//返回2条数据</span></span><br><span class="line">POST movies/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"constant_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"term"</span>: &#123;</span><br><span class="line">          <span class="attr">"genre.keyword"</span>: <span class="string">"Comedy"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Match 跟 term 对比</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"term"</span>: &#123;</span><br><span class="line">      <span class="attr">"date"</span>: <span class="string">"2019-01-01"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"profile"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"date"</span>: <span class="string">"2019-01-01"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>小结</strong></p><ul><li>机构化数据 &amp; 结构化搜索<ul><li>如果不需要算分，可以通过 Constant Score ，将查询转为 Filterng</li></ul></li><li>范围查询 和 Date Match</li><li>使用 Exist 查询处理非空 NULL 值</li><li>精确值 &amp; 多值字段的精确值查找<ul><li>Term 查询是包含，不是完全相等。针对多值字段查询要尤其注意</li></ul></li></ul><p><strong>什么时候用 term 跟 match</strong></p><blockquote><p>结构化数据的精确匹配，就使用 term 查询。日期属于结构化数据。match 主要用于文本的 full-text 查询</p></blockquote><h2 id="搜索的相关性算分"><a href="#搜索的相关性算分" class="headerlink" title="搜索的相关性算分"></a>搜索的相关性算分</h2><p>ES 对查询关键字和索引文档的相关度进行打分，得分高的就排在前边。</p><ul><li>相关性 - Relevance<ul><li>搜索的相关性算分，描述了一个文档和查询语句匹配的程度。ES 会对每个匹配查询条件的结构进行算分_score</li><li>打分的本质是排序 , 需要把最符合用户需求的文档排在前面。ES 5 之前，默认的相关性打分采用 TF-IDF，现在采用 BM25</li></ul></li></ul><table><thead><tr><th align="center">词（Term）</th><th align="center">文档（Doc ID)</th></tr></thead><tbody><tr><td align="center">区块链</td><td align="center">1，2，3</td></tr><tr><td align="center">的</td><td align="center">2，3，4，5，6，7，8</td></tr><tr><td align="center">应用</td><td align="center">2，3，8，9，10</td></tr></tbody></table><h3 id="词频-TF"><a href="#词频-TF" class="headerlink" title="词频 TF"></a>词频 TF</h3><ul><li>Term Frequency∶ 检索词在一篇文档中出现的频率<ul><li>检索词出现的次数除以文档的总字数</li></ul></li><li>度量一条查询和结果文档相关性的简单方法：简单将搜索中每一个 词的 TF 进行相加<ul><li>$ TF(区块链) + TF(的) + TF(应用) $</li></ul></li><li>Stop Word<ul><li>“的”在文档中出现了很多次，但是对贡献相关度几乎没有用处，不应该考虑他们的 TF</li></ul></li></ul><h3 id="逆文档频率-IDF"><a href="#逆文档频率-IDF" class="headerlink" title="逆文档频率 IDF"></a>逆文档频率 IDF</h3><ul><li><p>DF：检索词在所有文档中出现的频率</p><ul><li>“区块链” 在相对比较少的文档中出现</li><li>“应用” 在相对比较多的文档中出现</li><li>“Stop Word” 在大量的文档中出现</li></ul></li><li><p>Inverse Document Frequency：$ 简单说 = log（全部文档数 / 检索词出现过的文档总数）$</p></li><li><p>TF-IDF 本质上就是将 TF 求和变成了加权求和</p></li><li><p>$ TF(区块链) * IDF(区块链) + TF(的) * IDF(的) + TF(应用) *  IDF(应用) $</p></li></ul><table><thead><tr><th align="center"></th><th align="center">出现的文档数</th><th align="center">总文档数</th><th align="center">IDF</th></tr></thead><tbody><tr><td align="center">区块链</td><td align="center">200万</td><td align="center">10亿</td><td align="center">log(500) = 8.96</td></tr><tr><td align="center">的</td><td align="center">10亿</td><td align="center">10亿</td><td align="center">log(1) = 0</td></tr><tr><td align="center">应用</td><td align="center">5亿</td><td align="center">10亿</td><td align="center">log(2) = 1</td></tr></tbody></table><blockquote><p>这里 log 底数是 2</p></blockquote><h3 id="TF-IDF-的概念"><a href="#TF-IDF-的概念" class="headerlink" title="TF-IDF 的概念"></a>TF-IDF 的概念</h3><ul><li>TF-IDF 被公认为是信息检索领域最重要的发明</li><li>除了在信息检索，在文献分类和其他相关领域有着非常广泛的应用</li><li>IDF 的概念，最早是剑桥大学的”斯巴克.琼斯”提出<ul><li>1972年 一 “关键词特殊性的统计解释和它在文献检索中的应用”</li><li>但是没有从理论上解释 IDF应该是用 log（全部文档数 / 检索词出现过的文档总数），而不是其他函数。他也没有做进一步的研究</li></ul></li><li>1970，1980年代萨尔顿和罗宾逊，进行了进一步的证明和研究，并用香农信息论做了证明<ul><li><a href="http://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf" target="_blank" rel="noopener">http://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf</a></li></ul></li><li>现代搜索引擎，对 TF-IDF 进行了大量细微的优化</li></ul><h3 id="Lucene-中的-TF-IDF-评分公式"><a href="#Lucene-中的-TF-IDF-评分公式" class="headerlink" title="Lucene 中的 TF-IDF 评分公式"></a>Lucene 中的 TF-IDF 评分公式</h3><p><img src="/images/big-data/es-05/3.jpg" alt="3"></p><ul><li><strong>score(q,d)</strong> 是指查询输入Q和当前文档D的相关性得分；</li><li><strong>coord(q,d)</strong> 是协调因子，表示输入的Token被文档匹配到的比例；</li><li><strong>queryNorm(q)</strong> 是查询输入归一化因子，其作用是使最终的得分不至于太大，从而具有一定的可比性；</li><li><strong>tf(t,d)</strong> 表示输入的一个Token在文档中出现的频率，频率越高，得分越高；</li><li>*<em>idf(t) *</em> 表示输入的一个Token的频率级别，它具体的计算与当前文档无关，而是与索引中出现的频率相关，出现频率越低，说明这个词是个稀缺词，得分会越高；</li><li><strong>boost(t)</strong> 是查询时指定的权重；</li><li><strong>norm(t,d)</strong> 是指当前文档的Term数量的一个权重，文档越短，相关性越高。</li></ul><h3 id="BM25"><a href="#BM25" class="headerlink" title="BM25"></a>BM25</h3><p><img src="/images/big-data/es-05/4.jpg" alt="4"></p><ul><li>从 ES 5开始，默认算法改为 BM25；</li><li>和经典的 TF-ID F相比，当 TF无限增加时，BM 25 算分会趋于一个数值。</li></ul><h3 id="定制-Similarity"><a href="#定制-Similarity" class="headerlink" title="定制 Similarity"></a>定制 Similarity</h3><p><img src="/images/big-data/es-05/5.jpg" alt="5"></p><h3 id="通过-Explain-API-查看-TF-IDF"><a href="#通过-Explain-API-查看-TF-IDF" class="headerlink" title="通过 Explain API 查看 TF-IDF"></a>通过 Explain API 查看 TF-IDF</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">PUT testscore/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">1</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"content"</span>:<span class="string">"we use Elasticsearch to power the search"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">2</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"content"</span>:<span class="string">"we like elasticsearch"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">3</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"content"</span>:<span class="string">"The scoring of documents is caculated by the scoring formula"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">4</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"content"</span>:<span class="string">"you know, for search"</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//查询</span></span><br><span class="line">POST /testscore/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"explain"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">     <span class="comment">// "content":"you"</span></span><br><span class="line">      <span class="attr">"content"</span>: <span class="string">"elasticsearch"</span></span><br><span class="line">      <span class="comment">//"content":"the"</span></span><br><span class="line">      <span class="comment">//"content": "the elasticsearch"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Boosting-Relevance"><a href="#Boosting-Relevance" class="headerlink" title="Boosting Relevance"></a>Boosting Relevance</h3><ul><li>Boosting 是控制相关度的一种手段<ul><li>索引，字段或查询子条件</li></ul></li><li>参数 boost 的含义<ul><li>当 boost &gt; 1 时，打分的相关度相对性提高</li><li>当 0 &lt; boost &lt; 1 时，打分的权重相对性降低</li><li>当 boost &lt; 0 时，贡献度负分</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">POST testscore/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"boosting"</span> : &#123;</span><br><span class="line">      <span class="attr">"positive"</span> : &#123;</span><br><span class="line">        <span class="attr">"term"</span> : &#123;</span><br><span class="line">          <span class="attr">"content"</span> : <span class="string">"elasticsearch"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"negative"</span> : &#123;</span><br><span class="line">        <span class="attr">"term"</span> : &#123;</span><br><span class="line">          <span class="attr">"content"</span> : <span class="string">"like"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"negative_boost"</span> : <span class="number">0.2</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Query-amp-Filtering-与-多字符串多字段查询"><a href="#Query-amp-Filtering-与-多字符串多字段查询" class="headerlink" title="Query &amp; Filtering 与 多字符串多字段查询"></a>Query &amp; Filtering 与 多字符串多字段查询</h2><p><img src="/images/big-data/es-05/6.jpg" alt="6"></p><ul><li>高级搜索的功能：支持多项文本输入，针对多个字段进行搜索</li><li>搜索引擎一般也提供基于时间，价格等条件的过滤</li><li>在 ES 中，有 Query 和 Filter 两种 Context<ul><li>Query Context：相关性算分</li><li>Filter Context：不需要算分（Yes or No）, 可以利用 Cache 获得更好的性能</li></ul></li></ul><h3 id="条件组合"><a href="#条件组合" class="headerlink" title="条件组合"></a>条件组合</h3><ul><li>假设要搜索一本电影，包含了以下条件<ul><li>评论中包含了 Guitar ，用户打分高于 3 分，同时上映时间在 1993 到 2000 年之间</li></ul></li><li>这个搜索包含了 3 段逻辑，针对不同的字段<ul><li>评论字段中要包含 Guitar 、用户评论大于 3、上映时间日期在给定范围内</li></ul></li><li>同时包含这三个逻辑，并且有比较好的性能<ul><li>复合查询： bool Query</li></ul></li></ul><h3 id="bool-查询"><a href="#bool-查询" class="headerlink" title="bool 查询"></a>bool 查询</h3><ul><li>一个 bool 查询，是一个或者多个查询子句的组合<ul><li>总共包含 4 种子句，其中 2 种会影响算分，2 种不影响算分</li></ul></li><li>相关性并不只是全文本搜索的专利。也适合 yes | no 的子句，匹配的子句越多，相关性评分越高。如果多条查询子句被合并为一条复合查询语句，比如 bool 查询，则每个查询子句计算得出的评分会被合并到总的相关性评分中。</li></ul><p><img src="/images/big-data/es-05/7.jpg" alt="7"></p><h3 id="bool-查询语句"><a href="#bool-查询语句" class="headerlink" title="bool 查询语句"></a>bool 查询语句</h3><ul><li>子查询可以任意顺序出现</li><li>可以嵌套多个查询</li><li>如果你的 bool 查询中，没有 must 条件，should 中必须满足一条查询</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//插入数据</span></span><br><span class="line">POST /products/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">1</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"price"</span>:<span class="number">10</span>,<span class="attr">"avaliable"</span>:<span class="literal">true</span>,<span class="attr">"date"</span>:<span class="string">"2018-01-01"</span>,<span class="attr">"productID"</span>:<span class="string">"XHDK-A-1293-#fJ3"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">2</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"price"</span>:<span class="number">20</span>,<span class="attr">"avaliable"</span>:<span class="literal">true</span>,<span class="attr">"date"</span>:<span class="string">"2019-01-01"</span>,<span class="attr">"productID"</span>:<span class="string">"KDKE-B-9947-#kL5"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">3</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"price"</span>:<span class="number">30</span>,<span class="attr">"avaliable"</span>:<span class="literal">true</span>,<span class="attr">"productID"</span>:<span class="string">"JODL-X-1937-#pV7"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">4</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"price"</span>:<span class="number">30</span>,<span class="attr">"avaliable"</span>:<span class="literal">false</span>,<span class="attr">"productID"</span>:<span class="string">"QQPX-R-3956-#aD8"</span>&#125;</span><br><span class="line"><span class="comment">//查询</span></span><br><span class="line">POST /products/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: &#123;</span><br><span class="line">        <span class="attr">"term"</span>: &#123;</span><br><span class="line">          <span class="attr">"price"</span>: <span class="string">"30"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"filter"</span>: &#123;</span><br><span class="line">        <span class="attr">"term"</span>: &#123;</span><br><span class="line">          <span class="attr">"avaliable"</span>: <span class="string">"true"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"must_not"</span>: &#123;</span><br><span class="line">        <span class="attr">"range"</span>: &#123;</span><br><span class="line">          <span class="attr">"price"</span>: &#123;</span><br><span class="line">            <span class="attr">"lte"</span>: <span class="number">10</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"should"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"term"</span>: &#123;</span><br><span class="line">            <span class="attr">"productID.keyword"</span>: <span class="string">"JODL-X-1937-#pV7"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"term"</span>: &#123;</span><br><span class="line">            <span class="attr">"productID.keyword"</span>: <span class="string">"XHDK-A-1293-#fJ3"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"minimum_should_match"</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注意：ES中 同时使用 should 和 must 导致只有 must 生效</strong></p><blockquote><p>should 并不是 or 的关系</p></blockquote><p><strong>解决1：</strong></p><p>使用多个must嵌套查询 将should组成的bool查询包含在其中一个must查询中</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">GET _search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"must"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"bool"</span>: &#123;</span><br><span class="line">            <span class="attr">"should"</span>: [</span><br><span class="line">              &#123;</span><br><span class="line">                <span class="attr">"match_phrase"</span>: &#123;</span><br><span class="line">                  <span class="attr">"title"</span>: <span class="string">"疫情期间"</span></span><br><span class="line">                &#125;</span><br><span class="line">              &#125;,</span><br><span class="line">              &#123;</span><br><span class="line">                <span class="attr">"match_phrase"</span>: &#123;</span><br><span class="line">                  <span class="attr">"content"</span>: <span class="string">"疫情期间"</span></span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            ]</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"1"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"must_not"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"enabled"</span>: <span class="number">0</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"highlight"</span>: &#123;</span><br><span class="line">    <span class="attr">"pre_tags"</span>: [</span><br><span class="line">      <span class="string">"&lt;font color='red'&gt;"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"post_tags"</span>: [</span><br><span class="line">      <span class="string">"&lt;/font&gt;"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"fields"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>: &#123;&#125;,</span><br><span class="line">      <span class="attr">"content"</span>: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>解决2：</strong></p><ul><li>minimum_should_match 设置为 1</li></ul><h3 id="如何解决结构化查询-“包含而不是相等”-的问题"><a href="#如何解决结构化查询-“包含而不是相等”-的问题" class="headerlink" title="如何解决结构化查询 - “包含而不是相等” 的问题"></a>如何解决结构化查询 - “包含而不是相等” 的问题</h3><p><img src="/images/big-data/es-05/8.jpg" alt="8"></p><p><strong>增加 count 字段，使用 bool 查询</strong></p><ul><li>从业务角度，按需改进 ES 数据模型</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">POST /newmovies/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">1</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title"</span>:<span class="string">"Father of the Bridge Part II"</span>,<span class="attr">"year"</span>:<span class="number">1995</span>,<span class="attr">"genre"</span>:<span class="string">"Comedy"</span>,<span class="attr">"genre_count"</span>:<span class="number">1</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">2</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title"</span>:<span class="string">"Dave"</span>,<span class="attr">"year"</span>:<span class="number">1993</span>,<span class="attr">"genre"</span>:[<span class="string">"Comedy"</span>,<span class="string">"Romance"</span>],<span class="attr">"genre_count"</span>:<span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Query Context - 影响算分</span></span><br><span class="line"><span class="comment">// must 有算分</span></span><br><span class="line">POST /newmovies/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">  <span class="attr">"bool"</span>: &#123;</span><br><span class="line">    <span class="attr">"must"</span>: [</span><br><span class="line">      &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"genre.keyword"</span>: &#123;<span class="attr">"value"</span>: <span class="string">"Comedy"</span>&#125;&#125;&#125;,</span><br><span class="line">      &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"genre_count"</span>: &#123;<span class="attr">"value"</span>: <span class="number">1</span>&#125;&#125;&#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Filter Context - 不影响算分</span></span><br><span class="line"><span class="comment">// Filter。不参与算分，结果的score是0</span></span><br><span class="line">POST /newmovies/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">  <span class="attr">"bool"</span>: &#123;</span><br><span class="line">    <span class="attr">"filter"</span>: [</span><br><span class="line">      &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"genre.keyword"</span>: &#123;<span class="attr">"value"</span>: <span class="string">"Comedy"</span>&#125;&#125;&#125;,</span><br><span class="line">      &#123;<span class="attr">"term"</span>: &#123;<span class="attr">"genre_count"</span>: &#123;<span class="attr">"value"</span>: <span class="number">1</span>&#125;&#125;&#125;</span><br><span class="line">      ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="bool-嵌套"><a href="#bool-嵌套" class="headerlink" title="bool 嵌套"></a>bool 嵌套</h3><p><img src="/images/big-data/es-05/9.jpg" alt="9"></p><h3 id="查询语句的结构，会对相关度算分产生影响"><a href="#查询语句的结构，会对相关度算分产生影响" class="headerlink" title="查询语句的结构，会对相关度算分产生影响"></a>查询语句的结构，会对相关度算分产生影响</h3><ul><li>同一层级下的竞争字段，具有相同的权重</li><li>通过嵌套 bool 查询，可以改变对算分的影响</li></ul><p><img src="/images/big-data/es-05/10.jpg" alt="10"></p><h3 id="控制字段的-Boosting"><a href="#控制字段的-Boosting" class="headerlink" title="控制字段的 Boosting"></a>控制字段的 Boosting</h3><p><img src="/images/big-data/es-05/11.jpg" alt="11"></p><h3 id="Not-Quite-Not"><a href="#Not-Quite-Not" class="headerlink" title="Not Quite Not"></a>Not Quite Not</h3><p><img src="/images/big-data/es-05/12.jpg" alt="12"></p><h3 id="Boosting-Query"><a href="#Boosting-Query" class="headerlink" title="Boosting Query"></a>Boosting Query</h3><p><img src="/images/big-data/es-05/13.jpg" alt="13"></p><p><strong>小结</strong></p><ul><li>Query Context vs Filter Context</li><li>Bool Query - 更多的条件组合</li><li>查询结构与相关性算分</li><li>如何控制查询的精确度<ul><li>Boosting &amp; Boosting Query</li></ul></li></ul><h2 id="单字符串多字段查询：Dis-Max-Query"><a href="#单字符串多字段查询：Dis-Max-Query" class="headerlink" title="单字符串多字段查询：Dis Max Query"></a>单字符串多字段查询：Dis Max Query</h2><h3 id="单字符串查询"><a href="#单字符串查询" class="headerlink" title="单字符串查询"></a>单字符串查询</h3><ul><li>Google 只提供一个输入框，查询相关的多个字段</li><li>支持按照价格，时间等进行过虑</li></ul><p><strong>单字符串查询的实例</strong></p><ul><li>博客标题<ul><li>文档1中出现”Brown”</li></ul></li><li>博客内容<ul><li>文档1中出现了”Brown”</li><li>“Brown fox”在文档 2中全部出现，并且保持和查询一致的顺序（目测相关性最高）</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">PUT /blogs/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>: <span class="string">"Quick brown rabbits"</span>,</span><br><span class="line">  <span class="attr">"body"</span>: <span class="string">"Brown rabbits are commonly seen."</span></span><br><span class="line">&#125;</span><br><span class="line">PUT /blogs/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>: <span class="string">"Keeping pets healthy"</span>,</span><br><span class="line">  <span class="attr">"body"</span>: <span class="string">"My quick brown fox eats rabbits on a regular basis."</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//查询语句</span></span><br><span class="line">POST /blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"bool"</span>: &#123;</span><br><span class="line">      <span class="attr">"should"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"title"</span>: <span class="string">"Brown fox"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"match"</span>: &#123;</span><br><span class="line">            <span class="attr">"body"</span>: <span class="string">"Brown fox"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="算分过程"><a href="#算分过程" class="headerlink" title="算分过程"></a>算分过程</h4><ul><li>查询 should 语句中的两个查询</li><li>加和两个查询的评分</li><li>乘以匹配语句的总数</li><li>除以所有语句的总数</li></ul><h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">"hits" : &#123;</span><br><span class="line">    "total" : &#123;</span><br><span class="line">      "value" : 2,</span><br><span class="line">      "relation" : "eq"</span><br><span class="line">    &#125;,</span><br><span class="line">    "max_score" : 0.90425634,</span><br><span class="line">    "hits" : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"blogs"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.90425634</span>, <span class="comment">// 因为2个字段都有brown</span></span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"title"</span> : <span class="string">"Quick brown rabbits"</span>,</span><br><span class="line">          <span class="attr">"body"</span> : <span class="string">"Brown rabbits are commonly seen."</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"blogs"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"2"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.77041256</span>,</span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"title"</span> : <span class="string">"Keeping pets healthy"</span>,</span><br><span class="line">          <span class="attr">"body"</span> : <span class="string">"My quick brown fox eats rabbits on a regular basis."</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p><img src="/images/big-data/es-05/14.jpg" alt="14"> <img src="/images/big-data/es-05/15.jpg" alt="15"></p><h3 id="Disjunction-Max-Query-查询"><a href="#Disjunction-Max-Query-查询" class="headerlink" title="Disjunction Max Query 查询"></a>Disjunction Max Query 查询</h3><ul><li>上列中，title 和 body 相互竞争<ul><li>不应该将分数简单叠加，而是应该找个单个最佳匹配的字段的评分</li></ul></li><li>Disjunction Max Query<ul><li>将任何与任一查询匹配的文档作为结果返回。采用字段上最匹配的评分返回</li></ul></li></ul><p><img src="/images/big-data/es-05/16.jpg" alt="16"></p><h3 id="最佳字段查询调优"><a href="#最佳字段查询调优" class="headerlink" title="最佳字段查询调优"></a>最佳字段查询调优</h3><ul><li>有一些情况下，同时匹配 title 和 body 字段的文档比只与一个字段匹配的文档的相关度更高</li><li>但 disjunction max query 查询指挥简单的使用单个最佳匹配语句的评分_scoce 作为整体评分，怎么办？</li></ul><h3 id="通过-Tie-Breaker-参数调整"><a href="#通过-Tie-Breaker-参数调整" class="headerlink" title="通过 Tie Breaker 参数调整"></a>通过 Tie Breaker 参数调整</h3><ul><li>获得最佳匹配语句的评分 _score</li><li>将其他匹配语句的评分 与 tie_breaker 相乘</li><li>对以上评分求和并规范化<ul><li>Tie Breanker 是一个介于 0-1 之间的浮点数。0 代表使用最佳匹配；1 代表所有语句同等重要。</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST blogs/_search</span><br><span class="line">&#123;</span><br><span class="line"><span class="attr">"query"</span>: &#123;</span><br><span class="line">  <span class="attr">"dis_max"</span>: &#123;</span><br><span class="line">      <span class="attr">"queries"</span>: [</span><br><span class="line">          &#123; <span class="attr">"match"</span>: &#123; <span class="attr">"title"</span>: <span class="string">"Quick pets"</span> &#125;&#125;,</span><br><span class="line">          &#123; <span class="attr">"match"</span>: &#123; <span class="attr">"body"</span>:  <span class="string">"Quick pets"</span> &#125;&#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"tie_breaker"</span>: <span class="number">0.2</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="单字符串多字段查询-Multi-Match"><a href="#单字符串多字段查询-Multi-Match" class="headerlink" title="单字符串多字段查询: Multi Match"></a>单字符串多字段查询: Multi Match</h2><ul><li>最佳字段（Best Fields）<ul><li>当字段之间相互竞争，又相互关联。例如 title 和 body 这样的字段，评分来自最匹配字段</li></ul></li><li>多数字段（Most Fields）<ul><li>处理英文内容时：一种常见的手段是，在主字段（English Analyzer），抽取词干，加入同义词，以匹配更多的文档。相同的文本，加入子字段（Standard Analyzer），以提供更加精确的匹配。其他字段作为匹配文档提高性相关度的信号。匹配字段越多越好</li></ul></li><li>混合字段（Cross Field）<ul><li>对于某些实体，例如人名，地址，图书信息。需要在多个字段中确定信息，单个字段只能作为整体的一部分。希望在任何这些列出的字段中尽可能找出多的词</li></ul></li></ul><h3 id="Multi-Match-Query"><a href="#Multi-Match-Query" class="headerlink" title="Multi Match Query"></a>Multi Match Query</h3><ul><li>Best Fields 是默认类型，可不指定</li><li>Minimum should match 等参数可以传递到生成的 query 中</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">POST blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"best_fields"</span>,</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"Quick pets"</span>,</span><br><span class="line">      <span class="attr">"fields"</span>: [<span class="string">"title"</span>,<span class="string">"body"</span>],</span><br><span class="line">      <span class="attr">"tie_breaker"</span>: <span class="number">0.2</span>,</span><br><span class="line">      <span class="attr">"minimum_should_match"</span>: <span class="string">"20%"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>查询案例</strong></p><ul><li>英文分词器，导致精确度降低，时态信息丢失</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">PUT /titles</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>:&#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"analyzer"</span>: <span class="string">"english"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST titles/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">1</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title"</span>:<span class="string">"My dog barks"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">2</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title"</span>:<span class="string">"I see a lot of barking dogs on the road "</span>&#125;</span><br><span class="line"></span><br><span class="line">GET titles/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>: <span class="string">"barking dogs"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//结果 因为是english 分词 ，且短 则 id 排第一个</span></span><br><span class="line">"hits" : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"titles"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.24399278</span>,</span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"title"</span> : <span class="string">"My dog barks"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"titles"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"2"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.1854345</span>,</span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"title"</span> : <span class="string">"I see a lot of barking dogs on the road "</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><p><strong>重新设置 mapping</strong></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">DELETE titles</span><br><span class="line">PUT /titles</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"title"</span>:&#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="attr">"analyzer"</span>: <span class="string">"english"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"std"</span>:&#123;</span><br><span class="line">            <span class="attr">"type"</span>:<span class="string">"text"</span>,</span><br><span class="line">            <span class="attr">"analyzer"</span>:<span class="string">"standard"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">POST titles/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">1</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title"</span>:<span class="string">"My dog barks"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;<span class="attr">"_id"</span>:<span class="number">2</span>&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title"</span>:<span class="string">"I see a lot of barking dogs on the road "</span>&#125;</span><br><span class="line"><span class="comment">//multi_match 查询</span></span><br><span class="line">GET titles/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"barking dogs"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"most_fields"</span>, <span class="comment">//默认是best_fields</span></span><br><span class="line">      <span class="attr">"fields"</span>: [<span class="string">"title"</span>,<span class="string">"title.std"</span>]<span class="comment">//累计叠加</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//返回</span></span><br><span class="line">"hits" : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"titles"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"2"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">1.4569323</span>,</span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"title"</span> : <span class="string">"I see a lot of barking dogs on the road "</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"titles"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.42221838</span>,</span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"title"</span> : <span class="string">"My dog barks"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><h3 id="使用多字段匹配解决"><a href="#使用多字段匹配解决" class="headerlink" title="使用多字段匹配解决"></a>使用多字段匹配解决</h3><ul><li>用广度匹配字段 title 包括尽可能多的文档 - 以提高召回率 ，同时又使用字段 title.std 作为信息将相关度更高的文档结至于文档顶部</li><li>每个字段对于最终评分的贡献可以通过自定义值 boost 来控制。比如，使 title 字段更为重要，这样同时也降低了其他信号字段的作用</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET titles/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"barking dogs"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"most_fields"</span>, </span><br><span class="line">      <span class="attr">"fields"</span>: [<span class="string">"title^10"</span>,<span class="string">"title.std"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="跨字段搜索"><a href="#跨字段搜索" class="headerlink" title="跨字段搜索"></a>跨字段搜索</h3><ul><li>most_fields 无法使用 opeartor<ul><li>可以用 copy_to 解决，但是需要额外的储存空间</li></ul></li><li>cross_fields 可以支持 operator<ul><li>与 copy_to 相比，其中一个优势就是可以在搜索时为某个字段提升权重</li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">PUT address/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"street"</span>:<span class="string">"5 Poland Street"</span>,</span><br><span class="line">  <span class="attr">"city"</span> : <span class="string">"Lodon"</span>,</span><br><span class="line">  <span class="attr">"country"</span>:<span class="string">"United Kingdom"</span>,</span><br><span class="line">  <span class="attr">"postcode"</span> : <span class="string">"W1V 3DG"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST address/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>:&#123;</span><br><span class="line">    <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: <span class="string">"Poland Street W1V"</span>,</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"cross_fields"</span>,  <span class="comment">//most_fields查询为空</span></span><br><span class="line">      <span class="attr">"operator"</span>: <span class="string">"and"</span>, </span><br><span class="line">      <span class="attr">"fields"</span>: [<span class="string">"street"</span>,<span class="string">"city"</span>,<span class="string">"country"</span>,<span class="string">"postcode"</span>]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">"hits" : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"_index"</span> : <span class="string">"address"</span>,</span><br><span class="line">        <span class="attr">"_type"</span> : <span class="string">"_doc"</span>,</span><br><span class="line">        <span class="attr">"_id"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"_score"</span> : <span class="number">0.8630463</span>,</span><br><span class="line">        <span class="attr">"_source"</span> : &#123;</span><br><span class="line">          <span class="attr">"street"</span> : <span class="string">"5 Poland Street"</span>,</span><br><span class="line">          <span class="attr">"city"</span> : <span class="string">"Lodon"</span>,</span><br><span class="line">          <span class="attr">"country"</span> : <span class="string">"United Kingdom"</span>,</span><br><span class="line">          <span class="attr">"postcode"</span> : <span class="string">"W1V 3DG"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure><h2 id="多语言及中文分词与检索"><a href="#多语言及中文分词与检索" class="headerlink" title="多语言及中文分词与检索"></a>多语言及中文分词与检索</h2><h3 id="自然语言与查询-Recall"><a href="#自然语言与查询-Recall" class="headerlink" title="自然语言与查询 Recall"></a>自然语言与查询 Recall</h3><ul><li>当处理人类自然语言时，有些情况，尽管搜索和原文不完全匹配，但是希望搜到一些内容<ul><li>Quick brown fox 和 fast brown fox / Jumping fox 和 Jumped foxes</li></ul></li><li>一些可采取的优化<ul><li>归一化词元：清除变音符号，如 rÔle 的的时候 也会匹配 role</li><li>抽取词根：清除单复数和时态的差异</li><li>包含同义词</li><li>拼写错误：拼写错误，或者同音异形词</li></ul></li></ul><h3 id="混合多语言的挑战"><a href="#混合多语言的挑战" class="headerlink" title="混合多语言的挑战"></a>混合多语言的挑战</h3><ul><li>一些具体的多语言场景<ul><li>不同的索引使用不同的语言 / 同一索引中，不同的字段使用不同的语言 / 一个文档的一个字段内混合不同的语言</li></ul></li><li>混合语言存在的一些挑战<ul><li>词干提取：以色列文档，包含了希伯来语，阿拉伯语，俄语和英文</li><li>不争取的文档频率 - 英文为主的文章中，德文算分高（稀有）</li><li>需要判断用户搜索时使用的语言，语言识别（Compact Language Detecor）<ul><li>例如，根据语言查询不同的索引</li></ul></li></ul></li></ul><h3 id="分词的挑战"><a href="#分词的挑战" class="headerlink" title="分词的挑战"></a>分词的挑战</h3><ul><li>英文分词：You’re 分成一个还是多个？Half-baked</li><li>中文分词<ul><li>分词的标椎：哈工大标椎中，姓和名分开。HanLP 是在一起的。具体情况需制定不同的标椎</li><li>歧义（组合型歧义，交际型歧义，真歧义）<ul><li>中华人民共和国 / 美国会通过对台收武器法案 / 上海仁和服装厂</li></ul></li></ul></li></ul><h3 id="中文分词方法的演变-字典法"><a href="#中文分词方法的演变-字典法" class="headerlink" title="中文分词方法的演变 - 字典法"></a>中文分词方法的演变 - 字典法</h3><ul><li>查字典 - 最容易想到的分词方法（北京航空大学的梁南元教授提出）<ul><li>一个句子从左到到右扫描一遍。遇到有点词就标识出来。找到复合词，就找最长的</li><li>不认识的字符串就分割成单字词</li></ul></li><li>最小词数的分词理论 - 哈工大王晓龙博士吧查字典的方法理论化<ul><li>一句话应该分词数量最少的词串</li><li>遇到二义性的分割，无能为力（例如：“发展中国家”/“上海大学城书店”）</li><li>用各种文化规则来解决二义性，都并不成功</li></ul></li></ul><h3 id="中文分词方法的演变-基于统计法的机器学习算法"><a href="#中文分词方法的演变-基于统计法的机器学习算法" class="headerlink" title="中文分词方法的演变 - 基于统计法的机器学习算法"></a>中文分词方法的演变 - 基于统计法的机器学习算法</h3><ul><li>统计语言模型 - 1990 年前后 ，清华大学电子工程系郭进博士<ul><li>解决了二义性问题，将中文分词的错误率降低了一个数据级。概率问题，动态规划 + 利用维特比算法快速找到最佳分词</li></ul></li><li>基于统计的机器学习算法<ul><li>这类目前常用的算法是 HMM、CRF、SVM、深度学习算法等算法。比如 Hanlp 分词工具是基于 CRF 算法为例，基本思路是对汉字进行标注训练，不仅考虑了词语出现的频率，还考虑上下文，具有较好的学习能力，因此其对歧义词和未登录词的识别都具有良好的下效果</li><li>随着深度学习的兴起，也出现了基于神经网路的分词器，有人尝试使用双向 LSTM + CRF 实现分词器，其本质上是序列标注，据报道其分词器字符准确率可高达 97.5%</li></ul></li></ul><h3 id="中文分词器现状"><a href="#中文分词器现状" class="headerlink" title="中文分词器现状"></a>中文分词器现状</h3><ul><li>中文分词器以统计语言模型为基础，经过几十年的发展，今天基本已经可以看做是一个已经解决的问题</li><li>不同分词器的好坏，主要的差别在于数据的使用和工程使用的精度</li><li>常见的分词器都是使用机器学期算法和词典相结合，一方面能够提高分词准确率，另一方面能够改善领域适应性</li></ul><h3 id="一些分词工具"><a href="#一些分词工具" class="headerlink" title="一些分词工具"></a>一些分词工具</h3><ul><li>Elasticsearch IK分词插件 <a href="https://github.com/medcl/elasticsearch-analysis-ik/releases" target="_blank" rel="noopener">https://github.com/medcl/elasticsearch-analysis-ik/releases</a></li><li>Elasticsearch HanLP 分词插件 <a href="https://github.com/KennFalcon/elasticsearch-analysis-hanlp" target="_blank" rel="noopener">https://github.com/KennFalcon/elasticsearch-analysis-hanlp</a></li><li>中科院计算所NLPIR <a href="http://ictclas.nlpir.org/nlpir/" target="_blank" rel="noopener">http://ictclas.nlpir.org/nlpir/</a></li><li>ansj分词器 <a href="https://github.com/NLPchina/ansj_seg" target="_blank" rel="noopener">https://github.com/NLPchina/ansj_seg</a></li><li>哈工大的LTP <a href="https://github.com/HIT-SCIR/ltp" target="_blank" rel="noopener">https://github.com/HIT-SCIR/ltp</a></li><li>清华大学THULAC <a href="https://github.com/thunlp/THULAC" target="_blank" rel="noopener">https://github.com/thunlp/THULAC</a></li><li>斯坦福分词器 <a href="https://nlp.stanford.edu/software/segmenter.shtml" target="_blank" rel="noopener">https://nlp.stanford.edu/software/segmenter.shtml</a></li><li>Hanlp分词器 <a href="https://github.com/hankcs/HanLP" target="_blank" rel="noopener">https://github.com/hankcs/HanLP</a></li><li>结巴分词 <a href="https://github.com/yanyiwu/cppjieba" target="_blank" rel="noopener">https://github.com/yanyiwu/cppjieba</a></li><li>KCWS分词器(字嵌入+Bi-LSTM+CRF) <a href="https://github.com/koth/kcws" target="_blank" rel="noopener">https://github.com/koth/kcws</a></li><li>ZPar <a href="https://github.com/frcchang/zpar/releases" target="_blank" rel="noopener">https://github.com/frcchang/zpar/releases</a></li><li>IKAnalyzer <a href="https://github.com/wks/ik-analyzer" target="_blank" rel="noopener">https://github.com/wks/ik-analyzer</a></li></ul><h3 id="中文分词-DEMO"><a href="#中文分词-DEMO" class="headerlink" title="中文分词 DEMO"></a>中文分词 DEMO</h3><ul><li>使用不同分词器测试效果</li><li>索引时，尽量切分的短，查询的时候，尽量用长的词</li><li>拼音分词器</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#安装插件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># IK Analysis - 支持字典热更新</span></span><br><span class="line">bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.1.0/elasticsearch-analysis-ik-7.1.0.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拼音</span></span><br><span class="line">bin/elasticsearch install https://github.com/medcl/elasticsearch-analysis-pinyin/releases/download/v7.1.0/elasticsearch-analysis-pinyin-7.1.0.zip</span><br><span class="line"></span><br><span class="line"><span class="comment"># HanLP - 支持加载远程字典</span></span><br><span class="line">bin/elasticsearch install https://github.com/KennFalcon/elasticsearch-analysis-hanlp/releases/download/v7.1.0/elasticsearch-analysis-hanlp-7.1.0.zip</span><br></pre></td></tr></table></figure><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ik_max_word</span></span><br><span class="line"><span class="comment">// ik_smart</span></span><br><span class="line"><span class="comment">// hanlp: hanlp默认分词</span></span><br><span class="line"><span class="comment">// hanlp_standard: 标准分词</span></span><br><span class="line"><span class="comment">// hanlp_index: 索引分词</span></span><br><span class="line"><span class="comment">// hanlp_nlp: NLP分词</span></span><br><span class="line"><span class="comment">// hanlp_n_short: N-最短路分词</span></span><br><span class="line"><span class="comment">// hanlp_dijkstra: 最短路分词</span></span><br><span class="line"><span class="comment">// hanlp_crf: CRF分词（在hanlp 1.6.6已开始废弃）</span></span><br><span class="line"><span class="comment">// hanlp_speed: 极速词典分词</span></span><br><span class="line"></span><br><span class="line">POST _analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"analyzer"</span>: <span class="string">"hanlp_standard"</span>,</span><br><span class="line">  <span class="attr">"text"</span>: [<span class="string">"剑桥分析公司多位高管对卧底记者说，他们确保了唐纳德·特朗普在总统大选中获胜"</span>]</span><br><span class="line">&#125;     </span><br><span class="line"></span><br><span class="line"><span class="comment">// Pinyin</span></span><br><span class="line">PUT /artists/</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"settings"</span> : &#123;</span><br><span class="line">        <span class="attr">"analysis"</span> : &#123;</span><br><span class="line">            <span class="attr">"analyzer"</span> : &#123;</span><br><span class="line">                <span class="attr">"user_name_analyzer"</span> : &#123;</span><br><span class="line">                    <span class="attr">"tokenizer"</span> : <span class="string">"whitespace"</span>,</span><br><span class="line">                    <span class="attr">"filter"</span> : <span class="string">"pinyin_first_letter_and_full_pinyin_filter"</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"filter"</span> : &#123;</span><br><span class="line">                <span class="attr">"pinyin_first_letter_and_full_pinyin_filter"</span> : &#123;</span><br><span class="line">                    <span class="attr">"type"</span> : <span class="string">"pinyin"</span>,</span><br><span class="line">                    <span class="attr">"keep_first_letter"</span> : <span class="literal">true</span>,</span><br><span class="line">                    <span class="attr">"keep_full_pinyin"</span> : <span class="literal">false</span>,</span><br><span class="line">                    <span class="attr">"keep_none_chinese"</span> : <span class="literal">true</span>,</span><br><span class="line">                    <span class="attr">"keep_original"</span> : <span class="literal">false</span>,</span><br><span class="line">                    <span class="attr">"limit_first_letter_length"</span> : <span class="number">16</span>,</span><br><span class="line">                    <span class="attr">"lowercase"</span> : <span class="literal">true</span>,</span><br><span class="line">                    <span class="attr">"trim_whitespace"</span> : <span class="literal">true</span>,</span><br><span class="line">                    <span class="attr">"keep_none_chinese_in_first_letter"</span> : <span class="literal">true</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET /artists/_analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"text"</span>: [<span class="string">"刘德华 张学友 郭富城 黎明 四大天王"</span>],</span><br><span class="line">  <span class="attr">"analyzer"</span>: <span class="string">"user_name_analyzer"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">curl -XPOST http://localhost:9200/index/_mapping -H 'Content-Type:application/json' -d &#123;</span><br><span class="line">  "properties": &#123;</span><br><span class="line">    "content": &#123;</span><br><span class="line">      "type": "text",</span><br><span class="line">      "analyzer": "ik_max_word",</span><br><span class="line">      "search_analyzer" : "ik_smart"</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="测试相关性一理解原理-＋-多分析-＋-多调整测试"><a href="#测试相关性一理解原理-＋-多分析-＋-多调整测试" class="headerlink" title="测试相关性一理解原理 ＋ 多分析 ＋ 多调整测试"></a>测试相关性一理解原理 ＋ 多分析 ＋ 多调整测试</h2><ul><li>技术分为道和术两种<ul><li>道 一 原理和原则</li><li>术 一 具体的做法，具体的解法</li></ul></li><li>关于搜索，为了有一个好的搜索结果。除了真正理解背后的原理，更需要多加实践与分析<ul><li>单纯追求”术”，会一直很辛苦。只有掌握了本质和精髓之”道”，做事才能游刃有余</li><li>要做好搜索，除了理解原理，也需要坚持去分析一些不好的搜索结果。只有通过一定时间的积累，<br>才能真正有所感觉</li><li>总希望一个模型，一个算法，就能毕其功于一役，是不现实的</li></ul></li></ul><h3 id="监控并且理解用户行为"><a href="#监控并且理解用户行为" class="headerlink" title="监控并且理解用户行为"></a>监控并且理解用户行为</h3><ul><li>不要过度调试相关度</li><li>而要监控搜索结果，监控用户点击最顶端结果的频次</li><li>将搜索结果提高到极高水平，唯一途径就是<ul><li>需要具有度量用户行为的强大能力</li><li>可以在后台实现统计数据，比如，用户的查询和结果，有多少被点击了</li><li>哪些搜索，没有返回结果</li></ul></li></ul><h2 id="使用-Search-Template-和-Index-Alias"><a href="#使用-Search-Template-和-Index-Alias" class="headerlink" title="使用 Search Template 和 Index Alias"></a>使用 Search Template 和 Index Alias</h2><h3 id="Search-Template-解耦程序-amp-搜索-DSL"><a href="#Search-Template-解耦程序-amp-搜索-DSL" class="headerlink" title="Search Template - 解耦程序 &amp; 搜索 DSL"></a>Search Template - 解耦程序 &amp; 搜索 DSL</h3><ul><li>Elasticsearch 的查询语句<ul><li>对相关性算分 / 查询性能都至关重要</li></ul></li><li>在开发初期，虽然可以明确查询参数，但是往往还不能最终定义查询的 DSL 的具体结构<ul><li>通过 Search Template 定义一个 Contract</li></ul></li><li>各司其职，解耦<ul><li>开发人员 / 搜索工程师 / 性能工程师</li></ul></li></ul><h3 id="使用-Search-Template-进行查询"><a href="#使用-Search-Template-进行查询" class="headerlink" title="使用 Search Template 进行查询"></a>使用 Search Template 进行查询</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">DELETE _scripts/tmdb</span><br><span class="line"><span class="comment">// 定义模板</span></span><br><span class="line">POST _scripts/tmdb</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"script"</span>: &#123;</span><br><span class="line">    <span class="attr">"lang"</span>: <span class="string">"mustache"</span>,</span><br><span class="line">    <span class="attr">"source"</span>: &#123;</span><br><span class="line">      <span class="attr">"_source"</span>: [</span><br><span class="line">        <span class="string">"title"</span>,<span class="string">"overview"</span></span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"size"</span>: <span class="number">20</span>,</span><br><span class="line">      <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">          <span class="attr">"query"</span>: <span class="string">"&#123;&#123;q&#125;&#125;"</span>,</span><br><span class="line">          <span class="attr">"fields"</span>: [<span class="string">"title"</span>,<span class="string">"overview"</span>]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">GET _scripts/tmdb</span><br><span class="line"></span><br><span class="line">POST tmdb/_search/template</span><br><span class="line">&#123;</span><br><span class="line">    <span class="attr">"id"</span>:<span class="string">"tmdb"</span>,</span><br><span class="line">    <span class="attr">"params"</span>: &#123;</span><br><span class="line">        <span class="attr">"q"</span>: <span class="string">"basketball with cartoon aliens"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用-Index-Alias-实现零停机运维"><a href="#使用-Index-Alias-实现零停机运维" class="headerlink" title="使用 Index Alias 实现零停机运维"></a>使用 Index Alias 实现零停机运维</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">PUT movies-2019/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"name"</span>:<span class="string">"the matrix"</span>,</span><br><span class="line">  <span class="attr">"rating"</span>:<span class="number">5</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT movies-2019/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"name"</span>:<span class="string">"Speed"</span>,</span><br><span class="line">  <span class="attr">"rating"</span>:<span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST _aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"movies-2019"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"movies-latest"</span> <span class="comment">// 为索引创建个别名</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//通过别名读写数据</span></span><br><span class="line">POST movies-latest/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用-Alias-创建不同查询的视图"><a href="#使用-Alias-创建不同查询的视图" class="headerlink" title="使用 Alias 创建不同查询的视图"></a>使用 Alias 创建不同查询的视图</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">POST _aliases</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"actions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"add"</span>: &#123;</span><br><span class="line">        <span class="attr">"index"</span>: <span class="string">"movies-2019"</span>,</span><br><span class="line">        <span class="attr">"alias"</span>: <span class="string">"movies-lastest-highrate"</span>,</span><br><span class="line">        <span class="attr">"filter"</span>: &#123;</span><br><span class="line">          <span class="attr">"range"</span>: &#123;</span><br><span class="line">            <span class="attr">"rating"</span>: &#123;</span><br><span class="line">              <span class="attr">"gte"</span>: <span class="number">4</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">POST movies-lastest-highrate/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match_all"</span>: &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="综合排序-Function-Score-Query-优化算分"><a href="#综合排序-Function-Score-Query-优化算分" class="headerlink" title="综合排序 Function Score Query 优化算分"></a>综合排序 Function Score Query 优化算分</h2><h3 id="算分与排序"><a href="#算分与排序" class="headerlink" title="算分与排序"></a>算分与排序</h3><ul><li>ES 默认会以文档的相关度算分进行排序</li><li>可以通过制定一个或者多个字段进行排序</li><li>使用相关性算分（score）排序，不能满足某些特定条件<ul><li>无法针对相关度，对排序实现更多的控制</li></ul></li></ul><h3 id="Function-Score-Query"><a href="#Function-Score-Query" class="headerlink" title="Function Score Query"></a>Function Score Query</h3><ul><li>Function Score Query<ul><li>可以在查询结束后，对每一个匹配的文档进行一系列的重新算分，根据新生成的分数进行排序</li></ul></li><li>提供了几种默认的计算分值的函数<ul><li>Weight：为每一个文档设置一个简单而不被规范化的权重</li><li>Field Value Factor：使用该数值来修改_score，例如将 “热度” 和 “点赞数” 作为算分的参考因素</li><li>Random Score：为每一个用户使用一个不同的，随机算分结果</li><li>衰减函数∶ 以某个字段的值为标准，距离某个值越近，得分越高</li><li>Script Score∶ 自定义脚本完全控制所需逻辑</li></ul></li></ul><h3 id="按受欢迎度提升权重"><a href="#按受欢迎度提升权重" class="headerlink" title="按受欢迎度提升权重"></a>按受欢迎度提升权重</h3><ul><li>希望能够将点赞多的 blog，放在搜索列表相对靠前的位置。同事搜索的评分，还是要作为排序的主要依据</li><li>新的算分 = 老的算分 * 投票数<ul><li>投票数为 0</li><li>投票数很大时</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">DELETE blogs</span><br><span class="line">PUT /blogs/_doc/1</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:   <span class="string">"About popularity"</span>,</span><br><span class="line">  <span class="attr">"content"</span>: <span class="string">"In this post we will talk about..."</span>,</span><br><span class="line">  <span class="attr">"votes"</span>:   <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /blogs/_doc/2</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:   <span class="string">"About popularity"</span>,</span><br><span class="line">  <span class="attr">"content"</span>: <span class="string">"In this post we will talk about..."</span>,</span><br><span class="line">  <span class="attr">"votes"</span>:   <span class="number">100</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT /blogs/_doc/3</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"title"</span>:   <span class="string">"About popularity"</span>,</span><br><span class="line">  <span class="attr">"content"</span>: <span class="string">"In this post we will talk about..."</span>,</span><br><span class="line">  <span class="attr">"votes"</span>:   <span class="number">1000000</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">POST /blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"function_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">          <span class="attr">"query"</span>:    <span class="string">"popularity"</span>,</span><br><span class="line">          <span class="attr">"fields"</span>: [ <span class="string">"title"</span>, <span class="string">"content"</span> ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"field_value_factor"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"votes"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用-Modifier-平滑曲线"><a href="#使用-Modifier-平滑曲线" class="headerlink" title="使用 Modifier 平滑曲线"></a>使用 Modifier 平滑曲线</h3><ul><li>新的算分 = 老的算分 * log（1 + 投票数）</li></ul><p><img src="/images/big-data/es-05/17.jpg" alt="17"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST /blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"function_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">          <span class="attr">"query"</span>:    <span class="string">"popularity"</span>,</span><br><span class="line">          <span class="attr">"fields"</span>: [ <span class="string">"title"</span>, <span class="string">"content"</span> ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"field_value_factor"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"votes"</span>,</span><br><span class="line">        <span class="attr">"modifier"</span>: <span class="string">"log1p"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="引入-Factor"><a href="#引入-Factor" class="headerlink" title="引入 Factor"></a>引入 Factor</h3><ul><li>新的算分 = 老的算分 * log（1 + factor * 投票数）</li></ul><p><img src="/images/big-data/es-05/18.jpg" alt="18"></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">POST /blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"function_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">          <span class="attr">"query"</span>:    <span class="string">"popularity"</span>,</span><br><span class="line">          <span class="attr">"fields"</span>: [ <span class="string">"title"</span>, <span class="string">"content"</span> ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"field_value_factor"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"votes"</span>,</span><br><span class="line">        <span class="attr">"modifier"</span>: <span class="string">"log1p"</span> ,</span><br><span class="line">        <span class="attr">"factor"</span>: <span class="number">0.1</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Boost-Mode-和-Max-Boost"><a href="#Boost-Mode-和-Max-Boost" class="headerlink" title="Boost Mode 和 Max Boost"></a>Boost Mode 和 Max Boost</h3><ul><li>Boost Mode<ul><li>Multiply：算分和函数值的乘积</li><li>Sum：算分和函数值的和</li><li>Min/Max：算分与函数去 最小 / 最大值</li><li>Replace：使用函数取代算分</li></ul></li><li>Max Boost 可以将算分控制在一个最大值</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">POST /blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"function_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"query"</span>: &#123;</span><br><span class="line">        <span class="attr">"multi_match"</span>: &#123;</span><br><span class="line">          <span class="attr">"query"</span>:    <span class="string">"popularity"</span>,</span><br><span class="line">          <span class="attr">"fields"</span>: [ <span class="string">"title"</span>, <span class="string">"content"</span> ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"field_value_factor"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"votes"</span>,</span><br><span class="line">        <span class="attr">"modifier"</span>: <span class="string">"log1p"</span> ,</span><br><span class="line">        <span class="attr">"factor"</span>: <span class="number">0.1</span></span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"boost_mode"</span>: <span class="string">"sum"</span>,</span><br><span class="line">      <span class="attr">"max_boost"</span>: <span class="number">3</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="一致性随机函数"><a href="#一致性随机函数" class="headerlink" title="一致性随机函数"></a>一致性随机函数</h3><ul><li>使用场景：网址的广告需要提高展示率</li><li>具体需求：让每个用户看到不同的随机排名，但是也希望同一个用户访问时，结果的相对顺序，保持一致（Consistently Random）</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">POST /blogs/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"function_score"</span>: &#123;</span><br><span class="line">      <span class="attr">"random_score"</span>: &#123;</span><br><span class="line">        <span class="attr">"seed"</span>: <span class="number">911119</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Term-amp-Phrase-Suggester"><a href="#Term-amp-Phrase-Suggester" class="headerlink" title="Term &amp; Phrase Suggester"></a>Term &amp; Phrase Suggester</h2><h3 id="什么是搜索建议"><a href="#什么是搜索建议" class="headerlink" title="什么是搜索建议"></a>什么是搜索建议</h3><ul><li>现代的搜索引擎，一般都会提供 Suggest as you type 的功能</li><li>帮助用户在输入搜索的过程中，进行自动补全或者纠错。通过协助用户输入更加精准的关键词，提高后续搜索阶段文档匹配的程度</li><li>在 google 上搜索，一开始会自动补全。当输入到一定长度，如因为单词拼写错误无法补全，就会开始提示相似的词或者句子</li></ul><h3 id="Elasticsearch-Suggester-API"><a href="#Elasticsearch-Suggester-API" class="headerlink" title="Elasticsearch Suggester API"></a>Elasticsearch Suggester API</h3><ul><li>搜索引擎中类似的功能，在 ES 中通过 Sugester API 实现的</li><li>原理：将输入的文档分解为 Token，然后在索引的字段里查找相似的 Term 并返回</li><li>根据不同的使用场景，ES 设计了 4 种类别的 Suggesters<ul><li>Term &amp; Phrase Suggester</li><li>Complete &amp; Context Suggester</li></ul></li></ul><h3 id="Term-Suggester"><a href="#Term-Suggester" class="headerlink" title="Term Suggester"></a>Term Suggester</h3><ul><li>Suggester 就是一种特殊类型的搜索。“text” 里是调用时候提供的文本，通常来自用户界面上用户输入的内容</li><li>用户输入的 “lucen” 是一个错误的拼写</li><li>会到 指定的字段 “body” 上搜索，当无法搜索到结果时（missing），返回建议的词</li></ul><h3 id="Term-Suggester-Missing-Mode"><a href="#Term-Suggester-Missing-Mode" class="headerlink" title="Term Suggester - Missing Mode"></a>Term Suggester - Missing Mode</h3><ul><li>搜索 “lucen rock”：<ul><li>每个建议都包含了一个算分，相似性是通过 Levenshtein Edit Distance 的算法实现的。核心思想就是一个词改动多少字段就可以和另外一个词一致。提供了很多可选参数来控制相似性的模糊程度。</li></ul></li><li>几种 Suggestion Mode<ul><li>Missing - 如索引中已存在，就不提供建议</li><li>Popular - 推荐出现频率更加高的词</li><li>Always - 无论是否存在，都提供建议</li></ul></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//插入数据</span></span><br><span class="line">POST article/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"body"</span>:<span class="string">"lucene is very cool"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"body"</span>:<span class="string">"Elasticsearch builds on top of lucene"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"body"</span>:<span class="string">"Elasticsearch rocks"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"body"</span>:<span class="string">"elastic is the company behind ELK stack"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"body"</span>:<span class="string">"Elk stack rocks"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"body"</span>:<span class="string">"elasticsearch is rock solid"</span>&#125;</span><br><span class="line"><span class="comment">//suggest</span></span><br><span class="line">POST article/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"match"</span>: &#123;</span><br><span class="line">      <span class="attr">"body"</span>: <span class="string">"lucen rock"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"suggest"</span>: &#123;</span><br><span class="line">    <span class="attr">"term-suggestion"</span>: &#123;</span><br><span class="line">      <span class="attr">"text"</span>: <span class="string">"lucen rock"</span>,</span><br><span class="line">      <span class="attr">"term"</span>: &#123;</span><br><span class="line">        <span class="attr">"suggest_mode"</span>: <span class="string">"missing"</span>, <span class="comment">// popular  always</span></span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"body"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//返回结果</span></span><br><span class="line">"suggest" : &#123;</span><br><span class="line">    "term-suggestion" : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"text"</span> : <span class="string">"lucen"</span>,</span><br><span class="line">        <span class="attr">"offset"</span> : <span class="number">0</span>,</span><br><span class="line">        <span class="attr">"length"</span> : <span class="number">5</span>,</span><br><span class="line">        <span class="attr">"options"</span> : [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="attr">"text"</span> : <span class="string">"lucene"</span>,<span class="comment">//推荐了</span></span><br><span class="line">            <span class="attr">"score"</span> : <span class="number">0.8</span>,</span><br><span class="line">            <span class="attr">"freq"</span> : <span class="number">2</span></span><br><span class="line">          &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"text"</span> : <span class="string">"rock"</span>,<span class="comment">//没有推荐</span></span><br><span class="line">        <span class="attr">"offset"</span> : <span class="number">6</span>,</span><br><span class="line">        <span class="attr">"length"</span> : <span class="number">4</span>,</span><br><span class="line">        <span class="attr">"options"</span> : [ ]</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ul><li>默认使用 standard 分词器<ul><li>大写转小写</li><li>rocks 和 rock 是两个词</li></ul></li></ul><h3 id="Term-Suggester-Popuar-Mode"><a href="#Term-Suggester-Popuar-Mode" class="headerlink" title="Term Suggester - Popuar Mode"></a>Term Suggester - Popuar Mode</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">POST article/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"suggest"</span>: &#123;</span><br><span class="line">    <span class="attr">"term-suggestion"</span>: &#123;</span><br><span class="line">      <span class="attr">"text"</span>: <span class="string">"lucen rock"</span>,</span><br><span class="line">      <span class="attr">"term"</span>: &#123;</span><br><span class="line">        <span class="attr">"suggest_mode"</span>: <span class="string">"popular"</span>,</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"body"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//返回</span></span><br><span class="line">"suggest" : &#123;</span><br><span class="line">    "term-suggestion" : [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"text"</span> : <span class="string">"lucen"</span>,</span><br><span class="line">        <span class="attr">"offset"</span> : <span class="number">0</span>,</span><br><span class="line">        <span class="attr">"length"</span> : <span class="number">5</span>,</span><br><span class="line">        <span class="attr">"options"</span> : [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="attr">"text"</span> : <span class="string">"lucene"</span>,</span><br><span class="line">            <span class="attr">"score"</span> : <span class="number">0.8</span>,</span><br><span class="line">            <span class="attr">"freq"</span> : <span class="number">2</span></span><br><span class="line">          &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"text"</span> : <span class="string">"rock"</span>,</span><br><span class="line">        <span class="attr">"offset"</span> : <span class="number">6</span>,</span><br><span class="line">        <span class="attr">"length"</span> : <span class="number">4</span>,</span><br><span class="line">        <span class="attr">"options"</span> : [</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="attr">"text"</span> : <span class="string">"rocks"</span>,</span><br><span class="line">            <span class="attr">"score"</span> : <span class="number">0.75</span>,</span><br><span class="line">            <span class="attr">"freq"</span> : <span class="number">2</span></span><br><span class="line">          &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="Sorting-by-Frequency-amp-PrefixLength"><a href="#Sorting-by-Frequency-amp-PrefixLength" class="headerlink" title="Sorting by Frequency &amp; PrefixLength"></a>Sorting by Frequency &amp; PrefixLength</h3><ul><li>默认按照 score 排序，也可以按照 “frequency”</li><li>默认首字母不一致就不会匹配推荐，但是如果将 prefix_length 设置为 0，就会为 hock 建议 rock</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">POST /articles/_search</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">  <span class="attr">"suggest"</span>: &#123;</span><br><span class="line">    <span class="attr">"term-suggestion"</span>: &#123;</span><br><span class="line">      <span class="attr">"text"</span>: <span class="string">"lucen hocks"</span>,</span><br><span class="line">      <span class="attr">"term"</span>: &#123;</span><br><span class="line">        <span class="attr">"suggest_mode"</span>: <span class="string">"always"</span>,</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"body"</span>,</span><br><span class="line">        <span class="attr">"prefix_length"</span>:<span class="number">0</span>,</span><br><span class="line">        <span class="attr">"sort"</span>: <span class="string">"frequency"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Phrase-Suggester"><a href="#Phrase-Suggester" class="headerlink" title="Phrase Suggester"></a>Phrase Suggester</h3><ul><li>Phrase Suggesetr 上增加了一些额外的逻辑<br>一些参数<ul><li>Suggeset Mode ： missing,popular ,always</li><li>Max Errors: 最多可以拼错的 Terms 数</li><li>Condfidence ： 限制返回结果数，默认为 1</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">POST /articles/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"suggest"</span>: &#123;</span><br><span class="line">    <span class="attr">"my-suggestion"</span>: &#123;</span><br><span class="line">      <span class="attr">"text"</span>: <span class="string">"lucne and elasticsear rock hello world "</span>,</span><br><span class="line">      <span class="attr">"phrase"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"body"</span>,</span><br><span class="line">        <span class="attr">"max_errors"</span>:<span class="number">2</span>,</span><br><span class="line">        <span class="attr">"confidence"</span>:<span class="number">0</span>,</span><br><span class="line">        <span class="attr">"direct_generator"</span>:[&#123;</span><br><span class="line">          <span class="attr">"field"</span>:<span class="string">"body"</span>,</span><br><span class="line">          <span class="attr">"suggest_mode"</span>:<span class="string">"always"</span></span><br><span class="line">        &#125;],</span><br><span class="line">        <span class="attr">"highlight"</span>: &#123;</span><br><span class="line">          <span class="attr">"pre_tag"</span>: <span class="string">"&lt;em&gt;"</span>,</span><br><span class="line">          <span class="attr">"post_tag"</span>: <span class="string">"&lt;/em&gt;"</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="自动补全与基于上下文的提示"><a href="#自动补全与基于上下文的提示" class="headerlink" title="自动补全与基于上下文的提示"></a>自动补全与基于上下文的提示</h2><h3 id="The-Completion-Suggester"><a href="#The-Completion-Suggester" class="headerlink" title="The Completion Suggester"></a>The Completion Suggester</h3><ul><li>Completion Suggester 提供了 “自动完成”（Auto Complete）的功能。用户每输入一个字符，就需要即时发送一个查询请求到后端查询匹配项</li><li>对性能要求比较苛刻。ES 采用了不同的数据结构，并非通过倒排索引来完成。而是将 Analyze 的数据编码成 FST 和索引一起存放。FST 会被 ES 整个加载进内存，速度很快</li><li>FST 只能用于前缀查找</li></ul><h3 id="使用-Completion-Suggester-一些步骤"><a href="#使用-Completion-Suggester-一些步骤" class="headerlink" title="使用 Completion Suggester 一些步骤"></a>使用 Completion Suggester 一些步骤</h3><ul><li>定义 Mapping，使用 “completion” type</li><li>索引数据</li><li>运行 “suggest” 查询，得到搜索建议</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//定义mapping</span></span><br><span class="line">PUT articles</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"mappings"</span>: &#123;</span><br><span class="line">    <span class="attr">"properties"</span>: &#123;</span><br><span class="line">      <span class="attr">"title_completion"</span>: &#123;</span><br><span class="line">        <span class="attr">"type"</span>: <span class="string">"completion"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//写入数据</span></span><br><span class="line">POST articles/_bulk</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title_completion"</span>:<span class="string">"lucene is very cool"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title_completion"</span>:<span class="string">"Elasticsearch builds on top of lucene"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title_completion"</span>:<span class="string">"Elasticsearch rocks"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title_completion"</span>:<span class="string">"elastic is the company behind ELK stack"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line">&#123;<span class="attr">"title_completion"</span>:<span class="string">"Elk stack rocks"</span>&#125;</span><br><span class="line">&#123;<span class="attr">"index"</span>:&#123;&#125;&#125;</span><br><span class="line"><span class="comment">//查询</span></span><br><span class="line">POST articles/_search?pretty</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"size"</span>: <span class="number">0</span>,</span><br><span class="line">  <span class="attr">"suggest"</span>: &#123;</span><br><span class="line">    <span class="attr">"article-suggest"</span>: &#123;</span><br><span class="line">      <span class="attr">"prefix"</span>: <span class="string">"e"</span>, <span class="comment">//查询字段 </span></span><br><span class="line">      <span class="attr">"completion"</span>: &#123;</span><br><span class="line">        <span class="attr">"field"</span>: <span class="string">"title_completion"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="什么是-Context-Suggester"><a href="#什么是-Context-Suggester" class="headerlink" title="什么是 Context Suggester"></a>什么是 Context Suggester</h3><ul><li>Completion Suggester 的扩展</li><li>可以在搜索中加入耕读偶读上下文信息，例如，输入 “star”<ul><li>咖啡相关：starbucks</li><li>电影相关：star wars</li></ul></li></ul><h3 id="实现-Context-Suggester"><a href="#实现-Context-Suggester" class="headerlink" title="实现 Context Suggester"></a>实现 Context Suggester</h3><ul><li>可以定义两种类型的 Context<ul><li>Category - 任意的字符串</li><li>Geo - 地理信息位置</li></ul></li><li>实现 Context Suggester<ul><li>定制一个 Mapping</li><li>索引数据，并且为每个文档加入 Conetxt 信息</li><li>结合 Context 进行 Suggestion 查询</li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">DELETE comments</span><br><span class="line">PUT comments</span><br><span class="line"></span><br><span class="line"><span class="comment">// 添加 contexts type 和 name</span></span><br><span class="line">PUT comments/_mapping</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"properties"</span>:&#123;</span><br><span class="line">    <span class="attr">"comment_autocomplete"</span>:&#123;</span><br><span class="line">      <span class="attr">"type"</span>:<span class="string">"completion"</span>,</span><br><span class="line">      <span class="attr">"contexts"</span>:[&#123;</span><br><span class="line">       <span class="attr">"type"</span>:<span class="string">"category"</span>,</span><br><span class="line">       <span class="attr">"name"</span>:<span class="string">"comment_category"</span></span><br><span class="line">      &#125;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 索引数据 设置不同的 category</span></span><br><span class="line">POST comments/_doc</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"comment"</span>: <span class="string">"I love the star war movies"</span>,</span><br><span class="line">  <span class="attr">"comment_autocomplete"</span>: &#123;</span><br><span class="line">    <span class="attr">"input"</span>: [<span class="string">"star wars"</span>],</span><br><span class="line">    <span class="attr">"contexts"</span>: &#123;</span><br><span class="line">      <span class="attr">"comment_category"</span>: <span class="string">"movies"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">POST comments/_doc</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"comment"</span>:<span class="string">"Where can I find a Starbucks"</span>,</span><br><span class="line">  <span class="attr">"comment_autocomplete"</span>:&#123;</span><br><span class="line">    <span class="attr">"input"</span>:[<span class="string">"starbucks"</span>],</span><br><span class="line">    <span class="attr">"contexts"</span>:&#123;</span><br><span class="line">      <span class="attr">"comment_category"</span>:<span class="string">"coffee"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">POST comments/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"suggest"</span>: &#123;</span><br><span class="line">    <span class="attr">"MY_SUGGESTION"</span>: &#123;</span><br><span class="line">      <span class="attr">"prefix"</span>: <span class="string">"sta"</span>,</span><br><span class="line">      <span class="attr">"completion"</span>:&#123;</span><br><span class="line">        <span class="attr">"field"</span>:<span class="string">"comment_autocomplete"</span>,</span><br><span class="line">        <span class="attr">"contexts"</span>:&#123;</span><br><span class="line">         <span class="attr">"comment_category"</span>:<span class="string">"movies"</span> </span><br><span class="line">        <span class="comment">//  "comment_category":"coffee"  </span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="精确度和召回率"><a href="#精确度和召回率" class="headerlink" title="精确度和召回率"></a>精确度和召回率</h3><ul><li>精准度<ul><li>Completion &gt; Phrase &gt; Term</li></ul></li><li>召回率<ul><li>Term &gt; Phrase &gt; Completion</li></ul></li><li>性能<ul><li>Completion &gt; Phrase &gt; Term</li></ul></li></ul><h2 id="跨集群搜索"><a href="#跨集群搜索" class="headerlink" title="跨集群搜索"></a>跨集群搜索</h2><h3 id="水平扩展的痛点"><a href="#水平扩展的痛点" class="headerlink" title="水平扩展的痛点"></a>水平扩展的痛点</h3><ul><li>单集群 - 当水平扩展时，节点数不能无限增加<ul><li>当集群的 meta 信息（节点，索引，集群状态）过多，会导致更新压力变大，单个 Active Master 会成为性能瓶颈，导致整个集群无法正常工作</li></ul></li><li>早起版本，通过 Tribe Node 可以实现多集群访问的需求，但是还存在一定的问题<ul><li>Tribe Node 会以 Client Node 的方式加入集群。集群中 Master 节点的任务变更需要 Tribe Node 的回应才能继续</li><li>Tribe Node 不保存 Cluster State 信息，一旦重启，初始化很慢</li><li>当多个集群存在索引重名的情况下，只能设置一种 Perfer 规则</li></ul></li></ul><h3 id="跨集群搜索-Cross-Cluster-Search"><a href="#跨集群搜索-Cross-Cluster-Search" class="headerlink" title="跨集群搜索 - Cross Cluster Search"></a>跨集群搜索 - Cross Cluster Search</h3><ul><li>早期 Tribe Node 的方案存在一定的问题，现已被 Deprecated</li><li>ES 5.3 引入跨集群搜索的功能（Cross Cluster Search），推荐使用<ul><li>允许任何节点扮演 federated 节点，以轻量的方式，将搜索请求进行代理</li><li>不需要以 Client Node 的形式加入其它集群</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动3个集群</span></span><br><span class="line">bin/elasticsearch -E node.name=cluster0node -E cluster.name=cluster0 -E path.data=cluster0_data -E discovery.type=single-node -E http.port=9200 -E transport.port=9300</span><br><span class="line">bin/elasticsearch -E node.name=cluster1node -E cluster.name=cluster1 -E path.data=cluster1_data -E discovery.type=single-node -E http.port=9201 -E transport.port=9301</span><br><span class="line">bin/elasticsearch -E node.name=cluster2node -E cluster.name=cluster2 -E path.data=cluster2_data -E discovery.type=single-node -E http.port=9202 -E transport.port=9302</span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在每个集群上设置动态的设置</span></span><br><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"persistent"</span>: &#123;</span><br><span class="line">    <span class="attr">"cluster"</span>: &#123;</span><br><span class="line">      <span class="attr">"remote"</span>: &#123;</span><br><span class="line">        <span class="attr">"cluster0"</span>: &#123;</span><br><span class="line">          <span class="attr">"seeds"</span>: [</span><br><span class="line">            <span class="string">"127.0.0.1:9300"</span></span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">"transport.ping_schedule"</span>: <span class="string">"30s"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"cluster1"</span>: &#123;</span><br><span class="line">          <span class="attr">"seeds"</span>: [</span><br><span class="line">            <span class="string">"127.0.0.1:9301"</span></span><br><span class="line">          ],</span><br><span class="line">          <span class="attr">"transport.compress"</span>: <span class="literal">true</span>,</span><br><span class="line">          <span class="attr">"skip_unavailable"</span>: <span class="literal">true</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"cluster2"</span>: &#123;</span><br><span class="line">          <span class="attr">"seeds"</span>: [</span><br><span class="line">            <span class="string">"127.0.0.1:9302"</span></span><br><span class="line">          ]</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cURL</span></span><br><span class="line">curl -XPUT <span class="string">"http://localhost:9200/_cluster/settings"</span> -H <span class="string">'Content-Type: application/json'</span> -d<span class="string">'</span></span><br><span class="line"><span class="string">&#123;"persistent":&#123;"cluster":&#123;"remote":&#123;"cluster0":&#123;"seeds":["127.0.0.1:9300"],"transport.ping_schedule":"30s"&#125;,"cluster1":&#123;"seeds":["127.0.0.1:9301"],"transport.compress":true,"skip_unavailable":true&#125;,"cluster2":&#123;"seeds":["127.0.0.1:9302"]&#125;&#125;&#125;&#125;&#125;'</span></span><br><span class="line"></span><br><span class="line">curl -XPUT <span class="string">"http://localhost:9201/_cluster/settings"</span> -H <span class="string">'Content-Type: application/json'</span> -d<span class="string">'</span></span><br><span class="line"><span class="string">&#123;"persistent":&#123;"cluster":&#123;"remote":&#123;"cluster0":&#123;"seeds":["127.0.0.1:9300"],"transport.ping_schedule":"30s"&#125;,"cluster1":&#123;"seeds":["127.0.0.1:9301"],"transport.compress":true,"skip_unavailable":true&#125;,"cluster2":&#123;"seeds":["127.0.0.1:9302"]&#125;&#125;&#125;&#125;&#125;'</span></span><br><span class="line"></span><br><span class="line">curl -XPUT <span class="string">"http://localhost:9202/_cluster/settings"</span> -H <span class="string">'Content-Type: application/json'</span> -d<span class="string">'</span></span><br><span class="line"><span class="string">&#123;"persistent":&#123;"cluster":&#123;"remote":&#123;"cluster0":&#123;"seeds":["127.0.0.1:9300"],"transport.ping_schedule":"30s"&#125;,"cluster1":&#123;"seeds":["127.0.0.1:9301"],"transport.compress":true,"skip_unavailable":true&#125;,"cluster2":&#123;"seeds":["127.0.0.1:9302"]&#125;&#125;&#125;&#125;&#125;'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建测试数据</span></span><br><span class="line">curl -XPOST <span class="string">"http://localhost:9200/users/_doc"</span> -H <span class="string">'Content-Type: application/json'</span> -d<span class="string">'</span></span><br><span class="line"><span class="string">&#123;"name":"user1","age":10&#125;'</span></span><br><span class="line"></span><br><span class="line">curl -XPOST <span class="string">"http://localhost:9201/users/_doc"</span> -H <span class="string">'Content-Type: application/json'</span> -d<span class="string">'</span></span><br><span class="line"><span class="string">&#123;"name":"user2","age":20&#125;'</span></span><br><span class="line"></span><br><span class="line">curl -XPOST <span class="string">"http://localhost:9202/users/_doc"</span> -H <span class="string">'Content-Type: application/json'</span> -d<span class="string">'</span></span><br><span class="line"><span class="string">&#123;"name":"user3","age":30&#125;'</span></span><br></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 查询</span></span><br><span class="line">GET /users,cluster1:users,cluster2:users/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"range"</span>: &#123;</span><br><span class="line">      <span class="attr">"age"</span>: &#123;</span><br><span class="line">        <span class="attr">"gte"</span>: <span class="number">20</span>,</span><br><span class="line">        <span class="attr">"lte"</span>: <span class="number">40</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/term-level-queries.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/term-level-queries.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/full-text-queries.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/full-text-queries.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-exists-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-exists-query.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/query-filter-context.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-boosting-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-boosting-query.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-dis-max-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-dis-max-query.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-request-highlighting.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/search-request-highlighting.html</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.12/highlighting.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.12/highlighting.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/50444885" target="_blank" rel="noopener">分词算法综述</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-function-score-query.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.1/query-dsl-function-score-query.html</a></li><li>《Elasticsearch核心技术与实战》</li><li><a href="https://kelonsoftware.com/cross-cluster-search-kibana/" target="_blank" rel="noopener">在Kibana中使用Cross data search</a></li><li><a href="https://blog.csdn.net/laoyang360/article/details/104809787" target="_blank" rel="noopener">实战 | Elasticsearch自定义评分的N种方法</a></li></ul><style>  img {    zoom: 50%;  }</style>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;深入了解 ES 高级搜索、相关性评分、搜索建议、自动补全等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="BigData" scheme="https://blog.lichao.xin/categories/BigData/"/>
    
    
      <category term="Elastic Stack" scheme="https://blog.lichao.xin/tags/Elastic-Stack/"/>
    
      <category term="ES" scheme="https://blog.lichao.xin/tags/ES/"/>
    
  </entry>
  
</feed>
