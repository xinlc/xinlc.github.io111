
## 时代赋予测试开发的机遇与挑战

身处软件行业的人都知道，“软件的质量不是测试出来的”，既然质量不能被测试出来，那么测试工程师，乃至软件测试存在的意义是什么呢？

我认为，**软件测试存在的意义**是：通过一系列测试活动，**“提前”** 发现和定位软件产品质量的薄弱环节，并倒逼开发人员修正，从而保证交付的软件质量满足客户需求。

有研究表明，越早发现软件中存在的问题，开发费用就越低，软件质量越高，软件发布后的维护费用越低。因此，提前发现和定位问题极为重要，而在软件开发的整个历程中，越是新兴的软件开发模型，越重视“提前测试”。提前测试可以使得在需求分析时期就可发现的错误，不必等到开发完成才被发现。

那么，具体是如何一步步 “提前” 发现软件产品中存在的质量问题的呢？那就不得不从软件开发模型的演变过程说起了。

### 测试活动随着软件开发模型的演进被不断前置

大型或专业软件的研发，通常会遵循一定的开发模型，从软件发展的历程来看，其中比较典型的有瀑布模型、V 模型和 W 模型、迭代模型，以及敏捷开发模型。

**这里值得说明的一点是，各种开发模型并没有明显的适用范围，即使现在也有项目用瀑布模型开发，开发模型的选择并不是越新越好的，而是要根据项目而变化。**

1. 瀑布模型

我们知道，**瀑布模型**的主要特征在于项目完全按照阶段划分，只有前一阶段完成，才能开始下一阶段。具体到测试活动，则只能在全部编码完成后、发布之前执行，在这种开发模型中，测试活动被完全后置了，测试仅仅是编码后的一个活动阶段，测试的重要性没有被凸显出来。

![1][1]

2. V 模型

基于此，V 模型出现了。V 模型在整个开发过程中，不仅相对清晰地划分了测试活动的不同级别，还将其不同级别的测试活动与软件开发各阶段清晰地对应起来，强调了测试在整个开发过程中的重要性。但在 V 模型中，测试依旧是编码之后才开始的，测试介入时间还是太晚。比如，需求分析阶段出现的问题，要等到系统测试阶段才能发现。

![2][2]

3. W 模型

为了弥补这一缺点，V 模型的进一步深化版，即**W 模型**出现了。从 W 模型的示意图中，可以看到，W 模型是把 V 模型左边的每一个活动都加了一个测试设计活动，**体现了“尽早和不断地进行测试”的原则。**

![3][3]

但是说到底，W 模型和 V 模型都把软件的开发视为需求、设计、编码、测试等一系列串行的活动，无法支持迭代、自发性及变更调整。例如，需要根据市场及监管要求，快速调整项目需求时（比如，今年春节期间各大平台线上抢口罩的活动），使用 W 模型或 V 模型不仅无法快速响应，而且还会影响软件质量，甚至公司声誉。于是迭代模型应运而生，它正好可以弥补 W 模型和 V 模型的不足。

4. 迭代模型

迭代模型，常用于需求不甚明确、开发难度比较大的项目，比如互联网行业流行的先出 MVP 版本，然后再根据用户反馈进行调整的项目。

迭代模型将大型项目分为多个迭代，每个迭代本质上是一个小项目，每个小项目都包括了需求分析、设计、编码与测试等一系列项目活动。需要注意的一点是，迭代模型是增量的，它要求先完成部分系统功能或业务逻辑，然后依据客户反馈来进一步明确需求，最后通过一次次的迭代来给用户交付达标的产品。

以双 11 大促时的优惠会场项目为例，在一次迭代中，开发者会先实现会场的部分需求，然后在下一次迭代中，再根据用户的反馈，修正主会场的需求及完成剩余需求。

由于每次迭代都有测试，所以迭代模型客观上实现了测试的更早介入。

此外，作为一种以人为核心，强调迭代、循序渐进的开发方法，**敏捷开发**近几年非常流行。它有 Scrum、XP 等多种实现方式，当前 Scrum 模式采用较多。

虽然敏捷开发中的 Scrum 与上文提及的迭代模型（RUP）看起来很像，但两者概念完全不同，区别如下：

![4][4]

因此，从业务类型出发，如果有明确交付日（通常有合同约束），或者和外部公司合作的项目，比较适宜迭代模型；如果没有明确交付日，公司内部的产品，则更适用于敏捷开发。

综上所述可以看出，以上几种模型是随着技术与业务的变化逐渐演化的，软件测试从初始的瀑布模型的最后一道工序，逐渐被提前到敏捷开发模型（以 Scrum 为例）中的每一个 Sprint 中，测试在软件开发过程中发挥着越来越重要的作用。

### 敏捷、DevOps、微服务等开发模型给测试带来的挑战

那前面我们说到了各自不同的软件开发模型，对于测试人员来说，在不同的开发模型下，保障质量所采用的方式也不尽相同。

在瀑布模型下，测试人员有大量时间去准备详尽的测试计划，step by step 的测试用例，但如果在敏捷、DevOps、微服务的模式下还采用相同的处理方式，就会导致工作流积压在测试一侧，无法及时向后进行，而持续集成也会因为测试迟迟不能结束而受到影响。

“兵无常势、水无常形”， 面对敏捷、DevOps、微服务这些开发模型时，我们要保障质量，就必须知道，它们各有什么特点？以及相比较传统开发模型，给我们带来了哪些挑战？

1. 敏捷开发

由于敏捷开发模型每一个 Sprint 都是完整的，并且每一个 Sprint 结束时都会发布一个可工作的软件，所以在每一个 Sprint 内，测试工程师都要进行完备的测试，以确保发布出去的软件产品质量没问题。

而每个 Sprint 的周期比过去的瀑布模式开发缩短了很多，这意味着相同时间内，你发布的次数增多了。而每一次发布都意味着，你需要回归所有重要的测试场景（一般是 P0 和 P1 级别的测试必须回归，P2 和 P3 级别则视实际情况而定要不要回归）。那么可以想象一下，这里面的工作量有多大、多枯燥。

在敏捷开发模型中，测试不能仅仅关注测试本身，而且还要走出去。向左，要在项目立项阶段就介入进去，去寻找需求中可能存在的问题；向右，介入到发布后的流程中去，通过生产环境监控得来的各种数据去分析各种潜在的缺陷。在这过程当中“牵一发而动全身”，团队的每个角色（开发、质量保证人员、技术运维）都要对质量负责。

2. DevOps

这个时候，**DevOps** 和微服务便出现了。DevOps是开发、质量保证人员、技术运维三个角色的交集，它旨在通过自动化的“软件交付”和“架构变更”的流程，来解决不同角色之间合作的流畅度，以及把软件交付的构建、测试、发布变得更加快捷、频繁和可靠。

![5][5]

如果你所在公司采用了持续集成、持续部署流水线，它们一般都是 DevOps 的工作成果，DevOps 打破了部门墙，提升了研发效率。但这也给软件测试人员带来又一挑战：那就是如何在持续集成、持续部署的模式下保障质量？对于测试来说，如何把测试活动，特别是自动进行的测试活动无缝融合到公司的持续集成，持续部署的框架下，将是个很大的挑战，也是你在测试职业生涯上再走远些，将面对的问题。

3. 微服务

关于**微服务**，你只需知道微服务是相对于单体应用来说的，它将应用拆分成数个更小的独立服务，并使它们可以单独构建和部署。

![6][6]

微服务的引进提升了开发效率，降低了发布时间，但也带来了新的挑战：由于各个微服务常由不同的团队负责，并且各个服务之间普遍依赖 API 完成通信和调用，那么这些 API 之间的“契约”就变得非常重要，“契约测试”也就相应产生了。

还有，相较于传统单体应用，微服务的测试也更加复杂。仅从代码打包部署这件事儿来说，在单体应用里，不太出现使用错测试包的情况，但是在微服务里，这个情况可能会发生。单体应用，一个版本就对应一个代码分支；而使用微服务，每个微服务通常对应不同的代码分支。这就意味着在测试微服务时，测试不仅要关注你测试的微服务是否版本部署正确，还要检查其依赖的其他微服务的部署分支，查看其他微服务的分支是不是也部署正确。

而且，微服务的采用，也让我们的技术栈更为繁多、复杂，比如：

- 因为我解决微服务间复杂的通信和消息传递问题，引入了 RabbitMQ、RocketMQ、Kafka 各种消息中间件；
- 因为多个微服务的独立部署导致的环境依赖问题，引入了容器化技术 Docker；
- 容器越来越多，要解决其管理和维护问题而引入了 Kubernetes；
- 为简化故障定位问题，引入 ELK（Elasticsearch + Logstash + Kibana）；
- 上线后，要对系统运行情况进行监控，因而引入了 Prometheus 与 Grafana 等。

以上“新”技术的引入，是为了不断应对软件开发演变中带来的各项需求和问题，解决了旧问题的同时，也带来了新挑战，例如：

- 微服务独立部署、独立发布，那么微服务下的测试还能保持一成不变吗？以数据库举例，分库分表怎么来的？要怎么测试？
- 由于某些特殊情况（比如双十一）而导致服务雪崩，微服务会引发熔断、降级、限流等一系列保护措施，要怎么保证这些措施被正确实施了？
- 持续集成，持续部署流水线建立了，以往的测试框架如何最小成本嵌入变成流水线的一环？

面对这些挑战，软件测试在快速演进的同时，也在裹挟前行，寻找破局之道。

**破局之道：测试开发**

发布动作变得越来越频繁，以往靠大量手工功能测试 + 少量主流程自动化测试 + 部分回归测试来保障质量的做法，变得越来越不现实。自动化测试，特别是不同层次的自动化测试在整个测试活动中的占比，正逐渐成为影响软件发布质量的关键。这也就是测试开发在近年来越来越受追捧的原因。

这么多的自动化测试用例，需不需要维护？如何维护？如何将自动化测试融入公司的持续集成流程中并自动触发运行？这些都是测试开发首要关注的问题，可以预料的是，随着交付频率的加快，**测试开发会变成软件测试人员的基本技能。**

## 测试开发的职业生涯是怎样的？

### 一个典型的敏捷开发测试流程

为了详细讲解不同阶段或职位（Title）的测试开发所做的工作有哪些不同，我以当前流行的敏捷模式下的软件开发测试生命周期为例来讲解。

![开发测试流程图][7]

如上图所示，你可以看到，一个软件产品的立项是从**软件产品规划**（图片顶部）开始的，一般我们根据业务目标把规划的软件产品需求项，基于实际情况（业务目标、公司战略等）拆分为多个 Backlog 进行进一步细化，即 **Backlog Grooming。**

细化之后的需求按照**优先级和发布规划**，会分为多个 **Sprint** 进行开发、测试、上线。在每一个 Sprint 内，需求会被拆分为一个个的开发和测试任务，开发人员完成 **Task** 开发后，就进行自测。

自测没问题，通过提交 Pull Request 的方式，请求提交代码到 Master 分支（这个动作对应于**提交测试**），请求提交后，代码托管平台比如 GitHub、GitLab 等会触发由 Pull Request 引起的自动构建。之后，自动构建会引导持续集成平台，把开发提交的最新代码打包成可用的测试版本。

同时，开发通过更改 Jira Task 状态的方式（或者平台自动更改 Jira 状态、开发邮件/口头通知等方式），提醒测试人员进行测试验证。

软件测试版本生成后，有两个测试内容会同时进行：

- 持续集成平台会触发预设的测试脚本进行自动化测试验证（一般是整个产品的主流程冒烟测试）；
- 测试人员根据获取到的软件测试版本，针对开发提交的 Task 进行测试（主要针对新功能，手工执行的方式居多）。

测试人员在进行人工验证时， 先根据测试计划和之前准备的测试脚本进行冒烟测试（主要关注点在于本测试组负责的业务模块）。

冒烟测试通过后，再进行功能、性能、安全等方面的**测试验证**（也就是图中 Sprint 这个模块内的蓝色的测试验证部分，这是测试人员花费最多时间的地方）。测试人员进行测试验证的依据来自测试计划的制定和细化， 这部分工作通常由项目立项开始，至 Sprint Grooming 后，开发提测之前结束。

如果测试验证**不通过**，测试失败的结果会被反馈给开发，Pull Request 不会被 Approve，开发人员会修复问题，再次提交 Pull Request 流程；反之，如果测试验证**通过**，会通知开发人员测试已经通过（这相当于 Approve 之前开发提交的 Pull Request），然后开发就会合并代码到 Master 分支。合并会再次触发新一轮的持续集成流程，如此循环往复。

合并进入 Master 分支的代码，通过自动测试验证后，就会被发布到指定**测试环境**，测试人员会将自动化脚本在此环境进行新一轮的测试验证，直至没问题后，会依次经历几个测试环境的验证，最终被持续部署平台采用蓝绿部署、灰度发布、滚动发布等方式部署上线。

OK，了解了一个典型的敏捷开发测试流程后，接下来，我们看一下不同阶段的测试人员在这一流程中分别担任怎样的作用。

### 测试开发、资深测试开发、测试专家的不同工作职责

为了方便你理解，我按照测试开发的不同阶段在上面的流程图中标记了不同的颜色。

1. 蓝色——初级测试开发

从功能测试转为测试开发，你的工作内容会包括帮助功能测试人员编写测试工具及测试框架，进而来提升功能测试的效率，也就是通过开发手段让功能测试变得更简单、快捷。

这一阶段的目的纯粹是助力功能测试，减少人工重复劳动，缩短测试周期。该阶段的测试开发仅仅**聚焦在开发**这个纯粹的事情上。

举例来说，你通过编写自动化工具/框架，把本应该是手工执行的工作转换为机器自动运行；通过编写造数平台（Data Platform），让构造测试数据变得比以往更为简单。

**所以，判断一个测试开发是否合格的标准，是看他能否让功能测试更省力。**

2. 橙色和绿色——资深测试开发

资深测试开发不再局限于开发本身，而是**从流程出发**，检测公司整个软件开发周期中，哪个部分耗时最长，哪个部分最复杂，哪个部分最容易出错；然后资深测试开发就要改造现有流程，通过详尽分析、仔细论证，把最复杂、最容易出错的部分流程自动化掉，纳入当前的持续集成流水线中去。

这一阶段的测试开发，已经不满足于完成功能测试提出的开发需求，而是通过自己的开发技能，把测试各个阶段的任务有机地结合起来，经过消化后重新组织输出。

比如，以前公司没有持续集成、持续部署平台，代码打包都是开发或者测试人工去操作的，那么资深测试开发就要和整个开发团队合作，建立并完善这些流程。再比如，以前测试流水线没有建立，自动化测试脚本需要人工触发执行，那么，资深测试开发就需要把这些流程整合。

**因此，判断一个资深测试开发是否合格的标准，是要看他的技术产出是否能融入公司的技术体系中去。**换言之，就是要看**功能测试的工作是否严重依赖他的产出：**如果测试开发停工，那么功能测试就会很痛苦，甚至也被迫停工。

需要注意的是，这一阶段资深测试开发的产出，肯定非常贴切公司的情况，但未必符合其他公司的情况，或者未必跟业界的主流情况一致。

3. 红色——测试架构师或者测试专家

可以看到，这一部分的测试开发重点已经不是测试本身了，而在于**整个软件开发全流程的梳理**。从项目立项开始，测试架构师就要规划当前的测试框架需要何种裁剪才能保证本项目顺利发布，并且在项目最开始阶段，通过**测试左移**的手段，对需求、开发技术方案进行分析，在保证可测试性的前提下，把公司现有的测试手段完美嵌入整个开发生命周期中。

在项目发布后，通过**测试右移**的手段，对生产系统进行监控，对系统本身或业务本身的各种线上情况进行分析，找出薄弱点，反查整个开发测试流程中的短板，然后补齐，从而保证产品的高质量和业务的高可用性。

**判断一个测试架构师或者测试专家是否合格的标准，是看他能否在某个领域全部或者部分重新定义测试活动、测试顺序。**换言之，这一阶段的工作产出，不仅仅适用于本公司，放到其他公司也可以，从方法论上来说，应该是普适的。

围绕以上三个测试角色，我们简要总结下：

- **测试开发**，即**提升**测试活动的效率，通过技术手段帮助功能测试工程师提升测试效率；
- **资深测试开发，即重构**测试活动，技术产出完全融入公司的技术体系；
- **测试专家/测试架构师，即重新定义**测试活动，输出普适的测试方法论。

## 参考

- 《测试开发入门与实战》

[1]: ./img/auto-test-01/1.png
[2]: ./img/auto-test-01/2.png
[3]: ./img/auto-test-01/3.png
[4]: ./img/auto-test-01/4.png
[5]: ./img/auto-test-01/5.png
[6]: ./img/auto-test-01/6.png
[7]: ./img/auto-test-01/7.png
