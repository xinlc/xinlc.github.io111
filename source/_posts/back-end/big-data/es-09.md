---
title: 重学 Elastic Stack 之 ES 实战
date: 2021-02-12 13:00:00
categories: BigData
tags:
  - Elastic Stack
  - ES
---

Spring Boot 整合 Elasticsearch。

<!--more-->

## 集成方式

Spring Boot 中集成 ES 有以下几种方式：

1. [Jest](https://github.com/searchbox-io/Jest)
   - 这是社区封装的 Client，比较老，目前仅支持到 6.x，看 Issues 已经不怎么更新了，不建议使用。
2. [Java Client](https://www.elastic.co/guide/en/elasticsearch/client/java-api/current/index.html)
   - java client 使用 TransportClient，各种操作本质上都是异步的(可以用 listener，或返回 Future ）。
   - ES的发展规划中在7.0版本开始将废弃 TransportClient，8.0版本中将完全移除 TransportClient，取而代之的是High Level REST Client。High Level REST Client 中的操作API和java client 大多是一样的。
3. [REST Client](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/index.html)
   - Java Low Level REST Client: 低级别的REST客户端，通过http与集群交互，用户需自己编组请求JSON串，及解析响应JSON串。兼容所有ES版本。
   - Java High Level REST Client: 高级别的REST客户端，基于低级别的REST客户端，增加了编组请求JSON串、解析响应JSON串等相关api。使用的版本需要保持和ES服务端的版本一致，否则会有版本问题。（官方推荐）
4. [Spring Data Elasticsearch](https://github.com/spring-projects/spring-data-elasticsearch)
   - Spring Data 项目的子项目，提供了 Elasticsearch 与 Spring 的集成。
   - 高版本也是用的 High Level 封装。Repository 风格，上手简单，复杂查询提供原生访问能力。

## Elasticsearch Rest High Level Client

引入Maven 依赖：

```xml
<dependency>
    <groupId>org.elasticsearch.client</groupId>
    <artifactId>elasticsearch-rest-high-level-client</artifactId>
    <version>7.11.1</version>
</dependency>
```

初始化客户端：

```java
RestHighLevelClient client = new RestHighLevelClient(
        RestClient.builder(
                new HttpHost("localhost", 9200, "http"),
                new HttpHost("localhost", 9201, "http")));
```

## Spring Data Elasticsearch

Spring Data Elasticsearch 是 Spring Data 项目的子项目，提供了 Elasticsearch 与 Spring 的集成。实现了 Spring Data Repository 风格的 Elasticsearch 文档交互风格，让你轻松进行 Elasticsearch 客户端开发。


## 分词技巧

索引时最小分词，搜索时最大分词，例如"Java知音"索引时分词包含Java、知音、音、知等，最小粒度分词可以让我们匹配更多的检索需求，但是我们搜索时应该设置最大分词，用“Java”和“知音”去匹配索引库，得到的结果更贴近我们的目的，

对分词字段同时也设置keyword，便于后续排查错误时可以精确匹配搜索，快速定位。


## 常见问题

### 普通对象结构

- ES 会做压扁处理（扁平化），对象会变 k -> v，形式，对象数组会变 xxx.name -> ["a", "b"]
- 对象内部关联关系消失
- 无法做子对象内关联条件过滤
- 高亮无法对应位置，因为文档扁平化后对象边界消失

### 嵌套查询

- ES 内部子对象会有多个隐藏文档
- 能做高亮和关联查询
- 保证不了事务的话很有可能会有数据相互覆盖的问题

### 父子文档

- 只能有一个 join 类型
- 可以设置多个子文档，子文档名称设置为数组就可以了

### 文章-关注案例

场景是 要查一个人关注的文章列表，就是我关注的文章功能，要能全文检索

分开存，es里放全量文章做全文搜索，mysql里放关注列表，搜的时候拿关注列表做前置或者后置过滤

关联你如果想把用户id缓存在es里，保证不了事务的话很有可能会有数据相互覆盖的问题

## 最佳实践

### Elasticsearch更新 Mapping&重建索引

**索引变成的场景：**

– 索引的 Mappings 发生变更：字段类型更改，分词器及字典更新
– 索引的 Settings 发⽣变更：索引的主分⽚数发⽣生改变
– 集群内，集群间需要做数据迁移

**索引变更的方式**

– Update By Query：在现有索引上重建
– Reindex：在其他索引上重建索引

**Update By Query**

使用场景：

– 为字段增加子字段
– 字段更换分词器
– 更新分词器词库

案例：使用 update by query 增加子字段

```json
# 自动补全功能
# 变更 mapping ，增加一个子字段，类型为 completion
PUT blog/_mapping
{
  "properties": {
    "title": {
      "type": "text",
      "analyzer": "ik_max_word",
      "search_analyzer": "ik_smart",
      "fields": {
        "keyword": {
          "type": "keyword",
          "ignore_above": 256
        },
        "completion": {
          "type": "completion"
        }
      }
    }
  }
}
# 执行 update by query 使刚刚的变成生效
POST blog/_update_by_query
{

}
# 自定补全查询
POST blog/_search?pretty
{
  "_source": [
    "title",
    "id"
  ],
  "suggest": {
    "blog-suggest": {
      "prefix": "使用",
      "completion": {
        "field": "title.completion",
        "skip_duplicates": true
      }
    }
  }
}
```

**Reindex**

使用场景：

– 修改字段类型. 需要先设置索引 mapping， 索引的设置和映射关系不会被复制
– 修改索引的主分片数
– 集群内迁移数据、跨集群迁移数据

reindex 一般是一个比较耗时的操作，但是直接调用 reindex api 的接口超时时间比较端，我们可以使用 wait_for_completion，这样不必等待 reindex 执行完成才返回。结合 _tasks 可以查看任务执行的进度。

案例：修改字段类型

```json
# 修改索引：修改索引类型
# 创建被迁移的索引
PUT blog_reindex
{
  "mappings": {
    "properties": {
      "id": {
        "type": "long"
      },
      "createTime": {
        "type": "date"
      },
      "lastTime": {
        "type": "date"
      },
      "content": {
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 10240
          }
        }
      },
      "title": {
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      },
      "status": {
        "type": "keyword"
      },
      "type": {
        "type": "keyword"
      },
      "content_filtered": {
        "type": "text",
        "analyzer": "ik_max_word",
        "search_analyzer": "ik_smart",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 10240
          }
        }
      },
      "comment_count": {
        "type": "integer"
      },
      "new_field": {
        "type": "integer"
      }
    }
  },
  "settings": {
    "index": {
      "number_of_shards": "1",
      "number_of_replicas": "0"
    }
  }
}
# 重建索引
POST _reindex?wait_for_completion=false
{
  "source": {
    "index": "blog"
  },
  "dest": {
    "index": "blog_reindex",
    "op_type": "create"
  }
}
# 查看迁移状态
GET _tasks?detailed=true&actions=*reindex
```

### 索引Mapping 模板操作

```bash
# 获取模板
GET _template/demo_template

# 删除索引模板
DELETE _template/demo_template

# 添加模板
PUT _template/demo_template
{
  // ……
}
```

### reindex 操作

```bash
POST _reindex?wait_for_completion=false
{
  "conflicts": "proceed",
  "source": {
    "index": "demo_index_v1",
    "size": 5000
  },
  "dest": {
    "index": "demo_index_v2",
    "op_type": "create",
    "version_type": "external"
  }
}

# 查看异步任务
GET /_tasks/{id}

# 对比迁移后的文档数是否一致
GET /_cat/indices/demo_index_v1,demo_index_v2?v
```

- `conflicts: proceed`：默认情况下，版本冲突会导致_reindex操作终止，可以设置这个字段使该请求遇到冲突时不会终止，而是统计冲突数量；

- `version_type: extrenal`：_reindex指令会生成源索引的快照，它的目标索引必须是一个不同的索引[新索引]，以便避免版本冲突。如果不设置version_type字段，默认为internal，ES会直接将文档转存储到目标索引中(dest index)，直接覆盖任何具有相同类型和id的document，不会产生版本冲突。如果把version_type设置为extertral，那么ES会从源索引(source index)中读取version字段，当遇到具有相同类型和id的document时，只会保留new version，即最新的version对应的数据。此时可能会有冲突产生，比如当把op_tpye设置为create，对于产生的冲突现象，返回体中的 failures 会携带冲突的数据信息【类似详细的日志可以查看】。

- `op_type：op_type` 参数控制着写入数据的冲突处理方式，如果把 op_type 设置为 create【默认值】，在 _reindex API 中，表示写入时只在 dest index 中添加不存在的 doucment，如果相同的 document 已经存在，则会报 version confilct 的错误，那么索引操作就会失败。【这种方式与使用 _create API 时效果一致】。

> 可以执行远程夸集群 reindex，具体操作可以查看官方文档。注意：远程IP需要加入白名单配置。

### 别名操作

零停机时间实现重新索引方式：

```bash
POST _aliases
{
  "actions": [
    {
      "remove": {
        "index": "demo_index_v1",
        "alias": "demo_latest"
      }
    },
    {
      "add": {
        "index": "demo_index_v2",
        "alias": "demo_latest"
      }
    }
  ]
}
```

### 重命名字段

可以使用 Painless 脚本或者 Ingest pipelines

**Painless**

```json
POST _reindex
{
  "source": {
    "index": "my-index-000001"
  },
  "dest": {
    "index": "my-new-index-000001"
  },
  "script": {
    "source": "ctx._source.tag = ctx._source.remove(\"flag\")"
  }
}
```

ES有些历史数据是用逗号分隔的字符串，需要将历史数据拆分为数组形式。

使用painless脚本更新历史数据。有几点需要注意：

- 只更新符合某些条件的数据，可以使用_update_by_query操作，这个例子比较简单没有设置query语句。
- 执行过程中冲突处理方式，这里使用的是conflicts=proceed，表示继续执行；
- painless检测对象类型使用关键字instanceof;
- painless脚本拆分字符串，想避免使用正则表达式，而是选用了StringTokenizer实现。

```json
POST test_cj/_update_by_query?conflicts=proceed
{
  "script": {
    "source": """
    if(ctx._source['types'] instanceof String){
      String s=ctx._source['types'];
      ArrayList array=new ArrayList();
      if(!s.isEmpty()){
         String splitter = ",";
         StringTokenizer tokenValue = new StringTokenizer(s, splitter);
         while (tokenValue.hasMoreTokens()) {
            array.add(tokenValue.nextToken());
         }
      }
     ctx._source.types=array;
    }
"""
  }
}

// 查看进度
GET _tasks?detailed=true&actions=*byquery
```

重命名字段并把逗号分隔的字符串转换为数组

```json
POST _reindex?wait_for_completion=false
{
  "conflicts": "proceed",
  "source": {
    "index": "demo_index_v1",
    "size": 10
  },
  "dest": {
    "index": "demo_index_v2",
    "version_type": "external"
  },
  "script": {
    "lang":   "painless",
    "source": """
      if(ctx._source['type'] instanceof String){
        String s = ctx._source['type'];
        ArrayList array = new ArrayList();
        if(!s.isEmpty()){
            String splitter = ',';
            StringTokenizer tokenValue = new StringTokenizer(s, splitter);
            while (tokenValue.hasMoreTokens()) {
              array.add(tokenValue.nextToken());
            }
        }
        ctx._source.typeList=array;
      }
      ctx._source.remove('type');
    """
  }
}
```

**Ingest pipelines**

```json
PUT _ingest/pipeline/my_rename_pipeline
{
  "description" : "describe pipeline",
  "processors" : [
    {
      "rename": {
        "field": "fieldCamelcase",
        "target_field": "fieldCamelCase"
      }
    }
  ]
}

POST _reindex
{
  "source": {
    "index": "source"
  },
  "dest": {
    "index": "dest",
    "pipeline": "my_rename_pipeline"
  }
}
```

### 增加一个新的字段

```json
POST twitter/_update_by_query
{
  "script": {
    "source": "ctx._source['contact'] = \"139111111111\""
  }
}
```

### 修改已有的字段

假如我们想对所有在北京的文档里的 uid 都加1，那么我么有通过如下的方法：

```json
POST twitter/_update_by_query?wait_for_completion=false
{
  "query": {
    "match": {
      "city.keyword": "北京"
    }
  },
  "script": {
    "source": """
       if(ctx._source.containsKey("content")) {
          ctx._source.content_length = ctx._source.content.length();
       } else {
          ctx._source.content_length = 0;
       }
       ctx._source['uid'] += params['one']";
    """
    "params": {
      "one": 1
    }
  }
}
```

### 没有动态mapping时，reindex索引

假设您创建了一个没有动态 mapping 的索引，将其填充了数据，然后添加了一个 mapping 值以从数据中获取更多字段：

```json

PUT test
{
  "mappings": {
    "dynamic": false,   
    "properties": {
      "text": {"type": "text"}
    }
  }
}
 
POST test/_doc?refresh
{
  "text": "words words",
  "flag": "bar"
}
 
POST test/_doc?refresh
{
  "text": "words words",
  "flag": "foo"
}
 
PUT test/_mapping   
{
  "properties": {
    "text": {"type": "text"},
    "flag": {"type": "text", "analyzer": "keyword"}
  }
}
```

在上面我们创建一个叫做 test 的索引。首先它的动态 mapping 被禁止了，也就是在索引时凡是不在 mapping 定义的字段将被自动识别，它们仅仅存在于 source 里，我们不能对它进行搜索。为了纠正这个错误，我们在上面的最后一步尝试来修改它的 mapping 来解决这个问题。那么在新的 mapping 下，我们之前导入的文档能进行搜索吗？我们尝试如下的命令：

```json
POST test/_search?filter_path=hits.total
{
  "query": {
    "match": {
      "flag": "foo"
    }
  }
}
```

我们尝试搜索所有 flag 中含有 foo 的文档，但是上面的返回结果是：

```json
{
  "hits" : {
    "total" : {
      "value" : 0,
      "relation" : "eq"
    }
  }
}
```

那么问题出现在哪里呢？其实在我们修改完 mapping 以后，我们没有更新我们之前已经导入的文档。我们需要使用 _update_by_query 来做类似 reindex 的工作。我们使用如下的命令：

```json
POST test/_update_by_query?refresh&conflicts=proceed
```

我们重新来搜索我们的文档：

```json
POST test/_search?filter_path=hits.total
{
  "query": {
    "match": {
      "flag": "foo"
    }
  }
}
```

显然，在运行完 _update_by_query 后，我们可以找到我们的文档了。

### 针对大量数据的 reindex

上面所有的 _update_by_query 针对少量的数据还是很不错的。但是在我们的实际应用中，我们可能遇到很大的数据量，那么万一在 reindex 的过程中发生意外，那我们还需要从头开始吗？或者我们已经处理过的数据还需要再做一遍吗？一种通用的解决办法就是在我们的 mapping 中定义一个字段，比如叫做 flag，那么我们可以通过添加这个字段来跟踪我们的进度：

```json
POST blogs_fixed/_update_by_query
{
  "query": {
    "range": {
      "flag": {
        "lt": 1
      }
    }
  },
  "script": {
    "source": "ctx._source['flag']=1"
  }
}
```

即使在 reindex 的过程已经失败了，我们再次运行上面的 _update_by_query 时，之前已经处理过的文件将不再被处理了。

### 根据查询条件删除数据

```json
POST demo_latest/_delete_by_query
{
  "query": {
    "bool": {
      "must_not": [
        {
          "exists": {
            "field": "typeList"
          }
        }
      ]
    }
  }
}
```

## 参考

- http://elasticsearch-cheatsheet.jolicode.com
- https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html
- https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html
- https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update-by-query.html

